{% extends "layouts/base.html" %}
{% load static %}
{% block title %} Crawl Website {% endblock %}

<!-- Specific Page CSS goes HERE  -->
{% block extrastyle %}
<style>
    /* Specific styles for this page - progress bar styling is now in custom-fixes.css */
    .list-group-item {
        padding: 0.5rem 1rem;
    }
    #visitors-chart-container {
        height: 300px;
        position: relative;
    }
    .timeline-block {
        margin-bottom: 1rem;
    }
    .timeline-step {
        width: 30px;
        height: 30px;
        border-radius: 50%;
        display: flex;
        align-items: center;
        justify-content: center;
        margin-right: 0.75rem;
    }
    .timeline-content {
        flex: 1;
    }

    /* Styling for processing overlay */
    .processing-overlay {
        position: absolute;
        top: 0;
        left: 0;
        width: 100%;
        height: 100%;
        background-color: rgba(255, 255, 255, 0.8);
        display: flex;
        align-items: center;
        justify-content: center;
        z-index: 10;
    }

    .processing-spinner i {
        font-size: 2rem;
    }
</style>
{% endblock extrastyle %}

{% block content %}

    <div class="container-fluid py-4"
         id="crawl-container"
         hx-ext="ws"
         {# ws-connect="/ws/crawl/{{ task_id }}/" -- Remove initial connection attribute #}
         >

        <div class="row mb-4">
            <div class="col-12">
                <div class="card">
                    <div class="card-header pb-0 p-3 d-flex justify-content-between align-items-center">
                        <h6 class="mb-0">Active Crawls</h6>
                        <button id="refresh-active-crawls" class="btn btn-sm btn-info">
                            <i class="fas fa-sync-alt"></i> Refresh
                        </button>
                    </div>
                    <div class="card-body p-3">
                        <div id="active-crawls-container">
                            <p class="text-muted">Loading active crawls...</p>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <div class="row">
            <div class="col-12 col-xl-4">
                <div class="card h-100">
                    <div class="card-header pb-0 p-3">
                        <h6 class="mb-0">Site to crawl</h6>
                    </div>
                    <div class="card-body p-3">
                        <form id="crawl-form"
                              hx-post="{% url 'crawl_website:initiate_crawl' %}"
                              hx-target="#crawl-status-message"
                              hx-swap="innerHTML"
                              hx-indicator="#processing-indicator">
                            {% csrf_token %}

                            <div class="mb-3">
                                <label for="url" class="form-label">URL to crawl
                                    <i class="fas fa-info-circle text-info ms-1" data-bs-toggle="tooltip" data-bs-placement="top"
                                       title="Specify the base URL where the crawl will begin. Ensure the URL is valid, includes the protocol (http:// or https://), and points to the desired starting page."></i>
                                </label>
                                <input type="url" class="form-control" id="url" name="url" placeholder="https://example.com" required>
                            </div>

                            <!-- Crawl Type Selection -->
                            <div class="mb-3">
                                <label class="form-label">Crawl Method
                                    <i class="fas fa-info-circle text-info ms-1" data-bs-toggle="tooltip" data-bs-placement="top"
                                       title="Choose between standard link-following crawl or sitemap-based crawl."></i>
                                </label>
                                <div class="form-check">
                                    <input class="form-check-input" type="radio" name="crawl_type" id="crawl_type_standard" value="standard" checked>
                                    <label class="form-check-label" for="crawl_type_standard">
                                        Standard Crawl (Follows links)
                                        <i class="fas fa-info-circle text-info ms-1" data-bs-toggle="tooltip" data-bs-placement="top"
                                           title="The crawler will parse the HTML of each page to extract and follow links (anchor tags). This method is suitable for websites without a sitemap or for broader exploration."></i>
                                    </label>
                                </div>
                                <div class="form-check">
                                    <input class="form-check-input" type="radio" name="crawl_type" id="crawl_type_sitemap" value="sitemap">
                                    <label class="form-check-label" for="crawl_type_sitemap">
                                        Sitemap-Based Crawl
                                        <i class="fas fa-info-circle text-info ms-1" data-bs-toggle="tooltip" data-bs-placement="top"
                                           title="The crawler will fetch and parse the website's sitemap.xml file (if available) to identify pages for crawling. This method is faster and more structured but relies on the sitemap's accuracy and completeness."></i>
                                    </label>
                                </div>
                            </div>

                            <!-- Standard Crawl Options -->
                            <div id="standard-crawl-options">
                            <div class="mb-3">
                                <label for="max-pages" class="form-label">Maximum Pages
                                    <i class="fas fa-info-circle text-info ms-1" data-bs-toggle="tooltip" data-bs-placement="top"
                                       title="Set an upper limit on the number of pages to crawl. This prevents excessive crawling and resource usage. For example, a value of '7' will stop the crawl after processing 7 pages, regardless of the total number of pages available."></i>
                                </label>
                                    <input type="number" class="form-control" id="max-pages" name="max_pages" value="100" min="1">
                            </div>
                            <div class="mb-3">
                                <label for="max-depth" class="form-label">Maximum Depth
                                    <i class="fas fa-info-circle text-info ms-1" data-bs-toggle="tooltip" data-bs-placement="top"
                                       title="Define the depth of the crawl: Level 1: Crawl only the starting page. Level 2: Crawl the starting page and all links found on it. Higher levels recursively follow links on each page, exponentially increasing the number of pages crawled."></i>
                                </label>
                                    <input type="number" class="form-control" id="max-depth" name="max_depth" value="3" min="0">
                                </div>
                                <div class="mb-3">
                                    <label for="include-patterns" class="form-label">Include Patterns (Optional)
                                        <i class="fas fa-info-circle text-info ms-1" data-bs-toggle="tooltip" data-bs-placement="top"
                                           title="Use glob patterns to specify which URLs to include in the crawl. For example: 'blog/*' matches all URLs under the 'blog' path. 'docs/*' matches all URLs under the 'docs' path. Patterns are case-sensitive and should align with the website's URL structure."></i>
                                    </label>
                                    <input type="text" class="form-control" id="include-patterns" name="include_patterns" placeholder="e.g., blog/*, docs/*">
                                    <small class="form-text text-muted">Comma-separated glob patterns</small>
                                </div>
                                <div class="mb-3">
                                    <label for="exclude-patterns" class="form-label">Exclude Patterns (Optional)
                                        <i class="fas fa-info-circle text-info ms-1" data-bs-toggle="tooltip" data-bs-placement="top"
                                           title="Use glob patterns to exclude specific URLs from the crawl. For example: 'admin/*' excludes all URLs under the 'admin' path. 'login/*' excludes all URLs under the 'login' path. Patterns are case-sensitive and should be used to avoid unnecessary or restricted pages."></i>
                                    </label>
                                    <input type="text" class="form-control" id="exclude-patterns" name="exclude_patterns" placeholder="e.g., admin/*, login/*">
                                    <small class="form-text text-muted">Comma-separated glob patterns</small>
                                </div>
                            </div>

                            <!-- Sitemap Crawl Options -->
                            <div id="sitemap-crawl-options" style="display: none;">
                                <div class="mb-3">
                                    <label for="max-sitemap-urls" class="form-label">Max Sitemap URLs to Process</label>
                                    <input type="number" class="form-control" id="max-sitemap-urls" name="max_sitemap_urls" value="50" min="1">
                                </div>
                                <div class="mb-3">
                                    <label for="max-sitemap-retriever-pages" class="form-label">Max Sitemap Discovery Pages</label>
                                    <input type="number" class="form-control" id="max-sitemap-retriever-pages" name="max_sitemap_retriever_pages" value="1000" min="1">
                                </div>
                                <div class="mb-3">
                                    <label for="sitemap-requests-per-second" class="form-label">Requests per Second</label>
                                    <input type="number" class="form-control" id="sitemap-requests-per-second" name="sitemap_requests_per_second" value="5.0" step="0.1" min="0.1">
                                </div>
                                <div class="mb-3">
                                    <label for="sitemap-timeout" class="form-label">Timeout (ms)</label>
                                    <input type="number" class="form-control" id="sitemap-timeout" name="sitemap_timeout" value="15000" min="1000">
                                </div>
                            </div>

                            <!-- Common Options -->
                            <div class="mb-3">
                                <label for="output-format" class="form-label">Output Format
                                    <i class="fas fa-info-circle text-info ms-1" data-bs-toggle="tooltip" data-bs-placement="top"
                                       title="Select the type of content you want to extract from each page."></i>
                                </label>
                                <select class="form-control" id="output-format" name="output_format">
                                    <option value="text" selected>Text</option>
                                    <option value="html">HTML</option>
                                    <option value="metadata">Metadata</option>
                                </select>
                            </div>


                            <div class="mb-3">
                                <label for="css-selector" class="form-label">CSS Selector (Optional)
                                    <i class="fas fa-info-circle text-info ms-1" data-bs-toggle="tooltip" data-bs-placement="top"
                                       title="Specify a CSS selector to target specific elements on the page for scraping. For example: '.article-content' selects all elements with the class 'article-content'. '#main-content' selects the element with the ID 'main-content'. Leave blank to scrape the entire page. Use standard CSS selector syntax."></i>
                                </label>
                                <input type="text" class="form-control" id="css-selector" name="css-selector" placeholder="e.g., article.content">
                            </div>
                            <div class="mb-3">
                                <label for="wait-for" class="form-label">Wait For Element (Optional)
                                    <i class="fas fa-info-circle text-info ms-1" data-bs-toggle="tooltip" data-bs-placement="top"
                                       title="Specify a CSS selector for an element the crawler should wait for before starting to scrape. This is useful for handling dynamic content that loads asynchronously (e.g., JavaScript-rendered pages). For example: '#main-content' waits for the element with ID 'main-content' to load before proceeding."></i>
                                </label>
                                <input type="text" class="form-control" id="wait-for" name="wait-for" placeholder="e.g., #main-content">
                            </div>

                            <div class="mb-3 form-check">
                                <input type="checkbox" class="form-check-input" id="save-file" name="save-file" checked>
                                <label class="form-check-label" for="save-file">Save result to file
                                    <i class="fas fa-info-circle text-info ms-1" data-bs-toggle="tooltip" data-bs-placement="top"
                                       title="Save the crawl results to a file for later reference or processing."></i>
                                </label>
                            </div>
                            <div class="mb-3 form-check">
                                <input type="checkbox" class="form-check-input" id="save-as-csv" name="save-as-csv" checked>
                                <label class="form-check-label" for="save-as-csv">Save as CSV
                                    <i class="fas fa-info-circle text-info ms-1" data-bs-toggle="tooltip" data-bs-placement="top"
                                       title="Exports the scraped data to a CSV file, which can be easily imported into tools like Excel, Google Sheets, or data analysis software."></i>
                                </label>
                            </div>

                            <button type="submit" class="btn btn-primary">
                                <span class="indicator-label">Initiate Crawl</span>
                                <span class="indicator-progress" id="processing-indicator" style="display: none;">
                                    Please wait...
                                    <span class="spinner-border spinner-border-sm align-middle ms-2"></span>
                                </span>
                            </button>
                        </form>

                        <div id="screenshot-container" class="mt-3">
                            <!-- Screenshot will be displayed here -->
                        </div>
                    </div>
                </div>
            </div>
            <div class="col-12 col-xl-4">
                <div class="card h-100">
                    <div class="card-header pb-0 p-3">
                        <h6 class="mb-0">Crawl Progress</h6>
                    </div>
                    <div class="card-body p-3 position-relative">

                        <div id="crawl-status-progress">
                            {% include "crawl_website/partials/_crawl_status_progress.html" %}
                        </div>

                        <div class="text-center mt-3 mb-3" id="cancel-crawl-container" style="display: none;">
                            <button id="cancel-crawl-btn" class="btn btn-danger btn-sm">
                                <i class="fas fa-stop-circle me-1"></i> Stop Crawl
                            </button>
                        </div>

                        <div id="visitors-chart-container">
                            <canvas id="visitors-chart"></canvas>
                        </div>
                    </div>
                </div>
            </div>
            <div class="col-12 col-xl-4">
                <div class="card h-100">
                    <div class="card-header pb-0">
                        <h6 class="mb-0">Results</h6>
                    </div>
                    <div class="card-body p-3">

                        <div id="crawl-results">
                            <p>Results will appear here once the crawl is complete.</p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>

{% endblock content %}

<!-- Specific Page JS goes HERE  -->
{% block extra_js %}
<script src="{% static 'assets/js/plugins/sweetalert.min.js' %}"></script>
<script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
<script src="{% static 'assets/js/plugins/ws.js' %}"></script>

{# Include SweetAlert2 #}
<script src="https://cdn.jsdelivr.net/npm/sweetalert2@11"></script>

{# No custom WebSocket handler needed - using HTMX's built-in WebSocket support #}

<script>
document.addEventListener('DOMContentLoaded', (event) => {
    console.log("DOM fully loaded and parsed");

    // Define elements once at the top
    const crawlContainer = document.getElementById('crawl-container');
    const crawlForm = document.getElementById('crawl-form');
    const activeCrawlsContainer = document.getElementById('active-crawls-container');
    const refreshActiveCrawlsBtn = document.getElementById('refresh-active-crawls');
    const cancelCrawlContainer = document.getElementById('cancel-crawl-container');
    const cancelCrawlBtn = document.getElementById('cancel-crawl-btn');

    // Current task ID for cancel functionality
    let currentTaskId = null;

    // --- Toggle options based on crawl type --- //
    const standardOptions = document.getElementById('standard-crawl-options');
    const sitemapOptions = document.getElementById('sitemap-crawl-options');
    const crawlTypeRadios = document.querySelectorAll('input[name="crawl_type"]');

    function toggleCrawlOptions() {
        const selectedType = document.querySelector('input[name="crawl_type"]:checked').value;
        if (selectedType === 'sitemap') {
            standardOptions.style.display = 'none';
            sitemapOptions.style.display = 'block';
        } else {
            standardOptions.style.display = 'block';
            sitemapOptions.style.display = 'none';
        }
    }
    if (crawlTypeRadios.length > 0 && standardOptions && sitemapOptions) {
        crawlTypeRadios.forEach(radio => {
            radio.addEventListener('change', toggleCrawlOptions);
        });
        toggleCrawlOptions(); // Initial call
    } else {
         console.warn("Could not find all elements needed for crawl type toggle functionality.");
    }


    // Simple chart for visualizing crawl progress
    let visitorsChart = null;
    let chartData = {
        labels: [],
        values: [],
        startTime: null,
        pagesProcessed: 0
    };

    function initChart() {
        const ctx = document.getElementById('visitors-chart');
        if (!ctx) return;

        visitorsChart = new Chart(ctx, {
            type: 'line',
            data: {
                labels: [],
                datasets: [{
                    label: 'Pages Crawled',
                    data: [],
                    borderColor: 'rgb(75, 192, 192)',
                    tension: 0.1,
                    fill: false
                }]
            },
            options: {
                responsive: true,
                maintainAspectRatio: false,
                scales: {
                    y: {
                        beginAtZero: true,
                        title: {
                            display: true,
                            text: 'Pages Crawled'
                        }
                    },
                    x: {
                        title: {
                            display: true,
                            text: 'Time (seconds)'
                        }
                    }
                }
            }
        });
    }

    // Initialize chart
    initChart();

    // --- Function to fetch active crawls ---
    function fetchActiveCrawls() {
        if (activeCrawlsContainer) {
            activeCrawlsContainer.innerHTML = '<p class="text-muted">Loading active crawls...</p>';

            fetch('{% url "crawl_website:list_active_crawls" %}')
                .then(response => response.json())
                .then(data => {
                    if (data.error) {
                        activeCrawlsContainer.innerHTML = `<div class="alert alert-danger">${data.error}</div>`;
                        return;
                    }

                    if (!data.tasks || data.tasks.length === 0) {
                        activeCrawlsContainer.innerHTML = '<p class="text-muted">No active crawls found.</p>';
                        return;
                    }

                    // Create a table to display active crawls
                    let html = `
                        <div class="table-responsive">
                            <table class="table align-items-center mb-0">
                                <thead>
                                    <tr>
                                        <th class="text-uppercase text-secondary text-xxs font-weight-bolder opacity-7">URL</th>
                                        <th class="text-uppercase text-secondary text-xxs font-weight-bolder opacity-7 ps-2">Status</th>
                                        <th class="text-uppercase text-secondary text-xxs font-weight-bolder opacity-7 ps-2">Actions</th>
                                    </tr>
                                </thead>
                                <tbody>
                    `;

                    data.tasks.forEach(task => {
                        const url = task.kwargs.website_url || task.kwargs.url || 'Unknown URL';
                        html += `
                            <tr>
                                <td>
                                    <div class="d-flex px-2 py-1">
                                        <div class="d-flex flex-column justify-content-center">
                                            <h6 class="mb-0 text-sm">${url}</h6>
                                            <p class="text-xs text-secondary mb-0">Task ID: ${task.id}</p>
                                        </div>
                                    </div>
                                </td>
                                <td>
                                    <span class="badge bg-${task.status === 'RUNNING' ? 'info' : 'warning'}">${task.status}</span>
                                </td>
                                <td>
                                    <div class="d-flex gap-2">
                                        <button class="btn btn-sm btn-info connect-task-btn" data-task-id="${task.id}">
                                            <i class="fas fa-plug"></i> Connect
                                        </button>
                                        <button class="btn btn-sm btn-danger cancel-task-btn" data-task-id="${task.id}">
                                            <i class="fas fa-stop-circle"></i> Cancel
                                        </button>
                                    </div>
                                </td>
                            </tr>
                        `;
                    });

                    html += `
                                </tbody>
                            </table>
                        </div>
                    `;

                    activeCrawlsContainer.innerHTML = html;

                    // Add event listeners to cancel buttons
                    document.querySelectorAll('.cancel-task-btn').forEach(btn => {
                        btn.addEventListener('click', function() {
                            const taskId = this.getAttribute('data-task-id');
                            cancelCrawl(taskId);
                        });
                    });

                    // Add event listeners to connect buttons
                    document.querySelectorAll('.connect-task-btn').forEach(btn => {
                        btn.addEventListener('click', function() {
                            const taskId = this.getAttribute('data-task-id');
                            connectToCrawl(taskId);
                        });
                    });
                })
                .catch(error => {
                    console.error('Error fetching active crawls:', error);
                    activeCrawlsContainer.innerHTML = `<div class="alert alert-danger">Error fetching active crawls: ${error.message}</div>`;
                });
        }
    }

    // --- Function to connect to an existing crawl ---
    function connectToCrawl(taskId) {
        if (!taskId) return;

        // Store current task ID
        currentTaskId = taskId;

        // Reset chart data
        chartData.labels = [];
        chartData.values = [];
        chartData.startTime = Date.now();
        chartData.pagesProcessed = 0;

        if (visitorsChart) {
            visitorsChart.data.labels = [];
            visitorsChart.data.datasets[0].data = [];
            visitorsChart.update();
        }

        // Show cancel button
        if (cancelCrawlContainer) {
            cancelCrawlContainer.style.display = 'block';
        }

        // Set up WebSocket connection
        const wsScheme = window.location.protocol === "https:" ? "wss" : "ws";
        const wsPath = `${wsScheme}://${window.location.host}/ws/crawl/${taskId}/`;
        console.log(`Connecting to existing crawl: ${wsPath}`);

        // Set the WebSocket connection attribute
        crawlContainer.setAttribute('ws-connect', wsPath);

        // Process the container to connect WebSocket
        htmx.process(crawlContainer);

        // Show notification
        const Toast = Swal.mixin({
            toast: true,
            position: 'top-end',
            showConfirmButton: false,
            timer: 3000,
            timerProgressBar: true
        });
        Toast.fire({
            icon: 'info',
            title: 'Connected to crawl'
        });
    }

    // --- Function to cancel a crawl ---
    function cancelCrawl(taskId) {
        if (!taskId) return;

        // Confirm cancellation
        Swal.fire({
            title: 'Cancel Crawl?',
            text: 'Are you sure you want to cancel this crawl?',
            icon: 'warning',
            showCancelButton: true,
            confirmButtonText: 'Yes, cancel it!',
            cancelButtonText: 'No, keep it running'
        }).then((result) => {
            if (result.isConfirmed) {
                // Send request to cancel the crawl
                fetch(`{% url "crawl_website:cancel_crawl" task_id="TASK_ID" %}`.replace('TASK_ID', taskId), {
                    method: 'POST',
                    headers: {
                        'X-CSRFToken': document.querySelector('[name=csrfmiddlewaretoken]').value
                    }
                })
                .then(response => {
                    if (!response.ok) {
                        throw new Error(`HTTP error! Status: ${response.status}`);
                    }
                    return response.text();
                })
                .then(html => {
                    // Show success message
                    Swal.fire('Cancelled!', 'The crawl has been cancelled.', 'success');

                    // Refresh active crawls list
                    fetchActiveCrawls();
                })
                .catch(error => {
                    console.error('Error cancelling crawl:', error);
                    Swal.fire('Error', `Failed to cancel crawl: ${error.message}`, 'error');
                });
            }
        });
    }

    // --- Event listener for refresh button ---
    if (refreshActiveCrawlsBtn) {
        refreshActiveCrawlsBtn.addEventListener('click', fetchActiveCrawls);
    }

    // --- Event listener for cancel button ---
    if (cancelCrawlBtn) {
        cancelCrawlBtn.addEventListener('click', function() {
            if (currentTaskId) {
                cancelCrawl(currentTaskId);
            }
        });
    }

    // Fetch active crawls on page load
    fetchActiveCrawls();

    // --- Listener for Form Submission (to get Task ID and init WS) ---
    if (crawlForm && crawlContainer) {
        crawlForm.addEventListener('htmx:afterRequest', function(event) {
            console.log('htmx:afterRequest event on crawl-form:', event.detail);
            if (event.detail.successful) {
                const taskId = event.detail.xhr.getResponseHeader('X-Task-ID');
                if (taskId) {
                    console.log("Received Task ID:", taskId);

                    // Store current task ID for cancel functionality
                    currentTaskId = taskId;

                    // Show cancel button
                    if (cancelCrawlContainer) {
                        cancelCrawlContainer.style.display = 'block';
                    }

                    // Reset chart data for new crawl
                    chartData.labels = [];
                    chartData.values = [];
                    chartData.startTime = Date.now();
                    chartData.pagesProcessed = 0;

                    if (visitorsChart) {
                        visitorsChart.data.labels = [];
                        visitorsChart.data.datasets[0].data = [];
                        visitorsChart.update();
                    }

                    // Refresh active crawls list
                    setTimeout(fetchActiveCrawls, 1000);

                    // Set up HTMX WebSocket connection
                    const wsScheme = window.location.protocol === "https:" ? "wss" : "ws";
                    const wsPath = `${wsScheme}://${window.location.host}/ws/crawl/${taskId}/`;
                    console.log(`Setting ws-connect attribute on #crawl-container to: ${wsPath}`);
                    crawlContainer.setAttribute('ws-connect', wsPath);

                    // IMPORTANT: Process the container to make HTMX connect the WebSocket
                    htmx.process(crawlContainer);

                    // Show a small notification that the crawl has started
                    const Toast = Swal.mixin({
                        toast: true,
                        position: 'top-end',
                        showConfirmButton: false,
                        timer: 3000,
                        timerProgressBar: true
                    });
                    Toast.fire({
                        icon: 'info',
                        title: 'Crawl started'
                    });
                } else {
                    console.error("X-Task-ID header not found in response.");
                    Swal.fire('Error', 'Could not get Task ID from server to initiate monitoring.', 'error');
                }
            } else {
                console.error("HTMX request failed:", event.detail);
                Swal.fire('Error', `Failed to start crawl: ${event.detail.xhr.statusText || 'Server Error'}`, 'error');
            }
        });
    } else {
        if (!crawlForm) console.error("Could not find crawl form (#crawl-form) to attach listener.");
        if (!crawlContainer) console.error("Could not find crawl container (#crawl-container) for WS processing.");
    }


    // --- Listener for HTMX WebSocket Messages (Attached to the container) ---
    if (crawlContainer) {
        console.log("Adding WebSocket message listener to crawl container");

        // Handle WebSocket messages
        crawlContainer.addEventListener('htmx:wsAfterMessage', function (evt) {
            console.log("htmx:wsAfterMessage received");
            try {
                const data = JSON.parse(evt.detail.message);

                // Handle heartbeat messages to keep connection alive
                if (data && data.type === 'heartbeat') {
                    console.log(`Received heartbeat #${data.count}`);
                    // Heartbeats don't need UI updates, just prevent HTMX from processing them
                    evt.stopImmediatePropagation();
                    return;
                }

                // Check if it's our specific event structure
                if (data && data.type === 'event') {
                    console.log(`Handling event: ${data.event_name}`);

                    // --- Stop HTMX from processing this JSON message ---
                    evt.stopImmediatePropagation();

                    let iconType = 'info';
                    let title = 'Task Update';

                    if (data.event_name === 'crawl_complete') {
                        iconType = 'success';
                        title = 'Crawl Complete!';
                        // Hide cancel button
                        if (cancelCrawlContainer) {
                            cancelCrawlContainer.style.display = 'none';
                        }
                        // Reset current task ID
                        currentTaskId = null;
                        // Refresh active crawls list
                        setTimeout(fetchActiveCrawls, 1000);
                    } else if (data.event_name === 'crawl_error') {
                        iconType = 'error';
                        title = 'Crawl Failed!';
                        // Hide cancel button
                        if (cancelCrawlContainer) {
                            cancelCrawlContainer.style.display = 'none';
                        }
                        // Reset current task ID
                        currentTaskId = null;
                        // Refresh active crawls list
                        setTimeout(fetchActiveCrawls, 1000);
                    } else if (data.event_name === 'crawl_cancelled') {
                        iconType = 'warning';
                        title = 'Crawl Cancelled';
                        // Hide cancel button
                        if (cancelCrawlContainer) {
                            cancelCrawlContainer.style.display = 'none';
                        }
                        // Reset current task ID
                        currentTaskId = null;
                        // Refresh active crawls list
                        setTimeout(fetchActiveCrawls, 1000);
                    }

                    Swal.fire({
                        title: title,
                        text: data.message,
                        icon: iconType,
                        confirmButtonText: 'Ok'
                    });
                }
            } catch (e) {
                // Parsing failed, likely an HTML fragment meant for HTMX OOB swap
                // Update chart if we have a progress update
                if (evt.detail.message.includes('crawl-progress-bar') &&
                    evt.detail.message.includes('Current URL:')) {

                    // Extract progress information
                    const progressMatch = evt.detail.message.match(/progress-bar.*?(\d+)%/);
                    const urlMatch = evt.detail.message.match(/Current URL: <code>(.*?)<\/code>/);
                    const visitedMatch = evt.detail.message.match(/Pages Visited: <span.*?>(\d+)<\/span>/);

                    if (visitedMatch && visitedMatch[1]) {
                        const pagesVisited = parseInt(visitedMatch[1]);

                        // Only update if we have a new page count
                        if (pagesVisited > chartData.pagesProcessed) {
                            chartData.pagesProcessed = pagesVisited;

                            // Update chart
                            if (visitorsChart) {
                                const elapsedSeconds = Math.floor((Date.now() - chartData.startTime) / 1000);
                                visitorsChart.data.labels.push(elapsedSeconds);
                                visitorsChart.data.datasets[0].data.push(pagesVisited);
                                visitorsChart.update();
                            }
                        }
                    }
                }
                // Let HTMX handle the HTML fragment
            }
        });

         // HTMX WebSocket connection event listeners
         crawlContainer.addEventListener('htmx:wsConnecting', function(evt) {
             console.log('HTMX WebSocket connecting...', evt.detail.elt.getAttribute('ws-connect'));
         });

         crawlContainer.addEventListener('htmx:wsOpen', function(evt) {
             console.log('HTMX WebSocket opened.');
             // Show a small notification that connection is established
             const Toast = Swal.mixin({
                 toast: true,
                 position: 'top-end',
                 showConfirmButton: false,
                 timer: 3000,
                 timerProgressBar: true
             });
             Toast.fire({
                 icon: 'success',
                 title: 'Connected to server'
             });
         });

         crawlContainer.addEventListener('htmx:wsClose', function(evt) {
             console.log('HTMX WebSocket closed. Code:', evt.detail.code);

             // Only show a warning if this wasn't a normal closure
             if (evt.detail.code !== 1000 && evt.detail.code !== 1001) {
                 // Attempt to reconnect automatically
                 setTimeout(function() {
                     console.log('Attempting to reconnect WebSocket...');
                     htmx.process(crawlContainer);
                 }, 5000); // Wait 5 seconds before reconnecting

                 Swal.fire({
                     title: 'Connection Lost',
                     text: 'The connection to the server was lost. The crawl may still be running in the background. Attempting to reconnect...',
                     icon: 'warning',
                     confirmButtonText: 'Ok'
                 });
             }
         });

         crawlContainer.addEventListener('htmx:wsError', function(evt) {
             console.error('HTMX WebSocket error!', evt);
             Swal.fire({
                 title: 'WebSocket Error',
                 text: 'Could not connect to the server for real-time updates. Please check the server status and your connection.',
                 icon: 'error'
             });
         });

    } else {
        console.error("Could not find crawl container (#crawl-container) element for WebSocket binding.");
    }

}); // End of DOMContentLoaded

    // Initialize tooltips
    var tooltipTriggerList = [].slice.call(document.querySelectorAll('[data-bs-toggle="tooltip"]'))
    var tooltipList = tooltipTriggerList.map(function (tooltipTriggerEl) {
        return new bootstrap.Tooltip(tooltipTriggerEl)
    })
</script>
{% endblock extra_js %}