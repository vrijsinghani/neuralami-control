This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repomix on: 2024-12-12T19:06:17.220Z

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Repository structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.

Additional Info:
----------------

For more information about Repomix, visit: https://github.com/yamadashy/repomix

================================================================
Repository Structure
================================================================
chat/
  history.py
clients/
  manager.py
tasks/
  callbacks/
    execution.py
    tool.py
  core/
    agents.py
    tasks.py
  handlers/
    __init__.py
    input.py
    websocket.py
  __init__.py
  tools.py
templatetags/
  __init__.py
  agent_filters.py
  agent_tags.py
websockets/
  handlers/
    agent_handler.py
    callback_handler.py
    message_handler.py
  services/
    chat_service.py
  __init__.py
  base.py
  chat_consumer.py
  consumers.py
consumers.py
models.py
routing.py

================================================================
Repository Files
================================================================

================
File: chat/history.py
================
from langchain_core.chat_history import BaseChatMessageHistory
from langchain_core.messages import BaseMessage, messages_from_dict, messages_to_dict
from django.core.cache import cache
from typing import List
import logging

logger = logging.getLogger(__name__)

class DjangoCacheMessageHistory(BaseChatMessageHistory):
    """Message history that uses Django's cache backend"""
    
    def __init__(self, session_id: str, ttl: int = 3600):
        self.session_id = session_id
        self.ttl = ttl
        self.key = f"chat_history_{session_id}"

    @property
    def messages(self) -> List[BaseMessage]:
        """Retrieve the messages from cache"""
        messages_dict = cache.get(self.key, [])
        return messages_from_dict(messages_dict) if messages_dict else []

    @messages.setter 
    def messages(self, messages: List[BaseMessage]) -> None:
        """Set the messages in cache"""
        cache.set(self.key, messages_to_dict(messages), timeout=self.ttl)

    def add_message(self, message: BaseMessage) -> None:
        """Append the message to the history in cache"""
        messages = self.messages
        messages.append(message)
        cache.set(self.key, messages_to_dict(messages), timeout=self.ttl)

    def clear(self) -> None:
        """Clear message history from cache"""
        cache.delete(self.key)

================
File: clients/manager.py
================
import logging
from django.utils import timezone
from apps.seo_manager.models import Client
from channels.db import database_sync_to_async

logger = logging.getLogger(__name__)

class ClientDataManager:
    def __init__(self):
        pass

    @database_sync_to_async
    def get_client_data(self, client_id):
        """Get and format client data"""
        if not client_id:
            return {
                'client_id': None,
                'current_date': timezone.now().date().isoformat(),
            }
            
        try:
            client = Client.objects.get(id=client_id)
            current_date = timezone.now().date()
            
            return {
                'client_id': client.id,
                'current_date': current_date.isoformat(),
            }
        except Client.DoesNotExist:
            logger.info(f"No client found with ID {client_id}, returning default data")
            return {
                'client_id': None,
                'current_date': timezone.now().date().isoformat(),
            }
        except Exception as e:
            logger.error(f"Error getting client data: {str(e)}", exc_info=True)
            return {
                'client_id': None,
                'current_date': timezone.now().date().isoformat(),
            }

================
File: tasks/callbacks/execution.py
================
import logging
import traceback
from crewai.agents.parser import AgentAction, AgentFinish
from apps.agents.models import CrewExecution, Task
from ..utils.logging import log_crew_message
from ..handlers.websocket import send_message_to_websocket

logger = logging.getLogger(__name__)

class TaskCallback:
    def __init__(self, execution_id):
        self.execution_id = execution_id
        self.current_task_index = None
        self.current_agent_role = None

    def __call__(self, task_output):
        """Handle task callback from CrewAI."""
        try:
            execution = CrewExecution.objects.get(id=self.execution_id)
            
            # Get the task ID based on task index
            ordered_tasks = Task.objects.filter(
                crewtask__crew=execution.crew
            ).order_by('crewtask__order')
            
            if self.current_task_index is not None and self.current_task_index < len(ordered_tasks):
                crewai_task_id = ordered_tasks[self.current_task_index].id
                self.current_agent_role = ordered_tasks[self.current_task_index].agent.role
            else:
                crewai_task_id = None
            
            if task_output.raw:
                # Format as a proper execution update
                event = {
                    'type': 'execution_update',
                    'execution_id': self.execution_id,
                    'crewai_task_id': crewai_task_id,
                    'status': execution.status,
                    'stage': {
                        'stage_type': 'task_output',
                        'title': 'Task Output',
                        'content': task_output.raw,
                        'status': 'completed',
                        'agent': self.current_agent_role
                    }
                }
                send_message_to_websocket(event)
                
                # Log to database
                log_crew_message(
                    execution=execution,
                    content=task_output.raw,
                    agent=self.current_agent_role,
                    crewai_task_id=crewai_task_id
                )

        except Exception as e:
            logger.error(f"Error in task callback: {str(e)}")
            logger.error(f"Full traceback:\n{traceback.format_exc()}")
            raise

class StepCallback:
    def __init__(self, execution_id):
        self.execution_id = execution_id
        self.current_task_index = None
        self.current_agent_role = None

    def __call__(self, step_output):
        """Handle step callback from CrewAI."""
        try:
            # Only process tool usage, skip AgentFinish
            if isinstance(step_output, AgentAction):
                execution = CrewExecution.objects.get(id=self.execution_id)
                
                # Get the task ID based on task index
                ordered_tasks = Task.objects.filter(
                    crewtask__crew=execution.crew
                ).order_by('crewtask__order')
                
                if self.current_task_index is not None and self.current_task_index < len(ordered_tasks):
                    crewai_task_id = ordered_tasks[self.current_task_index].id
                    self.current_agent_role = ordered_tasks[self.current_task_index].agent.role
                else:
                    crewai_task_id = None

                # Log tool usage
                event = {
                    'type': 'execution_update',
                    'execution_id': self.execution_id,
                    'crewai_task_id': crewai_task_id,
                    'stage': {
                        'stage_type': 'tool_usage',
                        'title': f'Using Tool: {step_output.tool}',
                        'content': f'Tool: {step_output.tool}\nInput: {step_output.tool_input}',
                        'status': 'in_progress',
                        'agent': self.current_agent_role
                    }
                }
                send_message_to_websocket(event)
                
                log_crew_message(
                    execution=execution,
                    content=f"Using tool: {step_output.tool}\nInput: {step_output.tool_input}",
                    agent=self.current_agent_role,
                    crewai_task_id=crewai_task_id
                )
                
                if step_output.result:
                    # Log tool result
                    event = {
                        'type': 'execution_update',
                        'execution_id': self.execution_id,
                        'crewai_task_id': crewai_task_id,
                        'stage': {
                            'stage_type': 'tool_result',
                            'title': 'Tool Result',
                            'content': step_output.result,
                            'status': 'completed',
                            'agent': self.current_agent_role
                        }
                    }
                    send_message_to_websocket(event)
                    
                    log_crew_message(
                        execution=execution,
                        content=f"Tool result: {step_output.result}",
                        agent=self.current_agent_role,
                        crewai_task_id=crewai_task_id
                    )

        except Exception as e:
            logger.error(f"Error in step callback: {str(e)}")
            logger.error(f"Full traceback:\n{traceback.format_exc()}")
            raise

================
File: tasks/callbacks/tool.py
================
import logging
from crewai.tools.tool_usage_events import ToolUsageError
from crewai.utilities.events import on
from apps.agents.models import CrewExecution
from ..utils.logging import log_crew_message

logger = logging.getLogger(__name__)

@on(ToolUsageError)
def tool_error_callback(source, event: ToolUsageError):
    """
    This callback is triggered whenever a tool encounters an error during execution.

    Args:
        source: The source of the event (likely the ToolUsage instance).
        event (ToolUsageError): The ToolUsageError event containing error details.
    """
    execution_id = source.task.execution_id  # Assuming you've stored execution_id in the Task
    execution = CrewExecution.objects.get(id=execution_id)
    agent_role = event.agent_role

    error_message = f"Tool '{event.tool_name}' failed for agent '{agent_role}'."
    error_message += f"\n Error: {event.error}"
    error_message += f"\n Tool Arguments: {event.tool_args}"
    error_message += f"\n Run Attempts: {event.run_attempts}"
    error_message += f"\n Delegations: {event.delegations}"
    
    log_crew_message(execution, error_message, agent='Tool Error Callback')
    logger.error(error_message)

================
File: tasks/core/agents.py
================
import logging
from functools import partial
from crewai import Agent
from ..utils.tools import load_tool_in_task
from ..handlers.input import human_input_handler
from ..callbacks.execution import StepCallback
from apps.common.utils import get_llm

logger = logging.getLogger(__name__)

def create_crewai_agents(agent_models, execution_id):
    agents = []
    for agent_model in agent_models:
        try:
            agent_params = {
                'role': agent_model.role,
                'goal': agent_model.goal,
                'backstory': agent_model.backstory,
                'verbose': agent_model.verbose,
                'allow_delegation': agent_model.allow_delegation,
                'step_callback': StepCallback(execution_id),
                'human_input_handler': partial(human_input_handler, execution_id=execution_id),
                'tools': [],
                'execution_id': execution_id
            }

            # Handle LLM fields for Agent
            llm_fields = ['llm', 'function_calling_llm']
            for field in llm_fields:
                value = getattr(agent_model, field)
                if value:
                    logger.debug(f"Using LLM: {value}")
                    agent_llm, _ = get_llm(value)
                    agent_params[field] = agent_llm

            # Load tools with their settings
            for tool in agent_model.tools.all():
                loaded_tool = load_tool_in_task(tool)
                if loaded_tool:
                    # Get tool settings
                    tool_settings = agent_model.get_tool_settings(tool)
                    if tool_settings and tool_settings.force_output_as_result:
                        # Apply the force output setting
                        loaded_tool = type(loaded_tool)(
                            result_as_answer=True,
                            **{k: v for k, v in loaded_tool.__dict__.items() if k != 'result_as_answer'}
                        )
                    agent_params['tools'].append(loaded_tool)
                    logger.debug(f"Added tool {tool.name} to agent {agent_model.name}")
                else:
                    logger.warning(f"Failed to load tool {tool.name} for agent {agent_model.name}")

            optional_params = ['max_iter', 'max_rpm', 'system_template', 'prompt_template', 'response_template']
            agent_params.update({param: getattr(agent_model, param) for param in optional_params if getattr(agent_model, param) is not None})
            
            agent = Agent(**agent_params)
            logger.debug(f"CrewAI Agent created successfully for agent id: {agent_model.id} with {len(agent_params['tools'])} tools")
            agents.append(agent)
        except Exception as e:
            logger.error(f"Error creating CrewAI Agent for agent {agent_model.id}: {str(e)}")
    return agents

================
File: tasks/core/tasks.py
================
import logging
import os
from datetime import datetime
from django.conf import settings
from crewai import Task as CrewAITask
from apps.agents.models import Task, Agent
from ..utils.tools import load_tool_in_task
from ..utils.logging import log_crew_message

logger = logging.getLogger(__name__)

def create_crewai_tasks(task_models, agents, execution):
    tasks = []
    for task_model in task_models:
        try:
            # Log the task details
            logger.info(f"""
Task details:
- ID: {task_model.id}
- Description: {task_model.description}
- Agent ID: {task_model.agent_id}
""")
            
            # Get and log the agent model details
            agent_model = Agent.objects.get(id=task_model.agent_id)
            logger.info(f"""
Agent Model details:
- ID: {agent_model.id}
- Role: {agent_model.role}
""")
            
            # Log available CrewAI agents
            logger.info("Available CrewAI agents:")
            for agent in agents:
                logger.info(f"- Agent Role: {agent.role}")

            # Associate the Task with the CrewExecution
            task_model.crew_execution = execution
            task_model.save()

            # Try to find matching agent
            crewai_agent = next((agent for agent in agents if agent.role == agent_model.role), None)
            
            if not crewai_agent:
                logger.warning(f"""
No matching CrewAI agent found for task {task_model.id}
Looking for role: {agent_model.role}
Available roles: {[agent.role for agent in agents]}
""")
                continue

            task_tools = []
            for tool_model in task_model.tools.all():
                tool = load_tool_in_task(tool_model)
                if tool:
                    task_tools.append(tool)

            task_dict = {
                'description': task_model.description,
                'agent': crewai_agent,
                'expected_output': task_model.expected_output,
                'async_execution': task_model.async_execution,
                'human_input': task_model.human_input,
                'tools': task_tools,
                'execution_id': execution.id
            }
            logger.info(f"Task dict: {task_dict}")
            optional_fields = ['output_json', 'output_pydantic', 'converter_cls']
            task_dict.update({field: getattr(task_model, field) for field in optional_fields if getattr(task_model, field) is not None})

            # Handle output_file separately
            if task_model.output_file:
                description_part = task_model.description[:20]  # Adjust the slice as needed
                
                # Generate a pithy timestamp
                timestamp = datetime.now().strftime("%y-%m-%d-%H-%M")
                
                # Get the file name and extension
                file_name, file_extension = os.path.splitext(task_model.output_file)
                
                # Append the timestamp to the file name
                new_file_name = f"{file_name}_{timestamp}{file_extension}"

                # Construct the full path using MEDIA_ROOT
                full_path = os.path.join(settings.MEDIA_URL, str(execution.user.id), description_part, new_file_name)
                logger.debug(f"Full path for output_file: {full_path}")
                log_crew_message(execution, f"Task output will be saved to: {full_path}", agent='System')

                task_dict['output_file'] = full_path

            tasks.append(CrewAITask(**task_dict))
            logger.debug(f"CrewAITask created successfully for task: {task_model.id}")
        except Exception as e:
            logger.error(f"Error creating CrewAITask for task {task_model.id}: {str(e)}", exc_info=True)
    return tasks

================
File: tasks/handlers/__init__.py
================
"""
Handler modules for agent tasks.
"""

from .websocket import send_message_to_websocket

__all__ = ['send_message_to_websocket']

================
File: tasks/handlers/input.py
================
import logging
import time
from django.core.cache import cache
from asgiref.sync import async_to_sync
from channels.layers import get_channel_layer
from apps.agents.models import CrewExecution
from ..utils.logging import log_crew_message, update_execution_status

logger = logging.getLogger(__name__)
channel_layer = get_channel_layer()

def human_input_handler(prompt, execution_id):
    execution = CrewExecution.objects.get(id=execution_id)
    update_execution_status(execution, 'WAITING_FOR_HUMAN_INPUT', task_id=None)
    log_crew_message(execution, f"Human input required: {prompt}", agent='Human Input Requested', human_input_request=prompt)
    
    input_key = f"human_input_{execution_id}_{prompt[:20]}"
    cache.set(input_key, prompt, timeout=3600)  # 1 hour timeout
    
    async_to_sync(channel_layer.group_send)(
        f"crew_execution_{execution_id}",
        {
            "type": "crew_execution_update",
            "status": "WAITING_FOR_HUMAN_INPUT",
            "human_input_request": prompt
        }
    )
    
    max_wait_time = 3600  # 1 hour
    start_time = time.time()
    while time.time() - start_time < max_wait_time:
        response = cache.get(f"{input_key}_response")
        if response:
            cache.delete(input_key)
            cache.delete(f"{input_key}_response")
            return response
        time.sleep(1)
    
    return "No human input received within the specified time."

def custom_input_handler(prompt, execution_id):
    logger.debug(f"Custom input handler called for execution {execution_id} with prompt: {prompt}")
    execution = CrewExecution.objects.get(id=execution_id)
    update_execution_status(execution, 'WAITING_FOR_HUMAN_INPUT', task_id=None)
    log_crew_message(execution, prompt or "Input required", agent='Human Input Requested', human_input_request=prompt or "Input required")
    
    input_key = f'human_input_request_{execution_id}'
    response_key = f"{input_key}_response"
    cache.set(input_key, prompt or "Input required", timeout=3600)
    
    async_to_sync(channel_layer.group_send)(
        f"crew_execution_{execution_id}",
        {
            "type": "crew_execution_update",
            "status": "WAITING_FOR_HUMAN_INPUT",
            "human_input_request": prompt or "Input required"
        }
    )
    
    # Wait for the input (with a timeout)
    timeout = 300  # 5 minutes timeout
    poll_interval = 1  # Check every second
    start_time = time.time()
    
    while time.time() - start_time < timeout:
        user_input = cache.get(response_key)
        
        if user_input is not None:
            # Clear the cache
            cache.delete(input_key)
            cache.delete(response_key)
            
            log_crew_message(execution, f"Received human input: {user_input}", agent='Human')
            update_execution_status(execution, 'RUNNING', task_id=None)
            
            return user_input
       
        time.sleep(poll_interval)
    
    logger.warning(f"Timeout waiting for human input in execution {execution_id}")
    raise TimeoutError("No user input received within the timeout period")

================
File: tasks/handlers/websocket.py
================
import logging
from asgiref.sync import async_to_sync
from channels.layers import get_channel_layer
from apps.agents.models import CrewExecution

logger = logging.getLogger(__name__)
channel_layer = get_channel_layer()

def send_message_to_websocket(message):
    """Send message to websocket"""
    try:
        # Get execution ID from message
        execution_id = message.get('execution_id')
        if not execution_id:
            logger.error("No execution_id in message")
            return

        # Get crew ID from execution
        try:
            execution = CrewExecution.objects.get(id=execution_id)
            crew_id = execution.crew.id
        except CrewExecution.DoesNotExist:
            logger.error(f"No execution found for ID {execution_id}")
            return

        # Add status if not present
        if 'status' not in message:
            message['status'] = execution.status

        # Send message to websocket group
        group_name = f'crew_{crew_id}_kanban'
        async_to_sync(channel_layer.group_send)(
            group_name,
            message
        )
        logger.debug(f"Sent WebSocket message to group {group_name}: {message}")
    except Exception as e:
        logger.error(f"Error sending WebSocket message: {str(e)}")

================
File: tasks/__init__.py
================
from celery import shared_task
from .core.crew import execute_crew
from .tools import run_tool

__all__ = ['execute_crew', 'run_tool']

================
File: tasks/tools.py
================
from celery import shared_task
import asyncio
import logging
from ..utils import load_tool
from django.shortcuts import get_object_or_404
from ..models import Tool, ToolRun
import inspect
import json
import traceback

logger = logging.getLogger(__name__)

@shared_task(bind=True)
def run_tool(self, tool_id: int, inputs: dict):
    """Generic Celery task to run any tool"""
    try:
        # Load the tool
        tool = get_object_or_404(Tool, id=tool_id)
        tool_instance = load_tool(tool)
        
        if tool_instance is None:
            raise ValueError('Failed to load tool')

        # Create a tool run record
        tool_run = ToolRun.objects.create(
            tool=tool,
            status='STARTED',
            inputs=inputs
        )
        
        try:
            # Process inputs if tool has args_schema
            if hasattr(tool_instance, 'args_schema'):
                processed_inputs = {}
                for key, value in inputs.items():
                    if value != '':
                        try:
                            processed_inputs[key] = json.loads(value)
                        except json.JSONDecodeError:
                            processed_inputs[key] = value
                            
                validated_inputs = tool_instance.args_schema(**processed_inputs)
                inputs = validated_inputs.dict()
            
            # Run the tool
            if inspect.iscoroutinefunction(tool_instance._run):
                # Create event loop for async tools
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                try:
                    result = loop.run_until_complete(tool_instance._run(**inputs))
                finally:
                    loop.close()
            else:
                result = tool_instance._run(**inputs)
            
            # Update tool run record
            tool_run.status = 'SUCCESS'
            tool_run.result = result
            tool_run.save()
            
            return {
                'result': result,
                'error': None
            }
            
        except Exception as e:
            logger.error(f"Error running tool: {str(e)}\n{traceback.format_exc()}")
            tool_run.status = 'FAILURE'
            tool_run.error = str(e)
            tool_run.save()
            raise
            
    except Exception as e:
        logger.error(f"Error in run_tool task: {str(e)}\n{traceback.format_exc()}")
        raise

================
File: templatetags/__init__.py
================
# Empty file to make the directory a Python package

================
File: templatetags/agent_filters.py
================
from django import template

register = template.Library()

@register.filter
def has_force_output_enabled(agent, tool):
    """Template filter to check if force output is enabled for a tool."""
    if not agent:
        return False
    tool_setting = agent.tool_settings.filter(tool=tool).first()
    return tool_setting.force_output_as_result if tool_setting else False

================
File: templatetags/agent_tags.py
================
from django import template

register = template.Library()

@register.filter
def get_item(dictionary, key):
    return dictionary.get(key)

================
File: websockets/handlers/agent_handler.py
================
import logging
from apps.common.utils import format_message
from apps.agents.models import Agent

logger = logging.getLogger(__name__)

class AgentHandler:
    def __init__(self, consumer):
        self.consumer = consumer
        self.chat_service = None

    async def process_response(self, message, agent_id, model_name, client_id):
        """Process and send agent response"""
        try:
            # Get agent data
            agent = await self.get_agent(agent_id)
            if not agent:
                raise ValueError("Agent not found")

            # Get client data
            client_data = await self.consumer.client_manager.get_client_data(client_id)

            # Initialize chat service if needed
            if not self.chat_service:
                from ..services.chat_service import ChatService
                from ..handlers.callback_handler import WebSocketCallbackHandler
                
                callback_handler = WebSocketCallbackHandler(self.consumer)
                self.chat_service = ChatService(
                    agent=agent,
                    model_name=model_name,
                    client_data=client_data,
                    callback_handler=callback_handler,
                    session_id=self.consumer.session_id
                )
                await self.chat_service.initialize()

            # Process message
            response = await self.chat_service.process_message(message)
            
            # Generic error handling for any tool response
            if isinstance(response, dict) and not response.get('success', True):
                error_msg = response.get('error', 'Unknown error occurred')
                logger.error(f"Tool Error: {error_msg}")
                return f"Error: {error_msg}. Please check your input and try again."

            return response

        except Exception as e:
            logger.error(f"Error in agent handler: {str(e)}")
            raise

    async def get_agent(self, agent_id):
        """Get agent from database"""
        try:
            from django.db import models
            from channels.db import database_sync_to_async

            @database_sync_to_async
            def get_agent_from_db(agent_id):
                return Agent.objects.get(id=agent_id)

            return await get_agent_from_db(agent_id)
        except Exception as e:
            logger.error(f"Error getting agent: {str(e)}")
            raise 

    async def process_message(self, message: str, is_edit: bool = False) -> str:
        """Process a message using the agent"""
        try:
            # Get agent and model info
            agent_id = self.consumer.scope.get('agent_id')
            model_name = self.consumer.scope.get('model_name')
            client_id = self.consumer.scope.get('client_id')

            # Initialize chat service
            chat_service = ChatService(
                agent=await self.get_agent(agent_id),
                model_name=model_name,
                client_data=await self.get_client_data(client_id),
                callback_handler=self.callback_handler,
                session_id=self.consumer.session_id
            )

            await chat_service.initialize()
            
            # Process message with edit flag
            return await chat_service.process_message(message, is_edit=is_edit)

        except Exception as e:
            error_msg = f"Error in agent handler: {str(e)}"
            logger.error(error_msg)
            raise

================
File: websockets/handlers/callback_handler.py
================
from langchain_core.callbacks import BaseCallbackHandler
import logging
import time
import json
from typing import Any, Dict, List
from datetime import datetime

class WebSocketCallbackHandler(BaseCallbackHandler):
    """Enhanced callback handler with timing and comprehensive event tracking"""
    
    def __init__(self, consumer):
        self.consumer = consumer
        self.logger = logging.getLogger(__name__)
        self._last_time = None
        self._records = []
        self._current_chain_id = None
        self._current_tool_id = None

    def _record_timing(self) -> float:
        """Record time delta between events"""
        time_now = time.time()
        time_delta = time_now - self._last_time if self._last_time is not None else 0
        self._last_time = time_now
        return time_delta

    async def _append_record(self, event_type: str, content: Any, metadata: Dict = None):
        """Record an event with timing and metadata"""
        time_delta = self._record_timing()
        record = {
            "event_type": event_type,
            "content": content,
            "metadata": metadata or {},
            "time_delta": time_delta,
            "timestamp": datetime.now().isoformat(),
            "chain_id": self._current_chain_id,
            "tool_id": self._current_tool_id
        }
        self._records.append(record)
        return record

    async def _send_message(self, content: Any, message_type: str = None, is_error: bool = False):
        """Send formatted message through websocket"""
        try:
            # Format content based on type
            if isinstance(content, dict):
                if 'actions' in content:
                    # Handle ReAct agent actions
                    action = content['actions'][0]
                    formatted_content = {
                        'action': action.tool,
                        'action_input': action.tool_input,
                        'log': action.log
                    }
                elif 'steps' in content:
                    # Handle ReAct agent steps
                    step = content['steps'][0]
                    if hasattr(step, 'observation') and step.observation:
                        # If it's a valid observation, send it directly
                        formatted_content = step.observation
                    elif hasattr(step.action, 'tool') and step.action.tool == '_Exception':
                        # Handle error cases gracefully
                        self.logger.error(f"Agent step error: {step.action.tool_input}")
                        formatted_content = {
                            'error': True,
                            'message': step.action.tool_input
                        }
                    else:
                        # Format other step information
                        formatted_content = {
                            'action': step.action.tool if hasattr(step.action, 'tool') else None,
                            'action_input': step.action.tool_input if hasattr(step.action, 'tool_input') else None,
                            'observation': step.observation if hasattr(step, 'observation') else None
                        }
                else:
                    formatted_content = content
            else:
                formatted_content = content

            await self.consumer.message_handler.handle_message(
                formatted_content,
                is_agent=True,
                error=is_error,
                message_type=message_type
            )
        except Exception as e:
            self.logger.error(f"Error in _send_message: {str(e)}")
            await self.consumer.message_handler.handle_message(
                str(content),
                is_agent=True,
                error=True,
                message_type='error'
            )

    async def on_llm_start(self, serialized: Dict[str, Any], prompts: List[str], **kwargs: Any):
        """Handle LLM start event"""
        self.logger.debug("LLM Start callback triggered")
        record = await self._append_record("llm_start", {
            "serialized": serialized,
            "prompts": prompts,
            **kwargs
        })
        await self._send_message(
            "Processing your request...",
            message_type="llm_start"
        )

    async def on_llm_new_token(self, token: str, **kwargs: Any):
        """Handle streaming tokens"""
        if not token or not token.strip():
            return

        self.logger.debug(f"New token received: {token[:500]}...")
        
        # Check if token is a ReAct thought/action/observation
        if isinstance(token, dict):
            if 'actions' in token:
                # Format action for display
                action = token['actions'][0]
                formatted = {
                    'type': 'tool_start',
                    'name': action.tool,
                    'input': action.tool_input
                }
                await self._send_message(formatted, message_type="tool_start")
            elif 'steps' in token:
                step = token['steps'][0]
                if hasattr(step, 'observation') and step.observation:
                    # Format observation for display
                    formatted = {
                        'type': 'tool_output',
                        'output': step.observation
                    }
                    await self._send_message(formatted, message_type="tool_output")
                elif hasattr(step.action, 'tool') and step.action.tool == '_Exception':
                    # Log error but don't display parsing errors
                    self.logger.error(f"Agent step error: {step.action.tool_input}")
            elif 'output' in token:
                # Handle final output
                await self._send_message(token['output'], message_type="llm_token")
            else:
                # Handle other token types
                await self._send_message(token, message_type="llm_token")
        else:
            # Handle string tokens
            await self._send_message(token, message_type="llm_token")


    async def on_llm_end(self, response, **kwargs: Any):
        """Handle LLM completion"""
        self.logger.debug("LLM End callback triggered")
        record = await self._append_record("llm_end", {
            "response": response,
            **kwargs
        })
        try:
            output = response.generations[0][0].text if response.generations else ""
            if output.strip():
                await self._send_message(
                    output,
                    message_type="llm_end"
                )
        except Exception as e:
            self.logger.error(f"Error in on_llm_end: {str(e)}", exc_info=True)

    async def on_llm_error(self, error: str, **kwargs: Any):
        """Handle LLM errors"""
        self.logger.error(f"LLM Error: {error}")
        record = await self._append_record("llm_error", {
            "error": error,
            **kwargs
        })
        await self._send_message(
            f"Error: {error}",
            message_type="llm_error",
            is_error=True
        )

    async def on_chain_start(self, serialized: Dict[str, Any], inputs: Dict[str, Any], **kwargs: Any):
        """Handle chain start"""
        self._current_chain_id = kwargs.get("run_id", None)
        record = await self._append_record("chain_start", {
            "serialized": serialized,
            "inputs": inputs,
            **kwargs
        })

    async def on_chain_end(self, outputs: Dict[str, Any], **kwargs: Any):
        """Handle chain completion"""
        record = await self._append_record("chain_end", {
            "outputs": outputs,
            **kwargs
        })
        self._current_chain_id = None

    async def on_chain_error(self, error: str, **kwargs: Any):
        """Handle chain errors"""
        self.logger.error(f"Chain error: {error}")
        record = await self._append_record("chain_error", {
            "error": error,
            **kwargs
        })
        await self._send_message(
            f"Error: {error}",
            message_type="chain_error",
            is_error=True
        )
        self._current_chain_id = None

    async def on_tool_start(self, serialized: Dict[str, Any], input_str: str, **kwargs: Any):
        """Handle tool start"""
        self._current_tool_id = kwargs.get("run_id", None)
        record = await self._append_record("tool_start", {
            "serialized": serialized,
            "input": input_str,
            **kwargs
        })
        await self._send_message(
            f"Using tool: {serialized.get('name', 'unknown')}\nInput: {input_str}",
            message_type="tool_start"
        )

    async def on_tool_end(self, output: str, **kwargs: Any):
        """Handle tool completion"""
        if output and str(output).strip():
            # Try to parse JSON output
            try:
                if isinstance(output, str) and (output.startswith('{') or output.startswith('[')):
                    parsed_output = json.loads(output)
                    await self._send_message(parsed_output, message_type="tool_output")
                else:
                    await self._send_message(output, message_type="tool_output")
            except json.JSONDecodeError:
                await self._send_message(output, message_type="tool_output")
        self._current_tool_id = None

    async def on_tool_error(self, error: str, **kwargs: Any):
        """Handle tool errors"""
        self.logger.error(f"Tool error: {error}")
        record = await self._append_record("tool_error", {
            "error": error,
            **kwargs
        })
        await self._send_message(
            f"Tool error: {error}",
            message_type="tool_error",
            is_error=True
        )
        self._current_tool_id = None

    async def on_text(self, text: str, **kwargs: Any):
        """Handle text events"""
        record = await self._append_record("text", {
            "text": text,
            **kwargs
        })
        await self._send_message(
            text,
            message_type="text"
        )

    async def on_agent_action(self, action, **kwargs: Any):
        """Handle agent actions"""
        record = await self._append_record("agent_action", {
            "action": action,
            **kwargs
        })
        await self._send_message(
            f"Agent action: {action.tool}\nInput: {action.tool_input}",
            message_type="agent_action"
        )

    async def on_agent_finish(self, finish, **kwargs: Any):
        """Handle agent completion"""
        record = await self._append_record("agent_finish", {
            "finish": finish,
            **kwargs
        })
        if hasattr(finish, 'return_values'):
            await self._send_message(
                str(finish.return_values.get('output', '')),
                message_type="agent_finish"
            )

    def get_records(self) -> List[Dict]:
        """Get all recorded events"""
        return self._records

    async def save_records(self, session_id: str):
        """Save records to Django cache"""
        try:
            from django.core.cache import cache
            cache_key = f"callback_records_{session_id}"
            cache.set(cache_key, self._records, timeout=3600)  # 1 hour timeout
        except Exception as e:
            self.logger.error(f"Error saving callback records: {str(e)}", exc_info=True)

================
File: websockets/handlers/message_handler.py
================
import json
import logging
from datetime import datetime
from bs4 import BeautifulSoup
import re

logger = logging.getLogger(__name__)

class MessageHandler:
    def __init__(self, consumer):
        self.consumer = consumer

    def format_table(self, content):
        """Format content as an HTML table if it contains tabular data"""
        try:
            # Check if content has table-like format (e.g., "Date | Users")
            if '|' in content and '-|-' in content:
                lines = [line.strip() for line in content.strip().split('\n')]
                
                # Find the header line
                header_line = None
                separator_line = None
                data_lines = []
                
                for i, line in enumerate(lines):
                    if '|' in line:
                        if header_line is None:
                            header_line = line
                        elif separator_line is None and '-|-' in line:
                            separator_line = line
                        else:
                            data_lines.append(line)
                
                if not header_line or not separator_line:
                    return content
                    
                # Process headers
                headers = [h.strip() for h in header_line.split('|') if h.strip()]
                
                # Create HTML table
                html = ['<table class="table"><thead><tr>']
                html.extend([f'<th>{h}</th>' for h in headers])
                html.append('</tr></thead><tbody>')
                
                # Process data rows
                for line in data_lines:
                    if '|' in line:
                        cells = [cell.strip() for cell in line.split('|') if cell.strip()]
                        if cells:
                            html.append('<tr>')
                            html.extend([f'<td>{cell}</td>' for cell in cells])
                            html.append('</tr>')
                
                html.append('</tbody></table>')
                return '\n'.join(html)
                
            return content
            
        except Exception as e:
            logger.error(f"Error formatting table: {str(e)}")
            return content

    def format_tool_output(self, content):
        """Format tool output for display"""
        try:
            logger.debug(f"Formatting tool output. Raw content: {content}")
            
            if isinstance(content, dict):
                if 'agent' in content and 'messages' in content['agent']:
                    logger.debug("Processing agent messages structure")
                    messages = content['agent']['messages']
                    formatted_messages = []
                    for msg in messages:
                        logger.debug(f"Processing message: {msg}")
                        if hasattr(msg, 'content'):
                            formatted_messages.append(msg.content)
                    return json.dumps(formatted_messages, indent=2)

            # If content is a string, try to parse as JSON first
            if isinstance(content, str):
                try:
                    # Check for duplicated JSON blocks
                    if content.count('```json') > 1:
                        logger.warning(f"Multiple JSON blocks detected in: {content}")
                        # Take only the first JSON block
                        json_blocks = content.split('```json')
                        content = json_blocks[1].split('```')[0]
                        
                    json_content = json.loads(content)
                    logger.debug(f"Parsed JSON content: {json_content}")
                    return json.dumps(json_content, indent=2)
                except json.JSONDecodeError as e:
                    logger.error(f"JSON parse error: {e}")
                    logger.debug(f"Failed content: {content}")

            # Handle nested message structures
            if isinstance(content, dict):
                # Handle tool messages structure
                if 'tools' in content and 'messages' in content['tools']:
                    messages = content['tools']['messages']
                    # Extract content from ToolMessage objects
                    formatted_messages = []
                    for msg in messages:
                        if hasattr(msg, 'content'):
                            try:
                                # Try to parse content as JSON
                                msg_content = json.loads(msg.content)
                                formatted_messages.append(msg_content)
                            except json.JSONDecodeError:
                                formatted_messages.append(msg.content)
                        else:
                            formatted_messages.append(str(msg))
                    return json.dumps(formatted_messages, indent=2)

                # Default dict handling
                return json.dumps(content, indent=2)

            # Check for table format
            if '|' in content and '-|-' in content:
                return self.format_table(content)

            # Check for list format
            if content.strip().startswith(('-', '*', '1.')) or '\n-' in content or '\n*' in content:
                return content

            # Default formatting
            return str(content)
        except Exception as e:
            logger.error(f"Error formatting tool output: {str(e)}")
            return str(content)

    def format_tool_usage(self, content, message_type=None):
        """Format tool usage messages"""
        if message_type == "tool_start" and content.startswith('Using tool:'):
            tool_info = content.split('\n')
            formatted = f'''
            <div class="tool-usage">
                <i class="fas fa-tools"></i>
                <div>
                    <strong>{tool_info[0]}</strong>
                    <div class="tool-input">{tool_info[1] if len(tool_info) > 1 else ''}</div>
                </div>
            </div>
            '''
            return formatted
        elif message_type == "tool_error":
            return f'''
            <div class="tool-error">
                <i class="fas fa-exclamation-triangle"></i>
                <div>{content}</div>
            </div>
            '''
        return content

    def format_final_answer(self, content):
        """Format the final agent response"""
        try:
            # Format as table if possible
            content = self.format_table(content)
            return f'<div class="agent-response">{content}</div>'
        except Exception as e:
            logger.error(f"Error formatting final answer: {str(e)}")
            return content

    async def handle_message(self, message, is_agent=True, error=False, is_stream=False, message_type=None):
        """Format and send a message"""
        try:
            content = str(message)
            
            if is_agent:
                # Handle invalid/incomplete response errors
                if isinstance(message, dict) and 'steps' in message:
                    step = message['steps'][0]
                    if step.action.tool == '_Exception' and 'Could not parse LLM output' in step.log:
                        logger.warning(f"LLM parsing error: {step.log}")
                        error = True
                        content = "I encountered an error processing your request. Let me try again with a simpler query."

                # Apply formatting based on message type
                if message_type == "tool_output":
                    content = self.format_tool_output(content)
                elif message_type in ["tool_start", "tool_error"]:
                    content = self.format_tool_usage(content, message_type)
                elif message_type == "final_answer":
                    content = self.format_final_answer(content)
                else:
                    # Default formatting for other types
                    content = self.format_table(content)
            
            response_data = {
                'type': 'agent_message' if is_agent else 'user_message',
                'message': content,
                'is_agent': bool(is_agent),
                'error': bool(error),
                'is_stream': bool(is_stream),
                'message_type': message_type,
                'timestamp': datetime.now().isoformat()
            }
            
            logger.debug(f"📤 Sending {'agent' if is_agent else 'user'} message type: {message_type}")
            
            await self.consumer.send_json(response_data)
            
        except Exception as e:
            logger.error(f"Error in message handler: {str(e)}")
            await self.consumer.send_json({
                'type': 'error',
                'error': True,
                'message': 'Error processing message'
            })

    async def handle_keep_alive(self):
        """Handle keep-alive messages"""
        await self.consumer.send_json({
            'type': 'keep_alive_response',
            'timestamp': datetime.now().isoformat()
        })

================
File: websockets/services/chat_service.py
================
from apps.common.utils import get_llm
from apps.agents.utils import get_tool_classes
from langchain.agents import AgentExecutor
from langchain.memory import ConversationBufferMemory
from langchain.tools import Tool, StructuredTool
from apps.agents.chat.history import DjangoCacheMessageHistory
from channels.db import database_sync_to_async
#from apps.seo_manager.models import Client
from langchain.schema import SystemMessage, AIMessage, HumanMessage
#from langchain_core.runnables.history import RunnableWithMessageHistory
import json
import logging
from django.utils import timezone
from langchain.prompts import ChatPromptTemplate
from langchain.agents import create_structured_chat_agent

logger = logging.getLogger(__name__)

class ChatService:
    def __init__(self, agent, model_name, client_data, callback_handler, session_id=None):
        self.agent = agent
        self.model_name = model_name
        self.client_data = client_data
        self.callback_handler = callback_handler
        self.llm = None
        self.token_counter = None
        self.agent_executor = None
        self.processing = False
        self.tool_cache = {}  # Add tool caching back
        self.session_id = session_id or f"{agent.id}_{client_data['client_id'] if client_data else 'no_client'}"
        self.message_history = None

    async def initialize(self):
        """Initialize the chat service with LLM and agent"""
        try:
            # Get LLM and token counter
            self.llm, self.token_counter = get_llm(
                model_name=self.model_name,
                temperature=0.7,
                streaming=True
            )

            # Initialize message history
            self.message_history = DjangoCacheMessageHistory(
                session_id=self.session_id,
                ttl=3600
            )

            # Initialize memory with message history
            memory = ConversationBufferMemory(
                memory_key="chat_history",
                return_messages=True,
                chat_memory=self.message_history,
                output_key="output",
                input_key="input"
            )

            # Load tools
            tools = await self._load_tools()
            
            # Get tool names and descriptions
            tool_names = [tool.name for tool in tools]
            tool_descriptions = [f"{tool.name}: {tool.description}" for tool in tools]

            # Create prompt with required variables
            prompt = ChatPromptTemplate.from_messages([
                ("system", """
{system_prompt}

You have access to the following tools:
{tools}

Tool Names: {tool_names}

IMPORTANT INSTRUCTIONS:
1. If a tool call fails, examine the error message and try to fix the parameters
2. If multiple tool calls fail, return a helpful message explaining the limitation
3. Always provide a clear response even if data is limited
4. Never give up without providing some useful information
5. Keep responses focused and concise

To use a tool, respond with:
{{"action": "tool_name", "action_input": {{"param1": "value1", "param2": "value2"}}}}

For final responses, use:
{{"action": "Final Answer", "action_input": "your response here"}}
"""),
                ("human", "{input}"),
                ("ai", "{agent_scratchpad}"),
                ("system", "Previous conversation:\n{chat_history}")
            ])

            # Create the agent
            agent = create_structured_chat_agent(
                llm=self.llm,
                tools=tools,
                prompt=prompt.partial(
                    system_prompt=await self._create_agent_prompt(),
                    tools="\n".join(tool_descriptions),
                    tool_names=", ".join(tool_names)
                )
            )
            
            # Create agent executor
            self.agent_executor = AgentExecutor(
                agent=agent,
                tools=tools,
                memory=memory,
                verbose=True,
                max_iterations=10,
                max_execution_time=120,
                early_stopping_method="force",
                handle_parsing_errors=True,
                return_intermediate_steps=True,  # Enable to see tool usage
                output_key="output",
                input_key="input"
            )
            
            return self.agent_executor

        except Exception as e:
            logger.error(f"Error initializing chat service: {str(e)}", exc_info=True)
            raise

    async def process_message(self, message: str, is_edit: bool = False) -> None:
        """Process a message using the agent"""
        if not self.agent_executor:
            raise ValueError("Agent executor not initialized")

        if self.processing:
            return None

        try:
            self.processing = True
            
            # Handle message editing
            if is_edit:
                await self._handle_message_edit()
            
            # Format input for agent
            input_data = {
                "input": message
            }
            
            error_count = 0
            last_error = None
            
            async for chunk in self.agent_executor.astream(
                input_data
            ):
                try:
                    if isinstance(chunk, dict):
                        if "output" in chunk:
                            await self.callback_handler.on_llm_new_token(chunk["output"])
                        elif "intermediate_steps" in chunk:
                            await self._process_tool_steps(chunk["intermediate_steps"])
                        else:
                            content = str(chunk)
                            if content.strip():
                                await self.callback_handler.on_llm_new_token(content)
                    else:
                        content = str(chunk)
                        if content.strip():
                            await self.callback_handler.on_llm_new_token(content)
                            
                except Exception as chunk_error:
                    logger.error(f"Error processing chunk: {str(chunk_error)}")
                    error_count += 1
                    last_error = str(chunk_error)
                    if error_count >= 3:
                        await self.callback_handler.on_llm_new_token(
                            f"Multiple errors occurred. Last error: {last_error}"
                        )
                        return None
                    continue
                    
            return None

        except Exception as e:
            logger.error(f"Error processing message: {str(e)}")
            await self.callback_handler.on_llm_error(str(e))
            raise
        finally:
            self.processing = False

    @database_sync_to_async
    def _handle_message_edit(self):
        """Clear history from last user message for edit handling"""
        messages = self.message_history.messages
        for i in range(len(messages) - 1, -1, -1):
            if isinstance(messages[i], HumanMessage):
                self.message_history.messages = messages[:i]
                break

    async def _process_tool_steps(self, steps):
        """Process tool execution steps"""
        for step in steps:
            if len(step) >= 2:
                action, output = step
                if isinstance(output, str) and "Invalid or incomplete response" in output:
                    continue
                
                if hasattr(action, 'tool') and action.tool != '_Exception':
                    tool_interaction = {
                        'type': 'tool',
                        'tool': action.tool,
                        'input': action.tool_input,
                        'output': str(output)
                    }
                    
                    await self.callback_handler.on_llm_new_token({
                        'tool': action.tool,
                        'input': action.tool_input,
                        'output': output
                    })

    @database_sync_to_async
    def _load_tools(self):
        """Load and initialize agent tools asynchronously"""
        try:
            tools = []
            seen_tools = set()
            
            for tool_model in self.agent.tools.all():
                try:
                    tool_key = f"{tool_model.tool_class}_{tool_model.tool_subclass}"
                    if tool_key in seen_tools:
                        continue
                    seen_tools.add(tool_key)

                    tool_classes = get_tool_classes(tool_model.tool_class)
                    tool_class = next((cls for cls in tool_classes 
                                   if cls.__name__ == tool_model.tool_subclass), None)
                    
                    if tool_class:
                        logger.info(f"Initializing tool: {tool_class.__name__}")
                        tool_instance = tool_class()
                        
                        # Wrap tool output formatting
                        def format_tool_output(func):
                            def wrapper(*args, **kwargs):
                                result = func(*args, **kwargs)
                                if isinstance(result, dict):
                                    return json.dumps(result, indent=2)
                                return str(result)
                            return wrapper
                        
                        # Create structured or basic tool
                        if hasattr(tool_instance, 'args_schema'):
                            wrapped_run = format_tool_output(tool_instance._run)
                            tool = StructuredTool.from_function(
                                func=wrapped_run,
                                name=tool_model.name.lower().replace(" ", "_"),
                                description=self._create_tool_description(tool_instance, tool_model),
                                args_schema=tool_instance.args_schema,
                                coroutine=tool_instance.arun if hasattr(tool_instance, 'arun') else None,
                                return_direct=False
                            )
                        else:
                            wrapped_run = format_tool_output(tool_instance._run)
                            tool = Tool(
                                name=tool_model.name.lower().replace(" ", "_"),
                                description=self._create_tool_description(tool_instance, tool_model),
                                func=wrapped_run,
                                coroutine=tool_instance.arun if hasattr(tool_instance, 'arun') else None
                            )
                        
                        tools.append(tool)
                        logger.info(f"Successfully loaded tool: {tool_model.name}")
                        
                except Exception as e:
                    logger.error(f"Error loading tool {tool_model.name}: {str(e)}")
                    
            return tools
            
        except Exception as e:
            logger.error(f"Error loading tools: {str(e)}")
            return []

    def _create_tool_description(self, tool_instance, tool_model):
        """Create a detailed description for the tool"""
        try:
            base_description = tool_instance.description or tool_model.description
            schema = tool_instance.args_schema

            if schema:
                field_descriptions = []
                for field_name, field in schema.model_fields.items():
                    field_type = str(field.annotation).replace('typing.', '')
                    if hasattr(field.annotation, '__name__'):
                        field_type = field.annotation.__name__
                    
                    field_desc = field.description or ''
                    default = field.default
                    if default is Ellipsis:
                        default = "Required"
                    elif default is None:
                        default = "Optional"
                    
                    field_descriptions.append(
                        f"- {field_name} ({field_type}): {field_desc} Default: {default}"
                    )

                tool_description = f"""{base_description}

Parameters:
{chr(10).join(field_descriptions)}

Example:
{{"action": "{tool_model.name.lower().replace(' ', '_')}", 
  "action_input": {{
    "client_id": 123,
    "start_date": "2024-01-01",
    "end_date": "2024-01-31",
    "metrics": "newUsers",
    "dimensions": "date"
  }}
}}"""
                
                return tool_description
            
            return base_description

        except Exception as e:
            logger.error(f"Error creating tool description: {str(e)}")
            return base_description or "Tool description unavailable"

    @database_sync_to_async
    def _create_agent_prompt(self):
        """Create the system prompt for the agent"""
        client_context = ""
        
        if self.client_data:
            client_context = f"""Current Context:
- Client ID: {self.client_data.get('client_id', 'N/A')}
- Client Name: {self.client_data.get('client_name', 'N/A')}
- Website URL: {self.client_data.get('website_url', 'N/A')}
- Target Audience: {self.client_data.get('target_audience', 'N/A')}
- Current Date: {self.client_data.get('current_date', timezone.now().strftime('%Y-%m-%d'))}"""

            # Add business objectives if present
            objectives = self.client_data.get('business_objectives', [])
            if objectives:
                objectives_text = "\n".join([f"- {obj}" for obj in objectives])
                client_context += f"\n- Business Objectives:\n{objectives_text}"
        else:
            client_context = f"""Current Context:
- Current Date: {timezone.now().strftime('%Y-%m-%d')}"""

        return f"""You are {self.agent.name}, an AI assistant.

Role: {self.agent.role}

Goal: {self.agent.goal if hasattr(self.agent, 'goal') else ''}

Backstory: {self.agent.backstory if hasattr(self.agent, 'backstory') else ''}

{client_context}
"""

================
File: websockets/__init__.py
================
from .chat_consumer import ChatConsumer
from .base import BaseWebSocketConsumer

__all__ = ['ChatConsumer', 'BaseWebSocketConsumer']

================
File: websockets/base.py
================
from channels.generic.websocket import AsyncWebsocketConsumer
import json
import logging
from datetime import datetime

logger = logging.getLogger(__name__)

class BaseWebSocketConsumer(AsyncWebsocketConsumer):
    async def send_json(self, data):
        """Send JSON data as text"""
        try:
            await self.send(text_data=json.dumps(data))
        except Exception as e:
            logger.error(f"Error sending JSON: {str(e)}")
            await self.send(text_data=json.dumps({
                'error': True,
                'message': 'Error sending message'
            }))

    async def handle_binary_message(self, message):
        """Handle binary message data"""
        try:
            if isinstance(message, bytes):
                message = message.decode('utf-8')
            return json.loads(message)
        except Exception as e:
            logger.error(f"Error handling binary message: {str(e)}")
            return None

================
File: websockets/chat_consumer.py
================
from .base import BaseWebSocketConsumer
from .handlers.message_handler import MessageHandler
from .handlers.agent_handler import AgentHandler
from ..tools.manager import AgentToolManager
from ..clients.manager import ClientDataManager
from ..chat.history import DjangoCacheMessageHistory
from ..models import Conversation
import logging
import uuid
import json
from datetime import datetime
from urllib.parse import parse_qs

logger = logging.getLogger(__name__)

class ChatConsumer(BaseWebSocketConsumer):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.tool_manager = AgentToolManager()
        self.client_manager = ClientDataManager()
        self.session_id = None
        self.group_name = None
        self.message_handler = MessageHandler(self)
        self.agent_handler = AgentHandler(self)
        self.is_connected = False
        self.message_history = None

    async def connect(self):
        if self.is_connected:
            return

        try:
            # Get session ID from query parameters
            query_string = self.scope.get('query_string', b'').decode()
            params = dict(param.split('=') for param in query_string.split('&') if param)
            self.session_id = params.get('session')
            
            if not self.session_id:
                logger.error("No session ID provided")
                await self.close()
                return
                
            self.user = self.scope.get("user")
            if not self.user or not self.user.is_authenticated:
                logger.error("User not authenticated")
                await self.close()
                return
                
            self.group_name = f"chat_{self.session_id}"
            self.message_history = DjangoCacheMessageHistory(session_id=self.session_id)
            
            # Get or create conversation
            conversation = await self.get_or_create_conversation()
            if not conversation:
                logger.error("Failed to get/create conversation")
                await self.close()
                return
                
            await self.channel_layer.group_add(self.group_name, self.channel_name)
            await self.accept()
            self.is_connected = True
            
            # Send historical messages
            messages = self.message_history.messages
            for msg in messages:
                message_type = 'agent_message' if msg.type == 'ai' else 'user_message'
                message_content = msg.content
                
                # If it's an agent message, check if it's a tool usage
                if message_type == 'agent_message' and (
                    'AgentAction(tool=' in message_content or 
                    'AgentStep(action=' in message_content
                ):
                    # Send as is - the frontend will handle the formatting
                    pass
                
                await self.send_json({
                    'type': message_type,
                    'message': message_content,
                    'timestamp': conversation.updated_at.isoformat() if conversation else None
                })
            
            logger.info(f"WebSocket connected for session {self.session_id}")
            await self.send_json({
                'type': 'system_message',
                'message': 'Connected to chat server',
                'connection_status': 'connected',
                'session_id': self.session_id
            })
            
        except Exception as e:
            logger.error(f"Error in connect: {str(e)}")
            await self.close()
            return

    async def get_or_create_conversation(self):
        try:
            # Get existing conversation
            conversation = await Conversation.objects.filter(
                session_id=self.session_id,
                user=self.user
            ).afirst()
            
            if not conversation:
                # Create new conversation with placeholder title
                conversation = await Conversation.objects.acreate(
                    session_id=self.session_id,
                    user=self.user,
                    title="..."  # Will be updated with first message
                )
                logger.info(f"Created new conversation: {conversation.id}")
            else:
                logger.info(f"Found existing conversation: {conversation.id}")
            
            return conversation
            
        except Exception as e:
            logger.error(f"Error getting/creating conversation: {str(e)}")
            return None

    async def update_conversation(self, message, agent_id=None, client_id=None):
        try:
            conversation = await Conversation.objects.filter(
                session_id=self.session_id
            ).afirst()
            
            if conversation:
                # Update title if it's still the default
                if conversation.title == "...":
                    # Clean and truncate the message for the title
                    title = message.strip().replace('\n', ' ')[:50]
                    # Add ellipsis if truncated
                    if len(message) > 50:
                        title += "..."
                    conversation.title = title
                
                # Update agent and client if provided
                if agent_id:
                    conversation.agent_id = agent_id
                if client_id:
                    conversation.client_id = client_id
                    
                await conversation.asave()
                logger.info(f"Updated conversation: {conversation.id} with title: {conversation.title}")
                
        except Exception as e:
            logger.error(f"Error updating conversation: {str(e)}")

    async def receive(self, text_data=None, bytes_data=None):
        try:
            # Handle binary data if present
            if bytes_data:
                data = await self.handle_binary_message(bytes_data)
            else:
                data = json.loads(text_data)
                if data.get('type') != 'keep_alive':
                    logger.debug(f"📥 Received: {text_data}")

            if data.get('type') == 'keep_alive':
                await self.message_handler.handle_keep_alive()
                return

            await self.process_message(data)

        except json.JSONDecodeError as e:
            logger.error(f"❌ JSON decode error: {str(e)}")
            await self.message_handler.handle_message(
                'Invalid message format', is_agent=True, error=True
            )
        except Exception as e:
            logger.error(f"❌ Error: {str(e)}")
            await self.message_handler.handle_message(
                'Internal server error', is_agent=True, error=True) 

    async def process_message(self, data):
        """Process incoming message data"""
        try:
            message = data.get('message', '').strip()
            agent_id = data.get('agent_id')
            model_name = data.get('model')
            client_id = data.get('client_id')

            if not message or not agent_id:
                await self.message_handler.handle_message(
                    'Missing required fields (message or agent_id)',
                    is_agent=True,
                    error=True
                )
                return

            # Update conversation details before processing
            await self.update_conversation(message, agent_id, client_id if client_id else None)

            # Echo user's message back with proper type
            logger.debug("📤 Sending user message")
            await self.send_json({
                'type': 'user_message',
                'message': message,
                'timestamp': datetime.now().isoformat()
            })

            # Process with agent
            logger.debug("🤖 Processing with agent")
            response = await self.agent_handler.process_response(
                message,
                agent_id,
                model_name,
                client_id if client_id else None
            )

            # Handle error responses
            if isinstance(response, str) and response.startswith('Error:'):
                await self.send_json({
                    'type': 'error',
                    'message': response,
                    'timestamp': datetime.now().isoformat()
                })
                return

            logger.debug("📤 Sending agent response")
            await self.send_json({
                'type': 'agent_message',
                'message': response,
                'timestamp': datetime.now().isoformat()
            })

        except Exception as e:
            logger.error(f"❌ Error: {str(e)}")
            await self.send_json({
                'type': 'error',
                'message': f"Error processing message: {str(e)}",
                'error': True
            })

    async def receive_json(self, content):
        """Handle incoming WebSocket messages"""
        try:
            message_type = content.get('type')
            
            if message_type == 'user_message':
                message = content.get('message')
                is_edit = content.get('is_edit', False)  # Get edit flag
                
                if not message:
                    return
                
                # Send message back to confirm receipt
                await self.send_json({
                    'type': 'user_message',
                    'message': message
                })
                
                # Process message with edit flag
                await self.agent_handler.process_message(
                    message=message,
                    is_edit=is_edit
                )
        except Exception as e:
            logger.error(f"Error in receive_json: {str(e)}")
            await self.send_json({
                'type': 'error',
                'message': f"Error processing message: {str(e)}",
                'error': True
            })

================
File: websockets/consumers.py
================
async def handle_tool_call(self, tool_name, tool_args):
    """Handle tool calls from the agent"""
    try:
        # Implement your tool handling logic here
        if tool_name == "search":
            result = await self.search_tool(tool_args)
        elif tool_name == "calculator":
            result = await self.calculator_tool(tool_args)
        # Add more tool handlers as needed
        
        return result
    except Exception as e:
        logger.error(f"Error handling tool call: {str(e)}")
        return f"Error executing tool {tool_name}: {str(e)}"

================
File: consumers.py
================
import json
from channels.generic.websocket import AsyncWebsocketConsumer
from channels.db import database_sync_to_async
from django.contrib.auth import get_user_model
from .models import CrewExecution, CrewMessage, ChatMessage, Agent
from django.core.cache import cache
from apps.common.utils import format_message, get_llm
from .utils import get_tool_classes
import logging
import uuid
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, FunctionMessage, BaseMessage, messages_from_dict, messages_to_dict
import asyncio
import tiktoken
from langchain_community.chat_models import ChatLiteLLM
from langchain_core.tools import Tool
from django.utils import timezone
from apps.seo_manager.models import Client
from langchain.prompts import ChatPromptTemplate
from langchain.agents import initialize_agent, AgentType, AgentExecutor, create_structured_chat_agent
from langchain.agents.format_scratchpad import format_to_openai_function_messages
from langchain.agents.output_parsers import JSONAgentOutputParser
from langchain_core.callbacks import BaseCallbackHandler
import datetime
from langchain.tools import StructuredTool
from typing import Dict, Any, List
from pydantic import create_model
from langchain.memory import ConversationBufferMemory
from langchain_core.chat_history import BaseChatMessageHistory
import re
import time

logger = logging.getLogger(__name__)

def count_tokens(text):
    """Count tokens in text using tiktoken"""
    encoding = tiktoken.encoding_for_model("gpt-3.5-turbo")
    return len(encoding.encode(text))

class ConnectionTestConsumer(AsyncWebsocketConsumer):
    async def connect(self):
        await self.accept()
        await self.send(text_data=json.dumps({
            'message': 'Connected to server'
        }))

    async def disconnect(self, close_code):
        pass

    async def receive(self, text_data):
        try:
            text_data_json = json.loads(text_data)
            message = text_data_json['message']

            # Echo the received message back to the client
            await self.send(text_data=json.dumps({
                'message': f'Server received: {message}'
            }))
        except json.JSONDecodeError:
            await self.send(text_data=json.dumps({
                'error': 'Invalid JSON format'
            }))
        except KeyError:
            await self.send(text_data=json.dumps({
                'error': 'Missing "message" key in JSON'
            }))

class CrewExecutionConsumer(AsyncWebsocketConsumer):
    async def connect(self):
        self.execution_id = self.scope['url_route']['kwargs']['execution_id']
        self.execution_group_name = f'crew_execution_{self.execution_id}'

        # Join room group
        await self.channel_layer.group_add(
            self.execution_group_name,
            self.channel_name
        )

        await self.accept()

        # Send initial status
        await self.send_execution_status()

    async def disconnect(self, close_code):
        # Leave room group
        await self.channel_layer.group_discard(
            self.execution_group_name,
            self.channel_name
        )

    async def receive(self, text_data):
        text_data_json = json.loads(text_data)
        message_type = text_data_json.get('type')

        if message_type == 'human_input':
            input_key = text_data_json.get('input_key')
            user_input = text_data_json.get('input')
            await self.handle_human_input(input_key, user_input)

    async def crew_execution_update(self, event):
        status = event.get('status', '')  # No formatting applied
        formatted_messages = [
            {
                'agent': msg.get('agent', 'System'),
                'content': format_message(msg.get('content', ''))
            } for msg in event.get('messages', []) if msg.get('content')
        ]
        # logger.info(f"Sending status: {status}")
        # logger.info(f"Sending formatted messages: {formatted_messages}")
        await self.send(text_data=json.dumps({
            'status': status,
            'messages': formatted_messages,
            'human_input_request': event.get('human_input_request')
        }))

    @database_sync_to_async
    def handle_human_input(self, input_key, user_input):
        cache.set(f"{input_key}_response", user_input, timeout=3600)
        execution = CrewExecution.objects.get(id=self.execution_id)
        CrewMessage.objects.create(
            execution=execution,
            agent='Human',
            content=f"Human input received: {user_input}"
        )

    @database_sync_to_async
    def get_execution_status(self):
        execution = CrewExecution.objects.get(id=self.execution_id)
        messages = CrewMessage.objects.filter(execution=execution).order_by('-timestamp')[:10]
        return {
            'status': execution.status,
            'messages': [{'agent': msg.agent, 'content': msg.content} for msg in messages],
        }

    async def send_execution_status(self):
        status_data = await self.get_execution_status()
        status = status_data['status']  # No formatting applied
        formatted_messages = [
            {
                'agent': msg['agent'],
                'content': format_message(msg['content'])
            } for msg in status_data['messages'] if msg.get('content')
        ]
        
        # logger.info(f"Sending status: {status}")
        # logger.info(f"Sending formatted messages: {formatted_messages}")
        
        await self.send(text_data=json.dumps({
            'status': status,
            'messages': formatted_messages,
        }))

================
File: models.py
================
from django.db import models
from django.contrib.auth import get_user_model
from django.core.exceptions import ValidationError
from apps.common.utils import get_models
from pydantic import BaseModel
import os
import importlib
import logging
import uuid
import random
import json
from django.contrib.postgres.fields import ArrayField
from django.conf import settings
from apps.agents.utils import load_tool, get_tool_description

logger = logging.getLogger(__name__)

User = get_user_model()

AVATAR_CHOICES = [
    'user.jpg', 'team-5.jpg', 'team-4.jpg', 'team-3.jpg', 'team-2.jpg', 'kal-visuals-square.jpg',
    'team-1.jpg', 'marie.jpg', 'ivana-squares.jpg', 'ivana-square.jpg'
]

def random_avatar():
    return random.choice(AVATAR_CHOICES)

def get_available_tools():
    tools_dir = os.path.join('apps', 'agents', 'tools')
    available_tools = []

    for root, dirs, files in os.walk(tools_dir):
        for dir_name in dirs:
            if not dir_name.startswith('__'):  # Exclude directories like __pycache__
                tool_path = os.path.relpath(os.path.join(root, dir_name), tools_dir)
                available_tools.append(tool_path.replace(os.path.sep, '.'))

    return available_tools

def default_embedder():
    return {'provider': 'openai'}

def user_directory_path(instance, filename):
    # File will be uploaded to MEDIA_ROOT/user_<id>/<filename>
    return f'user_{instance.crew_execution.user.id}/{filename}'

class Tool(models.Model):
    tool_class = models.CharField(max_length=255)
    tool_subclass = models.CharField(max_length=255)
    name = models.CharField(max_length=255)
    description = models.TextField(blank=True)
    module_path = models.CharField(max_length=255)

    def __str__(self):
        return self.name

    def save(self, *args, **kwargs):
        if not self.module_path:
            self.module_path = f"apps.agents.tools.{self.tool_class}"
        
        try:
            tool = load_tool(self)
            if tool:
                self.name = getattr(tool, 'name', self.tool_subclass)
                self.description = get_tool_description(tool.__class__)
            else:
                raise ValueError(f"Failed to load tool: {self.module_path}.{self.tool_subclass}. Check the logs for more details.")
        except Exception as e:
            logger.error(f"Error in Tool.save: {str(e)}")
            raise ValidationError(f"Error loading tool: {str(e)}")

        super().save(*args, **kwargs)

class ToolRun(models.Model):
    """Model to track tool executions"""
    TOOL_RUN_STATUS = (
        ('pending', 'Pending'),
        ('running', 'Running'),
        ('completed', 'Completed'),
        ('failed', 'Failed'),
    )
    
    tool = models.ForeignKey(Tool, on_delete=models.CASCADE)
    status = models.CharField(max_length=20, choices=TOOL_RUN_STATUS, default='pending')
    inputs = models.JSONField()
    result = models.JSONField(null=True, blank=True)
    error = models.TextField(null=True, blank=True)
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)
    
    class Meta:
        ordering = ['-created_at']

class Agent(models.Model):
    name = models.CharField(max_length=255)
    role = models.CharField(max_length=100)
    goal = models.TextField()
    backstory = models.TextField()
    llm = models.CharField(max_length=100, default=settings.GENERAL_MODEL)
    tools = models.ManyToManyField(Tool, blank=True)
    function_calling_llm = models.CharField(max_length=100, null=True, blank=True, default=settings.GENERAL_MODEL)
    max_iter = models.IntegerField(default=25)
    max_rpm = models.IntegerField(null=True, blank=True)
    max_execution_time = models.IntegerField(null=True, blank=True)
    verbose = models.BooleanField(default=False)
    allow_delegation = models.BooleanField(default=False)
    step_callback = models.CharField(max_length=255, null=True, blank=True)
    cache = models.BooleanField(default=True)
    system_template = models.TextField(null=True, blank=True)
    prompt_template = models.TextField(null=True, blank=True)
    response_template = models.TextField(null=True, blank=True)
    allow_code_execution = models.BooleanField(default=False)
    max_retry_limit = models.IntegerField(default=2)
    use_system_prompt = models.BooleanField(default=True)
    respect_context_window = models.BooleanField(default=True)
    avatar = models.CharField(max_length=100, default=random_avatar)

    def __str__(self):
        return self.name

    def clean(self):
        super().clean()
        available_models = get_models()
        if self.llm not in available_models:
            raise ValidationError({'llm': f"Selected LLM '{self.llm}' is not available. Please choose from: {', '.join(available_models)}"})

    def get_tool_settings(self, tool):
        """Get settings for a specific tool."""
        return self.tool_settings.filter(tool=tool).first()

    def get_forced_output_tools(self):
        """Get all tools that have force_output_as_result=True."""
        return self.tools.filter(
            id__in=self.tool_settings.filter(
                force_output_as_result=True
            ).values_list('tool_id', flat=True)
        )

    def has_force_output_enabled(self, tool):
        """Check if force output is enabled for a specific tool."""
        tool_setting = self.tool_settings.filter(tool=tool).first()
        return tool_setting.force_output_as_result if tool_setting else False

class Task(models.Model):
    description = models.TextField()
    agent = models.ForeignKey(Agent, on_delete=models.SET_NULL, null=True, blank=True)
    expected_output = models.TextField()
    tools = models.ManyToManyField(Tool, blank=True)
    async_execution = models.BooleanField(default=False)
    context = models.ManyToManyField('self', symmetrical=False, blank=True)
    config = models.JSONField(null=True, blank=True)
    output_json = models.CharField(max_length=255, null=True, blank=True)
    output_pydantic = models.CharField(max_length=255, null=True, blank=True)
    output_file = models.CharField(max_length=255, null=True, blank=True)
    output = models.TextField(null=True, blank=True)
    callback = models.CharField(max_length=255, null=True, blank=True)
    human_input = models.BooleanField(default=False)
    converter_cls = models.CharField(max_length=255, null=True, blank=True)
    crew_execution = models.ForeignKey('CrewExecution', on_delete=models.CASCADE, null=True, blank=True)

    def __str__(self):
        return self.description[:50]

    def save_output_file(self, content):
        if self.output_file:
            file_name = os.path.basename(self.output_file)
        else:
            file_name = f"task_{self.id}_output.txt"
        
        file_path = user_directory_path(self, file_name)
        full_path = os.path.join(settings.MEDIA_ROOT, file_path)
        
        os.makedirs(os.path.dirname(full_path), exist_ok=True)
        
        with open(full_path, 'w') as f:
            f.write(content)
        
        self.output_file = file_path
        self.save()

class Crew(models.Model):
    name = models.CharField(max_length=100)
    agents = models.ManyToManyField(Agent)
    tasks = models.ManyToManyField(Task, through='CrewTask')
    process = models.CharField(max_length=20, choices=[('sequential', 'Sequential'), ('hierarchical', 'Hierarchical')], default='sequential')
    verbose = models.BooleanField(default=False)
    manager_llm = models.CharField(max_length=100, null=True, blank=True, default=settings.GENERAL_MODEL)
    function_calling_llm = models.CharField(max_length=100, null=True, blank=True, default=settings.GENERAL_MODEL)
    config = models.JSONField(null=True, blank=True)
    max_rpm = models.IntegerField(null=True, blank=True)
    language = models.CharField(max_length=50, default='English')
    language_file = models.CharField(max_length=255, null=True, blank=True)
    memory = models.BooleanField(default=False)
    cache = models.BooleanField(default=True)
    embedder = models.JSONField(default=default_embedder)
    full_output = models.BooleanField(default=False)
    share_crew = models.BooleanField(default=False)
    output_log_file = models.CharField(max_length=255, null=True, blank=True)
    manager_agent = models.ForeignKey(Agent, on_delete=models.SET_NULL, null=True, blank=True, related_name='managed_crews')
    manager_callbacks = models.JSONField(null=True, blank=True)
    prompt_file = models.CharField(max_length=255, null=True, blank=True)
    planning = models.BooleanField(default=False)
    planning_llm = models.CharField(max_length=100, null=True, blank=True, default=settings.GENERAL_MODEL)
    input_variables = ArrayField(
        models.CharField(max_length=100),
        blank=True,
        null=True,
        default=list
    )

    def __str__(self):
        return self.name

class CrewExecution(models.Model):
    crew = models.ForeignKey(Crew, on_delete=models.CASCADE)
    status = models.CharField(max_length=25, choices=[
        ('PENDING', 'Pending'),
        ('RUNNING', 'Running'),
        ('WAITING_FOR_HUMAN_INPUT', 'Waiting for Human Input'),
        ('COMPLETED', 'Completed'),
        ('FAILED', 'Failed')
    ], default='PENDING')
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)
    inputs = models.JSONField(null=True, blank=True)
    client = models.ForeignKey('seo_manager.Client', on_delete=models.CASCADE, null=True)
    user = models.ForeignKey(User, on_delete=models.CASCADE, null=True)
    crew_output = models.OneToOneField('CrewOutput', on_delete=models.SET_NULL, null=True, blank=True, related_name='crew_execution')
    task_id = models.CharField(max_length=100, null=True, blank=True)
    human_input_request = models.JSONField(null=True, blank=True)
    human_input_response = models.JSONField(null=True, blank=True)
    error_message = models.TextField(blank=True, null=True)

    def __str__(self):
        return f"{self.crew.name} - {self.created_at}"

    def save_task_output_file(self, task, content):
        task.crew_execution = self
        task.save_output_file(content)

class CrewMessage(models.Model):
    execution = models.ForeignKey(CrewExecution, on_delete=models.CASCADE, related_name='messages')
    content = models.TextField()
    timestamp = models.DateTimeField(auto_now_add=True)
    agent = models.CharField(max_length=255, null=True, blank=True)
    crewai_task_id = models.IntegerField(null=True, blank=True)  # For kanban board placement

    def __str__(self):
        return f"{self.timestamp}: {self.content[:50]}"

class Pipeline(models.Model):
    id = models.UUIDField(primary_key=True, default=uuid.uuid4, editable=False)
    name = models.CharField(max_length=100)
    description = models.TextField(blank=True)
    status = models.CharField(max_length=20, default='Idle')
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)

    def __str__(self):
        return self.name

    def clean(self):
        # Validate that stages are properly structured
        stages = self.stages.all().order_by('order')
        for stage in stages:
            if stage.is_parallel:
                if stage.crew is not None:
                    raise ValidationError("Parallel stages should not have a single crew assigned.")
            else:
                if stage.crew is None:
                    raise ValidationError("Sequential stages must have a crew assigned.")

class PipelineStage(models.Model):
    pipeline = models.ForeignKey(Pipeline, related_name='stages', on_delete=models.CASCADE)
    name = models.CharField(max_length=100)
    crew = models.ForeignKey('Crew', on_delete=models.SET_NULL, null=True, blank=True)
    order = models.PositiveIntegerField()
    is_parallel = models.BooleanField(default=False)
    is_router = models.BooleanField(default=False)

    class Meta:
        ordering = ['order']

    def __str__(self):
        return f"{self.pipeline.name} - {self.name}"

    def clean(self):
        if self.is_router and self.crew is not None:
            raise ValidationError("Router stages should not have a crew assigned.")

class PipelineRoute(models.Model):
    stage = models.ForeignKey(PipelineStage, related_name='routes', on_delete=models.CASCADE)
    name = models.CharField(max_length=100)
    condition = models.TextField()  # This would store a serialized form of the condition
    target_pipeline = models.ForeignKey(Pipeline, on_delete=models.CASCADE)

    def __str__(self):
        return f"{self.stage.name} - {self.name}"

class PipelineExecution(models.Model):
    id = models.UUIDField(primary_key=True, default=uuid.uuid4, editable=False)
    pipeline = models.ForeignKey(Pipeline, on_delete=models.CASCADE)
    user = models.ForeignKey(User, on_delete=models.CASCADE)
    status = models.CharField(max_length=20, default='Pending')
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)

    def __str__(self):
        return f"{self.pipeline.name} Execution - {self.created_at}"

class PipelineRunResult(models.Model):
    execution = models.ForeignKey(PipelineExecution, related_name='run_results', on_delete=models.CASCADE)
    raw_output = models.TextField(blank=True)
    json_output = models.JSONField(null=True, blank=True)
    pydantic_output = models.TextField(null=True, blank=True)  # This would store a serialized form of the Pydantic model
    token_usage = models.JSONField(null=True, blank=True)
    trace = models.JSONField(null=True, blank=True)

    def __str__(self):
        return f"Run Result for {self.execution.pipeline.name}"

class CrewOutput(models.Model):
    raw = models.TextField()
    pydantic = models.JSONField(null=True, blank=True)
    json_dict = models.JSONField(null=True, blank=True)
    token_usage = models.JSONField(null=True, blank=True)

    @property
    def json(self):
        return json.dumps(self.json_dict) if self.json_dict else None

    def to_dict(self):
        return self.json_dict or (self.pydantic.dict() if self.pydantic else None) or {}

    def __str__(self):
        if self.pydantic:
            return str(self.pydantic)
        elif self.json_dict:
            return json.dumps(self.json_dict)
        else:
            return self.raw

    def save(self, *args, **kwargs):
        # Convert UsageMetrics to a dictionary if it's not already
        if self.token_usage and hasattr(self.token_usage, 'dict'):
            self.token_usage = self.token_usage.dict()
        super().save(*args, **kwargs)

class CrewTask(models.Model):
    crew = models.ForeignKey(Crew, on_delete=models.CASCADE, related_name='crew_tasks')
    task = models.ForeignKey(Task, on_delete=models.CASCADE)
    order = models.PositiveIntegerField(default=0)

    class Meta:
        ordering = ['order']
        unique_together = ('crew', 'task')

    def __str__(self):
        return f"{self.crew.name} - {self.task.description} (Order: {self.order})"

class AgentToolSettings(models.Model):
    agent = models.ForeignKey('Agent', on_delete=models.CASCADE, related_name='tool_settings')
    tool = models.ForeignKey('Tool', on_delete=models.CASCADE)
    force_output_as_result = models.BooleanField(default=False)

    class Meta:
        unique_together = ('agent', 'tool')

class ChatMessage(models.Model):
    session_id = models.UUIDField(default=uuid.uuid4)
    agent = models.ForeignKey('Agent', on_delete=models.CASCADE)
    user = models.ForeignKey(settings.AUTH_USER_MODEL, on_delete=models.CASCADE)
    content = models.TextField()
    is_agent = models.BooleanField()
    timestamp = models.DateTimeField(auto_now_add=True)
    model = models.CharField(max_length=100)

    class Meta:
        ordering = ['timestamp']

class ExecutionStage(models.Model):
    STAGE_TYPES = [
        ('task_start', 'Task Start'),
        ('thinking', 'Thinking'),
        ('tool_usage', 'Tool Usage'),
        ('tool_results', 'Tool Results'),
        ('human_input', 'Human Input'),
        ('completion', 'Completion')
    ]
    
    STATUS_CHOICES = [
        ('pending', 'Pending'),
        ('in_progress', 'In Progress'),
        ('completed', 'Completed'),
        ('failed', 'Failed')
    ]
    
    execution = models.ForeignKey(CrewExecution, on_delete=models.CASCADE, related_name='stages')
    stage_type = models.CharField(max_length=20, choices=STAGE_TYPES)
    title = models.CharField(max_length=200)
    content = models.TextField()
    status = models.CharField(max_length=20, choices=STATUS_CHOICES, default='pending')
    agent = models.ForeignKey(Agent, on_delete=models.SET_NULL, null=True, blank=True)
    metadata = models.JSONField(default=dict)
    crewai_task_id = models.IntegerField(null=True, blank=True)  # For kanban board placement
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)
    
    class Meta:
        ordering = ['created_at']
        verbose_name = 'Execution Stage'
        verbose_name_plural = 'Execution Stages'
    
    def __str__(self):
        return f"{self.get_stage_type_display()} - {self.title}"

class Conversation(models.Model):
    session_id = models.UUIDField(unique=True)
    user = models.ForeignKey(get_user_model(), on_delete=models.CASCADE)
    agent = models.ForeignKey('Agent', on_delete=models.SET_NULL, null=True)
    client = models.ForeignKey('seo_manager.Client', on_delete=models.SET_NULL, null=True)
    title = models.CharField(max_length=255)
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)
    is_active = models.BooleanField(default=True)

    class Meta:
        ordering = ['-updated_at']

    def __str__(self):
        return f"{self.title} ({self.created_at.strftime('%Y-%m-%d %H:%M')})"

================
File: routing.py
================
from django.urls import re_path
from .consumers import ConnectionTestConsumer, ChatConsumer, CrewExecutionConsumer
from .kanban_consumers import CrewKanbanConsumer

websocket_urlpatterns = [
    re_path(r'ws/chat/$', ChatConsumer.as_asgi()),
    re_path(r'ws/crew_execution/(?P<execution_id>\w+)/$', CrewExecutionConsumer.as_asgi()),
    re_path(r'ws/test-connection/$', ConnectionTestConsumer.as_asgi()),
]
