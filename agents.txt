This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repomix on: 2025-02-06T15:34:00.856Z

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Repository structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.

Additional Info:
----------------

For more information about Repomix, visit: https://github.com/yamadashy/repomix

================================================================
Repository Structure
================================================================
chat/
  formatters/
    output_formatter.py
    table_formatter.py
    tool_formatter.py
  managers/
    crew_manager.py
    message_manager.py
    prompt_manager.py
    token_manager.py
    tool_manager.py
  tests/
    test_callback_handler.py
  history.py
clients/
  manager.py
integrations/
  slack_bot.py
  slack_message_formatter.py
static/
  agents/
    css/
      chat.css
      content_expander.css
      crew_kanban.css
    js/
      chat/
        app.js
      components/
        tool_outputs/
          base.js
        message_list.js
        message.js
      modules/
        content_expander.js
      services/
        message_handler.js
        websocket.js
      crew_kanban.js
tasks/
  callbacks/
    execution.py
    tool.py
  core/
    agents.py
    crew.py
    tasks.py
  handlers/
    input.py
  messaging/
    execution_bus.py
  utils/
    context.py
    logging.py
    tools.py
  tools.py
templates/
  agents/
    modals/
      details_modal.html
      human_input_modal.html
      start_execution_modal.html
    agent_form.html
    base_agents.html
    chat.html
    confirm_delete.html
    connection_test.html
    crew_detail.html
    crew_form.html
    crew_kanban.html
    crew_list.html
    crewai_home.html
    dashboard_home.html
    execution_detail.html
    execution_list.html
    manage_agents_card_view.html
    manage_agents.html
    manage_crews_card_view.html
    manage_crews.html
    manage_tasks.html
    manage_tools.html
    task_form.html
    tool_form.html
templatetags/
  agent_filters.py
  agent_tags.py
tests/
  integration/
    test_callback_flow.py
  test_file_writer_tool.py
tools/
  browser_tool/
    browser_tool.py
    test_browser_tool.py
  business_credibility_tool/
    business_credibility_tool.py
  client_profile_tool/
    client_profile_tool.py
  code_interpreter_tool/
    code_interpreter_tool.py
    Dockerfile
    README.md
  competitor_tools/
    competitor_tools.py
  compression_tool/
    compression_tool.py
  content_expertise_tool/
    content_expertise_tool.py
  crawl_website_tool/
    crawl_website_tool.py
    test_crawl_website_tool.py
    utils.py
  crewai_file_writer/
    crewai_file_writer.py
  csv_search_tool/
    csv_search_tool.py
    README.md
  directory_read_tool/
    directory_read_tool.py
    README.md
  directory_search_tool/
    directory_search_tool.py
    README.md
  docx_search_tool/
    docx_search_tool.py
    README.md
  file_read_tool/
    file_read_tool.py
    README.md
  file_writer_tool/
    file_writer_tool.py
    README.md
  google_analytics_tool/
    generic_google_analytics_tool.py
    google_analytics_tool.py
  google_overview_tool/
    google_overview_tool.py
  google_report_tool/
    google_rankings_tool.py
    google_report_tool.py
  google_search_console_tool/
    generic_google_search_console_tool.py
  google_suggestions_tool/
    google_suggestions_tool.py
  keyword_tools/
    keyword_tools.py
    ranked_keywords_tool.py
  neuralami_api_tool/
    neuralami_api_tool.py
  pagespeed_tool/
    pagespeed_tool.py
  pandas_ai_tool/
    pandas_ai_tool.py
    README.md
  rag/
    rag_tool.py
    README.md
  screenshot_tool/
    screenshot_tool.py
  search_context_tool/
    search_context_tool.py
    test_search_context_tool.py
  searxng_tool/
    searxng_tool.py
  seo_audit_tool/
    content_type_detector.py
    seo_audit_tool.py
    seo_checkers.py
  seo_crawler_tool/
    seo_crawler_tool.py
  website_distiller_tool/
    website_distiller_tool.py
  wordpress/
    base.py
    content_tool.py
    meta_tool.py
    post_tool.py
    reader_tool.py
  youtube_video_search_tool/
    youtube_video_search_tool.py
  analytics_tool.py
  base_tool.py
  manager.py
  pandasai.md
  tool_design.md
  utils.py
utils/
  error_handling.py
  formatters.py
websockets/
  handlers/
    agent_handler.py
    callback_handler.py
  services/
    chat_service.py
    crew_chat_service.py
  base.py
  chat_consumer.py
admin.py
apps.py
celery.py
consumers.py
forms.py
kanban_consumers.py
models.py
README.md
tasks.py
tools.py
urls.py
utils.py
views_agents.py
views_chat.py
views_crews.py
views_kanban.py
views_tasks.py
views_tools.py
views.py

================================================================
Repository Files
================================================================

================
File: chat/formatters/output_formatter.py
================
import json
import logging
from typing import Any, Dict

from .table_formatter import TableFormatter

logger = logging.getLogger(__name__)

class OutputFormatter:
    """Handles general output formatting"""
    
    @staticmethod
    def format_response(response: Dict) -> str:
        """Format agent response"""
        try:
            output = response.get("output")
            if not output:
                return "No response generated"
                
            # If output is a dict, check for tabular data
            if isinstance(output, dict):
                if "formatted_table" in output:
                    return output["formatted_table"]
                if TableFormatter.detect_tabular_data(output):
                    return TableFormatter.format_table(output)
                return json.dumps(output, indent=2)
                
            # If output is a string but contains JSON, try to parse and format
            if isinstance(output, str) and (output.startswith('{') or output.startswith('[')):
                try:
                    json_data = json.loads(output)
                    if "formatted_table" in json_data:
                        return json_data["formatted_table"]
                    if TableFormatter.detect_tabular_data(json_data):
                        return TableFormatter.format_table(json_data)
                    return json.dumps(json_data, indent=2)
                except json.JSONDecodeError:
                    pass
                    
            return output

        except Exception as e:
            logger.error(f"Error formatting response: {str(e)}", exc_info=True)
            return "Error formatting response"

    @staticmethod
    def format_final_answer(content: Any) -> str:
        """Format the final agent response"""
        try:
            # Format as table if possible
            if TableFormatter.detect_tabular_data(content):
                content = TableFormatter.format_table(content)
            return f'<div class="agent-response">{content}</div>'
        except Exception as e:
            logger.error(f"Error formatting final answer: {str(e)}")
            return str(content)

================
File: chat/formatters/table_formatter.py
================
from typing import Any, Dict, List, Union
import json
import logging

logger = logging.getLogger(__name__)

class TableFormatter:
    """Generic table formatter for structured data"""
    
    @staticmethod
    def _is_json(data: str) -> bool:
        """Check if string is valid JSON"""
        try:
            json.loads(data)
            return True
        except (json.JSONDecodeError, TypeError):
            return False

    @staticmethod
    def _is_csv(data: str) -> bool:
        """Check if string appears to be CSV data"""
        if not isinstance(data, str):
            return False
        return (',' in data and 
                '\n' in data and 
                '{' not in data and 
                '[' not in data)

    @staticmethod
    def _parse_csv(csv_data: str) -> List[Dict]:
        """Convert CSV string to list of dictionaries"""
        try:
            lines = csv_data.strip().split('\n')
            headers = [h.strip() for h in lines[0].split(',')]
            
            return [
                {
                    headers[i]: value.strip() 
                    for i, value in enumerate(line.split(','))
                    if i < len(headers)
                }
                for line in lines[1:]
            ]
        except Exception as e:
            logger.error(f"Error parsing CSV: {str(e)}", exc_info=True)
            return []

    @staticmethod
    def _find_tabular_data(data: Any) -> Union[List[Dict], None]:
        """
        Recursively search for tabular data in the structure.
        Returns the first found list of dictionaries with consistent keys.
        """
        # Handle string input
        if isinstance(data, str):
            if TableFormatter._is_json(data):
                try:
                    data = json.loads(data)
                except json.JSONDecodeError:
                    return None
            elif TableFormatter._is_csv(data):
                return TableFormatter._parse_csv(data)
            else:
                return None

        # Handle list of dictionaries
        if isinstance(data, list) and data:
            if all(isinstance(item, dict) for item in data):
                # Get all unique keys from all objects
                keys = set().union(*(item.keys() for item in data))
                if keys:  # If we have keys, it's tabular
                    return data
            
            # Check each list item for nested tabular data
            for item in data:
                result = TableFormatter._find_tabular_data(item)
                if result:
                    return result

        # Handle dictionary
        if isinstance(data, dict):
            # First check direct values
            for value in data.values():
                if isinstance(value, list) and value:
                    if all(isinstance(item, dict) for item in value):
                        return value
            
            # Then check nested structures
            for value in data.values():
                result = TableFormatter._find_tabular_data(value)
                if result:
                    return result

        return None

    @staticmethod
    def detect_tabular_data(data: Any) -> bool:
        """Detect if data contains tabular structure anywhere in the hierarchy"""
        try:
            return TableFormatter._find_tabular_data(data) is not None
        except Exception:
            logger.error("Error detecting tabular data", exc_info=True)
            return False

    @staticmethod
    def format_table(data: Any) -> str:
        """Format tabular data into a markdown table"""
        try:
            tabular_data = TableFormatter._find_tabular_data(data)
            if not tabular_data:
                return str(data)

            # Get all unique keys from all objects
            keys = list(set().union(*(item.keys() for item in tabular_data)))
            
            # Calculate column widths
            col_widths = {key: len(str(key)) for key in keys}
            for row in tabular_data:
                for key in keys:
                    value = row.get(key)
                    if value is None:
                        continue
                    elif isinstance(value, (dict, list)):
                        str_value = json.dumps(value)
                    else:
                        str_value = str(value)
                    col_widths[key] = max(col_widths[key], len(str_value))

            # Build table
            # Header row
            table = "| " + " | ".join(
                str(key).ljust(col_widths[key]) 
                for key in keys
            ) + " |\n"
            
            # Separator row
            table += "|" + "|".join(
                "-" * (col_widths[key] + 2) 
                for key in keys
            ) + "|\n"
            
            # Data rows
            for row in tabular_data:
                table += "| " + " | ".join(
                    str(row.get(key, '')).ljust(col_widths[key]) 
                    for key in keys
                ) + " |\n"

            return table

        except Exception as e:
            logger.error(f"Error formatting table: {str(e)}", exc_info=True)
            return str(data)  # Return original data if formatting fails

================
File: chat/formatters/tool_formatter.py
================
import json
import logging
from typing import Any, Dict

from .table_formatter import TableFormatter

logger = logging.getLogger(__name__)

class ToolFormatter:
    """Handles formatting of tool outputs and usage messages"""
    
    @staticmethod
    def format_tool_output(content: Any) -> str:
        """Format tool output with proper styling"""
        try:
            if isinstance(content, dict):
                return f'<div class="json-output">{json.dumps(content, indent=2)}</div>'
            elif isinstance(content, str):
                # Try to parse as JSON first
                try:
                    json_content = json.loads(content)
                    return f'<div class="json-output">{json.dumps(json_content, indent=2)}</div>'
                except json.JSONDecodeError:
                    pass
                
                # Format as table if possible
                if TableFormatter.detect_tabular_data(content):
                    content = TableFormatter.format_table(content)
            
            return f'<div class="tool-output">{content}</div>'
        except Exception as e:
            logger.error(f"Error formatting tool output: {str(e)}")
            return str(content)

    @staticmethod
    def format_tool_usage(content: str, message_type: str = None) -> str:
        """Format tool usage messages"""
        if message_type == "tool_start" and content.startswith('Using tool:'):
            tool_info = content.split('\n')
            formatted = f'''
            <div class="tool-usage">
                <i class="fas fa-tools"></i>
                <div>
                    <strong>{tool_info[0]}</strong>
                    <div class="tool-input">{tool_info[1] if len(tool_info) > 1 else ''}</div>
                </div>
            </div>
            '''
            return formatted
        elif message_type == "tool_error":
            return f'''
            <div class="tool-error">
                <i class="fas fa-exclamation-triangle"></i>
                <div>{content}</div>
            </div>
            '''
        return content

    @staticmethod
    def format_tool_result(observation: Any) -> Dict:
        """Format tool output into a standardized structure"""
        try:
            result_data = {
                'tool_type': None,
                'format': None,
                'data': None,
                'metadata': {}
            }

            if isinstance(observation, dict):
                # Handle tabular data
                if TableFormatter.detect_tabular_data(observation):
                    result_data.update({
                        'tool_type': observation.get('type', 'generic'),
                        'format': 'table',
                        'data': TableFormatter.format_table(observation),
                        'metadata': {
                            'raw_data': observation.get('raw_data', {}),
                            'tool': observation.get('tool')
                        }
                    })
                
                # Handle validation errors
                elif observation.get('type') == 'error':
                    result_data.update({
                        'tool_type': 'error',
                        'format': 'error',
                        'data': {
                            'message': observation.get('message'),
                            'error_type': observation.get('error'),
                            'suggestion': observation.get('suggestion')
                        }
                    })
                
                # Handle other structured data
                else:
                    result_data.update({
                        'tool_type': observation.get('type', 'generic'),
                        'format': 'json',
                        'data': json.dumps(observation, indent=2),
                        'metadata': {
                            'tool': observation.get('tool')
                        }
                    })

            return result_data

        except Exception as e:
            logger.error(f"Error formatting tool result: {str(e)}", exc_info=True)
            return {
                'tool_type': 'error',
                'format': 'error',
                'data': {
                    'message': str(e),
                    'error_type': 'formatting_error'
                }
            }

================
File: chat/managers/crew_manager.py
================
import logging
from typing import Optional, Dict, Any
from django.core.cache import cache
from django.utils import timezone
from apps.agents.models import CrewExecution

logger = logging.getLogger(__name__)

class CrewManager:
    """Manages message context for crew chats"""
    
    def __init__(self):
        self.execution = None
        self.context_key = None
    
    async def initialize(self, execution: CrewExecution):
        """Initialize message context for crew execution"""
        self.execution = execution
        self.context_key = f"crew_chat_context_{execution.id}"
        
        # Initialize context in cache if not exists
        if not cache.get(self.context_key):
            # Create base context
            context = {
                'messages': [],
                'task_outputs': {},
                'current_task': None,
                'execution_id': execution.id,
                'current_date': timezone.now().strftime("%Y-%m-%d")
            }
            
            cache.set(self.context_key, context, timeout=3600)  # 1 hour timeout
    
    async def add_message_to_context(self, message: str):
        """Add a message to the crew chat context"""
        if not self.context_key:
            raise ValueError("Context not initialized")
            
        try:
            context = cache.get(self.context_key, {})
            messages = context.get('messages', [])
            
            # Add message to context
            messages.append({
                'content': message,
                'timestamp': str(timezone.now()),
                'is_human': True
            })
            
            # Keep only last 50 messages
            if len(messages) > 50:
                messages = messages[-50:]
            
            context['messages'] = messages
            cache.set(self.context_key, context, timeout=3600)
            
        except Exception as e:
            logger.error(f"Error adding message to context: {str(e)}")
            raise
    
    async def add_task_output(self, task_id: int, output: Dict[str, Any]):
        """Add task output to context"""
        if not self.context_key:
            raise ValueError("Context not initialized")
            
        try:
            context = cache.get(self.context_key, {})
            task_outputs = context.get('task_outputs', {})
            
            # Add task output
            task_outputs[str(task_id)] = output
            context['task_outputs'] = task_outputs
            
            cache.set(self.context_key, context, timeout=3600)
            
        except Exception as e:
            logger.error(f"Error adding task output: {str(e)}")
            raise
    
    async def get_context(self) -> Dict[str, Any]:
        """Get current crew chat context"""
        if not self.context_key:
            raise ValueError("Context not initialized")
            
        return cache.get(self.context_key, {})
    
    async def update_current_task(self, task_id: Optional[int]):
        """Update current task in context"""
        if not self.context_key:
            raise ValueError("Context not initialized")
            
        try:
            context = cache.get(self.context_key, {})
            context['current_task'] = task_id
            cache.set(self.context_key, context, timeout=3600)
            
        except Exception as e:
            logger.error(f"Error updating current task: {str(e)}")
            raise

================
File: chat/managers/message_manager.py
================
from langchain_core.chat_history import BaseChatMessageHistory
from langchain_core.messages import BaseMessage, AIMessage, HumanMessage, SystemMessage
from django.core.cache import cache
from typing import List, Optional, Dict, Any
from channels.db import database_sync_to_async
from apps.agents.chat.formatters.tool_formatter import ToolFormatter
from apps.agents.chat.formatters.table_formatter import TableFormatter
from apps.agents.models import ChatMessage, ToolRun
import logging
import json
from django.db import models

logger = logging.getLogger(__name__)

def messages_to_dict(messages: List[BaseMessage]) -> List[Dict]:
    """Convert message objects to dictionary format for storage."""
    return [{
        'type': message.__class__.__name__,
        'content': message.content,
        'additional_kwargs': message.additional_kwargs
    } for message in messages]

def dict_to_messages(messages_dict: List[Dict]) -> List[BaseMessage]:
    """Convert dictionary format back to message objects."""
    message_types = {
        'HumanMessage': HumanMessage,
        'AIMessage': AIMessage,
        'SystemMessage': SystemMessage
    }
    
    return [
        message_types[msg['type']](
            content=msg['content'],
            additional_kwargs=msg.get('additional_kwargs', {})
        ) for msg in messages_dict
    ]

class MessageManager(BaseChatMessageHistory):
    """
    Manages chat message history, storage, and formatting.
    Consolidates message-related functionality from across the codebase.
    """
    
    def __init__(self, 
                 conversation_id: Optional[str] = None,
                 session_id: Optional[str] = None,
                 agent_id: Optional[int] = None,
                 ttl: int = 3600):
        """
        Initialize the MessageManager.
        
        Args:
            conversation_id: Unique identifier for the conversation
            session_id: Unique identifier for the current session
            agent_id: ID of the agent associated with this conversation
            ttl: Time-to-live for cached messages in seconds
        """
        super().__init__()
        self.conversation_id = conversation_id
        self.session_id = session_id
        self.agent_id = agent_id
        self.ttl = ttl
        self.tool_formatter = ToolFormatter()
        self.messages_cache_key = f"messages_{self.session_id}"
        self._messages = []

    @property
    def messages(self) -> List[BaseMessage]:
        """Get all messages in the history. Required by BaseChatMessageHistory."""
        if self.messages_cache_key:
            messages_dict = cache.get(self.messages_cache_key, [])
            return dict_to_messages(messages_dict)
        return self._messages.copy()

    @messages.setter
    def messages(self, messages: List[BaseMessage]) -> None:
        """Set messages in the history. Required by BaseChatMessageHistory."""
        self._messages = messages.copy()
        if self.messages_cache_key:
            messages_dict = messages_to_dict(messages)
            cache.set(self.messages_cache_key, messages_dict, self.ttl)

    async def add_message(self, message: BaseMessage, token_usage: Optional[Dict] = None) -> Optional[ChatMessage]:
        """
        Add a message to the history and persist it.
        This is the central function for all message persistence.
        
        Args:
            message: The message to add
            token_usage: Optional token usage stats
            
        Returns:
            ChatMessage: The created message object, or None if creation failed
        """
        try:
            # For agent finish messages, extract JSON data if present
            if isinstance(message, AIMessage) and message.content:
                # Look for JSON code blocks
                if '```json' in message.content:
                    parts = message.content.split('```json')
                    if len(parts) > 1:
                        text_content = parts[0].strip()
                        json_str = parts[1].split('```')[0].strip()
                        try:
                            # Validate JSON
                            json_data = json.loads(json_str)
                            # Store as separate messages
                            if text_content:
                                await self._store_message_in_db(AIMessage(content=text_content), token_usage)
                            message.content = json.dumps(json_data)
                        except json.JSONDecodeError:
                            # If JSON is invalid, keep original message
                            pass

            # Store in database only if we have a conversation ID
            if self.conversation_id:
                return await self._store_message_in_db(message, token_usage)
            return None
                
        except Exception as e:
            logger.error(f"Error adding message: {str(e)}")
            raise

    async def get_messages(self) -> List[BaseMessage]:
        """Get all non-deleted messages in the history."""
        try:
            if self.conversation_id:
                from apps.agents.models import ChatMessage, ToolRun
                
                # First get non-deleted messages
                query = {
                    'conversation_id': self.conversation_id,
                    'is_deleted': False  # Only get non-deleted messages
                }
                    
                messages = await database_sync_to_async(
                    lambda: list(
                        ChatMessage.objects.filter(**query)
                        .prefetch_related(
                            # Only prefetch tool runs associated with non-deleted messages
                            models.Prefetch(
                                'tool_runs',
                                queryset=ToolRun.objects.filter(
                                    message__is_deleted=False,
                                    is_deleted=False
                                )
                            )
                        )
                        .order_by('timestamp')
                    )
                )()

                result = []
                for msg in messages:
                    if not msg.is_agent:
                        # Human messages
                        result.append(HumanMessage(
                            content=msg.content,
                            additional_kwargs={'id': str(msg.id)}
                        ))
                    else:
                        # AI messages
                        result.append(AIMessage(
                            content=msg.content,
                            additional_kwargs={'id': str(msg.id)}
                        ))

                # Update the in-memory cache with the loaded messages
                self._messages = result.copy()
                if self.messages_cache_key:
                    messages_dict = messages_to_dict(result)
                    cache.set(self.messages_cache_key, messages_dict, self.ttl)
                
                return result
            return self._messages.copy()
        except Exception as e:
            logger.error(f"Error getting messages: {str(e)}")
            return []

    def add_messages(self, messages: List[BaseMessage]) -> None:
        """Add multiple messages to the history."""
        for message in messages:
            self.add_message(message)

    def clear(self) -> None:
        """Required abstract method: Clear all messages."""
        pass  # No cache to clear anymore

    async def clear_messages(self) -> None:
        """Clear all messages from the history."""
        try:
            if self.conversation_id:
                await database_sync_to_async(ChatMessage.objects.filter(
                    conversation_id=self.conversation_id
                ).delete)()
                
        except Exception as e:
            logger.error(f"Error clearing messages: {str(e)}")
            raise

    @database_sync_to_async
    def _store_message_in_db(self, message: BaseMessage, token_usage: Optional[Dict] = None) -> Optional[ChatMessage]:
        """
        Store a message in the database.
        Centralized database persistence function.
        
        Returns:
            ChatMessage: The created message object, or None if creation failed
        """
        try:
            from apps.agents.models import ChatMessage, Conversation, TokenUsage, ToolRun, Tool
            
            # Get the conversation by session_id
            conversation = Conversation.objects.filter(
                session_id=self.session_id
            ).select_related('user', 'agent').first()
            
            if not conversation:
                logger.error(f"No conversation found with session ID: {self.session_id}")
                return None
                
            # Determine if message is from agent or user
            is_agent = not isinstance(message, HumanMessage)
            
            # Create the message
            chat_message = ChatMessage.objects.create(
                session_id=self.session_id,
                conversation=conversation,
                agent=conversation.agent,
                user=conversation.user,
                content=message.content,
                is_agent=is_agent,
                model=token_usage.get('model', 'unknown') if token_usage else 'unknown'
            )
            
            # Store token usage if provided
            if token_usage:
                TokenUsage.objects.create(
                    conversation=conversation,
                    message=chat_message,
                    prompt_tokens=token_usage.get('prompt_tokens', 0),
                    completion_tokens=token_usage.get('completion_tokens', 0),
                    total_tokens=token_usage.get('total_tokens', 0),
                    model=token_usage.get('model', 'unknown'),
                    metadata={'message_type': message.__class__.__name__}
                )
            
            # Store tool runs if this is a tool-related message
            if message.additional_kwargs.get('tool_call'):
                tool_call = message.additional_kwargs['tool_call']
                tool_name = tool_call.get('name')
                tool_input = tool_call.get('input', {})
                tool_output = tool_call.get('output')
                
                if tool_name:
                    tool = Tool.objects.filter(name=tool_name).first()
                    if tool:
                        # Ensure tool_output is proper JSON
                        try:
                            if isinstance(tool_output, str):
                                # If it's a string, try to parse it to ensure valid JSON
                                output_json = json.loads(tool_output)
                            else:
                                output_json = tool_output
                            # Store as JSON string
                            tool_output = json.dumps(output_json)
                        except:
                            # If not valid JSON, store as string
                            tool_output = str(tool_output)
                            
                        ToolRun.objects.create(
                            tool=tool,
                            conversation=conversation,
                            message=chat_message,
                            status='completed',
                            inputs=tool_input,
                            result=tool_output
                        )
            
            return chat_message
                
        except Exception as e:
            logger.error(f"Error storing message in database: {str(e)}", exc_info=True)
            raise


    async def handle_edit(self, message_id: str) -> None:
        """Handle message editing by marking the message and subsequent messages as deleted."""
        try:
            # Get the message's timestamp
            message = await database_sync_to_async(
                ChatMessage.objects.get
            )(id=message_id)
            
            # Mark this message and all subsequent messages as deleted
            deleted_count = await database_sync_to_async(
                ChatMessage.objects.filter(
                    conversation_id=self.conversation_id,
                    timestamp__gte=message.timestamp
                ).update
            )(is_deleted=True)
            
            # Also mark associated tool runs as deleted
            await database_sync_to_async(
                ToolRun.objects.filter(
                    conversation_id=self.conversation_id,
                    message__timestamp__gte=message.timestamp
                ).update
            )(is_deleted=True)
            
            logger.debug(f"Message timestamp: {message.timestamp}. {deleted_count} messages and their tool runs marked as deleted.")
                    
        except Exception as e:
            logger.error(f"Error handling message edit: {str(e)}")
            raise

    def format_message(self, content: Any, message_type: Optional[str] = None) -> str:
        """Format a message for display."""
        try:
            # If content is a dict, convert to string representation
            if isinstance(content, dict):
                return json.dumps(content, indent=2)
                
            # Handle tool messages
            if message_type and message_type.startswith('tool_'):
                return self.tool_formatter.format_tool_usage(str(content), message_type)
                
            return str(content)
        except Exception as e:
            logger.error(f"Error formatting message: {str(e)}")
            return str(content)

    async def get_conversation_summary(self) -> str:
        """Get a summary of the conversation."""
        messages = await self.get_messages()
        if not messages:
            return "No messages in conversation"
        
        summary_parts = []
        for msg in messages:
            msg_type = msg.__class__.__name__.replace('Message', '')
            summary_parts.append(f"{msg_type}: {msg.content[:100]}...")
        
        return "\n".join(summary_parts) 

    async def get_message_ids(self) -> Dict[str, str]:
        """Get a mapping of message content to message IDs."""
        messages = await ChatMessage.objects.filter(
            conversation_id=self.conversation_id
        ).values('id', 'content')
        return {msg['content']: str(msg['id']) for msg in messages}

================
File: chat/managers/prompt_manager.py
================
import logging
from typing import Dict, List, Optional, Any, Union
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.schema import SystemMessage, HumanMessage, AIMessage
from langchain_core.messages import BaseMessage
from django.utils import timezone
import json
from apps.common.utils import create_box

logger = logging.getLogger(__name__)

class PromptManager:
    """
    Manages prompt generation, formatting, and template management for chat agents.
    Consolidates prompt-related functionality from across the codebase.
    """
    
    def __init__(self, system_prompt: Optional[str] = None):
        """
        Initialize the PromptManager.
        
        Args:
            system_prompt: Optional system prompt to use as default
        """
        self.system_prompt = system_prompt or self._get_default_system_prompt()
        self.prompt_templates = {}
        self._box_width = 80

    def _get_default_system_prompt(self) -> str:
        """Get the default system prompt."""
        return """You are a helpful AI assistant. You aim to provide accurate, helpful responses
        while maintaining a professional and friendly tone. You will:
        1. Answer questions clearly and concisely
        2. Use appropriate tools when needed
        3. Admit when you don't know something
        4. Ask for clarification when needed
        5. Give output in markdown format"""

    def create_chat_prompt(self, 
                        system_prompt: Optional[str] = None,
                        tools: Optional[List] = None,
                        chat_history: Optional[List] = None,
                        client_data: Optional[Dict] = None) -> ChatPromptTemplate:
        """
        Create a chat prompt template with system message and message history.
        """
        # Debug logging for message template creation

        # Create the system prompt with explicit JSON format instructions
        system_template = '''{system_prompt}

    You have access to the following tools:

    {tools}

    Use a json blob to specify a tool by providing an action key (tool name) and an action_input key (tool input).

    Valid "action" values: "Final Answer" or {tool_names}

    Provide only ONE action per $JSON_BLOB, as shown:

    ```
{{
  "action": $TOOL_NAME,
  "action_input": $INPUT
}}
```


    Follow this format:

    Question: input question to answer
    Thought: consider previous and subsequent steps
    Action:
    $JSON_BLOB

    Observation: action result
    ... (repeat Thought/Action/Observation N times)
    Thought: I know what to respond
    Action:
    {{
    "action": "Final Answer",
    "action_input": "Final response to human"
    }}


    Begin! Reminder to ALWAYS respond with a valid json blob of a single action. Use tools if necessary. Respond directly if appropriate.'''

        # Format tools and descriptions
        tool_descriptions = [f"{tool.name}: {tool.description}" for tool in (tools or [])]
        tool_names = [tool.name for tool in (tools or [])]

        # Create the prompt template with proper message structure
        messages = [
            ("system", system_template),
            MessagesPlaceholder(variable_name="chat_history", optional=True),
            ("human", "{input}\n\n{agent_scratchpad}\n\n(reminder to respond in a JSON blob no matter what)"),
        ]

        
        prompt = ChatPromptTemplate.from_messages(messages)

        # Only partially fill system-level variables, NOT agent_scratchpad or chat_history
        system_variables = {
            "system_prompt": system_prompt or self.system_prompt,
            "tools": "\n".join(tool_descriptions),
            "tool_names": ", ".join(tool_names)
        }
        
        partial = prompt.partial(**system_variables)



        return partial

    def format_chat_history(self, messages: Union[str, List[BaseMessage], List[Dict]]) -> List[BaseMessage]:
        """
        Format chat history for prompt inclusion.
        Handles string, dict, and BaseMessage formats.
        Escapes any template variables in message content.
        """
        if isinstance(messages, str):
            # Try to parse string as JSON list of messages
            try:
                messages = json.loads(messages)
            except:
                return []
        
        formatted_messages = []
        for msg in messages:
            if isinstance(msg, BaseMessage):
                # Escape any template variables in content
                content = msg.content.replace("{", "{{").replace("}", "}}")
                if isinstance(msg, HumanMessage):
                    formatted_messages.append(HumanMessage(content=content))
                elif isinstance(msg, AIMessage):
                    formatted_messages.append(AIMessage(content=content))
                else:
                    formatted_messages.append(msg.__class__(content=content))
            elif isinstance(msg, dict):
                # Convert dict to appropriate message type and escape content
                content = msg.get('content', '').replace("{", "{{").replace("}", "}}")
                if msg.get('type') == 'human' or msg.get('is_user', False):
                    formatted_messages.append(HumanMessage(content=content))
                else:
                    formatted_messages.append(AIMessage(content=content))
            else:
                logger.warning(f"Unhandled message format: {type(msg)}")
                
        return formatted_messages

    def _format_context(self, context: Dict) -> str:
        """Format additional context into a string."""
        context_parts = []
        for key, value in context.items():
            if isinstance(value, (list, dict)):
                context_parts.append(f"{key}:\n{self._format_structured_value(value)}")
            else:
                context_parts.append(f"{key}: {value}")
        return "\n".join(context_parts)

    def _format_structured_value(self, value: Any, indent: int = 2) -> str:
        """Format structured values (lists/dicts) with proper indentation."""
        if isinstance(value, list):
            return "\n".join(" " * indent + f"- {item}" for item in value)
        elif isinstance(value, dict):
            return "\n".join(" " * indent + f"{k}: {v}" for k, v in value.items())
        return str(value)

    def create_tool_prompt(self, tool_name: str, tool_args: Dict) -> str:
        """Create a prompt for tool execution."""
        return f"Using tool: {tool_name}\nInput: {tool_args}"

    def create_error_prompt(self, error: str) -> str:
        """Create a prompt for error messages."""
        return f"Error occurred: {error}\nPlease try again or use a different approach."

    def register_prompt_template(self, name: str, template: str) -> None:
        """Register a new prompt template."""
        self.prompt_templates[name] = template

    def get_prompt_template(self, name: str) -> Optional[str]:
        """Get a registered prompt template."""
        return self.prompt_templates.get(name)

    def format_prompt(self, template_name: str, **kwargs) -> Optional[str]:
        """Format a registered prompt template with provided arguments."""
        template = self.get_prompt_template(template_name)
        if template:
            try:
                return template.format(**kwargs)
            except KeyError as e:
                logger.error(f"Missing required argument in prompt template: {str(e)}")
            except Exception as e:
                logger.error(f"Error formatting prompt template: {str(e)}")
        return None 

    def create_agent_prompt(self, agent, client_data: Optional[Dict] = None) -> str:
        """
        Create the system prompt for the agent with client context.
        
        Args:
            agent: The agent instance
            client_data: Optional dictionary containing client information
        """
        try:
            # Base agent prompt with escaped variables
            prompt = f"""You are {agent.name}, an AI assistant.

Role: {agent.role}

Goal: {{{{goal}}}}

Backstory: {agent.backstory if hasattr(agent, 'backstory') else ''}
"""
            # Add client context if available
            if client_data:
                client_context = self._create_client_context(client_data)
                prompt += f"\n{client_context}"
            else:
                prompt += f"\nCurrent Context:\n- Current Date: {timezone.now().strftime('%Y-%m-%d')}"

            # Replace the goal placeholder with actual goal if available
            if hasattr(agent, 'goal'):
                prompt = prompt.replace('{{goal}}', agent.goal)
            else:
                prompt = prompt.replace('{{goal}}', 'Help users accomplish their tasks effectively.')
            #logger.debug(create_box("AGENT PROMPT",f"Agent prompt: {prompt}"))
            return prompt

        except Exception as e:
            logger.error(f"Error creating agent prompt: {str(e)}", exc_info=True)
            return self._get_default_system_prompt()

    def _create_client_context(self, client_data: Dict) -> str:
        """Create formatted client context string."""
        try:
            client = client_data.get('client')
            if not client:
                return f"Current Context:\n- Current Date: {timezone.now().strftime('%Y-%m-%d')}"

            context = f"""Current Context:
- Client ID: {client.id}
- Client Name: {client.name}
- Website URL: {client.website_url}
- Target Audience: {client.target_audience or 'N/A'}
- Current Date: {timezone.now().strftime('%Y-%m-%d')}
"""
            # Add business objectives if present
            if client.business_objectives:
                objectives_text = "\n".join([f"- {obj}" for obj in client.business_objectives])
                context += f"\n\nBusiness Objectives:\n{objectives_text}"

            # Add client profile if available
            if client.client_profile:
                context += f"\n\nClient Profile:\n{client.client_profile}"

            return context

        except Exception as e:
            logger.error(f"Error creating client context: {str(e)}", exc_info=True)
            return f"Current Context:\n- Current Date: {timezone.now().strftime('%Y-%m-%d')}"

================
File: chat/managers/token_manager.py
================
import logging
import tiktoken
from django.core.cache import cache
from django.db import models
from typing import Dict, Optional, Any
from channels.db import database_sync_to_async
from apps.agents.models import TokenUsage
from apps.common.utils import get_llm
from datetime import datetime
import uuid

logger = logging.getLogger(__name__)

class TokenManager:
    """
    Manages token counting, tracking, and limits for chat conversations.
    Consolidates token-related functionality from across the codebase.
    """
    
    def __init__(self, 
                 conversation_id: Optional[str] = None,
                 session_id: Optional[str] = None,
                 max_token_limit: int = 16384,
                 model_name: str = "gpt-3.5-turbo"):
        """
        Initialize the TokenManager.
        
        Args:
            conversation_id: Unique identifier for the conversation
            session_id: Unique identifier for the current session
            max_token_limit: Maximum number of tokens allowed in conversation history
            model_name: Name of the model to use for tokenization
        """
        self.conversation_id = conversation_id
        self.session_id = session_id
        self.max_token_limit = max_token_limit
        self.model_name = model_name
        # Use the same tokenizer setup as utils.py
        self.tokenizer = tiktoken.get_encoding("cl100k_base")
        self.input_tokens = 0
        self.output_tokens = 0
        self.token_callback = None

    def count_tokens(self, text: str) -> int:
        """Count tokens in text using the initialized tokenizer."""
        try:
            return len(self.tokenizer.encode(text, disallowed_special=()))
        except Exception as e:
            logger.error(f"Error counting tokens: {str(e)}")
            return 0

    def set_token_callback(self, callback):
        """Set the token callback from the LLM."""
        self.token_callback = callback

    def track_token_usage(self, prompt_tokens: int, completion_tokens: int) -> None:
        """Track token usage for the current session."""
        self.input_tokens += prompt_tokens
        self.output_tokens += completion_tokens
        
        if self.session_id:
            session_cache_key = f"token_totals_{self.session_id}"
            session_totals = cache.get(session_cache_key, {
                'prompt_tokens': 0,
                'completion_tokens': 0,
                'total_tokens': 0
            })
            
            session_totals['prompt_tokens'] += prompt_tokens
            session_totals['completion_tokens'] += completion_tokens
            session_totals['total_tokens'] += (prompt_tokens + completion_tokens)
            
            cache.set(session_cache_key, session_totals, 3600)  # 1 hour expiry

    def get_current_usage(self) -> Dict[str, int]:
        """Get current token usage for the session."""
        if self.token_callback:
            input_tokens = getattr(self.token_callback, 'input_tokens', 0) or 0
            output_tokens = getattr(self.token_callback, 'output_tokens', 0) or 0
            return {
                'prompt_tokens': input_tokens,
                'completion_tokens': output_tokens,
                'total_tokens': input_tokens + output_tokens,
                'model': self.model_name
            }
        return {
            'prompt_tokens': self.input_tokens or 0,
            'completion_tokens': self.output_tokens or 0,
            'total_tokens': (self.input_tokens or 0) + (self.output_tokens or 0),
            'model': self.model_name
        }

    def reset_tracking(self):
        """Reset token tracking for the current session."""
        self.input_tokens = 0
        self.output_tokens = 0
        if self.token_callback:
            self.token_callback.input_tokens = 0
            self.token_callback.output_tokens = 0

    async def _reset_session_token_totals(self):
        """Reset token totals for the session."""
        if self.session_id:
            cache.delete(f"token_totals_{self.session_id}")

    @database_sync_to_async
    def store_token_usage(self, message_id: str, token_usage: Dict[str, Any]):
        """Store token usage in the database."""
        if not self.conversation_id:
            return

        try:
            TokenUsage.objects.create(
                conversation_id=self.conversation_id,
                message_id=message_id,
                prompt_tokens=token_usage.get('prompt_tokens', 0),
                completion_tokens=token_usage.get('completion_tokens', 0),
                total_tokens=token_usage.get('total_tokens', 0),
                model=token_usage.get('model', ''),
                metadata=token_usage.get('metadata', {})
            )
        except Exception as e:
            logger.error(f"Error storing token usage: {str(e)}")

    @database_sync_to_async
    def get_conversation_token_usage(self) -> Dict[str, int]:
        """Get total token usage for the conversation."""
        if not self.conversation_id:
            return {'total_tokens': 0, 'prompt_tokens': 0, 'completion_tokens': 0}

        try:
            usage = TokenUsage.objects.filter(conversation_id=self.conversation_id).aggregate(
                total_tokens=models.Sum('total_tokens'),
                prompt_tokens=models.Sum('prompt_tokens'),
                completion_tokens=models.Sum('completion_tokens')
            )
            return {
                'total_tokens': usage['total_tokens'] or 0,
                'prompt_tokens': usage['prompt_tokens'] or 0,
                'completion_tokens': usage['completion_tokens'] or 0
            }
        except Exception as e:
            logger.error(f"Error getting conversation token usage: {str(e)}")
            return {'total_tokens': 0, 'prompt_tokens': 0, 'completion_tokens': 0}

    async def track_conversation_tokens(self):
        """Track token usage for the entire conversation."""
        if not self.conversation_id:
            return

        current_usage = self.get_current_usage()
        if current_usage['total_tokens'] > 0:
            await self.store_token_usage(
                message_id=None,  # Set to None since we're tracking conversation-level usage
                token_usage={
                    **current_usage,
                    'metadata': {'type': 'conversation_tracking'}
                }
            )

================
File: chat/managers/tool_manager.py
================
import logging
from typing import List, Dict, Any, Optional
from langchain.tools import Tool, StructuredTool
from apps.agents.utils import get_tool_classes
from channels.db import database_sync_to_async
from apps.agents.chat.formatters.tool_formatter import ToolFormatter

logger = logging.getLogger(__name__)

class ToolManager:
    """
    Manages tool loading, execution, and formatting.
    Consolidates tool-related functionality from across the codebase.
    """
    
    def __init__(self):
        """Initialize the ToolManager."""
        self.tools = []
        self.tool_formatter = ToolFormatter()

    async def load_tools(self, agent) -> List[Tool]:
        """Load and initialize agent tools."""
        try:
            tools = []
            seen_tools = set()
            
            # Get tools using database_sync_to_async
            agent_tools = await self._get_agent_tools(agent)
            
            for tool_model in agent_tools:
                try:
                    tool_key = f"{tool_model.tool_class}_{tool_model.tool_subclass}"
                    if tool_key in seen_tools:
                        continue
                    seen_tools.add(tool_key)

                    tool_classes = get_tool_classes(tool_model.tool_class)
                    tool_class = next((cls for cls in tool_classes 
                                   if cls.__name__ == tool_model.tool_subclass), None)
                    
                    if tool_class:
                        tool_instance = tool_class()
                        
                        # Convert to Langchain format
                        langchain_tool = self._create_langchain_tool(tool_instance)
                        if langchain_tool:
                            tools.append(langchain_tool)
                            
                except Exception as e:
                    logger.error(f"Error initializing tool {tool_model.tool_subclass}: {str(e)}")
                    continue

            self.tools = tools
            return tools
            
        except Exception as e:
            logger.error(f"Error loading tools: {str(e)}")
            raise

    @database_sync_to_async
    def _get_agent_tools(self, agent):
        """Get agent tools from database."""
        return list(agent.tools.all())

    def _create_langchain_tool(self, tool_instance) -> Optional[Tool]:
        """Create a Langchain tool from a tool instance."""
        try:
            # Use StructuredTool if args_schema is present
            if hasattr(tool_instance, 'args_schema'):
                return StructuredTool(
                    name=tool_instance.name,
                    description=self._create_tool_description(tool_instance),
                    func=tool_instance.run,
                    coroutine=tool_instance.arun if hasattr(tool_instance, 'arun') else None,
                    args_schema=tool_instance.args_schema
                )
            else:
                return Tool(
                    name=tool_instance.name,
                    description=self._create_tool_description(tool_instance),
                    func=tool_instance.run,
                    coroutine=tool_instance.arun if hasattr(tool_instance, 'arun') else None
                )
        except Exception as e:
            logger.error(f"Error creating Langchain tool: {str(e)}")
            return None

    def _create_tool_description(self, tool_instance) -> str:
        """Create a description for the tool."""
        description = tool_instance.description
        if hasattr(tool_instance, 'args_schema'):
            schema = tool_instance.args_schema.schema()
            if 'properties' in schema:
                args_desc = []
                for name, details in schema['properties'].items():
                    arg_desc = f"- {name}: {details.get('description', 'No description')}"
                    if details.get('type'):
                        arg_desc += f" (type: {details['type']})"
                    args_desc.append(arg_desc)
                if args_desc:
                    description += "\nArguments:\n" + "\n".join(args_desc)
        return description

    async def execute_tool(self, tool_name: str, **kwargs) -> Any:
        """Execute a tool with given arguments."""
        try:
            tool = next((t for t in self.tools if t.name == tool_name), None)
            if not tool:
                raise ValueError(f"Tool not found: {tool_name}")
            
            if tool.coroutine:
                result = await tool.coroutine(**kwargs)
            else:
                result = tool.func(**kwargs)
                
            return result
            
        except Exception as e:
            logger.error(f"Error executing tool {tool_name}: {str(e)}")
            raise

    def format_tool_output(self, content: Any) -> str:
        """Format tool output for display."""
        return self.tool_formatter.format_tool_output(content)

    def format_tool_usage(self, content: str, message_type: str = None) -> str:
        """Format tool usage messages."""
        return self.tool_formatter.format_tool_usage(content, message_type)

================
File: chat/tests/test_callback_handler.py
================
import pytest
import asyncio
from unittest.mock import Mock, patch
from datetime import datetime
from langchain_core.agents import AgentFinish
from apps.agents.websockets.handlers.callback_handler import WebSocketCallbackHandler

@pytest.fixture
def mock_consumer():
    consumer = Mock()
    consumer.session_id = "test_session"
    consumer.send_json = Mock()
    return consumer

@pytest.fixture
def callback_handler(mock_consumer):
    return WebSocketCallbackHandler(consumer=mock_consumer)

@pytest.mark.asyncio
async def test_send_message(callback_handler, mock_consumer):
    test_message = {
        'type': 'test_message',
        'content': 'test content'
    }
    await callback_handler._send_message(test_message)
    mock_consumer.send_json.assert_called_once()

@pytest.mark.asyncio
async def test_tool_start(callback_handler, mock_consumer):
    serialized = {'name': 'test_tool'}
    input_str = 'test input'
    await callback_handler.on_tool_start(serialized, input_str)
    mock_consumer.send_json.assert_called_once()

@pytest.mark.asyncio
async def test_tool_end(callback_handler, mock_consumer):
    output = 'test output'
    await callback_handler.on_tool_end(output)
    mock_consumer.send_json.assert_called_once()

@pytest.mark.asyncio
async def test_agent_finish(callback_handler, mock_consumer):
    finish = AgentFinish(
        return_values={'output': 'test output'},
        log='test log'
    )
    await callback_handler.on_agent_finish(finish)
    mock_consumer.send_json.assert_called_once()

@pytest.mark.asyncio
async def test_duplicate_agent_finish_prevention(callback_handler, mock_consumer):
    finish = AgentFinish(
        return_values={'output': 'test output'},
        log='test log'
    )
    # First call should send message
    await callback_handler.on_agent_finish(finish)
    # Second call with same output should not send message
    await callback_handler.on_agent_finish(finish)
    assert mock_consumer.send_json.call_count == 1

@pytest.mark.asyncio
async def test_message_lock(callback_handler, mock_consumer):
    # Test that message lock prevents concurrent sends
    async def send_messages():
        messages = [{'type': f'msg_{i}'} for i in range(5)]
        await asyncio.gather(*[callback_handler._send_message(msg) for msg in messages])
    
    await send_messages()
    assert mock_consumer.send_json.call_count == 5

================
File: chat/history.py
================
from langchain_core.chat_history import BaseChatMessageHistory
from langchain_core.messages import BaseMessage
from typing import List, Optional, Dict
import logging
from apps.agents.models import ChatMessage

logger = logging.getLogger(__name__)

class DjangoCacheMessageHistory(BaseChatMessageHistory):
    """Message history that uses Django's cache and database for storage."""
    
    def __init__(self, session_id: str, conversation_id: Optional[str] = None, agent_id: Optional[int] = None, ttl: int = 3600):
        """Initialize with session ID and optional conversation ID."""
        # Store these as instance variables since they're used by other parts of the system
        self.session_id = session_id
        self.conversation_id = conversation_id
        self.agent_id = agent_id
        self.ttl = ttl
        
        # Initialize the message manager for all operations
        from apps.agents.chat.managers.message_manager import MessageManager
        self.message_manager = MessageManager(
            conversation_id=conversation_id,
            session_id=session_id,
            agent_id=agent_id,
            ttl=ttl
        )

    async def aget_messages(self) -> List[BaseMessage]:
        """Get messages from the message manager."""
        try:
            return await self.message_manager.get_messages()
        except Exception as e:
            logger.error(f"Error getting messages: {str(e)}")
            return []

    async def add_message(self, message: BaseMessage, token_usage: Optional[Dict] = None) -> Optional[ChatMessage]:
        """
        Add message using the message manager.
        
        Returns:
            ChatMessage: The stored message object, or None if storage failed
        """
        try:
            return await self.message_manager.add_message(message, token_usage)
        except Exception as e:
            logger.error(f"Error adding message: {str(e)}")
            raise

    def clear(self) -> None:
        """Clear message history."""
        try:
            self.message_manager.clear()
        except Exception as e:
            logger.error(f"Error clearing messages: {str(e)}")
            raise

    async def handle_edit(self, message_id: str) -> None:
        """Handle message editing by marking messages as deleted."""
        try:
            if self.conversation_id:
                await self.message_manager.handle_edit(message_id)
        except Exception as e:
            logger.error(f"Error handling edit: {str(e)}")
            raise

================
File: clients/manager.py
================
import logging
from django.utils import timezone
from apps.seo_manager.models import Client
from channels.db import database_sync_to_async

logger = logging.getLogger(__name__)

class ClientDataManager:
    def __init__(self):
        pass

    @database_sync_to_async
    def get_client_data(self, client_id):
        """Get and format client data"""
        if not client_id:
            return {
                'client_id': None,
                'current_date': timezone.now().date().isoformat(),
            }
            
        try:
            client = Client.objects.get(id=client_id)
            current_date = timezone.now().date()
            
            return {
                'client_id': client.id,
                'current_date': current_date.isoformat(),
            }
        except Client.DoesNotExist:
            logger.info(f"No client found with ID {client_id}, returning default data")
            return {
                'client_id': None,
                'current_date': timezone.now().date().isoformat(),
            }
        except Exception as e:
            logger.error(f"Error getting client data: {str(e)}", exc_info=True)
            return {
                'client_id': None,
                'current_date': timezone.now().date().isoformat(),
            }

================
File: integrations/slack_bot.py
================
import logging
import json
from slack_bolt import App
from slack_bolt.adapter.socket_mode import SocketModeHandler
from channels.layers import get_channel_layer
from asgiref.sync import sync_to_async
from slack_sdk import WebClient
import threading
import time
from django.conf import settings
from django.db import connections
from django.db.models import Model
import uuid
import hashlib
from typing import Dict, Any, Union, List, Optional
from langchain_core.agents import AgentFinish
from .slack_message_formatter import SlackMessageFormatter

logger = logging.getLogger(__name__)

_slack_client = None

def get_client_for_channel(channel_id, team_id=None):
    """Get the client ID for a given Slack channel"""
    from apps.agents.models import SlackChannelClientMapping
    try:
        mapping = SlackChannelClientMapping.objects.get(channel_id=channel_id)
        return mapping.client_id
    except SlackChannelClientMapping.DoesNotExist:
        logger.warning(f"No client mapping found for channel {channel_id}")
        return None

def get_django_user_from_slack(user_id, team_id):
    """Get Django user from Slack user ID and team ID"""
    from apps.agents.models import UserSlackIntegration
    try:
        # Get the Slack integration for this team
        integration = UserSlackIntegration.objects.get(team_id=team_id, is_active=True)
        
        # Verify this is the correct user using Slack API
        client = WebClient(token=integration.access_token)
        user_info = client.users_info(user=user_id)
        
        if user_info['ok']:
            return integration.user
        
    except Exception as e:
        logger.error(f"Error getting Django user from Slack: {e}")
    
    return None

class SlackWebSocketClient:
    """Client for handling Slack WebSocket connections."""

    def __init__(self, channel_id, thread_ts, user_id, client_id=None):
        """Initialize the client."""
        self.channel_id = channel_id
        self.thread_ts = thread_ts
        self.user_id = user_id
        self.client_id = client_id
        
        # Create a deterministic UUID from channel and thread
        hash_input = f"slack_{channel_id}_{thread_ts}".encode('utf-8')
        hash_hex = hashlib.md5(hash_input).hexdigest()
        self.session_id = str(uuid.UUID(hash_hex))
        
        self.websocket = None
        self.say_callback = None
        self.web_client = WebClient(token=settings.DSLACK_BOT_TOKEN)

    async def connect(self, say_callback):
        """Connect to chat service WebSocket"""
        try:
            self.say_callback = say_callback
            
            # Import here to avoid circular imports
            from apps.agents.websockets.services.chat_service import ChatService
            from apps.agents.websockets.handlers.callback_handler import WebSocketCallbackHandler
            from apps.agents.models import Agent
            
            # Get default agent
            agent = await sync_to_async(Agent.objects.get)(id=25)  # TODO: Make configurable
            
            # Create custom callback handler for Slack
            class SlackCallbackHandler(WebSocketCallbackHandler):
                def __init__(self, slack_client, message_formatter, channel_id):
                    super().__init__(slack_client)
                    self.slack_client = slack_client
                    self.message_formatter = message_formatter
                    self.channel_id = channel_id

                async def on_tool_start(self, serialized: Dict[str, Any], input_str: str, **kwargs: Any):
                    """Handle tool start - send tool name and input."""
                    try:
                        # Skip internal exceptions
                        if serialized.get('name') == '_Exception':
                            return

                        tool_name = serialized.get('name', 'Unknown Tool')
                        self.slack_client.say_callback(
                            channel=self.channel_id,
                            thread_ts=self.slack_client.thread_ts,
                            blocks=[{
                                "type": "section",
                                "text": {
                                    "type": "mrkdwn",
                                    "text": f" Using tool: *{tool_name}*"
                                }
                            }, {
                                "type": "section",
                                "text": {
                                    "type": "mrkdwn",
                                    "text": f"```{input_str}```"
                                }
                            }],
                            text="Tool started"
                        )
                        
                        # Track token usage if available
                        token_usage = kwargs.get('token_usage', {})
                        if self.token_manager:
                            self.token_manager.track_token_usage(
                                token_usage.get('prompt_tokens', 0),
                                token_usage.get('completion_tokens', 0)
                            )
                    except Exception as e:
                        logger.error(f"Error in on_tool_start: {str(e)}", exc_info=True)

                async def on_tool_end(self, tool_result: Any, tool_name: str = None, **kwargs):
                    """Handle tool completion by sending the result to Slack."""
                    try:
                        # Parse the result if it's a string
                        result = json.loads(tool_result) if isinstance(tool_result, str) else tool_result
                        
                        # Format the result for Slack
                        formatted_result = self.message_formatter.format_tool_result(result)
                        
                        # If formatted result is a list of blocks
                        if isinstance(formatted_result, list):
                            # Check if we have an image block
                            image_blocks = [b for b in formatted_result if b.get('type') == 'image']
                            non_image_blocks = [b for b in formatted_result if b.get('type') != 'image']
                            
                            if image_blocks:
                                # First send non-image blocks
                                if non_image_blocks:
                                    self.slack_client.say_callback(
                                        channel=self.channel_id,
                                        thread_ts=self.slack_client.thread_ts,
                                        blocks=non_image_blocks[:50],  # Slack limit
                                        text="Tool result"
                                    )
                                
                                try:
                                    # Get time series info first
                                    time_series_info = self.message_formatter._find_time_series_data(result)
                                    if time_series_info:
                                        date_fields, metric_fields = time_series_info
                                        if date_fields and metric_fields:
                                            # Extract the data we need
                                            table_data = self.message_formatter._find_table_data(result)
                                            if table_data:
                                                # Create and upload chart
                                                chart_bytes = self.message_formatter._create_chart(
                                                    table_data,
                                                    date_fields[0],
                                                    metric_fields
                                                )
                                                
                                                # Upload file
                                                self.slack_client.files_upload_v2(
                                                    channel=self.channel_id,
                                                    thread_ts=self.slack_client.thread_ts,
                                                    file=chart_bytes,
                                                    filename="chart.png",
                                                    title="Time Series Chart"
                                                )
                                except Exception as e:
                                    logger.error(f"Error creating/uploading chart: {str(e)}", exc_info=True)
                                    # Continue without the chart
                            else:
                                # Send all blocks if no image
                                self.slack_client.say_callback(
                                    channel=self.channel_id,
                                    thread_ts=self.slack_client.thread_ts,
                                    blocks=formatted_result[:50],  # Slack limit
                                    text="Tool result"
                                )
                        else:
                            # If it's just text, send it directly
                            self.slack_client.say_callback(
                                channel=self.channel_id,
                                thread_ts=self.slack_client.thread_ts,
                                text=formatted_result
                            )
                            
                    except Exception as e:
                        logger.error(f"Error in on_tool_end: {str(e)}", exc_info=True)
                        self.slack_client.say_callback(
                            channel=self.channel_id,
                            thread_ts=self.slack_client.thread_ts,
                            text=f"Error processing tool result: {str(e)}"
                        )

                async def on_tool_error(self, error: str, **kwargs: Any):
                    """Handle tool errors"""
                    try:
                        self.slack_client.say_callback(
                            channel=self.channel_id,
                            thread_ts=self.slack_client.thread_ts,
                            blocks=[{
                                "type": "section",
                                "text": {
                                    "type": "mrkdwn",
                                    "text": f" Tool error: {error}"
                                }
                            }],
                            text="Tool error"
                        )
                        
                        # Track token usage if available
                        token_usage = kwargs.get('token_usage', {})
                        if self.token_manager:
                            self.token_manager.track_token_usage(
                                token_usage.get('prompt_tokens', 0),
                                token_usage.get('completion_tokens', 0)
                            )
                    except Exception as e:
                        logger.error(f"Error in on_tool_error: {str(e)}", exc_info=True)

                async def on_agent_finish(self, finish: AgentFinish, **kwargs: Any):
                    """Handle agent completion - send final answer."""
                    try:
                        if hasattr(finish, 'return_values'):
                            output = finish.return_values.get('output', '')
                            if output.strip():
                                self.slack_client.say_callback(
                                    channel=self.channel_id,
                                    thread_ts=self.slack_client.thread_ts,
                                    blocks=[{
                                        "type": "section",
                                        "text": {
                                            "type": "mrkdwn",
                                            "text": output
                                        }
                                    }],
                                    text="Agent finished"
                                )
                            
                            # Track token usage if available
                            token_usage = kwargs.get('token_usage', {})
                            if self.token_manager:
                                self.token_manager.track_token_usage(
                                    token_usage.get('prompt_tokens', 0),
                                    token_usage.get('completion_tokens', 0)
                                )
                                await self.token_manager.track_conversation_tokens()
                    except Exception as e:
                        logger.error(f"Error in on_agent_finish: {str(e)}", exc_info=True)
            
            # Initialize chat service with custom handler
            callback_handler = SlackCallbackHandler(
                slack_client=self,
                message_formatter=SlackMessageFormatter(),
                channel_id=self.channel_id
            )
            
            # Initialize chat service
            self.chat_service = ChatService(
                agent=agent,
                model_name="gemini/gemini-1.5-flash-002",  # TODO: Make configurable
                client_data={'client_id': self.client_id, 'user_id': self.user_id},
                callback_handler=callback_handler,
                session_id=self.session_id
            )
            
            # Initialize the service
            await self.chat_service.initialize()
            
            logger.info(f"Connected WebSocket for channel {self.channel_id}")
            
        except Exception as e:
            logger.error(f"Error connecting WebSocket: {e}", exc_info=True)
            raise

    async def send_json(self, content):
        """Callback handler uses this to send messages back to Slack"""
        if self.say_callback:
            message = content.get('message', '')
            if message:
                await sync_to_async(self.say_callback)(
                    text=message,
                    thread_ts=self.thread_ts
                )

    async def send_message(self, message):
        """Send message to chat service"""
        try:
            if not self.chat_service:
                raise Exception("WebSocket not connected")
                
            # Process message through chat service
            await self.chat_service.process_message(message)
            
        except Exception as e:
            logger.error(f"Error sending message: {e}", exc_info=True)
            if self.say_callback:
                await sync_to_async(self.say_callback)(
                    text=f"Error processing message: {str(e)}",
                    thread_ts=self.thread_ts
                )

    def say_callback(self, **kwargs):
        """Send a message to Slack."""
        return self.web_client.chat_postMessage(**kwargs)

    def files_upload_v2(self, **kwargs):
        """Upload a file to Slack using v2 API."""
        return self.web_client.files_upload_v2(**kwargs)

def process_message(message, say, is_mention=False):
    """Process a Slack message and send to chat service"""
    try:
        # Extract message details
        channel_id = message["channel"]
        user_id = message["user"]
        team_id = message.get("team")  # Get team ID from message
        text = message["text"]
        
        # Get Django user
        django_user = get_django_user_from_slack(user_id, team_id)
        if not django_user:
            logger.error(f"No Django user found for Slack user {user_id} in team {team_id}")
            say(
                text="Sorry, I couldn't find your user account. Please make sure you've connected your Slack account.",
                thread_ts=message.get('thread_ts', message.get('ts'))
            )
            return
        
        # For mentions, remove the bot mention
        if is_mention:
            text = text.split(">", 1)[1].strip()
            logger.info(f"Extracted text from mention: {text}")
        else:
            logger.info(f"Processing regular message: {text}")
        
        # Get thread_ts
        thread_ts = message.get('thread_ts', message.get('ts'))
        
        # Get client ID
        client_id = get_client_for_channel(channel_id)
        logger.info(f"Using client_id: {client_id} for channel: {channel_id}")

        # Send acknowledgment right away
        say(
            text="Processing your request...",
            thread_ts=thread_ts
        )
        
        # Create WebSocket client
        client = SlackWebSocketClient(
            channel_id=channel_id,
            thread_ts=thread_ts,
            user_id=django_user.id,  # Use Django user ID instead of Slack user ID
            client_id=client_id
        )
        
        # Create event loop for async operations
        import asyncio
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        
        # Run async operations
        async def process():
            try:
                await client.connect(say)
                await client.send_message(text)
            except Exception as e:
                logger.error(f"Error in async processing: {e}", exc_info=True)
                await sync_to_async(say)(
                    text=f"Error processing message: {str(e)}",
                    thread_ts=thread_ts
                )
                
        # Run the async process in the event loop
        loop.run_until_complete(process())
        loop.close()
        
    except Exception as e:
        logger.error(f"Error processing message: {e}", exc_info=True)
        say(
            text=f"Sorry, I encountered an error: {str(e)}",
            thread_ts=message.get('thread_ts', message.get('ts'))
        )

def maintain_connection():
    """Keep the Slack connection alive and handle reconnections"""
    global _slack_client
    while True:
        try:
            if _slack_client and not _slack_client.is_connected():
                logger.warning("Slack connection lost, attempting to reconnect...")
                _slack_client.connect()
                if _slack_client.is_connected():
                    logger.info("Successfully reconnected to Slack")
                else:
                    logger.error("Failed to reconnect to Slack")
        except Exception as e:
            logger.error(f"Error in connection maintenance: {e}")
        time.sleep(60)  # Check connection every minute

def start_slack_bot():
    """Start the Slack bot in Socket Mode"""
    try:        
        # Debug log environment variables
        import os
        
        # Get tokens
        bot_token = settings.DSLACK_BOT_TOKEN
        app_token = settings.DSLACK_APP_TOKEN
        
        if not bot_token or not app_token:
            logger.warning("Slack tokens not found, skipping bot initialization")
            return
        
        # Initialize app with bot token
        app = App(token=bot_token)        
        # Listen for messages (not mentions)
        @app.message("")
        def handle_message(message, say):
            logger.info(f"Received message: {message}")
            # Ignore bot messages
            if message.get("bot_id") or message.get("subtype") == "bot_message":
                logger.info("Ignoring bot message")
                return
            process_message(message, say)
        
        # Listen for mentions
        @app.event("app_mention")
        def handle_mention(event, say):
            logger.info(f"Received mention: {event}")
            process_message(event, say, is_mention=True)
                
        # Create handler
        handler = SocketModeHandler(app, app_token)
        _slack_client = handler
        
        # Start the Socket Mode handler in a separate thread
        def run_socket_handler():
            try:
                handler.start()
            except Exception as e:
                logger.error(f"Error in socket handler thread: {e}", exc_info=True)
        
        socket_thread = threading.Thread(target=run_socket_handler)
        socket_thread.daemon = True
        socket_thread.start()        
        # Start the connection maintenance thread
        maintenance_thread = threading.Thread(target=maintain_connection)
        maintenance_thread.daemon = True
        maintenance_thread.start()
        
    except Exception as e:
        logger.error(f"Error starting Slack bot: {str(e)}", exc_info=True)

================
File: integrations/slack_message_formatter.py
================
import json
from typing import Dict, List, Any, Optional, Tuple, Union
from datetime import datetime
import pandas as pd
import logging
import io
import base64
from django.conf import settings
import os
import matplotlib.pyplot as plt
import seaborn as sns

logger = logging.getLogger(__name__)

class SlackMessageFormatter:
    """Format tool outputs and messages for Slack using Block Kit."""
    
    @staticmethod
    def format_field_name(field: str) -> str:
        """Format a field name for display."""
        return field.replace('_', ' ').title()

    @staticmethod
    def _find_table_data(data: Any) -> Optional[List[Dict]]:
        """Find table-like data in the result."""
        if isinstance(data, dict):
            # Check common patterns in our API responses
            if 'analytics_data' in data and isinstance(data['analytics_data'], list):
                return data['analytics_data']
            if 'data' in data and isinstance(data['data'], list):
                return data['data']
            if 'results' in data and isinstance(data['results'], list):
                return data['results']
        elif isinstance(data, list) and data and isinstance(data[0], dict):
            return data
        return None

    @staticmethod
    def _find_time_series_data(data: Any) -> Optional[Tuple[List[str], List[Dict]]]:
        """Find time series data in the result."""
        table_data = SlackMessageFormatter._find_table_data(data)
        if not table_data:
            return None

        # Look for date/time fields
        date_fields = []
        metric_fields = []
        
        # Check first row for field types
        sample = table_data[0]
        for field, value in sample.items():
            field_lower = field.lower()
            # Check if field name suggests it's a date
            if any(date_hint in field_lower for date_hint in ['date', 'time', 'day', 'month', 'year']):
                try:
                    # Verify we can parse the date
                    pd.to_datetime(sample[field])
                    date_fields.append(field)
                except:
                    continue
            # For GA4 data, we know certain fields are metrics
            elif field in ['newUsers', 'totalUsers', 'sessions', 'screenPageViews', 'bounceRate', 'engagedSessions']:
                metric_fields.append(field)
            # Otherwise check if it's numeric
            elif isinstance(value, (int, float)) or (isinstance(value, str) and value.replace('.', '').isdigit()):
                metric_fields.append(field)

        if not date_fields or not metric_fields:
            return None

        return date_fields, metric_fields

    @staticmethod
    def _create_chart(data: List[Dict], date_field: str, metric_fields: List[str]) -> bytes:
        """Create a time series chart and return the bytes."""
        try:
            import seaborn as sns
            logger.info(f"Creating chart with date_field: {date_field}, metrics: {metric_fields}")
            
            df = pd.DataFrame(data)
            df[date_field] = pd.to_datetime(df[date_field])
            df = df.sort_values(date_field)
            
            # Convert metrics to numeric
            for metric in metric_fields:
                if df[metric].dtype == 'object':
                    df[metric] = pd.to_numeric(df[metric].str.replace(',', ''), errors='coerce')
            
            # Set seaborn style
            sns.set_style("whitegrid")
            plt.figure(figsize=(10, 6))
            
            # Create plot using seaborn
            for metric in metric_fields:
                sns.lineplot(data=df, x=date_field, y=metric, marker='o', label=metric)
            
            plt.title('Time Series Analysis')
            plt.xticks(rotation=45)
            plt.tight_layout()
            
            # Save to bytes
            buffer = io.BytesIO()
            plt.savefig(buffer, format='png', dpi=150)
            plt.close()
            buffer.seek(0)
            return buffer.getvalue()
            
        except Exception as e:
            logger.error(f"Error creating chart: {str(e)}", exc_info=True)
            raise

    @staticmethod
    def format_table(data: List[Dict]) -> List[Dict]:
        """Format data as a Slack section block with fields."""
        if not data:
            return [{"type": "section", "text": {"type": "mrkdwn", "text": "No data available"}}]

        blocks = []
        
        # Add header
        blocks.append({
            "type": "header",
            "text": {
                "type": "plain_text",
                "text": "Data Summary"
            }
        })

        # Group related fields together
        for row in data:
            text_parts = []
            for key, value in row.items():
                if isinstance(value, (int, float)):
                    formatted_value = f"{value:,}"
                elif isinstance(value, str) and any(date_hint in key.lower() for date_hint in ['date', 'time', 'day']):
                    try:
                        date = pd.to_datetime(value)
                        formatted_value = date.strftime('%Y-%m-%d')
                    except:
                        formatted_value = value
                else:
                    formatted_value = str(value)
                
                text_parts.append(f"*{SlackMessageFormatter.format_field_name(key)}*: {formatted_value}")
            
            # Join all fields with newlines
            blocks.append({
                "type": "section",
                "text": {
                    "type": "mrkdwn",
                    "text": "\n".join(text_parts)
                }
            })
            
            # Add divider between rows
            blocks.append({"type": "divider"})

        if len(data) > 10:
            blocks.append({
                "type": "context",
                "elements": [{
                    "type": "mrkdwn",
                    "text": f"_Showing 10 of {len(data)} rows_"
                }]
            })

        return blocks

    @staticmethod
    def _format_analytics_data(data: List[Dict]) -> List[Dict]:
        """Special formatter for analytics data."""
        if not data:
            return []
            
        blocks = []
        
        # Add header
        blocks.append({
            "type": "header",
            "text": {
                "type": "plain_text",
                "text": "Analytics Data Summary"
            }
        })

        # Add context about the data
        blocks.append({
            "type": "context",
            "elements": [{
                "type": "mrkdwn",
                "text": " Showing analytics data with all available metrics"
            }]
        })

        blocks.append({"type": "divider"})

        # Convert data to a more readable format
        df = pd.DataFrame(data)
        
        # Create a section for each row of data
        for _, row in df.iterrows():
            # Split fields into two columns
            fields = []
            for col in df.columns:
                value = row[col]
                # Format numbers with commas
                if isinstance(value, (int, float)):
                    if str(value).endswith('.0'):  # Integer values
                        formatted_value = f"{int(value):,}"
                    else:  # Float values
                        formatted_value = f"{value:,.2f}"
                else:
                    formatted_value = str(value)
                
                fields.append({
                    "type": "mrkdwn",
                    "text": f"*{SlackMessageFormatter.format_field_name(col)}*\n{formatted_value}"
                })
            
            blocks.append({
                "type": "section",
                "fields": fields
            })
            
            blocks.append({"type": "divider"})

        # If we have numeric columns, add summary statistics
        numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns
        if not numeric_cols.empty:
            blocks.append({
                "type": "header",
                "text": {
                    "type": "plain_text",
                    "text": "Summary Statistics"
                }
            })

            for col in numeric_cols:
                col_name = SlackMessageFormatter.format_field_name(col)
                total = df[col].sum()
                avg = df[col].mean()
                
                if str(total).endswith('.0'):  # Integer values
                    total_str = f"{int(total):,}"
                    avg_str = f"{avg:,.1f}"
                else:  # Float values
                    total_str = f"{total:,.2f}"
                    avg_str = f"{avg:,.2f}"

                blocks.append({
                    "type": "section",
                    "fields": [
                        {
                            "type": "mrkdwn",
                            "text": f"*{col_name}*\n Total: {total_str}"
                        },
                        {
                            "type": "mrkdwn",
                            "text": f"*Statistics*\n Average: {avg_str}"
                        }
                    ]
                })

        return blocks

    @staticmethod
    def format_tool_result(result: Any) -> Union[str, List[Dict]]:
        """Format a tool result for Slack using blocks where appropriate."""
        try:
            # Parse result if it's a string
            data = json.loads(result) if isinstance(result, str) else result
            logger.info(f"Formatting tool result. Data type: {type(data)}")
            
            # Try to find table data
            table_data = SlackMessageFormatter._find_table_data(data)
            if table_data:
                logger.info(f"Found table data with {len(table_data)} rows")
                blocks = []
                
                # Check if it's time series data first
                time_series_info = SlackMessageFormatter._find_time_series_data(data)
                if time_series_info:
                    date_fields, metric_fields = time_series_info
                    logger.info(f"Found time series data with date fields: {date_fields}, metric fields: {metric_fields}")
                    
                    # Create summary section
                    df = pd.DataFrame(table_data)
                    summary_blocks = []
                    for metric in metric_fields:
                        metric_name = SlackMessageFormatter.format_field_name(metric)
                        total = df[metric].sum()
                        avg = df[metric].mean()
                        max_val = df[metric].max()
                        max_date = df.loc[df[metric].idxmax(), date_fields[0]]
                        
                        summary_blocks.append({
                            "type": "section",
                            "text": {
                                "type": "mrkdwn",
                                "text": f"*{metric_name}*\n Total: {total:,.0f}\n Average: {avg:,.1f}\n Peak: {max_val:,.0f} on {max_date}"
                            }
                        })
                    
                    blocks.extend(summary_blocks)
                    
                    try:
                        # Create chart
                        chart_bytes = SlackMessageFormatter._create_chart(table_data, date_fields[0], metric_fields)
                        blocks.append({
                            "type": "image",
                            "title": {
                                "type": "plain_text",
                                "text": "Time Series Chart"
                            },
                            "image_url": f"attachment://chart.png",
                            "alt_text": "Time Series Chart"
                        })
                    except Exception as e:
                        logger.error(f"Error creating chart: {str(e)}", exc_info=True)
                        # Continue without the chart
                    
                    logger.info(f"Returning {len(blocks)} blocks")
                    return blocks[:50]  # Ensure we don't exceed Slack's block limit
                
                # If not time series, check if it's analytics data
                elif any('sessionSource' in row for row in table_data):
                    blocks.extend(SlackMessageFormatter._format_analytics_data(table_data[:10]))
                    return blocks[:50]
                
                # Regular table data
                else:
                    return SlackMessageFormatter.format_table(table_data[:10])[:50]
            
            # If no table data found, format as code block
            return f"```\n{json.dumps(data, indent=2)}\n```"
            
        except Exception as e:
            logger.error(f"Error formatting tool result: {str(e)}", exc_info=True)
            return str(result)

================
File: static/agents/css/chat.css
================
/* Base colors and variables from Soft UI */
:root {
    --soft-bg: #fbfbfb;
    --font-color: #202d47;
    --heading-color: #344767;
    
    /* Primary gradient */
    --primary-gradient: linear-gradient(310deg, #7928CA 0%, #FF0080 100%);
    --secondary-gradient: linear-gradient(310deg, #627594 0%, #A8B8D8 100%);
    --info-gradient: linear-gradient(310deg, #2152ff 0%, #21d4fd 100%);
}
/* Card header compact styling */
.card-header {
    min-height: auto !important;
}
/* Chat container styling */
#chat-messages {
    min-height: 500px;
    height: calc(100vh - 400px);

    overflow-y: auto;
    scroll-behavior: smooth;
    padding: 1.5rem;
    background: var(--soft-bg);
}

/* Message styling */
.message-content {
    padding: 1rem 1.5rem;
    border-radius: 1rem;
    position: relative;
    box-shadow: 0 20px 27px 0 rgba(0, 0, 0, 0.05);
    margin-bottom: 0.5rem;
}

.message.user {
    background-color: #e9ecef;
    border-radius: 1rem;
    padding: 1rem;
    margin-left: 2rem;
    margin-bottom: 1rem;
}

.message.user .message-content {
    background: var(--primary-gradient);
    color: #ffffff;
    border-bottom-right-radius: 0.25rem;
    font-size: 0.875rem;
    line-height: 1.5;
    margin-bottom: 0;  /* Remove bottom margin since parent has margin */
}

.agent-message .message-content {
    background: #ffffff;
    color: var(--heading-color);
    border-bottom-left-radius: 0.25rem;
}

/* Ensure proper spacing between messages */
.d-flex.justify-content-start,
.d-flex.justify-content-end {
    margin-bottom: 1rem;
}

/* Add some breathing room for the messages */
.d-flex.justify-content-start {
    padding-right: 10%;
}

.d-flex.justify-content-end {
    padding-left: 10%;
}

/* Style user message text */
.message.user .message-content {
    font-size: 0.875rem;
    line-height: 1.5;
}

/* Style agent message text */
.agent-message .message-content {
    font-size: 0.875rem;
    line-height: 1.5;
}

/* Tool output styling */
.tool-output {
    background: #f8f9fa;
    border-left: 4px solid #cb0c9f;
    padding: 1rem;
    margin: 0.5rem 0;
    border-radius: 1rem;
    box-shadow: 0 .125rem .25rem rgba(0, 0, 0, 0.075);
    font-size: 0.875rem;  /* Add consistent font size */
}

/* Table styling */
.message-content table {
    width: 100%;
    margin: 1rem 0;
    border-collapse: separate;
    border-spacing: 0;
    background: #ffffff;
    border-radius: 0.5rem;
    overflow: hidden;
    box-shadow: 0 2px 4px rgba(0, 0, 0, 0.05);
}

.message-content table.table {
    margin-bottom: 0;  /* Override Bootstrap margin */
}

.message-content table.table-sm td,
.message-content table.table-sm th {
    padding: 0.5rem 1rem;  /* Slightly more compact padding */
}

.message-content th {
    background: #f8f9fa;  /* Light gray background instead of gradient */
    color: #344767;  /* Dark text color for better readability */
    padding: 0.75rem 1.5rem;
    text-align: left;
    font-weight: 600;
    font-size: 0.875rem;
    white-space: nowrap;  /* Prevent header text wrapping */
    border-bottom: 2px solid #e9ecef;  /* Subtle border to separate header from body */
}

.message-content td {
    padding: 0.75rem 1.5rem;
    border-bottom: 1px solid #e9ecef;
    color: var(--heading-color);
    font-size: 0.875rem;
    background: #ffffff;  /* Ensure cell background is white */
}

.message-content tr:last-child td {
    border-bottom: none;  /* Remove border for last row */
}

.message-content tr:nth-child(even) td {
    background: #f8f9fa;  /* Subtle striping */
}

.message-content tr:hover td {
    background: #f0f2f5;  /* Hover effect */
}

/* Ensure table is scrollable on mobile */
@media (max-width: 768px) {
    .message-content {
        max-width: 95%;
    }
    
    .message-content table {
        min-width: 500px;  /* Ensure minimum width for readability */
    }
}

/* Tool usage styling */
.tool-usage {
    background: #ffffff !important;
    border-left: 4px solid #17c1e8 !important;
    padding: 1rem !important;
    margin-bottom: 1rem !important;
    border-radius: 0.5rem !important;
}

.tool-header {
    cursor: pointer;
    padding: 0.5rem;
    border-radius: 0.25rem;
    transition: background-color 0.2s ease;
    user-select: none;
}

.tool-header:hover {
    background-color: rgba(23, 193, 232, 0.1);
}

.tool-header .fa-chevron-down {
    transition: transform 0.3s ease;
}

.tool-header.collapsed .fa-chevron-down {
    transform: rotate(-90deg);
}

.tool-details {
    padding-top: 1rem;
    margin-top: 1rem;
    border-top: 1px solid rgba(0,0,0,0.1);
}

.tool-input, .tool-output {
    background: transparent;
    padding: 0.5rem;
    border-radius: 0.25rem;
}

.json-output {
    background: #ffffff;
    border-radius: 0.25rem;
    padding: 0.75rem;
    margin: 0;
    font-size: 0.875rem;
    color: #344767;
    white-space: pre-wrap; /* Allows line wrapping */
    word-break: break-word; /* Breaks long words */
}

/* Collapse animation */
.collapse {
    transition: height 0.35s ease;
}

.collapse:not(.show) {
    display: none;
}

/* Connection status */
.connection-dot {
    width: 10px;
    height: 10px;
    border-radius: 50%;
    display: inline-block;
    margin-right: 8px;
    position: relative;
    background-color: #ea0606;
}

.connection-dot.connected {
    background-color: #82d616;
}

.connection-dot.connecting {
    background-color: #fbcf33;
}

/* Typing indicator */
.typing-indicator {
    display: flex;
    align-items: center;
    margin-bottom: 1rem;
    padding: 0.5rem 1rem;
    background: #ffffff;
    border-radius: 1rem;
    box-shadow: 0 20px 27px 0 rgba(0, 0, 0, 0.05);
}

.typing-indicator span {
    height: 8px;
    width: 8px;
    background: #17c1e8;
    border-radius: 50%;
    margin: 0 2px;
    display: inline-block;
    animation: bounce 1.3s linear infinite;
}

/* Responsive adjustments */
@media (max-width: 768px) {
    .message-content {
        max-width: 95%;
    }
    
    #chat-messages {
        height: 60vh;
        padding: 1rem;
    }
}

/* Message actions */
.message-actions {
    position: absolute;
    bottom: -2rem; /* Position below the message */
    right: 0;
    transition: opacity 0.2s ease, transform 0.2s ease;
    z-index: 1;
    display: flex;
    gap: 0.25rem;
    background: rgba(0, 0, 0, 0.05);
    padding: 0.25rem;
    border-radius: 0.5rem;
    opacity: 1;
    transform: translateY(-0.5rem);
}

.message-content:hover .message-actions {
    opacity: 1;
    transform: translateY(0);
}

.message-actions .btn-link {
    width: 24px;
    height: 24px;
    padding: 0;
    display: flex;
    align-items: center;
    justify-content: center;
    border-radius: 4px;
    transition: all 0.2s ease;
    margin: 0;
}

.message-actions .btn-link i {
    font-size: 0.875rem;
    transition: transform 0.2s ease;
    line-height: 1;
}

.message-actions .btn-link:hover i {
    transform: scale(1.1);
}

.message-actions .btn-link:hover {
    color: white;
    background: rgba(255, 255, 255, 0.2);
}

.agent-message .message-actions {
    background: rgba(52, 71, 103, 0.05);
}

.agent-message .message-actions .btn-link {
    color: rgba(52, 71, 103, 0.6);
}

.agent-message .message-actions .btn-link:hover {
    color: rgb(52, 71, 103);
    background: rgba(52, 71, 103, 0.1);
}

/* Message content positioning */
.message-content {
    position: relative;
    padding-bottom: 2.5rem; /* Add space for the action buttons */
    margin-bottom: 0.5rem; /* Add some spacing between messages */
}

/* Message content hover effect */
.message-content {
    transition: all 0.2s ease;
}

.message-content:hover {
    box-shadow: 0 20px 27px 0 rgba(0, 0, 0, 0.1);
}

/* Success feedback animation */
@keyframes checkmark {
    0% { transform: scale(0.8); }
    50% { transform: scale(1.2); }
    100% { transform: scale(1); }
}

.fa-check {
    animation: checkmark 0.3s ease-in-out;
    color: #82d616;
}

/* Loading indicator styles */
.loading-content {
    background: rgba(255, 255, 255, 0.1);
    padding: 1rem;
    border-radius: 0.5rem;
}

.typing-indicator {
    display: flex;
    align-items: center;
}

.typing-dots {
    display: flex;
    align-items: center;
}

.typing-dots span {
    height: 8px;
    width: 8px;
    margin: 0 2px;
    background-color: #344767;
    display: block;
    border-radius: 50%;
    opacity: 0.4;
    animation: typing 1s infinite;
}

.typing-dots span:nth-child(1) {
    animation-delay: 0.2s;
}

.typing-dots span:nth-child(2) {
    animation-delay: 0.4s;
}

.typing-dots span:nth-child(3) {
    animation-delay: 0.6s;
}

.typing-text {
    color: #344767;
    font-size: 0.875rem;
}

@keyframes typing {
    0%, 100% {
        transform: translateY(0);
        opacity: 0.4;
    }
    50% {
        transform: translateY(-4px);
        opacity: 0.8;
    }
}

/* Error message styles */
.alert {
    border: 0;
    position: relative;
}

.alert.alert-danger {
    background-image: linear-gradient(310deg, #f5365c 0%, #f56036 100%);
    color: #fff;
}

.alert i {
    font-size: 1.25rem;
}

/* Tool output styles */
.tool-execution {
    background: var(--bs-gray-100);
    border-radius: 8px;
    padding: 1rem;
    margin: 1rem 0;
}

.tool-header {
    color: var(--bs-primary);
    font-size: 0.9rem;
}

.tool-thought {
    font-size: 0.85rem;
    padding: 0.5rem;
    background: rgba(0,0,0,0.05);
    border-radius: 4px;
}

.tool-result {
    background: white;
    padding: 1rem;
    border-radius: 4px;
    box-shadow: 0 1px 3px rgba(0,0,0,0.1);
}

.tool-result .table {
    margin-bottom: 0;
    font-size: 0.9rem;
}

.tool-result .json {
    margin-bottom: 0;
    font-size: 0.85rem;
}

/* Tool type indicators */
.tool-execution[data-tool-type="analytics"] {
    border-left: 3px solid var(--bs-primary);
}

.tool-execution[data-tool-type="search_console"] {
    border-left: 3px solid var(--bs-success);
}

.tool-execution[data-tool-type="error"] {
    border-left: 3px solid var(--bs-danger);
}

.tool-message {
    background: #f8f9fa;
    border-radius: 0.5rem;
    padding: 1rem;
    margin-bottom: 1rem;
}

.tool-header {
    cursor: pointer;
    padding: 0.5rem;
    background: #eaecef;
    border-radius: 0.25rem;
}

.tool-header i.fa-chevron-down {
    transition: transform 0.2s;
}

.tool-header[aria-expanded="true"] i.fa-chevron-down {
    transform: rotate(180deg);
}

.json-output {
    background: #f1f3f5;
    padding: 1rem;
    border-radius: 0.25rem;
    font-size: 0.875rem;
    overflow-x: auto;
    max-height: 300px;
}

.table-responsive {
    max-height: 400px;
    overflow-y: auto;
}

.error-output {
    color: #dc3545;
    padding: 0.5rem;
    background: #f8d7da;
    border-radius: 0.25rem;
}

/* Message Styles */
.message {
    padding: 1rem;
    border-radius: 0.75rem;
    position: relative;
    margin-bottom: 1rem; /* Increase bottom margin to prevent overlap */
}

.message.agent {
    background-color: #f8f9fa;
    margin-right: 2rem;
}

.message.user {
    background-color: #e9ecef;
    margin-left: 2rem;
}

.message-content {
    font-size: 0.875rem;
    line-height: 1.5;
}

.message-timestamp {
    color: #6c757d;
    font-size: 0.75rem;
    margin-top: 0.5rem;
}

/* Tool Output Styles */
.tool-output {
    background-color: #f8f9fa;
    padding: 1rem;
    border-radius: 0.75rem;
    border-left: 4px solid #5e72e4;
    margin-right: 2rem;
}

.tool-header {
    color: #5e72e4;
    font-size: 0.875rem;
    margin-bottom: 0.5rem;
}

.tool-content {
    font-size: 0.875rem;
    line-height: 1.5;
}

.tool-content pre {
    margin: 0;
    padding: 0.5rem;
    background-color: #ffffff;
    border-radius: 0.5rem;
}

.tool-content code {
    font-size: 0.8125rem;
}

.tool-timestamp {
    color: #6c757d;
    margin-top: 0.5rem;
}

/* Avatar Styles */
.avatar {
    width: 40px;
    height: 40px;
    overflow: hidden;
}

.avatar img {
    width: 100%;
    height: 100%;
    object-fit: cover;
}

/* Connection Status */
.connection-dot {
    width: 10px;
    height: 10px;
    border-radius: 50%;
    display: inline-block;
    margin-right: 0.5rem;
    background-color: #dc3545;
}

.connection-dot.connected {
    background-color: #2dce89;
}

.connection-dot.disconnected {
    background-color: #fb6340;
}

.connection-dot.error {
    background-color: #dc3545;
}

.cursor-pointer {
    cursor: pointer;
}

.toggle-icon {
    transition: transform 0.2s ease-in-out;
}

.tool-output .tool-content {
    transition: all 0.3s ease-in-out;
}

/* Tool output styling */
.tool-output pre {
    margin-bottom: 0;
    max-height: 600px;
    overflow-y: auto;
}

.tool-output code {
    font-size: 0.875rem;
}

/* Add some padding to nested content */
.tool-output .tool-input,
.tool-output .tool-output {
    padding-left: 1rem;
}

/* Status icon styling */
.tool-status i {
    font-size: 1rem;
}

/* Ensure the collapse animation is smooth */
.collapse {
    transition: height 0.35s ease;
}

/* Add some hover effect to collapsible headers */
[data-bs-toggle="collapse"]:hover {
    background-color: rgba(0, 0, 0, 0.05);
    border-radius: 0.375rem;
}

/* Add some padding to the collapsible headers */
[data-bs-toggle="collapse"] {
    padding: 0.5rem;
    margin: -0.5rem;
    transition: background-color 0.2s ease-in-out;
}

/* Tooltip styles */
[title] {
    position: relative;
}

[title]:hover::after {
    content: attr(title);
    position: absolute;
    bottom: 100%;
    left: 50%;
    transform: translateX(-50%);
    padding: 0.25rem 0.5rem;
    background: rgba(0, 0, 0, 0.8);
    color: white;
    font-size: 0.75rem;
    border-radius: 0.25rem;
    white-space: nowrap;
    pointer-events: none;
    z-index: 10;
    margin-bottom: 0.25rem;
}

/* Update message margins to account for action buttons */
.message {
    margin-bottom: 1rem; /* Increase bottom margin to prevent overlap */
}

.mb-4 {
    margin-bottom: 2rem !important; /* Increase spacing between message groups */
}

/* Tool error styling */
.tool-error {
    background: #fff5f5;
    border-radius: 0.5rem;
    padding: 1rem;
    color: #dc3545;
}

.tool-error i {
    color: #dc3545;
}

/* Ensure crew messages have consistent font size */
.crew-message .tool-result,
.crew-message .tool-output,
.crew-message .message-content {
    font-size: 0.875rem !important;
    line-height: 1.5;
}

================
File: static/agents/css/content_expander.css
================
/* Content expander styles */
.content-side-panel {
    position: fixed;
    top: 0;
    right: -400px;
    width: 400px;
    height: 100vh;
    transition: right 0.3s ease;
    z-index: 1040;
    border: 0;
    box-shadow: 0 8px 16px rgba(0, 0, 0, 0.1);
}

.content-side-panel.panel-visible {
    right: 0;
}

.content-side-panel .card-body {
    height: calc(100vh - 140px);  /* Account for header and footer */
}

/* Card content truncation */
.kanban-item .card-content {
    max-height: 4.5em;
    overflow: hidden;
    position: relative;
    margin-bottom: 1rem;
}

.kanban-item .card-content::after {
    content: '';
    position: absolute;
    bottom: 0;
    left: 0;
    right: 0;
    height: 1.5em;
    background: linear-gradient(transparent, var(--bs-card-bg));
    pointer-events: none;
}

.kanban-item .expand-icon {
    position: absolute;
    right: 1rem;
    bottom: 1rem;
    width: 24px;
    height: 24px;
    display: flex;
    align-items: center;
    justify-content: center;
    border-radius: 6px;
    background: var(--bs-gray-100);
    color: var(--bs-gray-600);
    cursor: pointer;
    transition: all 0.2s ease;
}

.kanban-item .expand-icon:hover {
    background: var(--bs-gray-200);
    color: var(--bs-gray-700);
}

.kanban-item.card-expanded {
    box-shadow: 0 0 0 2px var(--bs-primary) !important;
}

================
File: static/agents/css/crew_kanban.css
================
.kanban-container {
  position: relative;
  box-sizing: border-box;
  width: 100%;
  display: flex;
  flex-direction: row;
  flex-wrap: nowrap;
  gap: 1rem;
  overflow-x: auto;
  padding: 1.25rem;
  min-height: 200px;
  align-items: flex-start;
}

.kanban-board {
  position: relative;
  flex: 0 0 620px;
  width: 640px;
  height: 100%;
  margin-bottom: 1.25rem;
  transition: all 0.3s ease;
  background-color: transparent;
}

#kanban-tasks .kanban-board-header {
    background: var(--bs-dark-gradient) !important;
}

/* If that doesn't work, try this alternative */
#kanban-tasks .kanban-board-header {
    background: linear-gradient(310deg, #141727, #3A416F) !important;
    background-image: linear-gradient(310deg, #141727, #3A416F) !important;
}

.kanban-board .kanban-board-header {
  position: relative;
  height: auto;
  border-radius: 0.5rem 0.5rem 0 0;
  padding: 1rem;
  color: white;
}

.kanban-drag {
  position: relative;
  min-height: 200px;
  padding: 1.25rem;
  height: auto;
  background-color: #fff;
  border: 1px solid #e9ecef;
  border-top: none;
  border-radius: 0 0 0.5rem 0.5rem;
  display: block;
}

.kanban-container * {
  box-sizing: border-box;
}

.kanban-container:after {
  clear: both;
  display: block;
  content: "";
}

.kanban-item {
  margin-bottom: 0.9375rem;
}

/* Custom scrollbar for better visibility */
.kanban-container::-webkit-scrollbar {
  height: 0.5rem;
}

.kanban-container::-webkit-scrollbar-track {
  background: rgba(0, 0, 0, 0.1);
}

.kanban-container::-webkit-scrollbar-thumb {
  background: var(--bs-primary);
  border-radius: 0.25rem;
}

.kanban-container::-webkit-scrollbar-thumb:hover {
  background: var(--bs-primary-darker);
}

/* Stage status indicators */
.stage-item {
  border: 1px solid #e9ecef;
  border-radius: 0.5rem;
  padding: 1rem;
  margin-bottom: 1rem;
  background-color: white;
  box-shadow: 0 2px 4px rgba(0,0,0,0.05);
  transition: all 0.3s ease;
  width: 100%;
}
.stage-item:hover {
  box-shadow: 0 4px 6px rgba(0,0,0,0.1);
  transform: translateY(-2px);
}
.stage-content {
  margin-top: 1rem;
}
.stage-metadata {
  margin-top: 0.5rem;
  font-size: 0.875rem;
  color: #6c757d;
}
.stage-status {
    display: inline-flex;
    align-items: center;
    padding: 0.25rem 0.5rem;
    border-radius: 0.25rem;
    font-size: 0.875rem;
    font-weight: 600;
    line-height: 1;
    text-transform: lowercase;
    white-space: nowrap;
}

.status-pending { 
    background-color: #6c757d;  /* gray */
    color: white;
}

.status-in_progress,
.status-running { 
    background-color: #0d6efd;  /* blue */
    color: white;
}

.status-completed { 
    background-color: #198754;  /* green */
    color: white;
}

.status-error { 
    background-color: #dc3545;  /* red */
    color: white;
}
/* Time stamp styling */
.time-stamp {
  color: #6c757d;
  font-size: 0.875rem;
}

/* Title styling */
.stage-title {
  color: #344767;
  font-size: 0.875rem;
  font-weight: 600;
  margin: 0.75rem 0;
}

/* Content styling */
.stage-content {
  color: #67748e;
  font-size: 0.875rem;
  line-height: 1.5;
}

/* Agent info styling */
.stage-agent {
  display: inline-flex;
  align-items: center;
  margin-top: 1rem;
  color: #67748e;
  font-size: 0.75rem;
}

.stage-agent i {
  margin-right: 0.5rem;
  font-size: 0.875rem;
}

/* Show more button styling */
.toggle-content {
  color: #0d6efd;
  font-size: 0.75rem;
  font-weight: 600;
  text-decoration: none;
  margin-top: 0.5rem;
  display: inline-block;
}

.toggle-content:hover {
  color: #0a58ca;
}

.btn-group .btn-link {
    color: #6c757d;
    text-decoration: none;
    transition: color 0.2s;
}

.btn-group .btn-link:hover {
    color: #344767;
}

.gap-2 {
    gap: 0.5rem;
}
.task-description {
cursor: pointer;
}
.task-description:hover {
opacity: 0.9;
}
.task-description::after {
content: '\f078';  /* FontAwesome chevron-down icon */
font-family: "Font Awesome 5 Free";
font-weight: 900;
margin-left: 0.5rem;
font-size: 0.75rem;
transition: transform 0.2s;
}
.task-description[aria-expanded="true"]::after {
transform: rotate(180deg);
}

================
File: static/agents/js/chat/app.js
================
// Get current timestamp for cache busting
const version = new Date().getTime();

// Create URLs with cache busting
const messageListUrl = new URL('/static/agents/js/components/message_list.js', window.location.href);
const webSocketUrl = new URL('/static/agents/js/services/websocket.js', window.location.href);
const messageHandlerUrl = new URL('/static/agents/js/services/message_handler.js', window.location.href);
const toolOutputUrl = new URL('/static/agents/js/components/tool_outputs/base.js', window.location.href);

// Add version parameter to each URL
messageListUrl.searchParams.set('v', version);
webSocketUrl.searchParams.set('v', version);
messageHandlerUrl.searchParams.set('v', version);
toolOutputUrl.searchParams.set('v', version);

// Initialize components asynchronously
async function initializeComponents() {
    // Import modules dynamically
    const [
        { MessageList },
        { ChatWebSocket },
        { MessageHandler },
        { ToolOutputManager }
    ] = await Promise.all([
        import(messageListUrl.toString()),
        import(webSocketUrl.toString()),
        import(messageHandlerUrl.toString()),
        import(toolOutputUrl.toString())
    ]);

    return { MessageList, ChatWebSocket, MessageHandler, ToolOutputManager };
}

class ChatApp {
    constructor(config) {
        this.config = config;
        this.participantType = 'unset'; // Track participant type
        this.crewInitialized = false; // Track if crew has been initialized
        
        // Initialize highlight.js
        hljs.configure({
            ignoreUnescapedHTML: true,
            languages: ['javascript', 'python', 'bash', 'json', 'html', 'css']
        });
        
        this.elements = {
            messages: document.getElementById('chat-messages'),
            input: document.getElementById('message-input'),
            sendButton: document.getElementById('send-message'),
            agentSelect: document.getElementById('agent-select'),
            modelSelect: document.getElementById('model-select'),
            clientSelect: document.getElementById('client-select'),
            crewSelect: document.getElementById('crew-select'),
            newChatBtn: document.getElementById('new-chat-btn'),
            shareBtn: document.getElementById('share-conversation')
        };
    }

    async initialize() {
        // Import and initialize components
        const { MessageList, ChatWebSocket, MessageHandler, ToolOutputManager } = await initializeComponents();
        
        // Initialize components
        this.messageList = new MessageList(this.elements.messages);
        this.toolOutputManager = new ToolOutputManager();
        
        // Create message handler first without websocket
        this.messageHandler = new MessageHandler(this.messageList, this.toolOutputManager);
        
        // Create websocket with message handler
        this.websocket = new ChatWebSocket(this.config, this.messageHandler);
        
        // Update message handler with websocket
        this.messageHandler.websocket = this.websocket;
        
        // Set message handler callback for system messages
        this.messageHandler.onSystemMessage = this.handleSystemMessage.bind(this);
        
        // Bind event handlers
        this._bindEvents();

        // Listen for edit-message custom event
        document.addEventListener('edit-message', (event) => {
            const messageContainer = document.getElementById(`${event.detail.domId}-container`);
            if (messageContainer) {
                this.editMessage(messageContainer.querySelector('.edit-message'));
            }
        });

        // Connect WebSocket
        this.websocket.connect();
        
        // Initialize autosize for textarea
        if (this.elements.input) {
            autosize(this.elements.input);
        }
        
        // Set initial agent avatar and initialize chatConfig
        if (!window.chatConfig.currentAgent) {
            const selectedOption = this.elements.agentSelect?.selectedOptions[0];

            window.chatConfig.currentAgent = {
                avatar: selectedOption ? selectedOption.dataset.avatar : '/static/assets/img/team-3.jpg',
                name: selectedOption ? selectedOption.dataset.name : 'AI Assistant'
            };
        }
        this._updateAgentAvatar();
        
        // Update MessageList with current agent
        this.messageList.updateCurrentAgent(window.chatConfig.currentAgent);

        // Expose functions globally
        window.editMessage = this.editMessage.bind(this);
        window.copyMessage = this.copyMessage.bind(this);
        window.deleteConversation = this.deleteConversation.bind(this);
    }

    handleSystemMessage(message) {
        console.log('Handling system message:', message);
        // Update participant type from system message
        if (message.participant_type) {
            this.participantType = message.participant_type;
            this._updateUIForParticipantType();
        }
    }

    _updateUIForParticipantType() {
        console.log('Updating UI for participant type:', this.participantType);
        const selectedOption = this.elements.agentSelect?.selectedOptions[0];
        const selectedType = selectedOption?.dataset.type;

        // Update UI based on participant type
        if (this.participantType === 'crew' || selectedType === 'crew') {
            if (this.elements.agentSelect) {
                this.elements.agentSelect.disabled = true;
                this.elements.modelSelect.disabled = true;
            }
            // Update agent name to show crew if available
            const crewOption = this.elements.crewSelect?.selectedOptions[0];
            if (crewOption && document.getElementById('agent-name')) {
                document.getElementById('agent-name').textContent = `Crew: ${crewOption.textContent}`;
            }
        } else if (this.participantType === 'agent' || selectedType === 'agent') {
            if (this.elements.crewSelect) {
                this.elements.crewSelect.disabled = true;
            }
        }
    }

    _handleAgentOrCrewSelection() {
        const selectedOption = this.elements.agentSelect?.selectedOptions[0];
        if (!selectedOption) return;

        const selectedType = selectedOption.dataset.type;
        const selectedId = selectedOption.value;

        if (selectedType === 'crew') {
            // Just update the UI and participant type, don't start crew yet
            this.participantType = 'crew';
            this.crewInitialized = false; // Reset initialization flag
        } else {
            // Update participant type for agent
            this.participantType = 'agent';
        }

        this._updateUIForParticipantType();
        this._updateAgentAvatar();
    }

    _sendMessage() {
        const message = this.elements.input.value.trim();
        if (!message) return;

        const selectedOption = this.elements.agentSelect?.selectedOptions[0];
        const selectedType = selectedOption?.dataset.type;

        // Send message based on participant type
        if (this.participantType === 'crew' || selectedType === 'crew') {
            // If this is the first message to the crew, initialize it
            if (!this.crewInitialized) {
                this.websocket.send({
                    type: 'start_crew',
                    crew_id: selectedOption.value,
                    client_id: this.elements.clientSelect.value
                });
                this.crewInitialized = true;
            }
            
            // Send the crew message
            this.websocket.send({
                message: message,
                type: 'crew_message',
                crew_id: selectedOption.value,
                client_id: this.elements.clientSelect.value
            });
        } else {
            // Regular agent message
            this.websocket.send({
                message: message,
                agent_id: selectedOption.value,
                model: this.elements.modelSelect.value,
                client_id: this.elements.clientSelect.value
            });
        }

        // Clear input
        this.elements.input.value = '';
        autosize.update(this.elements.input);
    }

    editMessage(button) {
        const messageContainer = button.closest('.d-flex');
        if (!messageContainer) {
            console.warn('Could not find message container');
            return;
        }

        const messageText = messageContainer.querySelector('.message-text')?.textContent.trim();
        if (!messageText) {
            console.warn('Could not find message text');
            return;
        }
        
        // Get the message ID
        const domId = messageContainer.id.replace('-container', '');
        const backendId = this.messageList.getMessageId(domId);
        
        if (!backendId) {
            console.warn('No backend message ID found for container:', domId);
            return;
        }
        
        try {
            console.log('Editing message:', { domId, backendId, messageText });
            
            // Set input value to message content
            this.elements.input.value = messageText;
            this.elements.input.focus();
            autosize.update(this.elements.input);
            
            // Delete messages from the message list
            this.messageList.deleteMessagesFromIndex(domId);
            
            // Notify backend to handle edit
            this.websocket.send({
                type: 'edit',
                message: messageText,
                message_id: backendId,
                session_id: this.config.sessionId
            });
            
        } catch (error) {
            console.error('Error editing message:', error);
            alert('Failed to edit message. Please try again.');
        }
    }

    copyMessage(button) {
        const messageText = button.closest('.message-content')?.querySelector('.message-text')?.textContent.trim();
        if (!messageText) {
            console.warn('Could not find message text');
            return;
        }
        
        navigator.clipboard.writeText(messageText).then(() => {
            // Show temporary success indicator
            const icon = button.querySelector('i');
            icon.classList.remove('fa-copy');
            icon.classList.add('fa-check');
            setTimeout(() => {
                icon.classList.remove('fa-check');
                icon.classList.add('fa-copy');
            }, 1000);
        }).catch(err => {
            console.error('Failed to copy text:', err);
        });
    }

    _bindEvents() {
        // Message sending
        if (this.elements.input && this.elements.sendButton) {
            this.elements.input.addEventListener('keypress', (e) => {
                if (e.key === 'Enter' && !e.shiftKey) {
                    e.preventDefault();
                    this._sendMessage();
                }
            });
            
            this.elements.sendButton.addEventListener('click', () => {
                this._sendMessage();
            });
        }

        // Agent/Crew selection
        if (this.elements.agentSelect) {
            this.elements.agentSelect.addEventListener('change', () => {
                this._handleAgentOrCrewSelection();
            });
        }

        // New chat button
        if (this.elements.newChatBtn) {
            this.elements.newChatBtn.addEventListener('click', () => {
                window.location.href = this.elements.newChatBtn.dataset.url;
            });
        }

        // Share button
        if (this.elements.shareBtn) {
            this.elements.shareBtn.addEventListener('click', () => {
                this.exportToMarkdown();
            });
        }
    }

    _updateAgentAvatar() {
        const selectedOption = this.elements.agentSelect.selectedOptions[0];
        if (selectedOption) {
            const avatarPath = selectedOption.dataset.avatar || '/static/assets/img/team-3.jpg';
            const avatarUrl = avatarPath.startsWith('/') ? avatarPath : `/static/assets/img/${avatarPath}`;
            const name = selectedOption.dataset.name;
            
            const avatarImg = document.getElementById('agent-avatar').querySelector('img');
            if (avatarImg) {
                avatarImg.src = avatarUrl;
                avatarImg.alt = name;
            }
            
            const nameElement = document.getElementById('agent-name');
            if (nameElement) {
                nameElement.textContent = name;
            }
            
            // Update global config for Message component
            window.chatConfig.currentAgent = {
                avatar: avatarUrl,
                name: name
            };
            
            // Update MessageList with new agent info
            this.messageList.updateCurrentAgent(window.chatConfig.currentAgent);
        }
    }

    async deleteConversation(sessionId, event) {
        if (event) {
            event.preventDefault();
            event.stopPropagation();
        }

        if (!confirm('Are you sure you want to delete this conversation?')) {
            return;
        }

        try {
            const url = this.config.urls.deleteConversation.replace('{sessionId}', sessionId);
            const response = await fetch(url, {
                method: 'POST',
                headers: {
                    'X-CSRFToken': this.config.csrfToken,
                    'Content-Type': 'application/json'
                }
            });

            if (!response.ok) {
                throw new Error('Failed to delete conversation');
            }

            // Redirect to new chat if we're deleting the current conversation
            if (sessionId === this.config.sessionId) {
                window.location.href = this.config.urls.newChat;
            } else {
                // Otherwise just remove the conversation from the list
                const conversationElement = event.target.closest('.position-relative');
                if (conversationElement) {
                    conversationElement.remove();
                }
            }
        } catch (error) {
            console.error('Error deleting conversation:', error);
            alert('Failed to delete conversation. Please try again.');
        }
    }

    scrollToBottom() {
        if (this.elements.messages) {
            const scrollHeight = this.elements.messages.scrollHeight;
            this.elements.messages.scrollTo({
                top: scrollHeight,
                behavior: 'smooth'
            });
        }
    }

    appendMessage(content, isAgent = false, withActions = true, messageId = null) {
        // Use MessageList's addMessage method
        const domId = this.messageList.addMessage(content, isAgent, 
            isAgent ? window.chatConfig.currentAgent?.avatar : null, 
            messageId
        );
        
        // Add event listeners for actions
        if (withActions) {
            this.addMessageEventListeners(domId);
        }
    }

    async deleteMessagesFromIndex(messageContainer) {
        // Get the actual message container if we're passed a child element
        const container = messageContainer.closest('.d-flex');
        if (!container) {
            console.warn('Could not find message container');
            return;
        }

        // Get the message ID from the container ID
        const domId = container.id.replace('-container', '');
        const backendId = this.messageList.getMessageId(domId);
        
        if (!backendId) {
            console.warn('No backend message ID found for container:', domId);
            return;
        }
        
        try {
            // Delete messages from the message list
            this.messageList.deleteMessagesFromIndex(domId);
            
            // Notify backend to handle edit
            const editData = {
                type: 'edit',
                message: this.elements.input.value.trim(),
                message_id: backendId,
                session_id: this.config.sessionId
            };
            this.websocket.send(editData);
            
        } catch (error) {
            console.error('Error editing messages:', error);
            alert('Failed to edit messages. Please try again.');
        }
    }

    addMessageEventListeners(domId) {
        const container = document.getElementById(`${domId}-container`);
        if (!container) return;

        const messageContent = container.querySelector('.message-content');
        const messageActions = container.querySelector('.message-actions');
        const copyButton = container.querySelector('.copy-message');
        const editButton = container.querySelector('.edit-message');

        // Copy button functionality
        if (copyButton) {
            copyButton.addEventListener('click', (e) => {
                e.stopPropagation();
                const messageText = container.querySelector('.message-text').textContent.trim();
                navigator.clipboard.writeText(messageText).then(() => {
                    // Show success feedback
                    const icon = copyButton.querySelector('i');
                    icon.classList.remove('fa-copy');
                    icon.classList.add('fa-check');
                    setTimeout(() => {
                        icon.classList.remove('fa-check');
                        icon.classList.add('fa-copy');
                    }, 1000);
                });
            });
        }

        // Edit button functionality
        if (editButton) {
            editButton.addEventListener('click', async (e) => {
                e.stopPropagation();
                const messageText = container.querySelector('.message-text').textContent.trim();
                
                // 1. Put the message text in the input field
                this.elements.input.value = messageText;
                this.elements.input.focus();
                autosize.update(this.elements.input);

                // 2. Delete this message and all subsequent messages
                await this.deleteMessagesFromIndex(container);
            });
        }
    }

    exportToMarkdown() {
        let markdown = '# Chat Conversation\n\n';
        const messages = this.elements.messages.querySelectorAll('.message');
        
        messages.forEach(message => {
            const isAgent = message.classList.contains('agent');
            const messageText = message.querySelector('.message-text').textContent.trim();
            const role = isAgent ? 'Assistant' : 'User';
            
            markdown += `**${role}**: ${messageText}\n\n`;
        });

        // Create a blob and trigger download
        const blob = new Blob([markdown], { type: 'text/markdown' });
        const url = window.URL.createObjectURL(blob);
        const a = document.createElement('a');
        a.href = url;
        a.download = `chat-export-${new Date().toISOString().slice(0,10)}.md`;
        document.body.appendChild(a);
        a.click();
        window.URL.revokeObjectURL(url);
        document.body.removeChild(a);
    }
}

export { ChatApp };

================
File: static/agents/js/components/tool_outputs/base.js
================
class ToolOutputManager {
    constructor() {
        this.activeContainer = null;
        this.messagesContainer = document.getElementById('chat-messages');
        this.charts = new Map(); // Store chart instances
        
        // The date-fns adapter is automatically registered via the bundle
    }

    handleToolStart(data) {
        try {
            // Try to parse if string, otherwise use as is
            const toolData = typeof data === 'string' ? JSON.parse(data) : data;
            
            // Create a new container for this tool output
            const container = document.createElement('div');
            container.className = 'd-flex justify-content-start mb-4';
            const containerId = `tool-${Date.now()}`;
            container.innerHTML = `
                <div class="avatar me-2">
                    <img src="${window.chatConfig.currentAgent.avatar}" 
                         alt="${window.chatConfig.currentAgent.name}" 
                         class="border-radius-lg shadow">
                </div>
                <div class="message agent" style="max-width: 75%;">
                    <div class="tool-output">
                        <div class="tool-header d-flex align-items-center justify-content-between">
                            <div class="d-flex align-items-center cursor-pointer collapsed" data-bs-toggle="collapse" data-bs-target="#${containerId}-content">
                                <i class="fas fa-chevron-down me-2 toggle-icon"></i>
                                <i class="fas fa-tools me-2"></i>
                                <span class="tool-name small">${toolData.tool || 'Tool'}</span>
                            </div>
                        </div>
                        <div class="tool-content mt-2 collapse" id="${containerId}-content">
                            ${toolData.input ? `
                            <div class="tool-input text-muted mb-2">
                                <small>Input: ${toolData.input}</small>
                            </div>` : ''}
                            <div class="tool-result"></div>
                        </div>
                    </div>
                </div>
            `;
            
            // Add to messages container
            if (this.messagesContainer) {
                this.messagesContainer.appendChild(container);
                this.activeContainer = container;
                
                // Scroll to the new container
                container.scrollIntoView({ behavior: 'smooth', block: 'end' });
            }
        } catch (error) {
            console.error('Error handling tool start:', error);
            // Create a minimal container for error case
            const container = document.createElement('div');
            container.className = 'd-flex justify-content-start mb-4';
            container.innerHTML = `
                <div class="avatar me-2">
                    <img src="${window.chatConfig.currentAgent.avatar}" 
                         alt="${window.chatConfig.currentAgent.name}" 
                         class="border-radius-lg shadow">
                </div>
                <div class="message agent" style="max-width: 75%;">
                    <div class="tool-output">
                        <div class="tool-header d-flex align-items-center">
                            <i class="fas fa-tools me-2"></i>
                            <span class="tool-name small">Tool Execution</span>
                        </div>
                    </div>
                </div>
            `;
            
            if (this.messagesContainer) {
                this.messagesContainer.appendChild(container);
                this.activeContainer = container;
            }
        }
    }

    handleToolResult(result) {
        try {
            let container = this.activeContainer;
            
            if (!container) {
                console.warn('No active tool container found for result');
                return;
            }

            const resultContainer = container.querySelector('.tool-result');
            if (!resultContainer) return;

            if (result.type === 'error') {
                resultContainer.innerHTML = `
                    <div class="tool-error mt-2">
                        <i class="fas fa-exclamation-triangle me-2"></i>
                        <span class="text-danger small">${result.data}</span>
                    </div>
                `;
            } else if (result.type === 'text') {
                // Handle text-based results with markdown formatting
                resultContainer.innerHTML = `
                    <div class="tool-text mt-2">
                        <small>${marked.parse(result.data)}</small>
                    </div>
                `;
            } else if (result.type === 'json' || (result.type === 'table' && Array.isArray(result.data))) {
                const data = result.data;
                const timeSeriesData = this._findTimeSeriesData(data);
                
                if (timeSeriesData) {
                    // Add visualization toggle buttons
                    const toggleContainer = document.createElement('div');
                    toggleContainer.className = 'mb-2 btn-group';
                    toggleContainer.innerHTML = `
                        <button class="btn btn-primary btn-sm active" data-view="chart">
                            <i class="fas fa-chart-line me-1"></i>Chart
                        </button>
                        <button class="btn btn-primary btn-sm" data-view="table">
                            <i class="fas fa-table me-1"></i>Table
                        </button>
                    `;
                    
                    // Add visualization container
                    const vizContainer = document.createElement('div');
                    vizContainer.className = 'visualization-container';
                    
                    resultContainer.appendChild(toggleContainer);
                    resultContainer.appendChild(vizContainer);
                    
                    // Add event listeners for toggle buttons
                    toggleContainer.querySelectorAll('button').forEach(button => {
                        button.addEventListener('click', (e) => {
                            const view = e.currentTarget.dataset.view;
                            this._updateVisualization(vizContainer, view, timeSeriesData, data);
                            
                            // Update active button state
                            toggleContainer.querySelectorAll('button').forEach(btn => 
                                btn.classList.toggle('active', btn === e.currentTarget)
                            );
                        });
                    });
                    
                    // Show initial visualization
                    this._updateVisualization(vizContainer, 'chart', timeSeriesData, data);
                    
                    // Add CSV download button for full data
                    this._addCsvDownloadButton(container, data);
                } else {
                    const tableData = this._findTableData(data);
                    if (tableData) {
                        resultContainer.innerHTML = this._createTable(tableData);
                        this._addCsvDownloadButton(container, tableData);
                    } else {
                        resultContainer.innerHTML = `
                            <pre class="json-output small">${JSON.stringify(data, null, 2)}</pre>
                        `;
                    }
                }
            } else {
                resultContainer.innerHTML = `
                    <div class="tool-text mt-2">
                        <small>${typeof result === 'string' ? result : JSON.stringify(result)}</small>
                    </div>
                `;
            }

            // Show the tool content after adding result
            const toolContent = container.querySelector('.tool-content');
            if (toolContent) {
                toolContent.classList.add('show');
            }
        } catch (error) {
            console.error('Error handling tool result:', error);
        }
    }

    _updateVisualization(container, view, timeSeriesData, originalData) {
        // Clear previous visualization
        container.innerHTML = '';
        
        if (view === 'chart' && timeSeriesData) {
            // Create chart with filtered data
            this._createChart(container, timeSeriesData);
        } else if (view === 'table') {
            // Create table with original data
            container.innerHTML = this._createTable(originalData);
            
            // Initialize DataTable
            setTimeout(() => {
                try {
                    const tableId = container.querySelector('table').id;
                    new simpleDatatables.DataTable(`#${tableId}`, {
                        searchable: true,
                        fixedHeight: false,
                        perPage: 10
                    });
                } catch (error) {
                    console.warn('Failed to initialize DataTable:', error);
                }
            }, 100);
        }
    }

    _findTableData(data) {
        // If data is already an array of objects with at least one row, it's tabular
        if (Array.isArray(data) && data.length > 0 && typeof data[0] === 'object') {
            return data;
        }

        // Look for arrays in the object values
        if (typeof data === 'object') {
            for (const key in data) {
                const value = data[key];
                if (Array.isArray(value) && value.length > 0 && typeof value[0] === 'object') {
                    return value;
                }
            }
        }

        return null;
    }

    _createTable(data) {
        if (!Array.isArray(data) || !data.length) return '';

        const tableId = `table-${Date.now()}`;
        const headers = Object.keys(data[0]);
        const rows = data.map(row => headers.map(header => {
            const value = row[header];
            // Format dates and numbers
            if (value instanceof Date || (typeof value === 'string' && !isNaN(Date.parse(value)))) {
                return new Date(value).toISOString().split('T')[0];
            }
            if (typeof value === 'number') {
                return value.toLocaleString(undefined, { maximumFractionDigits: 2 });
            }
            return value;
        }));

        const html = `
            <div class="table-responsive">
                <table id="${tableId}" class="table table-sm">
                    <thead>
                        <tr>
                            ${headers.map(header => `<th>${this._formatFieldName(header)}</th>`).join('')}
                        </tr>
                    </thead>
                    <tbody>
                        ${rows.map(row => `
                            <tr>
                                ${row.map(cell => `<td>${cell}</td>`).join('')}
                            </tr>
                        `).join('')}
                    </tbody>
                </table>
            </div>
        `;

        // Initialize DataTable after a short delay to ensure the table is in the DOM
        setTimeout(() => {
            try {
                new simpleDatatables.DataTable(`#${tableId}`, {
                    searchable: true,
                    fixedHeight: false,
                    perPage: 10
                });
            } catch (error) {
                console.warn(`Failed to initialize DataTable for ${tableId}:`, error);
            }
        }, 100);

        return html;
    }

    _addCsvDownloadButton(container, data) {
        const toolActions = container.querySelector('.tool-actions');
        if (!toolActions || !data || !data.length) return;

        const headers = Object.keys(data[0]);
        const csvContent = [
            headers.join(','),
            ...data.map(row => headers.map(header => {
                let value = row[header];
                // Format dates and numbers
                if (value instanceof Date || (typeof value === 'string' && !isNaN(Date.parse(value)))) {
                    value = new Date(value).toISOString().split('T')[0];
                } else if (typeof value === 'number') {
                    value = value.toFixed(2);
                }
                // Handle values that need quotes (contains commas, quotes, or newlines)
                if (typeof value === 'string' && (value.includes(',') || value.includes('"') || value.includes('\n'))) {
                    value = `"${value.replace(/"/g, '""')}"`;
                }
                return value;
            }).join(','))
        ].join('\n');

        // Create download button
        const blob = new Blob([csvContent], { type: 'text/csv;charset=utf-8;' });
        const url = URL.createObjectURL(blob);
        
        const downloadButton = document.createElement('a');
        downloadButton.href = url;
        downloadButton.download = 'table_data.csv';
        downloadButton.className = 'btn btn-link btn text-primary p-0 ms-2';
        downloadButton.innerHTML = '<i class="fas fa-download"></i>';
        downloadButton.title = 'Download as CSV';
        
        // Clean up the URL on click
        downloadButton.addEventListener('click', () => {
            setTimeout(() => URL.revokeObjectURL(url), 100);
        });

        // Create copy button
        const copyButton = document.createElement('button');
        copyButton.className = 'btn btn-link btn text-primary p-0 ms-2';
        copyButton.innerHTML = '<i class="fas fa-copy"></i>';
        copyButton.title = 'Copy CSV to clipboard';
        
        copyButton.addEventListener('click', async () => {
            try {
                await navigator.clipboard.writeText(csvContent);
                // Show success feedback
                const originalIcon = copyButton.innerHTML;
                copyButton.innerHTML = '<i class="fas fa-check text-success"></i>';
                setTimeout(() => {
                    copyButton.innerHTML = originalIcon;
                }, 1000);
            } catch (err) {
                console.error('Failed to copy:', err);
                // Show error feedback
                const originalIcon = copyButton.innerHTML;
                copyButton.innerHTML = '<i class="fas fa-times text-danger"></i>';
                setTimeout(() => {
                    copyButton.innerHTML = originalIcon;
                }, 1000);
            }
        });

        toolActions.appendChild(copyButton);
        toolActions.appendChild(downloadButton);
    }

    _findTimeSeriesData(data) {
        // Check if data is an array of objects with date/time and numeric fields
        if (!Array.isArray(data) || !data.length) return null;

        // Look for date/time fields (prefer 'date' or 'timestamp' if they exist)
        const dateFields = Object.keys(data[0]).filter(key => {
            const value = data[0][key];
            return typeof value === 'string' && !isNaN(Date.parse(value));
        });

        if (dateFields.length === 0) return null;

        // Prefer fields named 'date' or 'timestamp', otherwise take the first date field
        const dateField = dateFields.find(field => 
            field.toLowerCase() === 'date' || 
            field.toLowerCase() === 'timestamp'
        ) || dateFields[0];

        // Find numeric fields, excluding those that end with common suffixes for derived values
        const excludeSuffixes = ['_change', '_previous', '_percent', '_ratio', '_delta'];
        const numericFields = Object.keys(data[0]).filter(key => {
            if (key === dateField) return false;
            const value = data[0][key];
            // Check if it's a number and doesn't end with excluded suffixes
            return typeof value === 'number' && 
                   !excludeSuffixes.some(suffix => key.toLowerCase().endsWith(suffix.toLowerCase()));
        });

        if (numericFields.length === 0) return null;

        // Find potential categorical fields (string fields with a reasonable number of unique values)
        const maxCategories = 10; // Maximum number of unique categories to consider
        const categoricalFields = Object.keys(data[0]).filter(key => {
            if (key === dateField || numericFields.includes(key)) return false;
            const values = new Set(data.map(item => item[key]));
            return typeof data[0][key] === 'string' && values.size > 1 && values.size <= maxCategories;
        });

        // If we found categorical fields, use the first one for grouping
        const categoryField = categoricalFields.length > 0 ? categoricalFields[0] : null;

        // Group data by date and category (if exists)
        const groupedData = new Map();
        
        data.forEach(item => {
            const date = new Date(item[dateField]);
            const dateKey = date.toISOString().split('T')[0]; // Group by day
            const categoryKey = categoryField ? item[categoryField] : 'default';
            const groupKey = `${dateKey}|${categoryKey}`;
            
            if (!groupedData.has(groupKey)) {
                groupedData.set(groupKey, {
                    counts: {},
                    sums: {},
                    date,
                    category: categoryKey
                });
            }
            
            const group = groupedData.get(groupKey);
            numericFields.forEach(field => {
                if (typeof item[field] === 'number' && !isNaN(item[field])) {
                    group.sums[field] = (group.sums[field] || 0) + item[field];
                    group.counts[field] = (group.counts[field] || 0) + 1;
                }
            });
        });

        // Convert grouped data back to array format with averages
        const aggregatedData = Array.from(groupedData.values()).map(group => {
            const result = {
                [dateField]: group.date
            };
            if (categoryField) {
                result[categoryField] = group.category;
            }
            numericFields.forEach(field => {
                if (group.counts[field]) {
                    result[field] = group.sums[field] / group.counts[field];
                }
            });
            return result;
        });

        // Sort by date
        aggregatedData.sort((a, b) => a[dateField] - b[dateField]);

        return {
            dateField,
            numericFields,
            categoryField,
            data: aggregatedData
        };
    }

    _createChart(container, timeSeriesData) {
        const { dateField, numericFields, categoryField, data } = timeSeriesData;
        const chartId = `chart-${Date.now()}`;
        const canvas = document.createElement('canvas');
        canvas.id = chartId;
        container.appendChild(canvas);

        const ctx = canvas.getContext('2d');
        
        // Create datasets based on numeric fields and categories
        let datasets = [];
        if (categoryField) {
            // Get unique categories
            const categories = [...new Set(data.map(item => item[categoryField]))];
            
            // For each numeric field and category combination
            numericFields.forEach(field => {
                categories.forEach(category => {
                    const categoryData = data.filter(item => item[categoryField] === category);
                    datasets.push({
                        label: `${this._formatFieldName(field)} - ${category}`,
                        data: categoryData.map(item => ({ x: new Date(item[dateField]), y: item[field] })),
                        borderColor: this._getRandomColor(),
                        tension: 0.4,
                        fill: false,
                        pointRadius: 3,
                        pointHoverRadius: 5,
                        pointHitRadius: 10
                    });
                });
            });
        } else {
            // Original behavior for no categories
            datasets = numericFields.map(field => ({
                label: this._formatFieldName(field),
                data: data.map(item => ({ x: new Date(item[dateField]), y: item[field] })),
                borderColor: this._getRandomColor(),
                tension: 0.4,
                fill: false,
                pointRadius: 3,
                pointHoverRadius: 5,
                pointHitRadius: 10
            }));
        }

        // Determine the time unit based on the data
        const dates = data.map(item => new Date(item[dateField]));
        const timeUnit = this._determineTimeUnit(dates);
        
        // Calculate min and max dates for the scale
        const minDate = new Date(Math.min(...dates));
        const maxDate = new Date(Math.max(...dates));
        
        // Calculate a reasonable number of ticks based on the date range
        const range = maxDate - minDate;
        const numberOfTicks = Math.min(10, data.length);
        
        const chart = new Chart(ctx, {
            type: 'line',
            data: {
                datasets: datasets
            },
            options: {
                responsive: true,
                maintainAspectRatio: false,
                interaction: {
                    intersect: false,
                    mode: 'index'
                },
                scales: {
                    x: {
                        type: 'time',
                        time: {
                            unit: timeUnit,
                            displayFormats: {
                                hour: 'MMM d, HH:mm',
                                day: 'MMM d',
                                week: 'MMM d',
                                month: 'MMM yyyy'
                            },
                            tooltipFormat: timeUnit === 'hour' ? 'MMM d, HH:mm' :
                                         timeUnit === 'day' ? 'MMM d, yyyy' :
                                         timeUnit === 'week' ? 'MMM d, yyyy' :
                                         'MMM yyyy'
                        },
                        min: minDate,
                        max: maxDate,
                        ticks: {
                            source: 'auto',
                            autoSkip: true,
                            maxTicksLimit: numberOfTicks
                        },
                        title: {
                            display: true,
                            text: 'Time'
                        }
                    },
                    y: {
                        beginAtZero: false,
                        title: {
                            display: true,
                            text: 'Value'
                        },
                        ticks: {
                            autoSkip: true,
                            maxTicksLimit: 8
                        }
                    }
                },
                plugins: {
                    title: {
                        display: true,
                        text: 'Time Series Data'
                    },
                    tooltip: {
                        enabled: true,
                        mode: 'index',
                        intersect: false,
                        callbacks: {
                            label: function(context) {
                                const label = context.dataset.label || '';
                                const value = context.parsed.y;
                                return `${label}: ${value.toLocaleString(undefined, {maximumFractionDigits: 2})}`;
                            }
                        }
                    },
                    legend: {
                        position: 'top',
                        align: 'center'
                    }
                },
                elements: {
                    point: {
                        radius: 3,
                        hitRadius: 10,
                        hoverRadius: 5
                    },
                    line: {
                        tension: 0.4
                    }
                }
            }
        });

        // Set a fixed height for the chart container
        canvas.style.height = '400px';
        
        this.charts.set(chartId, chart);
        return chartId;
    }

    _formatFieldName(field) {
        // Convert camelCase or snake_case to Title Case
        return field
            .replace(/([A-Z])/g, ' $1') // Split camelCase
            .replace(/_/g, ' ')         // Replace underscores with spaces
            .replace(/\w\S*/g, txt => txt.charAt(0).toUpperCase() + txt.substr(1).toLowerCase()); // Title case
    }

    _determineTimeUnit(dates) {
        if (dates.length < 2) return 'day'; // Default to day if not enough data points
        
        // Sort dates to ensure correct interval calculation
        dates.sort((a, b) => a - b);
        
        // Calculate all intervals between consecutive dates
        const intervals = [];
        for (let i = 1; i < dates.length; i++) {
            intervals.push(dates[i] - dates[i-1]);
        }
        
        // Get median interval in milliseconds
        intervals.sort((a, b) => a - b);
        const medianInterval = intervals[Math.floor(intervals.length / 2)];
        
        // Convert to hours for easier comparison
        const hours = medianInterval / (1000 * 60 * 60);
        
        // Determine appropriate unit based on median interval
        // For hourly data (intervals between 30 mins and 4 hours)
        if (hours <= 4) return 'hour';
        
        // For daily data (intervals between 4 hours and 5 days)
        if (hours <= 24 * 5) return 'day';
        
        // For weekly data (intervals between 5 days and 15 days)
        if (hours <= 24 * 15) return 'week';
        
        // For monthly data (intervals greater than 15 days)
        return 'month';
    }

    _getRandomColor() {
        const colors = [
            '#3498db', '#2ecc71', '#e74c3c', '#f1c40f', '#9b59b6',
            '#1abc9c', '#e67e22', '#34495e', '#16a085', '#c0392b'
        ];
        return colors[Math.floor(Math.random() * colors.length)];
    }

    _convertTimeSeriesDataToTable(timeSeriesData) {
        const { dateField, numericFields, data } = timeSeriesData;
        
        // Convert the time series data to a tabular format
        return data.map(item => {
            const row = {
                [dateField]: new Date(item[dateField]).toISOString()
            };
            numericFields.forEach(field => {
                row[field] = item[field];
            });
            return row;
        });
    }
}

export { ToolOutputManager };

================
File: static/agents/js/components/message_list.js
================
import { Message } from '/static/agents/js/components/message.js';

class MessageList {
    constructor(container) {
        this.container = container;
        this.messages = [];
        this.messageIds = new Map();  // Track message IDs
        
        // Get agent info from window.chatConfig
        this.currentAgent = {
            avatar: '/static/assets/img/agent-avatar-female-3.jfif',
            name: 'Agent'
        };
        
        this._setupContainer();
    }

    // Add method to update current agent
    updateCurrentAgent(agent) {
        if (agent?.avatar && agent?.name) {
            this.currentAgent = {
                avatar: agent.avatar,
                name: agent.name
            };
        }
    }

    _setupContainer() {
        // Ensure container has proper styling
        this.container.style.overflowY = 'auto';
    }

    addMessage(content, isAgent = false, avatar = null, messageId = null) {
        // Check if this is a crew message
        const isCrewMessage = typeof content === 'object' && content?.type === 'crew_message';
        
        const message = new Message(content, isAgent || isCrewMessage, avatar);
        this.messages.push(message);
        const domId = this._appendMessageToDOM(message);
        
        // Track message ID if provided
        if (messageId) {
            this.messageIds.set(domId, messageId);
        }
        
        this._scrollToBottom();
        return domId;
    }

    _appendMessageToDOM(message) {
        const domId = `msg-${Date.now()}`;
        const messageElement = message.render(domId);
        this.container.appendChild(messageElement);
        
        // Handle code blocks if any
        const codeBlocks = messageElement.querySelectorAll('pre code');
        if (codeBlocks.length > 0) {
            codeBlocks.forEach(block => {
                hljs.highlightElement(block);
            });
        }
        
        return domId;
    }

    _scrollToBottom() {
        this.container.scrollTop = this.container.scrollHeight;
    }

    clear() {
        this.messages = [];
        this.messageIds.clear();
        this.container.innerHTML = '';
    }

    // Method to handle historical messages
    loadHistory(messages) {
        this.clear();
        messages.forEach(msg => {
            this.addMessage(
                msg.content,
                msg.is_agent,
                msg.avatar,
                msg.id
            );
        });
    }

    deleteMessagesFromIndex(domId) {
        const container = document.getElementById(`${domId}-container`);
        if (!container) {
            console.warn('Could not find message container');
            return;
        }

        // Get the message ID
        const messageId = this.messageIds.get(domId);
        if (!messageId) {
            console.warn('No backend message ID found for container:', domId);
            return;
        }

        // Find all messages after this one (including this one)
        let currentElement = container;
        const messagesToDelete = [];
        
        while (currentElement) {
            if (currentElement.id && currentElement.id.includes('msg-')) {
                const currentDomId = currentElement.id.replace('-container', '');
                messagesToDelete.push({
                    element: currentElement,
                    domId: currentDomId,
                    backendId: this.messageIds.get(currentDomId)
                });
            }
            currentElement = currentElement.nextElementSibling;
        }

        // Remove messages and clear their IDs
        messagesToDelete.forEach(({ element, domId }) => {
            this.messageIds.delete(domId);
            element.remove();
        });
    }

    getMessageId(domId) {
        const messageId = this.messageIds.get(domId);
        return messageId;
    }
}

export { MessageList };

================
File: static/agents/js/components/message.js
================
class Message {
    constructor(content, isAgent = false, avatar = null) {
        // Handle case where content is a JSON object with message field
        if (typeof content === 'object' && content !== null && content.message) {
            this.content = content.message;
            this.rawContent = content;
            this.isCrewMessage = content.type === 'crew_message';
            this.isAgent = isAgent || this.isCrewMessage; // Treat crew messages like agent messages
        } else {
            this.content = content;
            this.rawContent = null;
            this.isCrewMessage = false;
            this.isAgent = isAgent;
        }
        this.avatar = avatar || (this.isAgent ? window.chatConfig.currentAgent.avatar : '/static/assets/img/user-avatar.jfif');
    }

    _detectAndFormatTableData(content) {
        try {
            // First check if content starts with markdown headers or common markdown elements
            if (typeof content === 'string' && 
                (content.trim().startsWith('#') || 
                 content.trim().startsWith('*') || 
                 content.trim().startsWith('-'))) {
                return null; // Let the markdown parser handle it
            }

            // Try to parse the content as JSON
            let data = content;
            if (typeof content === 'string') {
                // Check if content is wrapped in markdown code block
                const codeBlockMatch = content.match(/```(?:json)?\n([\s\S]*?)\n```/);
                if (codeBlockMatch) {
                    try {
                        // Clean up the JSON content
                        let jsonContent = codeBlockMatch[1].trim();
                        data = JSON.parse(jsonContent);
                    } catch (e) {
                        console.debug('Content is not valid JSON, will be handled as markdown');
                        return null;
                    }
                }
            }

            // Look for common patterns in the data structure
            if (typeof data === 'object' && data !== null) {
                // Check for common response patterns and nested data
                for (const key of ['data', 'results', 'analytics_data', 'records', 'rows', 'items', 'response']) {
                    if (data[key] && Array.isArray(data[key]) && data[key].length > 0) {
                        const tableHtml = this._createTable(data[key]);
                        if (tableHtml) {
                            // If there's text before or after the code block, preserve it
                            let parts = [];
                            if (this.rawContent && this.rawContent.message) {
                                parts = this.rawContent.message.split(/```json\n[\s\S]*?\n```/);
                            } else {
                                parts = this.content.split(/```(?:json)?\n[\s\S]*?\n```/);
                            }
                            const prefix = parts[0] ? marked.parse(parts[0].trim()) : '';
                            const suffix = parts[1] ? marked.parse(parts[1].trim()) : '';
                            return prefix + tableHtml + suffix;
                        }
                    }
                }

                // If no list found in known keys, check all values
                for (const value of Object.values(data)) {
                    if (Array.isArray(value) && value.length > 0 && typeof value[0] === 'object') {
                        return this._createTable(value);
                    }
                }
            }
        } catch (error) {
            console.error('Error detecting table data:', error);
        }
        return null;
    }

    _createTable(data) {
        if (!Array.isArray(data) || !data.length) return null;

        const tableId = `table-${Date.now()}`;
        const headers = Object.keys(data[0]);
        const rows = data.map(row => headers.map(header => {
            const value = row[header];
            // Format dates and numbers
            if (value instanceof Date || (typeof value === 'string' && !isNaN(Date.parse(value)))) {
                return new Date(value).toISOString().split('T')[0];
            }
            if (typeof value === 'number') {
                return value.toLocaleString(undefined, { maximumFractionDigits: 2 });
            }
            return value;
        }));

        return `
            <div class="table-responsive">
                <table id="${tableId}" class="table table-sm">
                    <thead>
                        <tr>
                            ${headers.map(header => `<th>${this._formatFieldName(header)}</th>`).join('')}
                        </tr>
                    </thead>
                    <tbody>
                        ${rows.map(row => `
                            <tr>
                                ${row.map(cell => `<td>${cell}</td>`).join('')}
                            </tr>
                        `).join('')}
                    </tbody>
                </table>
            </div>
        `;
    }

    _formatFieldName(field) {
        // Convert camelCase or snake_case to Title Case
        return field
            .replace(/([A-Z])/g, ' $1') // Split camelCase
            .replace(/_/g, ' ')         // Replace underscores with spaces
            .replace(/\w\S*/g, txt => txt.charAt(0).toUpperCase() + txt.substr(1).toLowerCase()); // Title case
    }

    render(domId) {
        const messageElement = document.createElement('div');
        messageElement.id = `${domId}-container`;
        messageElement.className = `d-flex ${this.isAgent ? 'justify-content-start' : 'justify-content-end'} mb-4`;

        // Format content for display
        let formattedContent = this.content;
        if (this.isAgent || this.isCrewMessage) {
            try {
                // First try to detect and format table data
                const tableHtml = this._detectAndFormatTableData(this.content);
                if (tableHtml) {
                    formattedContent = tableHtml;
                } else {
                    formattedContent = marked.parse(this.content);
                }
            } catch (error) {
                console.error('Error parsing content:', error);
                formattedContent = this.content;
            }
        }

        messageElement.innerHTML = `
            ${this.isAgent || this.isCrewMessage ? `<div class="avatar me-2">
                <img src="${this.avatar}" 
                     alt="${this.isCrewMessage ? 'Crew' : window.chatConfig.currentAgent.name}" 
                     class="border-radius-lg shadow">
            </div>` : ''}
            <div class="message ${this.isAgent || this.isCrewMessage ? 'agent' : 'user'}" style="max-width: 75%;">
                <div class="message-content">
                    <div class="message-actions">
                        <button class="btn btn-link copy-message" title="Copy to clipboard">
                            <i class="fas fa-copy"></i>
                        </button>
                        ${!this.isAgent && !this.isCrewMessage ? `
                        <button class="btn btn-link edit-message" title="Edit message">
                            <i class="fas fa-edit"></i>
                        </button>` : ''}
                    </div>
                    <div class="message-text">
                        ${formattedContent}
                    </div>
                </div>
            </div>
            ${!this.isAgent && !this.isCrewMessage ? `<div class="avatar ms-2">
                <img src="${this.avatar}" alt="User" class="border-radius-lg shadow">
            </div>` : ''}
        `;

        // Add event listeners for message actions
        const copyButton = messageElement.querySelector('.copy-message');
        if (copyButton) {
            copyButton.addEventListener('click', () => {
                const textToCopy = messageElement.querySelector('.message-text').textContent;
                navigator.clipboard.writeText(textToCopy).then(() => {
                    copyButton.innerHTML = '<i class="fas fa-check"></i>';
                    setTimeout(() => {
                        copyButton.innerHTML = '<i class="fas fa-copy"></i>';
                    }, 1000);
                }).catch(err => {
                    console.error('Failed to copy text:', err);
                    copyButton.innerHTML = '<i class="fas fa-times"></i>';
                    setTimeout(() => {
                        copyButton.innerHTML = '<i class="fas fa-copy"></i>';
                    }, 1000);
                });
            });
        }

        // Add event listener for edit button
        const editButton = messageElement.querySelector('.edit-message');
        if (editButton) {
            editButton.addEventListener('click', () => {
                const event = new CustomEvent('edit-message', { detail: { domId } });
                document.dispatchEvent(event);
            });
        }

        // Initialize DataTable for any tables in the message
        const table = messageElement.querySelector('table');
        if (table) {
            setTimeout(() => {
                try {
                    new simpleDatatables.DataTable(table, {
                        searchable: true,
                        fixedHeight: false,
                        perPage: 10
                    });
                } catch (error) {
                    console.warn(`Failed to initialize DataTable:`, error);
                }
            }, 100);
        }

        return messageElement;
    }
}

export { Message };

================
File: static/agents/js/modules/content_expander.js
================
// Content expander module for handling expandable card content
export class ContentExpander {
    constructor() {
        this.sidePanel = null;
        this.activeCard = null;
        this.setupSidePanel();
    }

    setupSidePanel() {
        // Create side panel if it doesn't exist
        if (!document.getElementById('content-side-panel')) {
            const panel = document.createElement('div');
            panel.id = 'content-side-panel';
            panel.className = 'position-fixed end-0 top-0 h-100 bg-white shadow-lg';
            panel.style.width = '0';
            panel.style.transition = 'width 0.3s ease-in-out';
            panel.style.zIndex = '1040';
            panel.innerHTML = `
                <div class="d-flex flex-column h-100">
                    <div class="p-3 border-bottom d-flex justify-content-between align-items-center">
                        <h6 class="mb-0 content-title"></h6>
                        <div>
                            <button class="btn btn-link text-dark p-0 me-3" id="export-content">
                                <i class="fas fa-download"></i>
                            </button>
                            <button class="btn btn-link text-dark p-0" id="close-panel">
                                <i class="fas fa-times"></i>
                            </button>
                        </div>
                    </div>
                    <div class="p-3 flex-grow-1 overflow-auto content-body"></div>
                </div>
            `;
            document.body.appendChild(panel);
            this.sidePanel = panel;
            
            // Add event listeners
            document.getElementById('close-panel').addEventListener('click', () => this.closeSidePanel());
            document.getElementById('export-content').addEventListener('click', () => this.exportContent());
        }
    }

    expandContent(cardElement, title, content, metadata = {}) {
        console.log('expandContent called', { title, content, metadata });
        this.activeCard = cardElement;
        this.activeContent = { title, content, metadata };
        
        // Highlight active card
        if (this.activeCard) {
            this.activeCard.classList.add('border-primary');
        }
        
        // Update panel content
        const titleEl = this.sidePanel.querySelector('.content-title');
        const bodyEl = this.sidePanel.querySelector('.content-body');
        
        titleEl.textContent = title;
        // Use the global markdown-it instance
        if (!window.md) {
            console.error('markdown-it not initialized');
            return;
        }
        
        // Check if content appears to be markdown
        // const isMarkdown = /^#|\[.*\]\(.*\)|\*{1,2}|`{1,3}/.test(content);

        const renderedContent = window.md.render(content);

        console.log('Rendered content:', renderedContent);  // Fixed syntax error here
    
        bodyEl.innerHTML = `
            <div class="card border-0">
                <div class="card-body">
                    <div class="markdown-content mb-3">${renderedContent}</div>
                    ${this.renderMetadata(metadata)}
                </div>
            </div>
        `;
            
        // Show panel
        this.sidePanel.style.width = '500px';
    }

    renderMetadata(metadata) {
        if (!Object.keys(metadata).length) return '';
        
        return `
            <div class="border-top pt-3 mt-3">
                ${Object.entries(metadata).map(([key, value]) => `
                    <div class="d-flex justify-content-between align-items-center mb-2">
                        <small class="text-muted">${key}:</small>
                        <span class="text-sm">${value}</span>
                    </div>
                `).join('')}
            </div>
        `;
    }

    closeSidePanel() {
        // Remove highlight from active card
        if (this.activeCard) {
            this.activeCard.classList.remove('border-primary');
            this.activeCard = null;
        }
        
        // Hide panel
        this.sidePanel.style.width = '0';
    }

    exportContent() {
        if (!this.activeContent) return;
        
        const { title, content, metadata } = this.activeContent;
        const exportData = {
            title,
            content,
            metadata,
            exportedAt: new Date().toISOString()
        };
        
        // Create blob and download
        const blob = new Blob([JSON.stringify(exportData, null, 2)], { type: 'application/json' });
        const url = URL.createObjectURL(blob);
        const a = document.createElement('a');
        a.href = url;
        a.download = `${title.toLowerCase().replace(/\s+/g, '-')}-${new Date().getTime()}.json`;
        document.body.appendChild(a);
        a.click();
        document.body.removeChild(a);
        URL.revokeObjectURL(url);
    }
}

================
File: static/agents/js/services/message_handler.js
================
class MessageHandler {
    constructor(messageList, toolOutputManager) {
        this.messageList = messageList;
        this.toolOutputManager = toolOutputManager;
        this.websocket = null;  // Will be set after construction
        this.messagesContainer = document.getElementById('chat-messages');
        this.currentToolContainer = null;
        this.loadingIndicator = null;
        this.onSystemMessage = null; // Callback for system messages
        this.lastHumanInputContext = null; // Store context for human input
    }

    handleMessage(message) {
        console.log('Received message:', message);

        switch (message.type) {
            case 'system_message':
                this.handleSystemMessage(message);
                break;
            case 'user_message':
                this.handleUserMessage(message);
                break;
            case 'agent_message':
                this.removeLoadingIndicator();
                this.handleAgentMessage(message);
                break;
            case 'crew_message':
                // Only remove loading indicator if crew execution is completed
                if (message.status && (message.status === 'DONE' || message.status === 'COMPLETED')) {
                    this.removeLoadingIndicator();
                }
                this.handleCrewMessage(message);
                break;
            case 'execution_update':
                this.handleExecutionUpdate(message);
                break;
            case 'agent_finish':
                console.log('Agent finish:', message);
                this.handleAgentFinish(message);
                break;
            case 'tool_start':
                this.handleToolStart(message);
                break;
            case 'tool_end':
                this.handleToolEnd(message);
                break;
            case 'tool_result':
                this.handleToolResult(message);
                break;
            case 'error':
                console.log('Error message:', message);
                this.handleErrorMessage(message);
                break;
            default:
                console.warn('Unknown message type:', message.type);
        }
    }

    showLoadingIndicator() {
        // Remove any existing loading indicator first
        this.removeLoadingIndicator();

        // Create the loading indicator
        const loadingContainer = document.createElement('div');
        loadingContainer.className = 'd-flex justify-content-start mb-4 streaming-message';
        loadingContainer.innerHTML = `
            <div class="avatar me-2">
                <img src="${this.messageList.currentAgent.avatar}" 
                     alt="${this.messageList.currentAgent.name}" 
                     class="border-radius-lg shadow">
            </div>
            <div class="agent-message" style="max-width: 75%;">
                <div class="message-content loading-content">
                    <div class="typing-indicator">
                        <div class="typing-dots">
                            <span></span>
                            <span></span>
                            <span></span>
                        </div>
                        <div class="typing-text ms-2">Thinking...</div>
                    </div>
                </div>
            </div>
        `;

        this.loadingIndicator = loadingContainer;
        this.messagesContainer.appendChild(loadingContainer);
        this.scrollToBottom();
    }

    removeLoadingIndicator() {
        if (this.loadingIndicator) {
            this.loadingIndicator.remove();
            this.loadingIndicator = null;
        }
    }

    scrollToBottom() {
        if (this.messagesContainer) {
            this.messagesContainer.scrollTop = this.messagesContainer.scrollHeight;
        }
    }

    handleSystemMessage(message) {
        // Call the system message callback if set
        if (this.onSystemMessage) {
            this.onSystemMessage(message);
        }

        if (message.connection_status) {
            this.handleConnectionStatus(message.connection_status);
        }
    }

    handleConnectionStatus(status) {
        const dot = document.querySelector('.connection-dot');
        if (dot) {
            dot.className = 'connection-dot ' + status;
        }
    }

    handleUserMessage(message) {
        // Only add to UI if this is the first time we're seeing this message
        if (message.id) {
            this.messageList.addMessage(message.message, false, null, message.id);
            
            // If we have stored human input context, send the response
            if (this.lastHumanInputContext && this.websocket) {
                this.websocket.send({
                    type: 'user_message',
                    message: message.message,
                    context: this.lastHumanInputContext
                });
                this.lastHumanInputContext = null;
            }
        }
        
        this.showLoadingIndicator();
    }

    handleAgentMessage(message) {
        // Handle structured tool messages
        if (message.content && message.content.tool) {
            this.toolOutputManager.handleToolStart({
                tool: message.content.tool,
                input: message.content.input
            });
            return;
        }

        // Handle legacy text-based tool messages
        if (typeof message.message === 'string') {
            if (message.message.startsWith('Tool Start:') || message.message.startsWith('Using Tool:')) {
                try {
                    const toolMessage = message.message;
                    const toolMatch = toolMessage.match(/^(?:Tool Start:|Using Tool:)\s*(.*?)\s*-/);
                    const toolName = toolMatch ? toolMatch[1].trim() : 'Tool';
                    
                    this.toolOutputManager.handleToolStart({
                        tool: toolName,
                        input: toolMessage
                    });
                } catch (error) {
                    console.error('Error parsing tool start message:', error);
                    this.messageList.addMessage(message.message, true, null, message.id);
                }
            } else if (message.message.startsWith('Tool Result:') || message.message.startsWith('Tool result:')) {
                try {
                    const jsonStr = message.message.replace(/^(Tool Result:|Tool result:)/, '').trim();
                    const data = JSON.parse(jsonStr);
                    
                    if (data.analytics_data && Array.isArray(data.analytics_data)) {
                        this.toolOutputManager.handleToolResult({ 
                            type: 'table', 
                            data: data.analytics_data 
                        });
                    } else {
                        this.toolOutputManager.handleToolResult({ 
                            type: 'json', 
                            data 
                        });
                    }
                } catch (error) {
                    console.error('Error parsing tool result message:', error);
                    this.messageList.addMessage(message.message, true, null, message.id);
                }
            } else if (message.message.startsWith('Tool Error:')) {
                const errorMessage = message.message.replace('Tool Error:', '').trim();
                this.toolOutputManager.handleToolResult({
                    type: 'error',
                    data: errorMessage
                });
            } else {
                this.messageList.addMessage(message.message, true, null, message.id);
            }
        } else {
            // Handle structured message
            this.messageList.addMessage(message.message, true, null, message.id);
        }
    }

    handleAgentFinish(message) {
        try {
            const data = typeof message.message === 'string' ? JSON.parse(message.message) : message.message;
            if (data.analytics_data && Array.isArray(data.analytics_data)) {
                this.toolOutputManager.handleToolResult({
                    type: 'table',
                    data: data.analytics_data
                });
            } else {
                this.messageList.addMessage(message.message, true, null, message.id);
            }
        } catch (error) {
            this.messageList.addMessage(message.message, true, null, message.id);
        }
    }

    handleToolStart(message) {
        const toolData = {
            tool: message.content?.tool || message.message?.tool,
            input: message.content?.input || message.message?.input
        };
        this.toolOutputManager.handleToolStart(toolData);
    }

    handleToolEnd(message) {
        // Handle tool end if needed
    }

    handleToolResult(message) {
        let result;
        try {
            // Handle both content and message formats
            const data = message.content || message.message;
            const parsedData = typeof data === 'string' ? JSON.parse(data) : data;
            
            if (parsedData.error) {
                result = { type: 'error', data: parsedData.error };
            } else if (parsedData.analytics_data && Array.isArray(parsedData.analytics_data)) {
                result = { type: 'table', data: parsedData.analytics_data };
            } else {
                result = { type: 'json', data: parsedData };
            }
        } catch (error) {
            console.error('Error parsing tool result:', error);
            result = { type: 'text', data: message.content || message.message };
        }
        this.toolOutputManager.handleToolResult(result);
    }

    handleErrorMessage(message) {
        console.error('Server error:', message.message);
    }

    handleCrewMessage(message) {
        // Handle crew-specific messages
        if (message.message && typeof message.message === 'string') {
            // Handle tool messages
            if (message.message.startsWith('Using tool:') || message.message.startsWith('Tool Start:')) {
                // Don't add the tool start message directly to chat
                const toolMessage = message.message;
                const toolMatch = toolMessage.match(/^(?:Tool Start:|Using Tool:)\s*(.*?)(?:\nInput:|$)/);
                const toolName = toolMatch ? toolMatch[1].trim() : 'Tool';
                const inputMatch = toolMessage.match(/Input:(.*?)(?:\n|$)/s);
                const input = inputMatch ? inputMatch[1].trim() : '';
                
                this.toolOutputManager.handleToolStart({
                    tool: toolName,
                    input: input
                });
                return;
            } else if (message.message.startsWith('Tool Result:') || message.message.startsWith('Tool result:')) {
                // Don't add the tool result message directly to chat
                const resultContent = message.message.replace(/^(Tool Result:|Tool result:)/, '').trim();
                
                // Try to parse as JSON first
                try {
                    const jsonData = JSON.parse(resultContent);
                    if (jsonData.analytics_data && Array.isArray(jsonData.analytics_data)) {
                        this.toolOutputManager.handleToolResult({ 
                            type: 'table', 
                            data: jsonData.analytics_data 
                        });
                    } else {
                        this.toolOutputManager.handleToolResult({ 
                            type: 'json', 
                            data: jsonData 
                        });
                    }
                } catch (jsonError) {
                    // If not JSON, handle as text result
                    this.toolOutputManager.handleToolResult({ 
                        type: 'text', 
                        data: resultContent 
                    });
                }
                return;
            } else if (message.message.startsWith('Tool Error:')) {
                // Don't add the tool error message directly to chat
                const errorMessage = message.message.replace('Tool Error:', '').trim();
                this.toolOutputManager.handleToolResult({
                    type: 'error',
                    data: errorMessage
                });
                return;
            }
        }

        // If this is a human input request, store the context
        if (message.context?.is_human_input) {
            this.lastHumanInputContext = message.context;
            this.removeLoadingIndicator();
        }

        // Only add non-tool messages to UI
        if (!message.message?.startsWith('Using tool:') && 
            !message.message?.startsWith('Tool Start:') && 
            !message.message?.startsWith('Tool Result:') && 
            !message.message?.startsWith('Tool result:') && 
            !message.message?.startsWith('Tool Error:')) {
            this.messageList.addMessage(message, true);
            this.scrollToBottom();
        }
    }

    handleExecutionUpdate(message) {
        // Handle execution status updates
        if (message.status === 'RUNNING') {
            this.showLoadingIndicator();
        } else if (message.status === 'COMPLETED' || message.status === 'FAILED') {
            this.removeLoadingIndicator();
        }
        
        // Only add non-tool messages to UI
        if (message.message && 
            !message.message.startsWith('Using tool:') && 
            !message.message.startsWith('Tool Start:') && 
            !message.message.startsWith('Tool Result:') && 
            !message.message.startsWith('Tool result:') && 
            !message.message.startsWith('Tool Error:')) {
            this.messageList.addMessage({
                type: 'crew_message',
                message: message.message
            }, true, null, null);
            this.scrollToBottom();
        }
    }

    _sendMessage(message) {
        if (!this.websocket) {
            console.error('No websocket available for sending message');
            return;
        }

        // If we have human input context, send as human input response
        if (this.lastHumanInputContext) {
            this.websocket.send({
                type: 'user_message',
                message: message,
                context: this.lastHumanInputContext
            });
            this.lastHumanInputContext = null;
        } else {
            // Send as regular message
            this.websocket.send(message);
        }
    }
}

export { MessageHandler };

================
File: static/agents/js/services/websocket.js
================
class ChatWebSocket {
    constructor(config, messageHandler) {
        this.config = config;
        this.messageHandler = messageHandler;
        this.socket = null;
        this.reconnectAttempts = 0;
        this.maxReconnectAttempts = 5;
        this.reconnectDelay = 1000; // Start with 1 second
        this.isReconnecting = false;
        this.lastMessageQueue = [];  // Queue to store messages during reconnection
    }

    connect() {
        if (this.socket?.readyState === WebSocket.CONNECTING) {
            console.log('WebSocket already connecting, skipping connect attempt');
            return;
        }

        const wsUrl = `${this.config.urls.wsBase}?session=${this.config.sessionId}`;
        this.socket = new WebSocket(wsUrl);

        this.socket.onopen = () => {
            console.log('WebSocket connected');
            this.reconnectAttempts = 0;
            this.isReconnecting = false;
            this.messageHandler.handleConnectionStatus('connected');
            
            // Send any queued messages
            while (this.lastMessageQueue.length > 0) {
                const message = this.lastMessageQueue.shift();
                this.send(message);
            }
        };

        this.socket.onmessage = (event) => {
            try {
                const data = JSON.parse(event.data);
                this.messageHandler.handleMessage(data);
            } catch (error) {
                console.error('Error handling message:', error);
            }
        };

        this.socket.onclose = (event) => {
            console.log('WebSocket closed:', event);
            this.messageHandler.handleConnectionStatus('disconnected');
            
            // Don't attempt to reconnect if this was a normal closure
            if (event.code === 1000 || event.code === 1001) {
                console.log('WebSocket closed normally, not attempting reconnect');
                return;
            }
            
            this._handleReconnect();
        };

        this.socket.onerror = (error) => {
            console.error('WebSocket error:', error);
            this.messageHandler.handleConnectionStatus('error');
        };
    }

    send(data) {
        if (this.socket && this.socket.readyState === WebSocket.OPEN) {
            console.log('Sending WebSocket message:', data);
            this.socket.send(JSON.stringify(data));
        } else {
            console.warn('WebSocket is not open, queueing message:', data);
            // Queue the message if we're reconnecting
            if (this.isReconnecting) {
                this.lastMessageQueue.push(data);
            }
        }
    }

    _handleReconnect() {
        if (this.isReconnecting) {
            console.log('Already attempting to reconnect, skipping');
            return;
        }

        if (this.reconnectAttempts < this.maxReconnectAttempts) {
            this.isReconnecting = true;
            this.reconnectAttempts++;
            const delay = this.reconnectDelay * Math.pow(2, this.reconnectAttempts - 1);
            console.log(`Attempting to reconnect in ${delay}ms...`);
            
            setTimeout(() => {
                console.log('Reconnecting...');
                this.connect();
            }, delay);
        } else {
            console.error('Max reconnection attempts reached');
            this.messageHandler.handleError('Connection lost. Please refresh the page.');
            this.isReconnecting = false;
        }
    }

    disconnect() {
        if (this.socket) {
            this.socket.close(1000, 'Normal closure');  // Use 1000 for normal closure
        }
    }
}

export { ChatWebSocket };

================
File: static/agents/js/crew_kanban.js
================
// Check required dependencies
if (typeof bootstrap === 'undefined') {
    console.error('Bootstrap is required but not loaded');
}
if (typeof markdownit === 'undefined') {
    console.error('markdown-it is required but not loaded');
}
if (typeof jKanban === 'undefined') {
    console.error('jKanban is required but not loaded');
}

// Verify required variables from template
if (typeof crewId === 'undefined') {
    console.error('crewId is required but not defined');
}
if (typeof clientId === 'undefined') {
    console.warn('clientId is not defined'); // warning since it can be null
}

// Initialize markdown-it globally
window.md = window.markdownit();

// WebSocket configuration and state
const wsScheme = window.location.protocol === 'https:' ? 'wss' : 'ws';
let socket = null;
let reconnectAttempts = 0;
const maxReconnectAttempts = 5;
let reconnectDelay = 1000;
let pingInterval = null;
let lastPongTime = Date.now();

// Task tracking
let lastUpdatedTaskId = null;
let lastUpdatedTaskIndex = null;  // Track last used task index

// DOM elements cache
const elements = {
    kanbanContainer: document.getElementById('kanban-tasks'),
    executionNumber: document.getElementById('execution-number'),
    cancelButton: document.getElementById('cancelExecutionBtn')
};

// Initialize CSRF token
function getCsrfToken() {
    const token = document.querySelector('[name=csrfmiddlewaretoken]');
    if (!token) {
        console.error('CSRF token not found');
        return '';
    }
    return token.value;
}

// Import ContentExpander module
import { ContentExpander } from './modules/content_expander.js';
console.log('ContentExpander imported');
// Initialize content expander
const contentExpander = new ContentExpander();
console.log('ContentExpander initialized', contentExpander);
async function fetchActiveExecutions() {
    try {
        const response = await fetch(`/agents/crew/${crewId}/active-executions/`);
        if (!response.ok) {
            throw new Error(`HTTP error! status: ${response.status}`);
        }
        const data = await response.json();
        
        // Update cancel button based on active executions
        const hasActiveExecution = data.executions && data.executions.length > 0;
        const activeExecutionId = hasActiveExecution ? data.executions[0].execution_id : null;
        updateCancelButton(hasActiveExecution, activeExecutionId);
        
        // Clear boards first
        document.querySelectorAll('.kanban-drag').forEach(board => {
            board.innerHTML = '';
        });
        
        // Repopulate with active executions
        data.executions.forEach(execution => {
            updateKanbanBoard({
                execution_id: execution.execution_id,
                task_id: execution.task_id,
                name: execution.name,
                status: execution.status,
                stages: execution.stages
            });
        });
        
        return data;
    } catch (error) {
        console.error('Error fetching active executions:', error);
        return null;
    }
}

function connectWebSocket() {
    if (socket && socket.readyState === WebSocket.OPEN) {
        console.log('WebSocket already connected');
        return;
    }
    
    // Close existing socket if it exists
    if (socket) {
        socket.close();
    }

    // Clear all kanban boards
    document.querySelectorAll('.kanban-drag').forEach(board => {
        board.innerHTML = '';
    });
    
    try {
        socket = new WebSocket(
            `${wsScheme}://${window.location.host}/ws/crew/${crewId}/kanban/`
        );
        
        socket.onopen = function(e) {
            console.log('WebSocket connection established');
            // Fetch active executions when connection is established
            fetchActiveExecutions();
        };

        socket.onmessage = function(e) {
            const data = JSON.parse(e.data);
            
            if (!data.type) {
                console.error("Message missing type:", data);
                return;
            }
            
            handleWebSocketMessage(data);
        };

        socket.onclose = function(e) {
            console.log('WebSocket connection closed', e.code, e.reason);
            stopPingInterval();
            
            // Don't reconnect if closed normally
            if (e.code === 1000 || e.code === 1001) {
                console.log('WebSocket closed normally');
                return;
            }
            
            // Attempt to reconnect if not at max attempts
            if (reconnectAttempts < maxReconnectAttempts) {
                reconnectAttempts++;
                console.log(`Attempting to reconnect (${reconnectAttempts}/${maxReconnectAttempts})...`);
                
                // Exponential backoff with jitter
                reconnectDelay = Math.min(reconnectDelay * 2, 30000);
                const jitter = Math.random() * 1000;
                setTimeout(connectWebSocket, reconnectDelay + jitter);
            } else {
                console.error('Max reconnection attempts reached');
            }
        };

        socket.onerror = function(e) {
            console.error('WebSocket error:', e);
            // Let onclose handle reconnection
        };
        
    } catch (error) {
        console.error('Error creating WebSocket:', error);
        // Attempt to reconnect on connection error
        if (reconnectAttempts < maxReconnectAttempts) {
            reconnectAttempts++;
            setTimeout(connectWebSocket, reconnectDelay);
        }
    }
}

// Ping interval to keep connection alive
function startPingInterval() {
    stopPingInterval(); // Clear any existing interval
    
    // Send ping every 15 seconds
    pingInterval = setInterval(() => {
        if (socket && socket.readyState === WebSocket.OPEN) {
            // Check if we haven't received a pong in 45 seconds
            if (Date.now() - lastPongTime > 45000) {
                console.log('No pong received for 45 seconds, reconnecting...');
                socket.close();
                connectWebSocket();
                return;
            }
            
            socket.send(JSON.stringify({ type: 'ping' }));
        }
    }, 15000);
}

function stopPingInterval() {
    if (pingInterval) {
        clearInterval(pingInterval);
        pingInterval = null;
    }
}

// Initial connection
connectWebSocket();

// Clean up on page unload
window.addEventListener('beforeunload', () => {
    stopPingInterval();
    if (socket) {
        socket.close();
    }
});


function updateKanbanBoard(data) {
    // Only proceed if we have an execution_id
    if (!data.execution_id) {
        console.log('No execution_id provided, skipping update');
        return;
    }
    
    // Update cancel button based on execution status
    if (data.execution_id && data.status) {
        const isActive = ['PENDING', 'RUNNING'].includes(data.status.toUpperCase());
        updateCancelButton(isActive, isActive ? data.execution_id : null);
    }
    
    // Update execution number in header
    const executionSpan = document.getElementById('execution-number');
    if (executionSpan) {
        executionSpan.textContent = ` - Execution #${data.execution_id}`;
    }

    // Use task_index for board placement, fallback to last used index
    const taskIndex = data.task_index !== undefined ? data.task_index : lastUpdatedTaskIndex;
    console.log('Updating board with task index:', taskIndex, '(from data:', data.task_index, ', last:', lastUpdatedTaskIndex, ')');
    
    // Get all kanban boards in order
    const taskBoards = document.querySelectorAll('.kanban-board');
    let targetBoard;
    
    if (taskIndex !== null && taskIndex !== undefined && taskIndex < taskBoards.length) {
        targetBoard = taskBoards[taskIndex];
        lastUpdatedTaskIndex = taskIndex;  // Update the last used index
        console.log('Found target board for index:', taskIndex);
    } else {
        // Fallback to first board if no valid index available
        targetBoard = taskBoards[0];
        console.log('Using first board as fallback, no valid task index');
    }

    if (targetBoard) {
        addUpdateToBoard(targetBoard, data);
    } else {
        console.log('No board found for update');
    }
}

function handleHumanInputSubmit(button) {
    const stageItem = button.closest('.stage-item');
    const executionId = stageItem.getAttribute('data-execution-id');
    console.log("Submitting human input for execution:", executionId);
    
    if (!executionId) {
        console.error("No execution ID found for human input submission");
        alert('Error: Could not determine execution ID');
        return;
    }

    const textarea = button.parentElement.querySelector('textarea');
    const input = textarea.value.trim();
    
    if (!input) {
        alert('Please enter a response before submitting.');
        return;
    }
    
    // Disable the button and textarea while submitting
    button.disabled = true;
    textarea.disabled = true;
    
    console.log(`Sending human input to /agents/crew/execution/${executionId}/input/`);
    
    fetch(`/agents/crew/execution/${executionId}/input/`, {
        method: 'POST',
        headers: {
            'Content-Type': 'application/json',
            'X-CSRFToken': getCookie('csrftoken')
        },
        body: JSON.stringify({
            input: input
        })
    })
    .then(response => {
        if (!response.ok) {
            throw new Error(`Network response was not ok: ${response.status}`);
        }
        return response.json();
    })
    .then(data => {
        console.log("Successfully submitted human input:", data);
        // Clear and disable the input after successful submission
        textarea.value = '';
    })
    .catch(error => {
        console.error('Error submitting human input:', error);
        alert('Failed to submit input. Please try again.');
        // Re-enable the button and textarea on error
        button.disabled = false;
        textarea.disabled = false;
    });
}

function getCookie(name) {
    let cookieValue = null;
    if (document.cookie && document.cookie !== '') {
        const cookies = document.cookie.split(';');
        for (let i = 0; i < cookies.length; i++) {
            const cookie = cookies[i].trim();
            if (cookie.substring(0, name.length + 1) === (name + '=')) {
                cookieValue = decodeURIComponent(cookie.substring(name.length + 1));
                break;
            }
        }
    }
    return cookieValue;
}

function updateAgentProgress(data) {
    console.log('Updating agent progress:', data);
    const execution = document.querySelector(`[data-execution-id="${data.execution_id}"]`);
    if (!execution) return;

    const stageContainer = execution.querySelector('.card-body');
    const agentSection = stageContainer.querySelector('.agent-progress') || 
        stageContainer.insertAdjacentHTML('beforeend', '<div class="agent-progress mt-3"></div>');

    const progressHtml = `
        <div class="alert alert-info mb-2">
            <strong>${data.agent || 'Agent'}</strong>: ${data.content}
        </div>
    `;
    
    if (agentSection.children.length > 5) {
        agentSection.removeChild(agentSection.firstChild);
    }
    agentSection.insertAdjacentHTML('beforeend', progressHtml);
}

function handleTaskComplete(data) {
    console.log('Task completed:', data);
    const execution = document.querySelector(`[data-execution-id="${data.execution_id}"]`);
    if (!execution) return;

    // Show completion message
    const stageContainer = execution.querySelector('.card-body');
    const completionHtml = `
        <div class="alert alert-success mb-0">
            <strong>Task Complete!</strong> ${data.message || ''}
        </div>
    `;
    stageContainer.insertAdjacentHTML('beforeend', completionHtml);
}

function handleWebSocketMessage(data) {
    console.log('Received WebSocket message:', data);
    
    try {
        if (data.type === 'execution_update') {
            // For all updates, use task_index if provided, otherwise keep current
            const taskIndex = data.task_index !== undefined ? data.task_index : lastUpdatedTaskIndex;
            if (data.task_index !== undefined) {
                lastUpdatedTaskIndex = data.task_index;
            }
            console.log('Using task index:', taskIndex, '(from data:', data.task_index, ', last:', lastUpdatedTaskIndex, ')');
            
            updateKanbanBoard({
                ...data,
                task_index: taskIndex
            });
        } else if (data.type === 'human_input_request') {
            console.log('Received human input request:', data);
            // Create a stage object for the human input request
            const stageData = {
                execution_id: data.execution_id,
                task_index: data.task_index,
                stage: {
                    stage_type: 'human_input_request',
                    title: 'Human Input Required',
                    content: data.prompt,
                    status: 'waiting_for_human_input',
                    agent: 'System'
                },
                status: 'WAITING_FOR_HUMAN_INPUT'
            };
            updateKanbanBoard(stageData);
        } else {
            console.warn('Unknown message type:', data.type);
        }
    } catch (error) {
        console.error('Error processing WebSocket message:', error);
    }
}

// Initial fetch of active executions and setup of cancel button
document.addEventListener('DOMContentLoaded', async function() {
    const data = await fetchActiveExecutions();
    const hasActiveExecution = data && data.executions && data.executions.length > 0;
    const activeExecutionId = hasActiveExecution ? data.executions[0].execution_id : null;
    updateCancelButton(hasActiveExecution, activeExecutionId);
});







function getCurrentTime() {
    return new Date().toLocaleTimeString();
}

function getStatusBadgeClass(status) {
    switch (status?.toLowerCase()) {
        case 'running':
            return 'info';
        case 'completed':
            return 'success';
        case 'failed':
            return 'danger';
        case 'waiting_for_human_input':
            return 'warning';
        case 'pending':
        default:
            return 'secondary';
    }
}

// Function to show/hide cancel button based on execution status
function updateCancelButton(hasActiveExecution, executionId) {
    const cancelBtn = document.getElementById('cancelExecutionBtn');
    if (!cancelBtn) {
        console.error('Cancel button not found');  // Debug log
        return;
    }
    cancelBtn.style.display = hasActiveExecution ? 'block' : 'none';
    if (hasActiveExecution) {
        cancelBtn.setAttribute('data-execution-id', executionId);
    } else {
        cancelBtn.removeAttribute('data-execution-id');
    }
}

// Add cancel execution functionality
async function cancelExecution(executionId) {
    try {
        const result = await Swal.fire({
            title: 'Cancel Execution',
            html: `
                <div class="text-start">
                    <p>Are you sure you want to cancel this execution?</p>
                    <p class="text-warning">This action cannot be undone.</p>
                </div>
            `,
            icon: 'warning',
            showCancelButton: true,
            confirmButtonText: 'Yes, Cancel Execution',
            cancelButtonText: 'No, Keep Running',
            customClass: {
                confirmButton: 'btn bg-gradient-danger me-3',
                cancelButton: 'btn bg-gradient-secondary ms-3',
                actions: 'my-3'
            },
            buttonsStyling: false
        });

        if (result.isConfirmed) {
            const response = await fetch(`/agents/execution/${executionId}/cancel/`, {
                method: 'POST',
                headers: {
                    'X-CSRFToken': getCsrfToken(),
                    'Content-Type': 'application/json',
                },
            });

            if (!response.ok) {
                throw new Error('Failed to cancel execution');
            }
            
            Swal.fire({
                title: 'Execution Cancelled',
                text: 'The execution has been cancelled successfully.',
                icon: 'success',
                customClass: {
                    confirmButton: 'btn bg-gradient-success'
                },
                buttonsStyling: false
            });
            
            updateCancelButton(false);
        }
    } catch (error) {
        console.error('Error cancelling execution:', error);
        Swal.fire({
            title: 'Error',
            text: 'Failed to cancel execution. Please try again.',
            icon: 'error',
            customClass: {
                confirmButton: 'btn bg-gradient-primary'
            },
            buttonsStyling: false
        });
    }
}

// Add click handler for cancel button
document.getElementById('cancelExecutionBtn').addEventListener('click', function() {
    const executionId = this.getAttribute('data-execution-id');
    if (executionId) {
        cancelExecution(executionId);
    }
});

function addUpdateToBoard(taskBoard, data) {
    
    const kanbanDrag = taskBoard.querySelector('.kanban-drag');
    if (!kanbanDrag) return;
    
    const stageId = `stage-${data.execution_id}-${Date.now()}`;
    const stage = data.stage || {};
    
    // Special handling for human input request - only when it's an actual input request, not just a status update
    if (stage.stage_type === 'human_input_request' && data.status === 'WAITING_FOR_HUMAN_INPUT') {
        const cardHtml = `
            <div class="card mb-2 border-0 shadow-none">
                <div class="card-body p-3">
                    <div class="d-flex justify-content-between align-items-center mb-2">
                        <span class="badge bg-gradient-${getStatusBadgeClass(stage.status)} text-xs">${stage.status || 'unknown'}</span>
                        <button class="btn btn-link text-dark p-0 expand-content" data-stage-id="${stageId}">
                            <i class="fas fa-expand-alt"></i>
                        </button>
                    </div>
                    <h6 class="text-sm mb-2">${stage.title || 'Human Input Required'}</h6>
                    <div class="content-preview text-sm mb-3">
                        ${stage.content || ''}
                    </div>
                    <div class="human-input-container">
                        <div class="form-group">
                            <textarea class="form-control" rows="3" placeholder="Enter your response here..."></textarea>
                            <button class="btn btn-primary btn-sm mt-2" onclick="handleHumanInputSubmit(this)">Submit</button>
                        </div>
                    </div>
                </div>
            </div>
        `;
        
        // Create card element
        const card = document.createElement('div');
        card.id = stageId;
        card.className = 'kanban-item stage-item';
        card.setAttribute('data-execution-id', data.execution_id);
        card.setAttribute('data-stage-id', stageId);
        card.innerHTML = cardHtml;
        console.log('Adding click listener to expand button')
        // Add click handler for expand button
        card.querySelector('.expand-content').addEventListener('click', (e) => {
            console.log('Expand button clicked');
            e.stopPropagation();
            contentExpander.expandContent(
                card,
                stage.title || 'Human Input Required',
                stage.content || '',
                {
                    Status: stage.status || 'unknown',
                    Agent: stage.agent || 'System',
                    'Stage Type': stage.stage_type || 'unknown',
                    Timestamp: getCurrentTime()
                }
            );
        });
        
        kanbanDrag.appendChild(card);
        return;
    }
    const contentPreview = stage.content ? window.md.render(stage.content) : '';
    
    const cardHtml = `
        <div class="card mb-2 border-0 shadow-none">
            <div class="card-body p-3">
                <div class="d-flex justify-content-between align-items-center mb-2">
                    <span class="badge bg-gradient-${getStatusBadgeClass(stage.status)} text-xs">${stage.status || 'unknown'}</span>
                    <button class="btn btn-link text-dark p-0 expand-content" data-stage-id="${stageId}">
                        <i class="fas fa-expand-alt"></i>
                    </button>
                </div>
                <h6 class="text-sm mb-2">${stage.title || 'Untitled'}</h6>
                <div class="content-preview text-sm" style="max-height: 4.5em; overflow: hidden; position: relative;">
                    <div class="content-text markdown-content">${contentPreview}</div>
                    <div class="content-fade" style="position: absolute; bottom: 0; left: 0; right: 0; height: 20px; background: linear-gradient(transparent, white);"></div>
                </div>
            </div>
        </div>
    `;

    // Create card element
    const card = document.createElement('div');
    card.id = stageId;
    card.className = 'kanban-item';
    card.innerHTML = cardHtml;
    
    // Add click handler for expand button
    card.querySelector('.expand-content').addEventListener('click', (e) => {
        e.stopPropagation();
        contentExpander.expandContent(
            card,
            stage.title || 'Untitled',
            stage.content || '',
            {
                Status: stage.status || 'unknown',
                Agent: stage.agent || 'System',
                'Stage Type': stage.stage_type || 'unknown',
                Timestamp: getCurrentTime()
            }
        );
    });
    
    kanbanDrag.appendChild(card);
}

function showStartExecutionModal() {
    Swal.fire({
        title: 'Start Crew Execution',
        html: `
            <div class="text-start">
                <p>You are about to start a new crew execution.</p>
                ${!clientId ? '<p class="text-danger">Warning: No client selected. Please select a client first.</p>' : ''}
                <p>The crew will begin processing tasks in sequence.</p>
            </div>
        `,
        icon: 'info',
        showCancelButton: true,
        confirmButtonText: 'Start Execution',
        cancelButtonText: 'Cancel',
        customClass: {
            confirmButton: 'btn bg-gradient-success',
            cancelButton: 'btn bg-gradient-danger'
        },
        buttonsStyling: false
    }).then((result) => {
        if (result.isConfirmed) {
            startExecution();
        }
    });
}

function startExecution() {
    const csrfToken = getCsrfToken();
    
    if (!csrfToken) {
        Swal.fire({
            title: 'Error',
            text: 'CSRF token not found. Please refresh the page.',
            icon: 'error',
            customClass: {
                confirmButton: 'btn bg-gradient-primary'
            },
            buttonsStyling: false
        });
        return;
    }

    if (!clientId) {
        Swal.fire({
            title: 'Error',
            text: 'No client selected. Please select a client first.',
            icon: 'error',
            customClass: {
                confirmButton: 'btn bg-gradient-primary'
            },
            buttonsStyling: false
        });
        return;
    }

    // Clear all kanban boards
    const kanbanBoards = document.querySelectorAll('.kanban-board');
    kanbanBoards.forEach(board => {
        const kanbanDrag = board.querySelector('.kanban-drag');
        if (kanbanDrag) {
            kanbanDrag.innerHTML = '';
        }
    });

    // Reset execution number
    const executionSpan = document.getElementById('execution-number');
    if (executionSpan) {
        executionSpan.textContent = '';
    }

    fetch(`/agents/crew/${crewId}/start-execution/`, {
        method: 'POST',
        headers: {
            'Content-Type': 'application/json',
            'X-CSRFToken': csrfToken
        },
        body: JSON.stringify({
            client_id: clientId
        })
    })
    .then(response => response.json())
    .then(data => {
        if (data.status === 'success') {
            Swal.fire({
                title: 'Success',
                text: 'Execution started successfully',
                icon: 'success',
                customClass: {
                    confirmButton: 'btn bg-gradient-success'
                },
                buttonsStyling: false
            });
        } else {
            throw new Error(data.message || 'Unknown error');
        }
    })
    .catch(error => {
        console.error('Error:', error);
        Swal.fire({
            title: 'Error',
            text: 'Error starting execution: ' + error.message,
            icon: 'error',
            customClass: {
                confirmButton: 'btn bg-gradient-primary'
            },
            buttonsStyling: false
        });
    });
}

// Export functions that need to be globally accessible
window.showStartExecutionModal = showStartExecutionModal;
window.handleHumanInputSubmit = handleHumanInputSubmit;

================
File: tasks/callbacks/execution.py
================
import logging
import traceback
from crewai.agents.parser import AgentAction, AgentFinish
from apps.agents.models import CrewExecution, Task
from ..utils.logging import log_crew_message
from ..messaging.execution_bus import ExecutionMessageBus

logger = logging.getLogger(__name__)

class TaskCallback:
    def __init__(self, execution_id):
        self.execution_id = execution_id
        self.current_task_index = None
        self.current_agent_role = None
        self.message_bus = ExecutionMessageBus(execution_id)

    def __call__(self, task_output):
        """Handle task callback from CrewAI."""
        try:
            #logger.debug(f"TaskCallback called with task_output: {task_output}")
            #logger.debug(f"Current task index: {self.current_task_index}")
            logger.info(
                "Task executed - Name: %s, Description: %s",
                task_output.name or "Unnamed Task",
                task_output.description
            )
        
            execution = CrewExecution.objects.get(id=self.execution_id)
            
            # Get the task ID based on task index
            ordered_tasks = Task.objects.filter(
                crewtask__crew=execution.crew
            ).order_by('crewtask__order')
            
            if self.current_task_index is not None and self.current_task_index < len(ordered_tasks):
                crewai_task_id = ordered_tasks[self.current_task_index].id
                self.current_agent_role = ordered_tasks[self.current_task_index].agent.role
            else:
                crewai_task_id = None
            
            if task_output.raw:
                logger.debug(f"TaskCallback: processing task output with index: {self.current_task_index}")
                # Log to database
                log_crew_message(
                    execution=execution,
                    content=task_output.raw,
                    agent=self.current_agent_role,
                    crewai_task_id=crewai_task_id,
                    task_index=self.current_task_index
                )

        except Exception as e:
            logger.error(f"Error in task callback: {str(e)}")
            logger.error(f"Full traceback:\n{traceback.format_exc()}")
            raise

class StepCallback:
    def __init__(self, execution_id):
        self.execution_id = execution_id
        self.current_task_index = None
        self.current_agent_role = None
        self.message_bus = ExecutionMessageBus(execution_id)

    def __call__(self, step_output):
        """Handle step callback from CrewAI."""
        try:
            if isinstance(step_output, AgentFinish):
                #logger.debug(f"StepCallback: Skipping AgentFinish output for task index: {self.current_task_index}")
                #logger.debug(f"StepCallback: AgentFinish attributes: {vars(step_output)}")
                return
            else:
                #logger.debug(f"StepCallback: Processing step output for task index: {self.current_task_index}")
                #logger.debug(f"Step output: {step_output}")
                pass
            logger.debug("Received StepCallback")
            # Only process tool usage
            if isinstance(step_output, AgentAction):
                execution = CrewExecution.objects.get(id=self.execution_id)
                
                # Get the task ID based on task index
                ordered_tasks = Task.objects.filter(
                    crewtask__crew=execution.crew
                ).order_by('crewtask__order')
                
                if self.current_task_index is not None and self.current_task_index < len(ordered_tasks):
                    crewai_task_id = ordered_tasks[self.current_task_index].id
                    self.current_agent_role = ordered_tasks[self.current_task_index].agent.role
                else:
                    crewai_task_id = None

                # Log tool usage
                log_crew_message(
                    execution=execution,
                    content=f"Using tool: {step_output.tool}\nInput: {step_output.tool_input}",
                    agent=self.current_agent_role,
                    crewai_task_id=crewai_task_id,
                    task_index=self.current_task_index
                )
                
                if step_output.result:
                    # Log tool result
                    log_crew_message(
                        execution=execution,
                        content=f"Tool result: {step_output.result}",
                        agent=self.current_agent_role,
                        crewai_task_id=crewai_task_id,
                        task_index=self.current_task_index
                    )

        except Exception as e:
            logger.error(f"Error in step callback: {str(e)}")
            logger.error(f"Full traceback:\n{traceback.format_exc()}")
            raise

================
File: tasks/callbacks/tool.py
================
import logging
from crewai.tools.tool_usage_events import ToolUsageError
from crewai.utilities.events import on
from apps.agents.models import CrewExecution
from ..utils.logging import log_crew_message

logger = logging.getLogger(__name__)

@on(ToolUsageError)
def tool_error_callback(source, event: ToolUsageError):
    """
    This callback is triggered whenever a tool encounters an error during execution.

    Args:
        source: The source of the event (likely the ToolUsage instance).
        event (ToolUsageError): The ToolUsageError event containing error details.
    """
    execution_id = source.task.execution_id  # Assuming you've stored execution_id in the Task
    execution = CrewExecution.objects.get(id=execution_id)
    agent_role = event.agent_role

    error_message = f"Tool '{event.tool_name}' failed for agent '{agent_role}'."
    error_message += f"\n Error: {event.error}"
    error_message += f"\n Tool Arguments: {event.tool_args}"
    error_message += f"\n Run Attempts: {event.run_attempts}"
    error_message += f"\n Delegations: {event.delegations}"
    
    log_crew_message(execution, error_message, agent='Tool Error Callback')
    logger.error(error_message)

================
File: tasks/core/agents.py
================
import logging
from functools import partial
from crewai import Agent
from crewai.llm import LLM
from ..utils.tools import load_tool_in_task
from ..handlers.input import human_input_handler
from ..callbacks.execution import StepCallback
from apps.common.utils import get_llm

logger = logging.getLogger(__name__)

class ProxiedLLM(LLM):
    """Wrapper to make ChatOpenAI work with CrewAI"""
    def __init__(self, llm):
        self.llm = llm
        super().__init__(
            model=llm.model_name,
            temperature=llm.temperature,
        )
        
    def call(self, messages, *args, **kwargs):
        try:
            response = self.llm.invoke(messages)
            return response.content
        except Exception as e:
            logger.error(f"Error in ProxiedLLM call: {str(e)}")
            raise

def create_crewai_agents(agent_models, execution_id):
    agents = []
    for agent_model in agent_models:
        try:
            agent_params = {
                'role': agent_model.role,
                'goal': agent_model.goal,
                'backstory': agent_model.backstory,
                'verbose': agent_model.verbose,
                'allow_delegation': agent_model.allow_delegation,
                'step_callback': StepCallback(execution_id),
                'human_input_handler': partial(human_input_handler, execution_id=execution_id),
                'tools': [],
                'execution_id': execution_id
            }

            # Handle LLM fields for Agent
            llm_fields = ['llm', 'function_calling_llm']
            for field in llm_fields:
                value = getattr(agent_model, field)
                logger.debug(f"LLM field: {field}, value: {value}")
                if value:
                    agent_llm, _ = get_llm(value)
                    logger.debug(f"Agent LLM: {agent_llm}")
                    # Wrap the ChatOpenAI instance for CrewAI compatibility
                    agent_params[field] = ProxiedLLM(agent_llm)

            # Load tools with their settings
            for tool in agent_model.tools.all():
                loaded_tool = load_tool_in_task(tool)
                if loaded_tool:
                    # Get tool settings
                    tool_settings = agent_model.get_tool_settings(tool)
                    if tool_settings and tool_settings.force_output_as_result:
                        # Apply the force output setting
                        loaded_tool = type(loaded_tool)(
                            result_as_answer=True,
                            **{k: v for k, v in loaded_tool.__dict__.items() if k != 'result_as_answer'}
                        )
                    agent_params['tools'].append(loaded_tool)
                else:
                    logger.warning(f"Failed to load tool {tool.name} for agent {agent_model.name}")

            optional_params = ['max_iter', 'max_rpm', 'system_template', 'prompt_template', 'response_template']
            agent_params.update({param: getattr(agent_model, param) for param in optional_params if getattr(agent_model, param) is not None})
            
            agent = Agent(**agent_params)
            logger.debug(f"CrewAI Agent created successfully for agent id: {agent_model.id} with {len(agent_params['tools'])} tools")
            agents.append(agent)
        except Exception as e:
            logger.error(f"Error creating CrewAI Agent for agent {agent_model.id}: {str(e)}")
    return agents

================
File: tasks/core/crew.py
================
import logging
import traceback
from datetime import datetime
import re
import os
from functools import partial
from celery import shared_task
from django.conf import settings
from django.core.cache import cache
from crewai import Crew
from crewai.agents.agent_builder.base_agent_executor_mixin import CrewAgentExecutorMixin
from apps.agents.models import CrewExecution, ExecutionStage, CrewOutput, Task
from ..utils.logging import log_crew_message, update_execution_status
from .agents import create_crewai_agents
from .tasks import create_crewai_tasks
from ..callbacks.execution import StepCallback, TaskCallback
from ..handlers.input import human_input_handler
from apps.common.utils import get_llm
import time
from django.core.files.storage import default_storage
from django.core.files.base import ContentFile
from django.shortcuts import get_object_or_404
from apps.seo_manager.models import Client
from apps.file_manager.storage import PathManager

logger = logging.getLogger(__name__)

def clean_text(text, field_name):
    """Generic function to clean text by escaping JSON-like structures and removing problematic characters"""
    if not text:
        return text

    #logger.debug(f"Original {field_name}: {repr(text)}")

    try:
        # First remove any problematic whitespace/newline characters
        text = text.strip()

        # Handle the specific {{{{{ }}}}} format used in examples
        def escape_json_block(match):
            content = match.group(1)
            # Remove extra whitespace and newlines within the JSON
            content = ' '.join(content.split())
            return f"{{{{{{{{ {content} }}}}}}}}"

        # First pass: Handle the example blocks with multiple braces
        text = re.sub(r'{{{{{(.*?)}}}}}', escape_json_block, text, flags=re.DOTALL)

        # Second pass: Handle any remaining JSON-like structures
        def escape_json_block(match):
            content = match.group(1)
            # Remove extra whitespace and newlines within the JSON
            content = ' '.join(content.split())
            return f"{{{{ {content} }}}}"

        # Handle regular JSON blocks
        text = re.sub(r'(?<!{){([^{].*?)}(?!})', escape_json_block, text, flags=re.DOTALL)

        # Final pass: Escape any remaining single braces that might be format strings
        text = re.sub(r'(?<!{){(?!{)', '{{', text)
        text = re.sub(r'(?<!})}(?!})', '}}', text)

        #logger.debug(f"Cleaned {field_name}: {repr(text)}")
        return text

    except Exception as e:
        logger.error(f"Error cleaning ba{field_name}: {str(e)}")
        logger.error(f"Problematic {field_name}: {repr(text)}")
        # Return a safely escaped version as fallback
        return text.replace("{", "{{").replace("}", "}}")

def initialize_crew(execution):
    """Initialize a CrewAI crew instance from a CrewExecution object"""
    try:
        # Create regular agents (excluding manager)
        regular_agents = list(execution.crew.agents.all())
        #logger.debug(f"Regular agents: {regular_agents}")
        # Create CrewAI agents for regular agents
        agents = create_crewai_agents(regular_agents, execution.id)
        #logger.debug(f"Created CrewAI agents: {agents}")
        if not agents:
            raise ValueError("No valid agents created")
            
        # Create manager agent separately if it exists
        manager_agent = None
        if execution.crew.manager_agent:
            manager_agents = create_crewai_agents([execution.crew.manager_agent], execution.id)
            if manager_agents:
                manager_agent = manager_agents[0]
        
        # Fetch and order the tasks
        ordered_tasks = Task.objects.filter(
            crewtask__crew=execution.crew
        ).order_by('crewtask__order')
        
        tasks = create_crewai_tasks(ordered_tasks, agents, execution)
        if not tasks:
            raise ValueError("No valid tasks for crew execution")

        # Handle LLM fields first
        llm_fields = ['manager_llm', 'function_calling_llm', 'planning_llm']
        llm_params = {}
        for field in llm_fields:
            value = getattr(execution.crew, field)
            if value:
                #logger.debug(f"Using LLM: {value}")
                crew_llm, _ = get_llm(value)
                llm_params[field] = crew_llm

        # Build crew parameters
        crew_params = {
            'agents': agents,
            'tasks': tasks,
            'step_callback': StepCallback(execution.id),
            'task_callback': TaskCallback(execution.id),
            'process': execution.crew.process,
            'verbose': execution.crew.verbose,
            'execution_id': str(execution.id),
            **llm_params  # Add LLM parameters
        }

        # Add manager agent if it exists
        if manager_agent:
            crew_params['manager_agent'] = manager_agent

        # Add optional parameters if they exist
        optional_params = [
            'memory', 'max_rpm', 'language', 'language_file', 'full_output',
            'share_crew', 'output_log_file', 'planning', 'manager_callbacks', 
            'prompt_file', 'cache', 'embedder'
        ]

        for param in optional_params:
            value = getattr(execution.crew, param, None)
            if value is not None:
                crew_params[param] = value

        # Create and return the crew instance
        # logger.debug(f"Creating Crew with parameters: {crew_params}")
        crew = Crew(**crew_params)
        
        if not crew:
            raise ValueError("Failed to create Crew instance")
            
        return crew
        
    except Exception as e:
        logger.error(f"Error in initialize_crew: {str(e)}")
        logger.error(f"Full traceback:\n{traceback.format_exc()}")
        raise

def get_client_data(client):
    """Helper function to get formatted client data"""
    if not client:
        return {}
    
    # Format SEO projects into a readable string
    seo_projects_list = []
    for project in client.seo_projects.all().order_by('-implementation_date'):
        project_str = (
            f"Project: {project.title}\n"
            f"Description: {project.description}\n"
            f"Status: {project.status}\n"
            f"Implementation Date: {project.implementation_date.isoformat() if project.implementation_date else 'Not set'}\n"
            f"Completion Date: {project.completion_date.isoformat() if project.completion_date else 'Not set'}"
        )
        seo_projects_list.append(project_str)
    
    seo_projects_str = "\n\n".join(seo_projects_list) if seo_projects_list else ""
    
    return {
        'client_id': client.id,
        'client_name': client.name,
        'client_website_url': client.website_url,
        'client_business_objectives': '\n'.join(str(obj) for obj in client.business_objectives) if client.business_objectives else '',
        'client_target_audience': client.target_audience,
        'client_profile': client.client_profile,
        'client_seo_projects': seo_projects_str,
    }

def run_crew(task_id, crew, execution):
    """Run the crew and handle the execution"""
    try:
        # Update to running status
        update_execution_status(execution, 'RUNNING')
        
        # Create execution stage for running
        ExecutionStage.objects.create(
            execution=execution,
            stage_type='task_running',
            title='Running Crew',
            content=f'Executing crew tasks for: {execution.crew.name}',
            status='running'
        )
        
        # Get crew inputs with all task-specific data
        inputs = {
            'execution_id': execution.id,
            'current_date': datetime.now().strftime("%Y-%m-%d"),
        }
        
        # Add conversation history if available
        conversation_history = execution.get_conversation_history()
        if conversation_history:
            inputs['conversation_history'] = conversation_history
        
        # Only add client-specific inputs if client exists
        if execution.client:
            inputs.update(get_client_data(execution.client))
        
        # Create callback instances
        step_callback = StepCallback(execution.id)
        task_callback = TaskCallback(execution.id)
        
        # Monkey patch the crew's _execute_tasks method to track current task
        original_execute_tasks = crew._execute_tasks
        
        def execute_tasks_with_tracking(*args, **kwargs):
            task_outputs = []
            futures = []
            last_sync_output = None
            
            for task_index, task in enumerate(crew.tasks):
                #logger.debug(f"Starting task {task_index}")
                
                # Get the agent and continue with original logic
                agent_to_use = crew._get_agent_to_use(task)
                if not agent_to_use:
                    raise ValueError(f"No agent available for task: {task.description}")
                
                # Set current task index in callbacks BEFORE execution
                step_callback.current_task_index = task_index
                task_callback.current_task_index = task_index
                step_callback.current_agent_role = agent_to_use.role
                task_callback.current_agent_role = agent_to_use.role
                
                # Update execution status with current task index
                
                # Create or update agent executor with callbacks and human input handler
                if not agent_to_use.agent_executor:
                    logger.debug(f"Creating agent executor for {agent_to_use.role}")
                    logger.debug(f"Agent LLM before executor creation: {agent_to_use.llm}")
                    agent_to_use.create_agent_executor(tools=task.tools)
                    logger.debug(f"Agent executor created. Executor LLM: {agent_to_use.agent_executor.llm}")
                    
                agent_to_use.agent_executor.callbacks = [step_callback]
                # Patch the _ask_human_input method on the mixin class
                from crewai.agents.agent_builder.base_agent_executor_mixin import CrewAgentExecutorMixin
                CrewAgentExecutorMixin._ask_human_input = staticmethod(partial(human_input_handler, execution_id=execution.id))
                
                #logger.debug(f"Set task index to {task_index} before executing task with description: {task.description}")
                
                # Execute task
                try:
                    if task.async_execution:
                        context = crew._get_context(task, [last_sync_output] if last_sync_output else [])
                        future = task.execute_async(agent=agent_to_use, context=context)
                        futures.append((task, future, task_index))
                    else:
                        if futures:
                            task_outputs = crew._process_async_tasks(futures)
                            futures.clear()
                        
                        context = crew._get_context(task, task_outputs)
                        #logger.debug(f"Executing task {task_index} with agent {agent_to_use.role}")
                        
                        # If this is a human input task, add the input to context
                        if task.human_input:
                            input_key = f"execution_{execution.id}_task_{task_index}_input"
                            
                            # First execution to get the prompt
                            initial_output = task.execute_sync(agent=agent_to_use, context=context)
                            #logger.debug(f"Initial execution complete, waiting for human input")
                            
                            # Wait for human input
                            human_response = cache.get(input_key)
                            while not human_response:
                                time.sleep(1)
                                human_response = cache.get(input_key)
                            
                            logger.debug(f"Received human input: {human_response}")
                            
                            # Make sure context is a dictionary
                            if isinstance(context, str):
                                new_context = {'input': context}
                            elif context is None:
                                new_context = {}
                            else:
                                new_context = context.copy()
                                
                            # Add input to context and execute again
                            new_context['human_input'] = human_response
                            new_context['input'] = human_response
                            #logger.debug(f"Context for second execution: {new_context}")
                            
                            task_output = task.execute_sync(agent=agent_to_use, context=new_context)
                            logger.debug(f"Second execution complete with input")
                        else:
                            # Non-human input task
                            task_output = task.execute_sync(agent=agent_to_use, context=context)
                        #logger.debug(f"Task execution complete. Output: {task_output}")
                        task_outputs = [task_output]
                        last_sync_output = task_output
                        
                        #logger.debug(f"Completed task {task_index}")
                except Exception as e:
                    logger.error(f"Error executing task {task_index}: {str(e)}")
                    raise
            
            if futures:
                task_outputs = crew._process_async_tasks(futures)
            
            return crew._create_crew_output(task_outputs)
            
        # Replace the original _execute_tasks method
        crew._execute_tasks = execute_tasks_with_tracking
        
        # Set callbacks on crew
        crew.step_callback = step_callback
        crew.task_callback = task_callback
        
        for agent in crew.agents:
            if not hasattr(agent, 'backstory') or agent.backstory is None:
                logger.warning(f"Agent {agent.role} has no backstory!")
                continue

            try:
                # Store original backstory
                original_backstory = agent.backstory
                # Clean and update the backstory
                cleaned_backstory = clean_text(original_backstory,"backstory")
                agent.backstory = cleaned_backstory
                agent._original_backstory = cleaned_backstory  

            except Exception as e:
                logger.error(f"Error cleaning backstory for {agent.role}: {str(e)}")
                # Fallback to simple escaping if cleaning fails
                agent.backstory = original_backstory.replace("{", "{{").replace("}", "}}")
                agent._original_backstory = agent.backstory
                
        # Clean expected_output for each task
        for task in crew.tasks:
            if hasattr(task, 'expected_output') and task.expected_output:
                original_expected_output = task.expected_output
                cleaned_expected_output = clean_text(original_expected_output, "expected_output")
                task.expected_output = cleaned_expected_output
                # Store the original for reference if needed
                task._original_expected_output = cleaned_expected_output
                
        # Sanitize inputs
        sanitized_inputs = {
            k.strip(): v.strip() if isinstance(v, str) else v 
            for k, v in inputs.items()
        }
        
        # Run the crew based on process type
        if execution.crew.process == 'sequential':
            logger.debug("Starting sequential crew execution")
            result = crew.kickoff(inputs=sanitized_inputs)
        elif execution.crew.process == 'hierarchical':
            logger.debug("Starting hierarchical crew execution")
            result = crew.kickoff(inputs=sanitized_inputs)
        elif execution.crew.process == 'for_each':
            logger.debug("Starting for_each crew execution")
            inputs_array = sanitized_inputs.get('inputs_array', [])
            result = crew.kickoff_for_each(inputs=inputs_array)
        elif execution.crew.process == 'async':
            logger.debug("Starting async crew execution")
            result = crew.kickoff_async(inputs=sanitized_inputs)
        elif execution.crew.process == 'for_each_async':
            logger.debug("Starting for_each_async crew execution")
            inputs_array = sanitized_inputs.get('inputs_array', [])
            result = crew.kickoff_for_each_async(inputs=inputs_array)
        else:
            raise ValueError(f"Unknown process type: {execution.crew.process}")
            
        # Create completion stage
        ExecutionStage.objects.create(
            execution=execution,
            stage_type='task_complete',
            title='Execution Complete',
            content=str(result),
            status='completed'
        )
        
        # Create CrewOutput
        crew_output = CrewOutput.objects.create(
            raw=str(result),
            json_dict=result if isinstance(result, dict) else None
        )
        
        # Update execution with output
        execution.crew_output = crew_output
        execution.save()
        
        return result
        
    except Exception as e:
        # Create error stage
        ExecutionStage.objects.create(
            execution=execution,
            stage_type='task_error',
            title='Execution Error',
            content=str(e),
            status='error'
        )
        raise 


def handle_execution_error(execution, exception, task_id=None):
    logger.error(f"Error during crew execution: {str(exception)}", exc_info=True)
    update_execution_status(execution, 'FAILED')
    error_message = f"Crew execution failed: {str(exception)}"
    log_crew_message(execution, error_message, agent=None)
    execution.error_message = error_message
    execution.save()

    # Print the full traceback to stdout
    print("Full traceback:")
    traceback.print_exc()

def save_result_to_file(execution, result):
    """
    Save crew execution result to cloud storage using PathManager.
    
    Args:
        execution: The execution instance
        result: The result to save
    """
    try:
        # Generate the file name with timestamp
        timestamp = datetime.now().strftime("%y-%m-%d-%H-%M")
        crew_name = execution.crew.name.replace(' ', '_')
        
        # Get client name if available, otherwise use a default
        client_name = 'no_client'
        if execution.client_id:
            try:
                client = Client.objects.get(id=execution.client_id)
                if client.status == 'active':  # Check if client is active
                    client_name = client.name.replace(' ', '_')
                    logger.info(f"Using client name: {client_name} for output file")
                else:
                    logger.warning(f"Client {client.name} is not active (status: {client.status})")
            except Client.DoesNotExist:
                logger.warning(f"Client with ID {execution.client_id} not found")
            
        file_name = f"{client_name}-finaloutput_{timestamp}.txt"
        
        # Create relative path for the file
        relative_path = os.path.join(
            'crew_runs',
            crew_name,
            file_name
        )
        
        # Initialize PathManager with user ID
        path_manager = PathManager(user_id=execution.user.id)
        
        # Convert content to string and create a ContentFile
        content = str(result)
        file_obj = ContentFile(content)
        file_obj.name = file_name
        
        # Save the file using PathManager
        saved_path = path_manager.save_file(file_obj, relative_path)
        
        # Log the file creation
        log_message = f"Final output saved to: {saved_path}"
        log_crew_message(execution, log_message, agent="System")
        logger.info(log_message)
        
        return saved_path
        
    except Exception as e:
        error_message = f"Error saving crew result file: {str(e)}"
        logger.error(error_message)
        log_crew_message(execution, error_message, agent="System")
        raise

@shared_task(bind=True)
def execute_crew(self, execution_id):
    """Execute a crew with the given execution ID"""
    try:
        execution = CrewExecution.objects.get(id=execution_id)
        #logger.debug(f"Attempting to start crew execution for id: {execution_id} (task_id: {self.request.id})")
        
        # Save the Celery task ID
        execution.task_id = self.request.id
        execution.save()
        
        # Create initial stage
        ExecutionStage.objects.create(
            execution=execution,
            stage_type='task_start',
            title='Starting Execution',
            content=f'Starting execution for crew: {execution.crew.name}',
            status='completed'
        )
        
        # Update execution status to PENDING with task_index 0
        update_execution_status(execution, 'PENDING', task_index=0)
        
        logger.debug(f"Starting crew execution for id: {execution_id} (task_id: {self.request.id})")
        
        # Initialize crew
        crew = initialize_crew(execution)
        if not crew:
            raise ValueError("Failed to initialize crew")
            
        # Run crew
        result = run_crew(self.request.id, crew, execution)
        
        # Save the result and update execution status to COMPLETED
        if result:
            #log_crew_message(execution, str(result), agent='System')
            save_result_to_file(execution, result)
            pass

        # Use the last task index when setting completed status
        last_task_index = len(crew.tasks) - 1 if crew and crew.tasks else None
        update_execution_status(execution, 'COMPLETED', task_index=last_task_index)
        
        return execution.id
        
    except Exception as e:
        logger.error(f"Error during crew execution: {str(e)}")
        if 'execution' in locals():
            handle_execution_error(execution, e, task_id=getattr(self, 'request', None) and self.request.id)
        logger.error(f"Full traceback:\n{traceback.format_exc()}")
        raise

================
File: tasks/core/tasks.py
================
import logging
import os
from datetime import datetime
from django.core.files.storage import default_storage
from django.conf import settings
from crewai import Task as CrewAITask
from apps.agents.models import Task, Agent
from ..utils.tools import load_tool_in_task
from ..utils.logging import log_crew_message
from crewai import Task

logger = logging.getLogger(__name__)

def create_crewai_tasks(task_models, agents, execution):
    tasks = []
    for task_model in task_models:
        try:
            # Get and log the agent model details
            agent_model = Agent.objects.get(id=task_model.agent_id)
            task_model.save()

            # Try to find matching agent
            crewai_agent = next((agent for agent in agents if agent.role == agent_model.role), None)
            
            if not crewai_agent:
                logger.warning(f"""
No matching CrewAI agent found for task {task_model.id}
Looking for role: {agent_model.role}
Available roles: {[agent.role for agent in agents]}
""")
                continue

            task_tools = []
            for tool_model in task_model.tools.all():
                tool = load_tool_in_task(tool_model)
                if tool:
                    task_tools.append(tool)

            human_input = bool(task_model.human_input) if task_model.human_input is not None else False
            task_dict = {
                'description': task_model.description,
                'agent': crewai_agent,
                'expected_output': task_model.expected_output,
                'async_execution': task_model.async_execution,
                'human_input': human_input,
                'tools': task_tools,
                'execution_id': execution.id
            }

            optional_fields = ['output_json', 'output_pydantic', 'converter_cls']
            task_dict.update({field: getattr(task_model, field) for field in optional_fields if getattr(task_model, field) is not None})

            # Handle output_file
            if task_model.output_file:
                try:
                    # Generate a unique file path
                    description_part = task_model.description[:20]  # First 20 chars of description
                    timestamp = datetime.now().strftime("%y-%m-%d-%H-%M")
                    
                    # Get the file name and extension
                    file_name, file_extension = os.path.splitext(task_model.output_file)
                    
                    # Create the relative path
                    relative_path = os.path.join(
                        str(execution.user.id),
                        description_part,
                        f"{file_name}_{timestamp}{file_extension}"
                    )

                    # Get the full URL for the file
                    full_url = default_storage.url(relative_path)
                    
                    logger.debug(f"Output file will be saved to: {relative_path}")
                    log_crew_message(execution, f"Task output will be saved to: {full_url}", agent='System')

                    task_dict['output_file'] = relative_path

                except Exception as e:
                    logger.error(f"Error setting up output file path: {str(e)}", exc_info=True)
                    # Continue without output file if there's an error
                    pass

            if task_model.human_input:
                logger.debug(f"Creating task with human input enabled: {task_model.description}")
                # Add specific configuration for human input tasks
                task_dict.update({
                    'require_human_input': True,
                    'process_human_input': True
                })

            tasks.append(CrewAITask(**task_dict))
            logger.debug(f"CrewAITask created successfully for task: {task_model.id}")
        except Exception as e:
            logger.error(f"Error creating CrewAITask for task {task_model.id}: {str(e)}", exc_info=True)
    return tasks 

def create_writing_task():
    return Task(
        description="Write content to specified file",
        expected_output="SUCCESS: File 'fluffy-1.0.txt' written to 1/fluffy-1.0.txt (Length: 175 chars)",  # Match tool's success format
        agent=writer_agent,
        tools=[FileWriterTool(result_as_answer=True)],  # Force direct tool output
        max_retries=1  # Prevent infinite loops
    )

================
File: tasks/handlers/input.py
================
import logging
import time
from django.core.cache import cache
from apps.agents.models import CrewExecution
from ..messaging.execution_bus import ExecutionMessageBus

logger = logging.getLogger(__name__)

def human_input_handler(prompt, execution_id):
    """Handle human input requests via websocket."""
    logger.debug(f"human_input_handler called with prompt: {prompt}, execution_id: {execution_id}")
    execution = CrewExecution.objects.get(id=execution_id)
    message_bus = ExecutionMessageBus(execution_id)
    
    # Get current task index from execution state
    current_task = getattr(human_input_handler, 'current_task_index', 0)
    
    # Use consistent cache key format
    input_key = f"execution_{execution_id}_task_{current_task}_input"
    logger.debug(f"Using cache key: {input_key}")
    
    # Clear any existing value for this key
    cache.delete(input_key)
    
    # Send the human input request
    message_bus.publish('human_input_request', {
        'human_input_request': prompt,
        'task_index': current_task,
        'context': {
            'execution_id': execution_id,
            'task_index': current_task
        }
    })
    
    # Wait for input
    max_wait_time = 3600  # 1 hour
    start_time = time.time()
    
    while time.time() - start_time < max_wait_time:
        response = cache.get(input_key)
        
        if response:
            logger.debug(f"Received human input: {response}")
            # Send status update
            # message_bus.publish('execution_update', {
            #     'status': 'RUNNING',
            #     'message': f"Received human input: {response}",
            #     'task_index': current_task
            # })
            return str(response)
            
        time.sleep(1)
    
    logger.warning("No human input received within timeout period")
    return "APPROVED."

================
File: tasks/messaging/execution_bus.py
================
import logging
from datetime import datetime
from asgiref.sync import async_to_sync
from channels.layers import get_channel_layer
from apps.agents.models import CrewExecution, ChatMessage

logger = logging.getLogger(__name__)
channel_layer = get_channel_layer()

class ExecutionMessageBus:
    """Central message bus for crew execution events and websocket communication"""
    def __init__(self, execution_id):
        self.execution_id = execution_id
        self.execution = CrewExecution.objects.get(id=execution_id)

    def publish(self, event_type, data):
        """Publish event to all relevant interfaces"""
        try:
            #logger.debug(f"Publishing event {event_type} with data: {data}")
            
            # Special handling for human input requests
            if data.get('human_input_request'):
                self._send_to_groups('human_input_request', data)
                return
                
            if event_type == 'agent_action':
                self._handle_agent_action(data)
            elif event_type == 'agent_finish':
                self._handle_agent_finish(data)
            elif event_type == 'execution_update':
                self._handle_status_update(data)
        except Exception as e:
            logger.error(f"Error publishing event {event_type}: {str(e)}")

    def _send_to_groups(self, message_type, data):
        """Send message to all relevant websocket groups"""
        try:
            #logger.debug(f"Sending message to groups for execution {self.execution_id}")
            groups = []
            if self.execution.crew:
                groups.append(f'crew_{self.execution.crew.id}_kanban')
            if self.execution.conversation:
                groups.append(f'chat_{self.execution.conversation.session_id}')

            # Special handling for human input requests
            if data.get('human_input_request'):
                message = {
                    'type': 'human_input_request',
                    'execution_id': self.execution_id,
                    'prompt': data['human_input_request'],
                    'context': data.get('context', {}),
                    'task_index': data.get('task_index')
                }
            else:
                # Construct message with data first, then override with our fields
                message = {
                    **data,  # Base data first
                    'type': message_type,
                    'execution_id': self.execution_id,
                    'status': self.execution.status,
                    'task_index': data.get('task_index')  # Ensure task_index is last
                }

            #logger.debug(f"Sending message: {message}")

            for group in groups:
                try:
                    async_to_sync(channel_layer.group_send)(group, message)
                    #logger.debug(f"Sent message to group {group}")
                except Exception as e:
                    logger.error(f"Failed to send to group {group}: {str(e)}")

        except Exception as e:
            logger.error(f"Error in _send_to_groups: {str(e)}")

    def _handle_agent_action(self, data):
        message = {
            **data,  # Include all original data first
            'message': data['log'],
            'agent': data['agent_role'],
            'stage': {
                'stage_type': 'task_action',
                'title': 'Agent Action',
                'content': data['log'],
                'agent': data['agent_role'],
                'status': 'completed'
            }
        }
        
        self._send_to_groups('execution_update', message)
        
        if self.execution.conversation:
            self._store_chat_message(data['log'], data['agent_role'])

    def _handle_status_update(self, data):
        #logger.debug(f"Handling status update with task_index: {data.get('task_index')}")
        message = {
            **data,  # Include all original data first
            'message': data.get('message'),
            'stage': {
                'stage_type': 'status_update',
                'title': 'Status Update',
                'content': data.get('message') or f'Status changed to {data["status"]}',
                'status': data['status'].lower(),
                'agent': 'System'
            }
        }
        #logger.debug(f"Sending status update with task_index: {message.get('task_index')}")
        self._send_to_groups('execution_update', message)

    def _store_chat_message(self, content, agent_role):
        """Store message in chat history"""
        if self.execution.conversation:
            ChatMessage.objects.create(
                conversation=self.execution.conversation,
                content=content,
                is_agent=True,
                agent_role=agent_role
            )

================
File: tasks/utils/context.py
================
from contextvars import ContextVar

current_task_id = ContextVar('current_task_id', default=None)

class TaskContext:
    def __init__(self, task_id):
        self.task_id = task_id
        self.token = None

    def __enter__(self):
        self.token = current_task_id.set(self.task_id)
        return self

    def __exit__(self, *args):
        current_task_id.reset(self.token)

================
File: tasks/utils/logging.py
================
import logging
import time
from datetime import datetime
from apps.agents.models import CrewExecution, ExecutionStage, CrewMessage, Task
from ..messaging.execution_bus import ExecutionMessageBus

logger = logging.getLogger(__name__)

def update_execution_status(execution, status, message=None, task_index=None):
    """Update execution status and notify all UIs"""
    try:
        execution.status = status
        execution.save()
        
        # Create execution stage
        if message:
            ExecutionStage.objects.create(
                execution=execution,
                stage_type='status_update',
                title=status,
                content=message,
                status=status.lower()
            )
        
        # Use message bus for notifications with consistent event type
        message_bus = ExecutionMessageBus(execution.id)
        message_bus.publish('execution_update', {
            'status': status,
            'message': message,
            'task_index': task_index
        })
        
    except Exception as e:
        logger.error(f"Error updating execution status: {str(e)}")

def log_crew_message(execution, content, agent=None, human_input_request=None, crewai_task_id=None, task_index=None):
    """Log crew message and send via websocket"""
    try:
        # Store message in database if there's content
        if content:
            CrewMessage.objects.create(
                execution=execution,
                content=content,
                agent=agent,
                crewai_task_id=crewai_task_id
            )
            #logger.debug(f"Stored message in database: {content[:100]}")
        else:
            logger.warning("Attempted to log an empty message, skipping database storage")

        # Send via message bus
        message_bus = ExecutionMessageBus(execution.id)
        message_bus.publish('execution_update', {
            'status': 'RUNNING',
            'message': content,
            'task_index': task_index,
            'stage': {
                'stage_type': 'agent_action',
                'title': 'Agent Action',
                'content': content,
                'status': 'in_progress',
                'agent': agent or 'System'
            }
        })

    except Exception as e:
        logger.error(f"Error in log_crew_message: {str(e)}")

================
File: tasks/utils/tools.py
================
import importlib
import logging
import sys
from crewai.tools import BaseTool as CrewAIBaseTool
from langchain.tools import BaseTool as LangChainBaseTool
from apps.agents.utils import get_tool_info

logger = logging.getLogger(__name__)

def load_tool_in_task(tool_model):
    tool_info = get_tool_info(tool_model)
    
    try:
        print(f"Attempting to load tool: {tool_model.tool_class}.{tool_model.tool_subclass}", file=sys.stderr)
        logger.info(f"Attempting to load tool: {tool_model.tool_class}.{tool_model.tool_subclass}")
        
        module = importlib.import_module(tool_info['module_path'])
        tool_class = getattr(module, tool_info['class_name'])
        
        if issubclass(tool_class, (CrewAIBaseTool, LangChainBaseTool)):
            tool_instance = tool_class()
            return tool_instance
        else:
            logger.error(f"Unsupported tool class: {tool_class}")
            return None
    except Exception as e:
        logger.error(f"Error loading tool {tool_model.tool_class}.{tool_model.tool_subclass}: {str(e)}", exc_info=True)
        print(f"Error loading tool {tool_model.tool_class}.{tool_model.tool_subclass}: {str(e)}", file=sys.stderr)
        return None

================
File: tasks/tools.py
================
from celery import shared_task
import asyncio
import logging
from ..utils import load_tool
from django.shortcuts import get_object_or_404
from ..models import Tool, ToolRun
import inspect
import json
import traceback

logger = logging.getLogger(__name__)

@shared_task(bind=True)
def run_tool(self, tool_id: int, inputs: dict):
    """Generic Celery task to run any tool"""
    try:
        # Load the tool
        tool = get_object_or_404(Tool, id=tool_id)
        tool_instance = load_tool(tool)
        
        if tool_instance is None:
            raise ValueError('Failed to load tool')

        # Create a tool run record
        tool_run = ToolRun.objects.create(
            tool=tool,
            status='STARTED',
            inputs=inputs
        )
        
        try:
            # Process inputs if tool has args_schema
            if hasattr(tool_instance, 'args_schema'):
                processed_inputs = {}
                for key, value in inputs.items():
                    if value != '':
                        try:
                            processed_inputs[key] = json.loads(value)
                        except json.JSONDecodeError:
                            processed_inputs[key] = value
                            
                validated_inputs = tool_instance.args_schema(**processed_inputs)
                inputs = validated_inputs.dict()
            
            # Run the tool
            if inspect.iscoroutinefunction(tool_instance._run):
                # Create event loop for async tools
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                try:
                    result = loop.run_until_complete(tool_instance._run(**inputs))
                finally:
                    loop.close()
            else:
                result = tool_instance._run(**inputs)
            
            # Update tool run record
            tool_run.status = 'SUCCESS'
            tool_run.result = result
            tool_run.save()
            
            return {
                'result': result,
                'error': None
            }
            
        except Exception as e:
            logger.error(f"Error running tool: {str(e)}\n{traceback.format_exc()}")
            tool_run.status = 'FAILURE'
            tool_run.error = str(e)
            tool_run.save()
            raise
            
    except Exception as e:
        logger.error(f"Error in run_tool task: {str(e)}\n{traceback.format_exc()}")
        raise

================
File: templates/agents/modals/details_modal.html
================
<!-- Details Modal -->
<div class="modal fade" id="detailsModal" tabindex="-1" aria-labelledby="detailsModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-dialog-scrollable modal-xl">
        <div class="modal-content">
            <div class="modal-header bg-gradient-primary">
                <h5 class="modal-title text-white" id="detailsModalLabel">
                    <i class="fas fa-info-circle me-2"></i>Stage Details
                </h5>
                <button type="button" class="btn-close btn-close-white" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <div class="modal-body p-3">  <!-- reduced padding from p-4 -->
                <div class="row">
                    <div class="col-12">  <!-- changed from col-md-6 -->
                        <div class="card card-plain">
                            <div class="card-header pb-0">
                                <h6 class="text-uppercase text-primary">Basic Information</h6>
                            </div>
                            <div class="card-body py-2">  <!-- reduced padding -->
                                <dl class="row mb-0">  <!-- added mb-0 to remove bottom margin -->
                                    <dt class="col-auto text-dark me-2">Status:</dt>  <!-- modified for inline -->
                                    <dd class="col-auto me-4"><span class="badge bg-gradient-info" id="modalStatus"></span></dd>
                                    <dt class="col-auto text-dark me-2">Stage Type:</dt>
                                    <dd class="col-auto me-4"><span class="badge bg-gradient-success" id="modalStageType"></span></dd>
                                    <dt class="col-auto text-dark me-2">Agent:</dt>
                                    <dd class="col-auto"><span class="badge bg-gradient-warning" id="modalAgent"></span></dd>
                                </dl>
                            </div>
                        </div>
                    </div>
                </div>
                
                <div class="row mt-3">  <!-- reduced margin from mt-4 -->
                    <div class="col-12">
                        <div class="card card-plain">
                            <div class="card-header pb-0">
                                <h6 class="text-uppercase text-primary">Content</h6>
                            </div>
                            <div class="card-body">
                                <div class="bg-gray-100 border rounded p-3" style="max-height: 600px; overflow-y: auto;">  <!-- increased from 400px -->
                                    <div id="modalContent"></div>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            <div class="modal-footer bg-gray-100">
                <button type="button" class="btn bg-gradient-secondary" data-bs-dismiss="modal">Close</button>
                <button type="button" class="btn bg-gradient-primary">
                    <i class="fas fa-download me-2"></i>Export Details
                </button>
            </div>
        </div>
    </div>
</div>

================
File: templates/agents/modals/human_input_modal.html
================
<!-- Human Input Modal -->
<div class="modal fade" id="humanInputModal" tabindex="-1" role="dialog" aria-labelledby="humanInputModalLabel" aria-hidden="true">
  <div class="modal-dialog modal-dialog-centered" role="document">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title" id="humanInputModalLabel">Provide Human Input</h5>
        <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
      </div>
      <div class="modal-body">
        <div class="form-group">
          <label for="humanInputText">Input</label>
          <textarea class="form-control" id="humanInputText" rows="3"></textarea>
        </div>
      </div>
      <div class="modal-footer">
        <button type="button" class="btn btn-secondary" data-bs-dismiss="modal">Cancel</button>
        <button type="button" class="btn btn-primary" onclick="submitHumanInput()">Submit</button>
      </div>
    </div>
  </div>
</div>

================
File: templates/agents/modals/start_execution_modal.html
================
<!-- Start Execution Modal -->
<div class="modal fade" id="startExecutionModal" tabindex="-1" role="dialog" aria-labelledby="startExecutionModalLabel" aria-hidden="true">
  <div class="modal-dialog modal-dialog-centered" role="document">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title" id="startExecutionModalLabel">Start New Execution</h5>
        <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
      </div>
      <div class="modal-body">
        <p>Are you sure you want to start a new execution for this crew?</p>
      </div>
      <div class="modal-footer">
        <button type="button" class="btn btn-secondary" data-bs-dismiss="modal">Cancel</button>
        <button type="button" class="btn btn-primary" onclick="startExecution()">Start Execution</button>
      </div>
    </div>
  </div>
</div>

================
File: templates/agents/agent_form.html
================
{% extends "layouts/base.html" %}
{% load static %}
{% load agent_filters %}

{% block title %} {% if agent %}Edit Agent{% else %}Add Agent{% endif %} {% endblock %}

{% block content %}
<div class="container-fluid py-4">
    <div class="row">
        <div class="col-12">
            <div class="card">
                <div class="card-header pb-0">
                    <h6 class="mb-0">{% if agent %}Edit Agent{% else %}Add Agent{% endif %}</h6>
                </div>
                <div class="card-body">
                    <form method="post">
                        {% csrf_token %}
                        {% if request.GET.next %}
                            <input type="hidden" name="next" value="{{ request.GET.next }}">
                        {% endif %}
                        <div class="row">
                            <div class="col-md-6">
                                <div class="form-group {% if form.name.errors %}has-error{% endif %}">
                                    <label for="{{ form.name.id_for_label }}" class="form-control-label">Name</label>
                                    {{ form.name }}
                                    {% if form.name.errors %}
                                        <div class="invalid-feedback" style="display: block;">
                                            {{ form.name.errors|join:", " }}
                                        </div>
                                    {% endif %}
                                </div>
                            </div>
                            <div class="col-md-6">
                                <div class="form-group {% if form.role.errors %}has-error{% endif %}">
                                    <label for="{{ form.role.id_for_label }}" class="form-control-label">Role</label>
                                    {{ form.role }}
                                    {% if form.role.errors %}
                                        <div class="invalid-feedback" style="display: block;">
                                            {{ form.role.errors|join:", " }}
                                        </div>
                                    {% endif %}
                                </div>
                            </div>
                        </div>
                        <div class="row">
                            <div class="col-md-12">
                                <div class="form-group {% if form.goal.errors %}has-error{% endif %}">
                                    <label for="{{ form.goal.id_for_label }}" class="form-control-label">Goal</label>
                                    {{ form.goal }}
                                    {% if form.goal.errors %}
                                        <div class="invalid-feedback" style="display: block;">
                                            {{ form.goal.errors|join:", " }}
                                        </div>
                                    {% endif %}
                                </div>
                            </div>
                        </div>
                        <div class="row">
                            <div class="col-md-12">
                                <div class="form-group {% if form.backstory.errors %}has-error{% endif %}">
                                    <label for="{{ form.backstory.id_for_label }}" class="form-control-label">Backstory</label>
                                    {{ form.backstory }}
                                    {% if form.backstory.errors %}
                                        <div class="invalid-feedback" style="display: block;">
                                            {{ form.backstory.errors|join:", " }}
                                        </div>
                                    {% endif %}
                                </div>
                            </div>
                        </div>
                        <div class="row">
                            <div class="col-md-6">
                                <div class="form-group {% if form.llm.errors %}has-error{% endif %}">
                                    <label for="{{ form.llm.id_for_label }}" class="form-control-label">Language Model</label>
                                    <select name="llm" id="{{ form.llm.id_for_label }}" class="form-select">
                                        {% for value, display in form.llm.field.choices %}
                                            <option value="{{ value }}" {% if value == form.llm.value %}selected{% endif %}>{{ display }}</option>
                                        {% endfor %}
                                    </select>
                                    {% if form.llm.errors %}
                                        <div class="invalid-feedback" style="display: block;">
                                            {{ form.llm.errors|join:", " }}
                                        </div>
                                    {% endif %}
                                </div>
                            </div>
                            <div class="col-md-6">
                                <div class="form-group {% if form.function_calling_llm.errors %}has-error{% endif %}">
                                    <label for="{{ form.function_calling_llm.id_for_label }}" class="form-control-label">Function Calling LLM</label>
                                    <select name="function_calling_llm" id="{{ form.function_calling_llm.id_for_label }}" class="form-select">
                                        {% for value, display in form.function_calling_llm.field.choices %}
                                            <option value="{{ value }}" {% if value == form.function_calling_llm.value %}selected{% endif %}>{{ display }}</option>
                                        {% endfor %}
                                    </select>
                                    {% if form.function_calling_llm.errors %}
                                        <div class="invalid-feedback" style="display: block;">
                                            {{ form.function_calling_llm.errors|join:", " }}
                                        </div>
                                    {% endif %}
                                </div>
                            </div>
                        </div>
                        <div class="row">
                            <div class="col-md-12">
                                <div class="form-group {% if form.tools.errors %}has-error{% endif %}">
                                    <label for="{{ form.tools.id_for_label }}" class="form-control-label">Tools</label>
                                    <div class="tool-selection">
                                        {% for tool in form.tools.field.queryset %}
                                        <div class="tool-option mb-2">
                                            <div class="d-flex align-items-center">
                                                <div class="form-check">
                                                    <input type="checkbox" 
                                                           name="tools" 
                                                           value="{{ tool.id }}" 
                                                           id="tool_{{ tool.id }}"
                                                           class="form-check-input tool-checkbox"
                                                           {% if tool.id|stringformat:"i" in form.tools.value|stringformat:"s" %}checked{% endif %}>
                                                    <label class="form-check-label" for="tool_{{ tool.id }}">{{ tool.name }}</label>
                                                </div>
                                                <div class="ms-3 form-check">
                                                    <input type="checkbox" 
                                                           name="force_tool_output_{{ tool.id }}" 
                                                           id="force_tool_{{ tool.id }}"
                                                           class="form-check-input"
                                                           {% if agent and agent|has_force_output_enabled:tool %}checked{% endif %}>
                                                    <label class="form-check-label" for="force_tool_{{ tool.id }}">
                                                        <small>Force Output as Result</small>
                                                        <i class="fas fa-info-circle" data-bs-toggle="tooltip" title="When checked, the tool's output will be used directly as the task result without agent modifications."></i>
                                                    </label>
                                                </div>
                                            </div>
                                        </div>
                                        {% endfor %}
                                    </div>
                                </div>
                            </div>
                        </div>
                        <div class="row">
                            <div class="col-md-4">
                                <div class="form-group {% if form.max_iter.errors %}has-error{% endif %}">
                                    <label for="{{ form.max_iter.id_for_label }}" class="form-control-label">Max Iterations</label>
                                    {{ form.max_iter }}
                                    {% if form.max_iter.errors %}
                                        <div class="invalid-feedback" style="display: block;">
                                            {{ form.max_iter.errors|join:", " }}
                                        </div>
                                    {% endif %}
                                </div>
                            </div>
                            <div class="col-md-4">
                                <div class="form-group {% if form.max_rpm.errors %}has-error{% endif %}">
                                    <label for="{{ form.max_rpm.id_for_label }}" class="form-control-label">Max RPM</label>
                                    {{ form.max_rpm }}
                                    {% if form.max_rpm.errors %}
                                        <div class="invalid-feedback" style="display: block;">
                                            {{ form.max_rpm.errors|join:", " }}
                                        </div>
                                    {% endif %}
                                </div>
                            </div>
                            <div class="col-md-4">
                                <div class="form-group {% if form.max_execution_time.errors %}has-error{% endif %}">
                                    <label for="{{ form.max_execution_time.id_for_label }}" class="form-control-label">Max Execution Time</label>
                                    {{ form.max_execution_time }}
                                    {% if form.max_execution_time.errors %}
                                        <div class="invalid-feedback" style="display: block;">
                                            {{ form.max_execution_time.errors|join:", " }}
                                        </div>
                                    {% endif %}
                                </div>
                            </div>
                        </div>
                        <div class="row">
                            <div class="col-md-4">
                                <div class="form-check form-switch {% if form.verbose.errors %}has-error{% endif %}">
                                    {{ form.verbose }}
                                    <label class="form-check-label" for="{{ form.verbose.id_for_label }}">Verbose</label>
                                    {% if form.verbose.errors %}
                                        <div class="invalid-feedback" style="display: block;">
                                            {{ form.verbose.errors|join:", " }}
                                        </div>
                                    {% endif %}
                                </div>
                            </div>
                            <div class="col-md-4">
                                <div class="form-check form-switch {% if form.allow_delegation.errors %}has-error{% endif %}">
                                    {{ form.allow_delegation }}
                                    <label class="form-check-label" for="{{ form.allow_delegation.id_for_label }}">Allow Delegation</label>
                                    {% if form.allow_delegation.errors %}
                                        <div class="invalid-feedback" style="display: block;">
                                            {{ form.allow_delegation.errors|join:", " }}
                                        </div>
                                    {% endif %}
                                </div>
                            </div>
                            <div class="col-md-4">
                                <div class="form-check form-switch {% if form.cache.errors %}has-error{% endif %}">
                                    {{ form.cache }}
                                    <label class="form-check-label" for="{{ form.cache.id_for_label }}">Cache</label>
                                    {% if form.cache.errors %}
                                        <div class="invalid-feedback" style="display: block;">
                                            {{ form.cache.errors|join:", " }}
                                        </div>
                                    {% endif %}
                                </div>
                            </div>
                        </div>
                        <div class="row">
                            <div class="col-md-12">
                                <div class="form-group {% if form.step_callback.errors %}has-error{% endif %}">
                                    <label for="{{ form.step_callback.id_for_label }}" class="form-control-label">Step Callback</label>
                                    {{ form.step_callback }}
                                    {% if form.step_callback.errors %}
                                        <div class="invalid-feedback" style="display: block;">
                                            {{ form.step_callback.errors|join:", " }}
                                        </div>
                                    {% endif %}
                                </div>
                            </div>
                        </div>
                        <div class="row">
                            <div class="col-md-12">
                                <div class="form-group {% if form.system_template.errors %}has-error{% endif %}">
                                    <label for="{{ form.system_template.id_for_label }}" class="form-control-label">System Template</label>
                                    {{ form.system_template }}
                                    {% if form.system_template.errors %}
                                        <div class="invalid-feedback" style="display: block;">
                                            {{ form.system_template.errors|join:", " }}
                                        </div>
                                    {% endif %}
                                </div>
                            </div>
                        </div>
                        <div class="row">
                            <div class="col-md-12">
                                <div class="form-group {% if form.prompt_template.errors %}has-error{% endif %}">
                                    <label for="{{ form.prompt_template.id_for_label }}" class="form-control-label">Prompt Template</label>
                                    {{ form.prompt_template }}
                                    {% if form.prompt_template.errors %}
                                        <div class="invalid-feedback" style="display: block;">
                                            {{ form.prompt_template.errors|join:", " }}
                                        </div>
                                    {% endif %}
                                </div>
                            </div>
                        </div>
                        <div class="row">
                            <div class="col-md-12">
                                <div class="form-group {% if form.response_template.errors %}has-error{% endif %}">
                                    <label for="{{ form.response_template.id_for_label }}" class="form-control-label">Response Template</label>
                                    {{ form.response_template }}
                                    {% if form.response_template.errors %}
                                        <div class="invalid-feedback" style="display: block;">
                                            {{ form.response_template.errors|join:", " }}
                                        </div>
                                    {% endif %}
                                </div>
                            </div>
                        </div>
                        <div class="row">
                            <div class="col-md-4">
                                <div class="form-check form-switch {% if form.allow_code_execution.errors %}has-error{% endif %}">
                                    {{ form.allow_code_execution }}
                                    <label class="form-check-label" for="{{ form.allow_code_execution.id_for_label }}">Allow Code Execution</label>
                                    {% if form.allow_code_execution.errors %}
                                        <div class="invalid-feedback" style="display: block;">
                                            {{ form.allow_code_execution.errors|join:", " }}
                                        </div>
                                    {% endif %}
                                </div>
                            </div>
                            <div class="col-md-4">
                                <div class="form-check form-switch {% if form.use_system_prompt.errors %}has-error{% endif %}">
                                    {{ form.use_system_prompt }}
                                    <label class="form-check-label" for="{{ form.use_system_prompt.id_for_label }}">Use System Prompt</label>
                                    {% if form.use_system_prompt.errors %}
                                        <div class="invalid-feedback" style="display: block;">
                                            {{ form.use_system_prompt.errors|join:", " }}
                                        </div>
                                    {% endif %}
                                </div>
                            </div>
                            <div class="col-md-4">
                                <div class="form-check form-switch {% if form.respect_context_window.errors %}has-error{% endif %}">
                                    {{ form.respect_context_window }}
                                    <label class="form-check-label" for="{{ form.respect_context_window.id_for_label }}">Respect Context Window</label>
                                    {% if form.respect_context_window.errors %}
                                        <div class="invalid-feedback" style="display: block;">
                                            {{ form.respect_context_window.errors|join:", " }}
                                        </div>
                                    {% endif %}
                                </div>
                            </div>
                        </div>
                        <div class="row">
                            <div class="col-md-6">
                                <div class="form-group {% if form.max_retry_limit.errors %}has-error{% endif %}">
                                    <label for="{{ form.max_retry_limit.id_for_label }}" class="form-control-label">Max Retry Limit</label>
                                    {{ form.max_retry_limit }}
                                    {% if form.max_retry_limit.errors %}
                                        <div class="invalid-feedback" style="display: block;">
                                            {{ form.max_retry_limit.errors|join:", " }}
                                        </div>
                                    {% endif %}
                                </div>
                            </div>
                        </div>
                        <div class="row mt-3">
                            <div class="col-md-12">
                                <div class="form-group {% if form.avatar.errors %}has-error{% endif %}">
                                    <label class="form-control-label">Avatar</label>
                                    <div class="avatar-selection">
                                        {% for choice in form.avatar.field.choices %}
                                        <div class="avatar-option">
                                            <input type="radio" name="{{ form.avatar.name }}" id="avatar_{{ forloop.counter }}" value="{{ choice.0 }}" {% if form.avatar.value == choice.0 %}checked{% endif %} class="avatar-input">
                                            <label for="avatar_{{ forloop.counter }}" class="avatar-label">
                                                <img src="{% static 'assets/img/'|add:choice.0 %}" alt="{{ choice.0 }}" class="avatar-image">
                                            </label>
                                        </div>
                                        {% endfor %}
                                    </div>
                                </div>
                            </div>
                        </div>
                        <div class="row mt-4">
                            <div class="col-12 text-end">
                                <a href="{{ request.GET.next|default:'/agents/manage/' }}" class="btn btn-secondary me-2">Cancel</a>
                                <button type="submit" class="btn bg-gradient-primary">Save Agent</button>
                            </div>
                        </div>
                    </form>
                </div>
            </div>
        </div>
    </div>
</div>


{% endblock content %}

{% block extrastyle %}
{{ block.super }}
<style>
    .avatar-selection {
        display: flex;
        flex-wrap: wrap;
        gap: 15px;
    }
    .avatar-option {
        position: relative;
    }
    .avatar-input {
        display: none;
    }
    .avatar-label {
        cursor: pointer;
        display: inline-block;
        padding: 2px;
        border-radius: 50%;
        transition: all 0.3s ease;
    }
    .avatar-image {
        width: 72px;
        height: 72px;
        border-radius: 50%;
        object-fit: cover;
        border: 2px solid #fff;
        box-shadow: 0 4px 6px rgba(50, 50, 93, 0.11), 0 1px 3px rgba(0, 0, 0, 0.08);
        transition: all 0.15s ease;
    }
    .avatar-input:checked + .avatar-label .avatar-image {
        border-color: #5e72e4;
        box-shadow: 0 0 0 2px #5e72e4;
    }
    .avatar-input:checked + .avatar-label::after {
        content: '';
        position: absolute;
        top: -5px;
        right: -5px;
        background-color: #2dce89;
        color: white;
        border-radius: 50%;
        width: 20px;
        height: 20px;
        display: flex;
        align-items: center;
        justify-content: center;
        font-size: 12px;
        font-weight: bold;
    }
    .tool-selection {
        max-height: 200px;
        overflow-y: auto;
        border: 1px solid #ced4da;
        padding: 10px;
        border-radius: 4px;
    }
    .tool-selection label {
        display: block;
        margin-bottom: 5px;
    }
</style>
{% endblock extrastyle %}

{% block extra_js %}
{{ block.super }}
<script>
    document.addEventListener('DOMContentLoaded', function() {
        // Add 'form-control' class to all input, select, and textarea elements
        var formElements = document.querySelectorAll('input, select, textarea');
        formElements.forEach(function(element) {
            element.classList.add('form-control');
        });

        // Add 'form-select' class to select elements
        var selectElements = document.querySelectorAll('select');
        selectElements.forEach(function(element) {
            element.classList.add('form-select');
        });

        // Add 'form-check-input' class to checkbox inputs
        var checkboxInputs = document.querySelectorAll('input[type="checkbox"]');
        checkboxInputs.forEach(function(element) {
            element.classList.add('form-check-input');
        });

        // Add click event for avatar selection
        var avatarInputs = document.querySelectorAll('.avatar-input');
        avatarInputs.forEach(function(input) {
            input.addEventListener('change', function() {
                document.querySelectorAll('.avatar-label').forEach(function(label) {
                    label.classList.remove('selected');
                });
                if (this.checked) {
                    this.nextElementSibling.classList.add('selected');
                }
            });
        });

        // Trigger change event on the checked avatar input to highlight it on page load
        var checkedAvatar = document.querySelector('.avatar-input:checked');
        if (checkedAvatar) {
            checkedAvatar.dispatchEvent(new Event('change'));
        }

        // Add form validation
        const form = document.querySelector('form');
        form.addEventListener('submit', function(event) {
            const requiredFields = form.querySelectorAll('[required]');
            let isValid = true;

            requiredFields.forEach(function(field) {
                if (!field.value.trim()) {
                    isValid = false;
                    field.classList.add('is-invalid');
                } else {
                    field.classList.remove('is-invalid');
                }
            });

            if (!isValid) {
                event.preventDefault();
                alert('Please fill in all required fields.');
            }
        });
    });
</script>
{% endblock extra_js %}

================
File: templates/agents/base_agents.html
================
{% extends "layouts/base.html" %}

{% block title %} CrewAI Agents {% endblock %}

{% block content %}

<div class="container-fluid">
    <div class="row">
        <div class="col-md-3">
            <div class="card mb-3">
                <div class="card-header d-flex justify-content-between align-items-center">
                    <h5 class="card-title mb-0">Agents</h5>
                    <a href="{% url 'agents:manage_agents' %}" class="text-muted">
                        <i class="fas fa-cog"></i>
                    </a>
                </div>
                <div class="card-body">
                    {% block agents_list %}{% endblock %}
                </div>
            </div>
            <div class="card">
                <div class="card-header">
                    <h5 class="card-title mb-0">Previous Tasks</h5>
                </div>
                <div class="card-body">
                    {% block previous_tasks %}{% endblock %}
                </div>
            </div>
        </div>
        <div class="col-md-9">
            <div class="card">
                <div class="card-header">
                    <h5 class="card-title mb-0">CrewAI Execution</h5>
                </div>
                <div class="card-body">
                    {% block main_content %}{% endblock %}
                </div>
            </div>
        </div>
    </div>
</div>

{% endblock content %}

{% block extra_js %}
<script>
    // Add any JavaScript specific to the agents app here
</script>
{% endblock extra_js %}

{% block extrastyle %}
<style>
    .card-header .fa-cog {
        font-size: 1.2em;
        transition: transform 0.3s ease;
    }
    .card-header .fa-cog:hover {
        transform: rotate(90deg);
    }
</style>
{% endblock extrastyle %}

================
File: templates/agents/chat.html
================
{% extends 'layouts/base.html' %}
{% load static %}

{% block content %}
{% csrf_token %}
<div class="container-fluid py-4">
    <div class="row">
        <!-- Conversation List Sidebar -->
        <div class="col-md-3 order-2 order-md-1">
            <div class="card">
                <div class="card-header p-2">
                    <h6 class="mb-0">Conversations</h6>
                </div>
                <div class="card-body p-2" style="height: 75vh; overflow-y: auto;">
                    <div class="list-group list-group-flush" id="conversation-list">
                        {% for conv in conversations %}
                        <div class="position-relative mb-2">
                            <a href="{% url 'agents:chat' session_id=conv.session_id %}" 
                               class="list-group-item list-group-item-action border-radius-lg py-2 px-3 d-flex flex-column
                               {% if current_conversation and current_conversation.id == conv.id %}
                               bg-gradient-primary active
                               {% else %}
                               bg-transparent
                               {% endif %}">
                                <div class="d-flex justify-content-between align-items-center pe-4">
                                    <h6 class="mb-1 text-sm font-weight-bold {% if current_conversation and current_conversation.id == conv.id %}text-white{% else %}text-default{% endif %}">
                                        {{ conv.title|truncatechars:30 }}
                                    </h6>
                                    <small class="{% if current_conversation and current_conversation.id == conv.id %}text-white opacity-8{% else %}text-secondary{% endif %}">
                                        {{ conv.updated_at|date:"M d, Y" }}
                                    </small>
                                </div>
                                <div class="d-flex justify-content-between align-items-center">
                                    <small class="{% if current_conversation and current_conversation.id == conv.id %}text-white opacity-8{% else %}text-body{% endif %}">
                                        {% if conv.participant_type == 'crew' and conv.crew_execution %}
                                            {{ conv.crew_execution.crew.name }}
                                        {% else %}
                                            {% if conv.agent %}{{ conv.agent.name }}{% endif %}
                                        {% endif %}
                                        {% if conv.client %} - {{ conv.client.name }}{% endif %}
                                    </small>
                                </div>
                            </a>
                            <button type="button"
                                    class="btn btn-link position-absolute top-0 end-0 mt-2 me-1 p-1 z-index-3 {% if current_conversation and current_conversation.id == conv.id %}text-white opacity-8{% else %}text-danger{% endif %}"
                                    onclick="deleteConversation('{{ conv.session_id }}', event)"
                                    title="Delete conversation">
                                <i class="fas fa-trash-alt text-xs"></i>
                            </button>
                        </div>
                        {% endfor %}
                    </div>
                </div>
            </div>
        </div>

        <!-- Main Chat Area -->
        <div class="col-md-9 d-flex flex-column order-1 order-md-2">
            <div class="row g-2 mb-2">
                <div class="col-lg-2 col-md-6">
                    <div class="card mb-0">
                        <div class="card-body p-2 d-flex align-items-center justify-content-center">
                            <div class="d-inline-flex align-items-center gap-2">
                                <span class="connection-dot my-auto"></span>
                                <button id="new-chat-btn" class="btn btn-primary btn-sm my-auto" data-url="{% url 'agents:chat' %}">New Chat</button>
                            </div>
                        </div>
                    </div>
                </div>
                <div class="col-lg-3 col-md-6">
                    <div class="card mb-0">
                        <div class="card-body p-2">
                            <div class="form-group mb-0">
                                <label for="agent-select" class="form-control-label">Select Agent or Crew</label>
                                <select class="form-control" id="agent-select" searchable="true">
                                    <optgroup label="Agents">
                                        {% for agent in agents %}
                                            <option value="{{ agent.id }}" 
                                                data-type="agent"
                                                data-avatar="{{ agent.avatar }}"
                                                data-name="{{ agent.name }}"
                                                {% if current_conversation and current_conversation.agent_id == agent.id %}selected{% endif %}>
                                                {{ agent.name }}
                                            </option>
                                        {% endfor %}
                                    </optgroup>
                                    <optgroup label="Crews">
                                        {% for crew in crews %}
                                            <option value="{{ crew.id }}"
                                                data-type="crew"
                                                data-name="{{ crew.name }}"
                                                {% if current_conversation and current_conversation.crew_execution and current_conversation.crew_execution.crew_id == crew.id %}selected{% endif %}>
                                                {{ crew.name }}
                                            </option>
                                        {% endfor %}
                                    </optgroup>
                                </select>
                            </div>
                        </div>
                    </div>
                </div>
                <div class="col-lg-4 col-md-6">
                    <div class="card mb-0">
                        <div class="card-body p-2">
                            <div class="form-group mb-0">
                                <label for="model-select" class="form-control-label">Select Model</label>
                                <select class="form-control" id="model-select" searchable="true">
                                    {% for model in models %}
                                        <option value="{{ model }}" {% if model == default_model %}selected{% endif %}>
                                            {{ model }}
                                        </option>
                                    {% endfor %}
                                </select>
                            </div>
                        </div>
                    </div>
                </div>
                <div class="col-lg-3 col-md-6">
                    <div class="card mb-0">
                        <div class="card-body p-2">
                            <div class="form-group mb-0">
                                <label for="client-select" class="form-control-label">Select Client</label>
                                <select class="form-control" id="client-select" searchable="true">
                                    <option value="">No Client</option>
                                    {% for client in clients %}
                                        <option value="{{ client.id }}" {% if current_conversation and current_conversation.client_id == client.id %}selected{% endif %}>
                                            {{ client.name }}
                                        </option>
                                    {% endfor %}
                                </select>
                            </div>
                        </div>
                    </div>
                </div>

            </div>

            <div class="card flex-grow-1 d-flex flex-column">
                <div class="card-header py-2 px-3">
                    <div class="row g-0 align-items-center">
                        <div class="col-md-6">
                            <div class="d-flex align-items-center">
                                <div class="avatar avatar-sm me-2" id="agent-avatar">
                                    <img src="{% static 'assets/img/team-3.jpg' %}" class="avatar-img rounded-circle" alt="AI">
                                </div>
                                <h6 class="mb-0 text-sm" id="agent-name">AI Assistant</h6>
                            </div>
                        </div>
                        <div class="col-md-6 d-flex justify-content-end align-items-center">
                            <button id="share-btn" class="btn btn-link text-secondary me-2 p-1" title="Export conversation">
                                <i class="fas fa-share-alt"></i>
                            </button>
                            <span class="badge bg-gradient-primary" id="selected-model">
                                {{ default_model }}
                            </span>
                        </div>
                    </div>
                </div>
                <div class="card-body p-2 flex-grow-1" 
                     id="chat-messages" 
                     data-session-id="{{ session_id }}"
                     {% if current_conversation %}data-conversation-id="{{ current_conversation.id }}"{% endif %}
                     style="overflow-y: auto;">
                    <!-- Messages will be inserted here by JavaScript -->
                </div>
                <div class="card-footer p-2">
                    <div class="row">
                        <div class="col">
                            <div class="input-group">
                                <textarea id="message-input" class="form-control" 
                                    placeholder="Type your message..." rows="1"
                                    style="resize: none;"></textarea>
                                <button class="btn btn-primary mb-0 px-4" id="send-message" style="min-width: 100px;">
                                    <i class="fas fa-paper-plane me-2"></i>Send
                                </button>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>
{% endblock content %}

{% block extrastyle %}
{{ block.super }}
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/default.min.css">
<link rel="stylesheet" href="{% static 'agents/css/chat.css' %}?v={% now 'U' %}">
{% endblock extrastyle %}

{% block extra_js %}
<script src="{% static 'assets/js/plugins/marked.min.js' %}?v={% now 'U' %}"></script>
<script src="{% static 'assets/js/plugins/autosize.min.js' %}?v={% now 'U' %}"></script>
<script src="{% static 'assets/js/plugins/highlight.min.js' %}?v={% now 'U' %}"></script>
<script src="{% static 'assets/js/plugins/datatables.js' %}?v={% now 'U' %}"></script>
<script src="{% static 'assets/js/plugins/chartjs.min.js' %}?v={% now 'U' %}"></script>
<script src="https://cdn.jsdelivr.net/npm/chartjs-adapter-date-fns@3.0.0/dist/chartjs-adapter-date-fns.bundle.min.js"></script>

<script>
    // Initialize chat configuration
    window.chatConfig = {
        sessionId: '{{ session_id }}',
        currentConversation: {% if current_conversation %}{{ current_conversation.id }}{% else %}null{% endif %},
        urls: {
            newChat: '{% url "agents:chat" %}',
            deleteConversation: '/agents/chat/{sessionId}/delete/',
            wsBase: `${window.location.protocol === 'https:' ? 'wss:' : 'ws:'}//${window.location.host}/ws/chat/`
        },
        csrfToken: document.querySelector('[name=csrfmiddlewaretoken]').value,
        defaultModel: '{{ default_model }}'
    };
</script>

<script type="module">
    const appUrl = new URL("{% static 'agents/js/chat/app.js' %}", window.location.href);
    appUrl.searchParams.set('v', '{{ now|date:"YmdHis" }}');
    
    async function initializeApp() {
        const { ChatApp } = await import(appUrl.toString());
        const app = new ChatApp(window.chatConfig);
        app.initialize();
    }
    
    document.addEventListener('DOMContentLoaded', initializeApp);
</script>

<script>
    document.getElementById('new-chat-btn').addEventListener('click', function() {
        const url = this.dataset.url;
        // Update the model badge with the currently selected model
        const selectedModel = document.querySelector('#model-select').value;
        document.getElementById('selected-model').textContent = selectedModel;
        
        // Existing new chat initialization code...
    });

    // If you have a model selector dropdown, also update on change:
    document.querySelector('#model-select').addEventListener('change', function(e) {
        document.getElementById('selected-model').textContent = this.value;
    });
</script>
{% endblock extra_js %}

================
File: templates/agents/confirm_delete.html
================
{% extends "layouts/base.html" %}

{% block title %} Confirm Delete {% endblock %}

{% block content %}
<div class="container-fluid">
    <h1 class="mb-4">Confirm Delete</h1>
    <p>Are you sure you want to delete the following {{ type }}?</p>
    <p><strong>{{ object }}</strong></p>
    <form method="post">
        {% csrf_token %}
        <button type="submit" class="btn btn-danger">Confirm Delete</button>
        <a href="{% url 'agents:manage_crews_card_view' %}" class="btn btn-secondary">Cancel</a>
    </form>
</div>
{% endblock content %}

================
File: templates/agents/connection_test.html
================
{% extends "layouts/base.html" %}
{% load static %}

{% block title %} WebSocket Connection Test {% endblock %}

{% block content %}

<div class="container-fluid py-4">
  <div class="row">
    <div class="col-12">
      <div class="card mb-4">
        <div class="card-header pb-0">
          <h6>WebSocket Connection Test</h6>
        </div>
        <div class="card-body">
          <div id="status" class="alert alert-info">Initializing...</div>
          <button id="connect-btn" class="btn btn-primary mb-3">Connect to WebSocket</button>
          <button id="send-btn" class="btn btn-secondary mb-3" disabled>Send Test Message</button>
          <div id="log" class="bg-light p-3" style="height: 300px; overflow-y: auto;">
            <pre><code></code></pre>
          </div>
        </div>
      </div>
    </div>
  </div>
</div>

{% endblock content %}

{% block extra_js %}
<script>
  document.addEventListener('DOMContentLoaded', function() {
    const statusDiv = document.getElementById('status');
    const logDiv = document.getElementById('log');
    const connectBtn = document.getElementById('connect-btn');
    const sendBtn = document.getElementById('send-btn');
    let socket = null;

    function log(message) {
      const logContent = logDiv.querySelector('code');
      logContent.innerHTML += message + '\n';
      logDiv.scrollTop = logDiv.scrollHeight;
    }

    function connect() {
      log('Attempting to connect...');
      
      const wsScheme = window.location.protocol === 'https:' ? 'wss://' : 'ws://';
      const wsPath = `${wsScheme}${window.location.host}/ws/connection_test/`;
      
      log(`Connecting to: ${wsPath}`);
      
      socket = new WebSocket(wsPath);

      socket.onopen = function(e) {
        log('WebSocket connection established');
        statusDiv.textContent = 'Connected';
        statusDiv.className = 'alert alert-success';
        connectBtn.disabled = true;
        sendBtn.disabled = false;
      };

      socket.onmessage = function(event) {
        const data = JSON.parse(event.data);
        if (data.error) {
          log(`Error: ${data.error}`);
        } else {
          log(`Received message: ${data.message}`);
        }
      };

      socket.onclose = function(event) {
        if (event.wasClean) {
          log(`Connection closed cleanly, code=${event.code}, reason=${event.reason}`);
        } else {
          log('Connection died');
        }
        statusDiv.textContent = 'Disconnected';
        statusDiv.className = 'alert alert-danger';
        connectBtn.disabled = false;
        sendBtn.disabled = true;
      };

      socket.onerror = function(error) {
        log(`WebSocket Error: ${error.message}`);
        console.error('WebSocket Error:', error);
        statusDiv.textContent = 'Error occurred';
        statusDiv.className = 'alert alert-danger';
      };
    }

    connectBtn.onclick = connect;

    sendBtn.onclick = function() {
      if (socket && socket.readyState === WebSocket.OPEN) {
        const message = 'Test message from client';
        socket.send(JSON.stringify({ message: message }));
        log(`Sent message: ${message}`);
      } else {
        log('WebSocket is not connected');
      }
    };
  });
</script>
{% endblock extra_js %}

================
File: templates/agents/crew_detail.html
================
{% extends "layouts/base.html" %}
{% load static %}

{% block title %} Crew Detail {% endblock %}

{% block content %}

<div class="container-fluid py-4">
  <div class="row">
    <div class="col-lg-8 col-md-12">
      <!-- Existing crew details card -->
      <div class="card mb-4">
        <div class="card-header pb-0">
          <div class="d-flex justify-content-between">
            <h6 class="mb-0">{{ crew.name }}</h6>
          </div>
          <p class="text-sm mb-0">{{ crew.description }}</p>
        </div>
        <div class="card-body">
          <div class="row">
            <div class="col-md-6">
              <h6 class="text-uppercase text-body text-xs font-weight-bolder">Process</h6>
              <p class="text-sm mb-3">{{ crew.get_process_display }}</p>
            </div>
            <div class="col-md-6">
              <h6 class="text-uppercase text-body text-xs font-weight-bolder">Verbose</h6>
              <p class="text-sm mb-3">{{ crew.verbose|yesno:"Yes,No" }}</p>
            </div>
          </div>
          <hr class="horizontal dark">
          <div class="row">
            <div class="col-md-6">
              <h6 class="text-uppercase text-body text-xs font-weight-bolder mb-3">Agents</h6>
              <ul class="list-group">
                {% for agent in crew.agents.all %}
                <li class="list-group-item border-0 ps-0 pt-0 text-sm">
                  <strong class="text-dark">{{ agent.name }}</strong> &nbsp;|&nbsp; {{ agent.role }}
                </li>
                {% empty %}
                <li class="list-group-item border-0 ps-0 pt-0 text-sm">No agents assigned to this crew.</li>
                {% endfor %}
              </ul>
            </div>
            <div class="col-md-6">
              <h6 class="text-uppercase text-body text-xs font-weight-bolder mb-3">Tasks</h6>
              <ul class="list-group">
                {% for task in crew.tasks.all %}
                <li class="list-group-item border-0 ps-0 pt-0 text-sm">{{ task.description|slice:":250" }}</li>
                {% empty %}
                <li class="list-group-item border-0 ps-0 pt-0 text-sm">No tasks assigned to this crew.</li>
                {% endfor %}
              </ul>
            </div>
          </div>
        </div>
      </div>

      <!-- Modify the "Start New Execution" card -->
      <div class="card mb-4">
        <div class="card-header pb-0">
          <h6 class="mb-0">Start New Execution for {{ crew.name }}</h6>
          {% if selected_client %}
            <p class="text-sm mb-0">Selected Client: {{ selected_client.name }}</p>
            <p class="text-sm mb-0">Selected Client URL: {{ selected_client.website_url }}</p>
          {% else %}
            <p class="text-sm mb-0">No client selected</p>
          {% endif %}
        </div>
        <div class="card-body">
          <form method="post" id="crew-execution-form">
            {% csrf_token %}
            {% for field in form %}
              {% if field.name != 'crew' %}
                <div class="form-group">
                  <label for="{{ field.id_for_label }}" class="form-control-label">{{ field.label }}</label>
                  {% if field.field.widget.input_type == 'textarea' %}
                    <textarea class="form-control" id="{{ field.id_for_label }}" name="{{ field.name }}" rows="4">{{ field.value|default:'' }}</textarea>
                  {% elif field.field.widget.input_type == 'select' %}
                    <select class="form-control" id="{{ field.id_for_label }}" name="{{ field.name }}">
                      {% for choice in field.field.choices %}
                        <option value="{{ choice.0 }}" {% if choice.0 == field.value %}selected{% endif %}>{{ choice.1 }}</option>
                      {% endfor %}
                    </select>
                  {% else %}
                    <input type="{{ field.field.widget.input_type }}" class="form-control" id="{{ field.id_for_label }}" name="{{ field.name }}" value="{{ field.value|default:'' }}">
                  {% endif %}
                  {% if field.help_text %}
                    <small class="form-text text-muted">{{ field.help_text }}</small>
                  {% endif %}
                  {% for error in field.errors %}
                    <div class="invalid-feedback d-block">{{ error }}</div>
                  {% endfor %}
                </div>
              {% endif %}
            {% endfor %}

            <!-- Add dynamic input fields based on crew.input_variables -->
            {% if crew.input_variables %}
              <h6 class="text-uppercase text-body text-xs font-weight-bolder mt-4 mb-3">Input Variables</h6>
              {% for variable in crew.input_variables %}
                <div class="form-group">
                  <label for="input_{{ variable }}" class="form-control-label">{{ variable|title }}</label>
                  <input type="text" class="form-control" id="input_{{ variable }}" name="input_variables[{{ variable }}]" required>
                </div>
              {% endfor %}
            {% endif %}

            <button type="submit" class="btn btn-primary mt-3" id="submit-btn">Start Execution</button>
          </form>
        </div>
      </div>
      <!-- New card for real-time updates -->
      <div class="card mb-4">
        <div class="card-header pb-0">
          <h6>Real-time Execution Updates</h6>
          <p class="text-sm">
            <i class="fa fa-clock me-1"></i>
            Status: <span id="execution-status" class="badge bg-gradient-info">No active execution</span>
          </p>
        </div>
        <div class="card-body p-3">
          <!-- Human input section -->
          <div id="human-input-section" style="display: none; margin-bottom: 20px;">
            <h6 class="text-uppercase text-body text-xs font-weight-bolder mb-3">Human Input Required</h6>
            <div id="human-input-prompt" class="text-sm mb-2"></div>
            <textarea id="human-input-response" class="form-control mb-3" rows="3"></textarea>
            <button id="submit-human-input" class="btn btn-primary">Submit Input</button>
          </div>

          <!-- Messages container with timeline styling -->
          <div class="messages-container" style="width: 100%; padding-left: 45px; position: relative;">
            <!-- Timeline vertical line -->
            <div style="position: absolute; left: 16px; top: 0; bottom: 0; width: 2px; background-color: #dee2e6;"></div>
            
            <div id="execution-messages">
              <!-- Messages will be dynamically inserted here -->
            </div>
          </div>
        </div>
      </div>
    </div>
    <div class="col-lg-4 col-md-12 mt-4 mt-lg-0">
      <div class="card h-100">
        <div class="card-header pb-0">
          <h6 class="mb-0">Recent Executions</h6>
        </div>
        <div class="card-body p-3">
          <div class="timeline timeline-one-side">
            {% for execution in recent_executions %}
            <div class="timeline-block mb-3">
              <span class="timeline-step">
                <i class="ni ni-bell-55 text-{% if execution.status == 'COMPLETED' %}success{% elif execution.status == 'FAILED' %}danger{% else %}warning{% endif %}"></i>
              </span>
              <div class="timeline-content">
                <h6 class="text-dark text-sm font-weight-bold mb-0">{{ execution.get_status_display }}</h6>
                <p class="text-secondary font-weight-bold text-xs mt-1 mb-0">{{ execution.created_at|date:"SHORT_DATETIME_FORMAT" }}</p>
                <p class="text-sm mt-3 mb-2">
                  <a href="{% url 'agents:execution_detail' execution.id %}" class="text-primary">View Details</a>
                </p>
              </div>
            </div>
            {% empty %}
            <p class="text-sm mb-0">No previous executions for this crew.</p>
            {% endfor %}
          </div>
        </div>
      </div>
    </div>
  </div>
</div>
<!-- Human Input Modal -->
<div class="modal fade" id="human-input-modal" tabindex="-1" role="dialog" aria-labelledby="human-input-modal-label" aria-hidden="true">
  <div class="modal-dialog modal-dialog-centered" role="document">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title" id="human-input-modal-label">Human Input Required</h5>
        <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
      </div>
      <div class="modal-body">
        <div class="form-group">
          <label for="human-input-prompt" class="form-control-label">Prompt:</label>
          <p id="human-input-prompt" class="text-sm mb-3"></p>
          <label for="human-input-response" class="form-control-label">Your Response:</label>
          <textarea class="form-control" id="human-input-response" rows="4"></textarea>
        </div>
      </div>
      <div class="modal-footer">
        <button type="button" class="btn btn-secondary" data-bs-dismiss="modal">Close</button>
        <button type="button" class="btn btn-primary" id="submit-human-input">Submit</button>
      </div>
    </div>
  </div>
</div>
{% endblock content %}

{% block extra_js %}
{{ block.super }}
<script>
  $(function () {
    let socket = null;
    let activeExecutionId = null;

    $('#crew-execution-form').on('submit', function(e) {
      e.preventDefault();
      var form = $(this);
      var url = form.attr('action');
      
      // Serialize the form data, including the dynamic input variables
      var formData = form.serializeArray();
      var inputVariables = {};
      formData.forEach(function(item) {
        if (item.name.startsWith('input_variables[')) {
          var key = item.name.match(/\[(.*?)\]/)[1];
          inputVariables[key] = item.value;
        }
      });
      
      // Add the input_variables to the form data
      formData.push({name: 'input_variables', value: JSON.stringify(inputVariables)});
      
      $.ajax({
        type: "POST",
        url: url,
        data: $.param(formData),
        success: function(data) {
          activeExecutionId = data.execution_id;
          connectWebSocket(activeExecutionId);
          $('#execution-status').text('Execution started');
          $('#execution-messages').empty();
        },
        error: function(xhr, status, error) {
          var errorMessage = xhr.status + ': ' + xhr.statusText;
          alert('Error - ' + errorMessage);
        }
      });
    });

    function connectWebSocket(executionId) {
      const wsScheme = window.location.protocol === 'https:' ? 'wss://' : 'ws://';
      const wsPath = `${wsScheme}${window.location.host}/ws/crew_execution/${executionId}/`;
      
      socket = new WebSocket(wsPath);

      socket.onopen = function(e) {
        console.log('WebSocket connection established');
      };

      socket.onmessage = function(event) {
        const data = JSON.parse(event.data);
        handleWebSocketMessage(data);
      };

      socket.onclose = function(event) {
        console.log('WebSocket connection closed');
      };

      socket.onerror = function(error) {
        console.error('WebSocket Error:', error);
      };
    }

    function handleWebSocketMessage(data) {
      if (data.status) {
        let statusClass = 'info';
        if (data.status === 'COMPLETED') statusClass = 'success';
        else if (data.status === 'FAILED') statusClass = 'danger';
        else if (data.status === 'WAITING_FOR_HUMAN_INPUT') statusClass = 'warning';
        
        $('#execution-status').removeClass().addClass(`badge bg-gradient-${statusClass}`).text(data.status);
      }
      
      if (data.messages && data.messages.length > 0) {
        data.messages.forEach(msg => {
          const timestamp = new Date().toLocaleString();
          const messageHtml = `
            <div class="message-block">
              <span class="timeline-step">
                <i class="ni ${msg.agent ? 'ni-spaceship text-primary' : 'ni-bell-55 text-success'} text-gradient"></i>
              </span>
              <div class="message-content">
                <div class="d-flex justify-content-between">
                  <h6 class="text-dark text-sm font-weight-bold mb-0">${msg.agent || 'System Message'}</h6>
                  <p class="text-secondary font-weight-bold text-xs mt-1 mb-0">${timestamp}</p>
                </div>
                <div class="message-content">
                  <div class="text-sm mt-2 mb-0 message-preview">
                    ${msg.content.substring(0, 150)}${msg.content.length > 150 ? '...' : ''}
                  </div>
                  <div class="message-full collapse">
                    <div class="text-sm mt-2 mb-0">
                      ${msg.content}
                    </div>
                  </div>
                  ${msg.content.length > 150 ? `
                    <a href="javascript:;" class="text-xs text-primary toggle-message">Show more</a>
                  ` : ''}
                </div>
              </div>
            </div>
          `;
          $('#execution-messages').append(messageHtml);
        });
        
        // Scroll to the bottom of the messages container
        const messagesContainer = document.querySelector('.messages-container');
        messagesContainer.scrollTop = messagesContainer.scrollHeight;
      }

      if (data.human_input_request) {
        showHumanInputPrompt(data.human_input_request);
      } else if (data.status !== 'WAITING_FOR_HUMAN_INPUT') {
        $('#human-input-section').hide();
      }

      if (data.status === 'COMPLETED' || data.status === 'FAILED') {
        socket.close();
        activeExecutionId = null;
      }
    }

    function showHumanInputPrompt(prompt) {
      $('#human-input-prompt').text(prompt);
      $('#human-input-section').show();
      $('#human-input-response').focus();
    }

    // Update this event listener
    $(document).on('click', '#submit-human-input', function() {
    let userInput = $('#human-input-response').val();
    let inputKey = `human_input_request_${activeExecutionId}`;
    
    $.ajax({
        type: "POST",
        url: `/agents/execution/${activeExecutionId}/submit_human_input/`,
        data: {
            input_key: inputKey,
            response: userInput
        },
        headers: {
            "X-CSRFToken": getCookie("csrftoken")
        },
        success: function(data) {
            $('#human-input-section').hide();
            $('#human-input-response').val('');
            
            // Scroll to the bottom of the messages container
            const messagesContainer = document.getElementById('execution-messages-container');
            messagesContainer.scrollTop = messagesContainer.scrollHeight;
        },
        error: function(xhr, status, error) {
            console.error('Error submitting human input:', error);
            alert('Error submitting input. Please try again.');
        }
    });
});
    function getCookie(name) {
      let cookieValue = null;
      if (document.cookie && document.cookie !== '') {
        const cookies = document.cookie.split(';');
        for (let i = 0; i < cookies.length; i++) {
          const cookie = cookies[i].trim();
          if (cookie.substring(0, name.length + 1) === (name + '=')) {
            cookieValue = decodeURIComponent(cookie.substring(name.length + 1));
            break;
          }
        }
      }
      return cookieValue;
    }

    // Add this event handler for the show more/less functionality
    $(document).on('click', '.toggle-message', function(e) {
      e.preventDefault();
      const messageContent = $(this).closest('.message-content');
      const preview = messageContent.find('.message-preview');
      const full = messageContent.find('.message-full');
      
      if (full.hasClass('show')) {
        full.collapse('hide');
        preview.show();
        $(this).text('Show more');
      } else {
        full.collapse('show');
        preview.hide();
        $(this).text('Show less');
      }
    });
  });
</script>
{% endblock extra_js %}

{% block extrastyle %}
{{ block.super }}
<style>
  .message-block {
    position: relative;
    margin-bottom: 1.5rem;
    width: 100%;
  }

  .timeline-step {
    position: absolute;
    left: -29px;
    width: 26px;
    height: 26px;
    border-radius: 50%;
    background: white;
    display: flex;
    align-items: center;
    justify-content: center;
    border: 2px solid #dee2e6;
  }

  .message-content {
    width: 100%;
  }

  .message-preview {
    display: block !important; /* Override the previous -webkit-box display */
    overflow: hidden;
    margin-bottom: 0.5rem;
  }

  .message-full {
    margin-top: 0.5rem;
    display: none; /* Hide by default */
  }

  .message-full.show {
    display: block;
  }

  .messages-container {
    max-height: 600px;
    overflow-y: auto;
  }

  /* Add styles for code blocks within messages */
  .message-content pre {
    background-color: #f8f9fa;
    padding: 1rem;
    border-radius: 0.5rem;
    overflow-x: auto;
    margin: 1rem 0;
    font-size: 0.875em;
  }

  .message-content code {
    font-family: SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
  }
</style>
{% endblock extrastyle %}

================
File: templates/agents/crew_form.html
================
{% extends "layouts/base.html" %}
{% load static %}

{% block title %} {% if crew %}Edit Crew{% else %}Add Crew{% endif %} {% endblock %}

{% block content %}
<div class="container-fluid py-4">
    <div class="row">
        <div class="col-12">
            <div class="card">
                <div class="card-header pb-0">
                    <h6 class="mb-0">{% if crew %}Edit Crew{% else %}Add Crew{% endif %}</h6>
                </div>
                <div class="card-body">
                    <form method="post" id="crew-form">
                        {% csrf_token %}
                        <div class="row">
                            <div class="col-md-6">
                                <div class="form-group">
                                    <label for="{{ form.name.id_for_label }}" class="form-control-label">Name</label>
                                    {{ form.name }}
                                    {% if form.name.errors %}
                                        <div class="text-danger">
                                            {{ form.name.errors|join:", " }}
                                        </div>
                                    {% endif %}
                                </div>
                            </div>
                            <div class="col-md-6">
                                <div class="form-group">
                                    <label for="{{ form.agents.id_for_label }}" class="form-control-label">Agents</label>
                                    {{ form.agents }}
                                    {% if form.agents.errors %}
                                        <div class="text-danger">
                                            {{ form.agents.errors|join:", " }}
                                        </div>
                                    {% endif %}
                                </div>
                            </div>
                        </div>
                        <div class="row">
                            <div class="col-md-12">
                                <div class="form-group">
                                    <label for="{{ form.tasks.id_for_label }}" class="form-control-label">Tasks</label>
                                    {{ form.tasks }}
                                    {% if form.tasks.errors %}
                                        <div class="text-danger">
                                            {{ form.tasks.errors|join:", " }}
                                        </div>
                                    {% endif %}
                                </div>
                            </div>
                        </div>
                        <div class="row mt-3">
                            <div class="col-md-12">
                                <div class="form-group">
                                    <label class="form-control-label">Task Order</label>
                                    <ul id="task-order-list" class="list-group">
                                        {% for crew_task in crew.crew_tasks.all %}
                                            <li class="list-group-item" data-task-id="{{ crew_task.task.id }}">
                                                <span class="badge bg-primary me-2">{{ forloop.counter }}</span>
                                                {{ crew_task.task.description }}
                                                <input type="hidden" name="task_order[]" value="{{ crew_task.task.id }}">
                                            </li>
                                        {% endfor %}
                                    </ul>
                                </div>
                            </div>
                        </div>
                        <div class="row">
                            <div class="col-md-6">
                                <div class="form-group">
                                    <label for="{{ form.process.id_for_label }}" class="form-control-label">Process</label>
                                    {{ form.process }}
                                    {% if form.process.errors %}
                                        <div class="text-danger">
                                            {{ form.process.errors|join:", " }}
                                        </div>
                                    {% endif %}
                                </div>
                            </div>
                            <div class="col-md-6">
                                <div class="form-group">
                                    <label for="{{ form.manager_llm.id_for_label }}" class="form-control-label">Manager LLM</label>
                                    {{ form.manager_llm }}
                                    {% if form.manager_llm.errors %}
                                        <div class="text-danger">
                                            {{ form.manager_llm.errors|join:", " }}
                                        </div>
                                    {% endif %}
                                </div>
                            </div>
                        </div>
                        <div class="row">
                            <div class="col-md-6">
                                <div class="form-group">
                                    <label for="{{ form.function_calling_llm.id_for_label }}" class="form-control-label">Function Calling LLM</label>
                                    {{ form.function_calling_llm }}
                                    {% if form.function_calling_llm.errors %}
                                        <div class="text-danger">
                                            {{ form.function_calling_llm.errors|join:", " }}
                                        </div>
                                    {% endif %}
                                </div>
                            </div>
                            <div class="col-md-6">
                                <div class="form-group">
                                    <label for="{{ form.config.id_for_label }}" class="form-control-label">Config</label>
                                    {{ form.config }}
                                    {% if form.config.errors %}
                                        <div class="text-danger">
                                            {{ form.config.errors|join:", " }}
                                        </div>
                                    {% endif %}
                                </div>
                            </div>
                        </div>
                        <div class="row">
                            <div class="col-md-4">
                                <div class="form-group">
                                    <label for="{{ form.max_rpm.id_for_label }}" class="form-control-label">Max RPM</label>
                                    {{ form.max_rpm }}
                                    {% if form.max_rpm.errors %}
                                        <div class="text-danger">
                                            {{ form.max_rpm.errors|join:", " }}
                                        </div>
                                    {% endif %}
                                </div>
                            </div>
                            <div class="col-md-4">
                                <div class="form-group">
                                    <label for="{{ form.language.id_for_label }}" class="form-control-label">Language</label>
                                    {{ form.language }}
                                    {% if form.language.errors %}
                                        <div class="text-danger">
                                            {{ form.language.errors|join:", " }}
                                        </div>
                                    {% endif %}
                                </div>
                            </div>
                            <div class="col-md-4">
                                <div class="form-group">
                                    <label for="{{ form.language_file.id_for_label }}" class="form-control-label">Language File</label>
                                    {{ form.language_file }}
                                    {% if form.language_file.errors %}
                                        <div class="text-danger">
                                            {{ form.language_file.errors|join:", " }}
                                        </div>
                                    {% endif %}
                                </div>
                            </div>
                        </div>
                        <div class="row">
                            <div class="col-md-6">
                                <div class="form-group">
                                    <label for="{{ form.embedder.id_for_label }}" class="form-control-label">Embedder</label>
                                    {{ form.embedder }}
                                    {% if form.embedder.errors %}
                                        <div class="text-danger">
                                            {{ form.embedder.errors|join:", " }}
                                        </div>
                                    {% endif %}
                                </div>
                            </div>
                            <div class="col-md-6">
                                <div class="form-group">
                                    <label for="{{ form.output_log_file.id_for_label }}" class="form-control-label">Output Log File</label>
                                    {{ form.output_log_file }}
                                    {% if form.output_log_file.errors %}
                                        <div class="text-danger">
                                            {{ form.output_log_file.errors|join:", " }}
                                        </div>
                                    {% endif %}
                                </div>
                            </div>
                        </div>
                        <div class="row">
                            <div class="col-md-6">
                                <div class="form-group">
                                    <label for="{{ form.manager_agent.id_for_label }}" class="form-control-label">Manager Agent</label>
                                    {{ form.manager_agent }}
                                    {% if form.manager_agent.errors %}
                                        <div class="text-danger">
                                            {{ form.manager_agent.errors|join:", " }}
                                        </div>
                                    {% endif %}
                                </div>
                            </div>
                            <div class="col-md-6">
                                <div class="form-group">
                                    <label for="{{ form.manager_callbacks.id_for_label }}" class="form-control-label">Manager Callbacks</label>
                                    {{ form.manager_callbacks }}
                                    {% if form.manager_callbacks.errors %}
                                        <div class="text-danger">
                                            {{ form.manager_callbacks.errors|join:", " }}
                                        </div>
                                    {% endif %}
                                </div>
                            </div>
                        </div>
                        <div class="row">
                            <div class="col-md-6">
                                <div class="form-group">
                                    <label for="{{ form.prompt_file.id_for_label }}" class="form-control-label">Prompt File</label>
                                    {{ form.prompt_file }}
                                    {% if form.prompt_file.errors %}
                                        <div class="text-danger">
                                            {{ form.prompt_file.errors|join:", " }}
                                        </div>
                                    {% endif %}
                                </div>
                            </div>
                            <div class="col-md-6">
                                <div class="form-group">
                                    <label for="{{ form.planning_llm.id_for_label }}" class="form-control-label">Planning LLM</label>
                                    {{ form.planning_llm }}
                                    {% if form.planning_llm.errors %}
                                        <div class="text-danger">
                                            {{ form.planning_llm.errors|join:", " }}
                                        </div>
                                    {% endif %}
                                </div>
                            </div>
                        </div>
                        <div class="row">
                            <div class="col-md-4">
                                <div class="form-check form-switch">
                                    {{ form.verbose }}
                                    <label class="form-check-label" for="{{ form.verbose.id_for_label }}">Verbose</label>
                                    {% if form.verbose.errors %}
                                        <div class="text-danger">
                                            {{ form.verbose.errors|join:", " }}
                                        </div>
                                    {% endif %}
                                </div>
                            </div>
                            <div class="col-md-4">
                                <div class="form-check form-switch">
                                    {{ form.memory }}
                                    <label class="form-check-label" for="{{ form.memory.id_for_label }}">Memory</label>
                                    {% if form.memory.errors %}
                                        <div class="text-danger">
                                            {{ form.memory.errors|join:", " }}
                                        </div>
                                    {% endif %}
                                </div>
                            </div>
                            <div class="col-md-4">
                                <div class="form-check form-switch">
                                    {{ form.cache }}
                                    <label class="form-check-label" for="{{ form.cache.id_for_label }}">Cache</label>
                                    {% if form.cache.errors %}
                                        <div class="text-danger">
                                            {{ form.cache.errors|join:", " }}
                                        </div>
                                    {% endif %}
                                </div>
                            </div>
                        </div>
                        <div class="row mt-3">
                            <div class="col-md-4">
                                <div class="form-check form-switch">
                                    {{ form.full_output }}
                                    <label class="form-check-label" for="{{ form.full_output.id_for_label }}">Full Output</label>
                                    {% if form.full_output.errors %}
                                        <div class="text-danger">
                                            {{ form.full_output.errors|join:", " }}
                                        </div>
                                    {% endif %}
                                </div>
                            </div>
                            <div class="col-md-4">
                                <div class="form-check form-switch">
                                    {{ form.share_crew }}
                                    <label class="form-check-label" for="{{ form.share_crew.id_for_label }}">Share Crew</label>
                                    {% if form.share_crew.errors %}
                                        <div class="text-danger">
                                            {{ form.share_crew.errors|join:", " }}
                                        </div>
                                    {% endif %}
                                </div>
                            </div>
                            <div class="col-md-4">
                                <div class="form-check form-switch">
                                    {{ form.planning }}
                                    <label class="form-check-label" for="{{ form.planning.id_for_label }}">Planning</label>
                                    {% if form.planning.errors %}
                                        <div class="text-danger">
                                            {{ form.planning.errors|join:", " }}
                                        </div>
                                    {% endif %}
                                </div>
                            </div>
                        </div>
                        <!-- Replace the existing input variables section with this -->
                        <div class="row mt-3">
                            <div class="col-md-12">
                                <div class="form-group">
                                    <label for="input_variables" class="form-control-label">Input Variables</label>
                                    <div id="input-variables-container" class="row">
                                        <!-- We'll populate this dynamically with JavaScript -->
                                    </div>
                                    <button type="button" id="add-variable" class="btn btn-outline-primary btn-sm mt-2">Add Variable</button>
                                </div>
                            </div>
                        </div>
                        <div class="row mt-4">
                            <div class="col-12 text-end">
                                <a href="{% url 'agents:manage_crews' %}" class="btn btn-secondary me-2">Cancel</a>
                                <button type="submit" class="btn bg-gradient-primary">Save Crew</button>
                            </div>
                        </div>
                    </form>
                </div>
            </div>
        </div>
    </div>
</div>
{% endblock content %}

{% block extra_js %}
<script src="{% static 'assets/js/plugins/choices.min.js' %}"></script>
<script src="https://cdn.jsdelivr.net/npm/sortablejs@1.14.0/Sortable.min.js"></script>
<script>
    document.addEventListener('DOMContentLoaded', function() {
        // Initialize Choices.js for select fields
        var selectFields = document.querySelectorAll('select');
        selectFields.forEach(function(select) {
            new Choices(select, {
                removeItemButton: true,
                placeholder: true,
                placeholderValue: 'Select an option'
            });
        });
        try {
            const initialInputVariables = JSON.parse('{{ input_variables_json|safe }}');
            // ... rest of your code ...
        } catch (error) {
            console.error('Error parsing initial input variables:', error, '{{ input_variables_json|safe }}'); //log the json
        }
        // Add classes to form elements
        var formElements = document.querySelectorAll('input:not([type="checkbox"]):not([type="radio"]), select, textarea');
        formElements.forEach(function(element) {
            element.classList.add('form-control');
        });

        var selectElements = document.querySelectorAll('select');
        selectElements.forEach(function(element) {
            element.classList.add('form-select');
        });

        var checkboxInputs = document.querySelectorAll('input[type="checkbox"], input[type="radio"]');
        checkboxInputs.forEach(function(element) {
            element.classList.add('form-check-input');
        });

        // Form validation and submission
        const form = document.querySelector('form');
        form.addEventListener('submit', function(event) {
            event.preventDefault();
            const requiredFields = form.querySelectorAll('[required]');
            let isValid = true;

            requiredFields.forEach(function(field) {
                if (!field.value.trim()) {
                    isValid = false;
                    field.classList.add('is-invalid');
                } else {
                    field.classList.remove('is-invalid');
                }
            });

            if (!isValid) {
                alert('Please fill in all required fields.');
                return;
            }

            const formData = new FormData(form);
            const inputVariables = formData.getAll('input_variables[]');
            console.log('Submitting form with input variables:', inputVariables);
            form.submit();
        });

        const taskSelect = document.getElementById('{{ form.tasks.id_for_label }}');
        const taskOrderList = document.getElementById('task-order-list');

        // Initialize Sortable
        new Sortable(taskOrderList, {
            animation: 150,
            onEnd: function() {
                updateTaskOrder();
            }
        });

        // Update task order when tasks are selected or deselected
        taskSelect.addEventListener('change', function() {
            updateTaskList();
        });

        function updateTaskList() {
            const selectedTasks = Array.from(taskSelect.selectedOptions);
            const currentOrder = Array.from(taskOrderList.children).map(li => li.dataset.taskId);
            
            // Remove tasks that are no longer selected
            currentOrder.forEach(taskId => {
                if (!selectedTasks.some(option => option.value === taskId)) {
                    const li = taskOrderList.querySelector(`li[data-task-id="${taskId}"]`);
                    if (li) li.remove();
                }
            });

            // Add newly selected tasks
            selectedTasks.forEach(function(option) {
                if (!currentOrder.includes(option.value)) {
                    const listItem = document.createElement('li');
                    listItem.className = 'list-group-item';
                    listItem.dataset.taskId = option.value;
                    listItem.innerHTML = `
                        <span class="badge bg-primary me-2"></span>
                        ${option.text}
                        <input type="hidden" name="task_order[]" value="${option.value}">
                    `;
                    taskOrderList.appendChild(listItem);
                }
            });

            updateTaskOrder();
        }

        function updateTaskOrder() {
            const items = taskOrderList.querySelectorAll('li');
            items.forEach(function(item, index) {
                item.querySelector('.badge').textContent = index + 1;
                item.querySelector('input[name="task_order[]"]').value = item.dataset.taskId;
            });
        }

        const inputVariablesContainer = document.getElementById('input-variables-container');
    const addVariableButton = document.getElementById('add-variable');

    addVariableButton.addEventListener('click', function() {
        addInputVariable();
    });

    inputVariablesContainer.addEventListener('click', function(e) {
        if (e.target.classList.contains('remove-variable') || e.target.closest('.remove-variable')) {
            e.target.closest('.col-md-4').remove();
        }
    });

    function addInputVariable(value = '') {
        const newInput = document.createElement('div');
        newInput.className = 'col-md-4 mb-2';
        newInput.innerHTML = `
            <div class="input-group">
                <input type="text" name="input_variables[]" class="form-control form-control-sm" value="${value}" required>
                <button type="button" class="btn btn-outline-secondary btn-sm remove-variable">
                    <i class="fas fa-times"></i>
                </button>
            </div>
        `;
        inputVariablesContainer.appendChild(newInput);
    }

    // Parse and render initial input variables
    try {
        const initialInputVariables = JSON.parse('{{ input_variables_json|safe }}');
        console.log('Initial input variables:', initialInputVariables);
        
        if (Array.isArray(initialInputVariables)) {
            initialInputVariables.forEach(variable => {
                addInputVariable(variable);
                console.log('Added input variable:', variable);
            });
        }
    } catch (error) {
        console.error('Error parsing initial input variables:', error);
    }
});
</script>
{% endblock extra_js %}

================
File: templates/agents/crew_kanban.html
================
{% extends "layouts/base.html" %}
{% load static %}

{% block title %} Crew Kanban {% endblock %}
{% block extrastyle %}
{{ block.super }}
<link rel="stylesheet" type="text/css" href="{% static 'agents/css/crew_kanban.css' %}?v=29" crossorigin="anonymous"/>
{% endblock extrastyle %}

{% block content %}
{% csrf_token %}

<div class="container-fluid py-4">
    <!-- Header Card -->
    <div class="row mb-4">
        <div class="col-12">
            <div class="card">
                <div class="card-body">
                    <div class="d-flex justify-content-between align-items-start">
                        <!-- Left side with crew info -->
                        <div class="d-flex">
                            <div class="me-3">
                                <div class="avatar avatar-xl position-relative">
                                    <img src="{% static 'assets/img/team-1.jpg' %}" alt="profile_image" class="w-100 border-radius-lg shadow-sm">
                                </div>
                            </div>
                            <div>
                                <h5 class="mb-1">{{ crew.name }}</h5>
                                <p class="mb-0 font-weight-bold text-sm">Execution #{{ execution.id }}</p>
                                <p class="mb-0 text-sm">Started: {{ execution.created_at|date:"Y-m-d H:i:s" }}</p>
                                <p class="mb-0 text-sm">Client: {{client.name}} - {{client.website_url}}</p>
                            </div>
                        </div>
                        
                        <!-- Right side with buttons -->
                        <div class="d-flex gap-2">
                            <button id="cancelExecutionBtn" class="btn btn-danger" style="display: none;">
                                <i class="fas fa-stop-circle me-2"></i>Cancel Execution
                            </button>
                            <button class="btn btn-primary" onclick="showStartExecutionModal()">
                                <i class="fas fa-play me-2"></i>Start Crew Execution
                            </button>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
  
    <!-- Tasks Section -->
    <div class="row">
        <div class="col-12">
            <div class="card">
                <div class="card-header pb-0">
                    <div class="d-flex align-items-center">
                        <h6 class="mb-0">Tasks</h6>
                        <span id="execution-number" class="text-sm ms-2"></span>
                    </div>
                </div>
                <div class="card-body">
                    <div class="kanban-container" id="kanban-tasks">
                        {% for task in tasks %}
                        <!-- Task Board -->
                        <div class="kanban-board" data-task-id="{{ task.id }}">
                            <header class="kanban-board-header rounded-top p-3">
                                <div class="text-white">
                                    <div class="task-description" data-bs-toggle="collapse" 
                                         href="#taskDesc{{ task.id }}" role="button" 
                                         aria-expanded="false" aria-controls="taskDesc{{ task.id }}">
                                        {{ task.name|truncatechars:200 }}
                                    </div>
                                    <div class="collapse" id="taskDesc{{ task.id }}">
                                        <div class="text-white-50 mt-2">
                                            {{ task.name }}
                                        </div>
                                    </div>
                                </div>
                            </header>
                            <div class="kanban-drag bg-white rounded-bottom border border-top-0">
                                <!-- Task items will be dynamically added here -->
                            </div>
                        </div>
                        {% endfor %}
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

{% endblock content %}

{% block extra_js %}
{{ block.super }}
<!-- Add SweetAlert2 -->
<script src="{% static 'assets/js/plugins/sweetalert.min.js' %}"></script>
<!-- jKanban -->
<script src="{% static 'assets/js/plugins/jkanban/jkanban.min.js' %}"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/markdown-it/13.0.1/markdown-it.min.js"></script>
<script>
    // Initialize crew and client IDs from Django template
    const crewId = "{{ crew.id }}";
    const clientId = "{% if client %}{{ client.id }}{% else %}null{% endif %}";

    // Initialize markdown-it
    window.md = window.markdownit();
</script>
<script src="{% static 'agents/js/crew_kanban.js' %}?v={% now 'YmdHis' %}" type="module"></script>
{% endblock extra_js %}

================
File: templates/agents/crew_list.html
================
{% extends "agents/base_agents.html" %}

{% block agents_list %}
<ul class="list-group">
    {% for crew in crews %}
    <li class="list-group-item">
        <a href="{% url 'agents:crew_detail' crew.id %}" data-toggle="tooltip" title="{{ crew.description }}">
            {{ crew.name }}
        </a>
    </li>
    {% empty %}
    <li class="list-group-item">No CrewAI crews available.</li>
    {% endfor %}
</ul>
{% endblock %}

{% block previous_tasks %}
<ul class="list-group">
    {% for execution in request.user.crewaiexecution_set.all|slice:":5" %}
    <li class="list-group-item">
        <a href="{% url 'agents:execution_detail' execution.id %}">
            {{ execution.crew.name }} - {{ execution.created_at|date:"SHORT_DATETIME_FORMAT" }}
        </a>
    </li>
    {% empty %}
    <li class="list-group-item">No previous tasks.</li>
    {% endfor %}
</ul>
{% endblock %}

{% block main_content %}
<h2>Welcome to CrewAI Agents</h2>
<p>Select a crew from the list on the left to start a new execution or view previous tasks.</p>
{% endblock %}

{% block extra_js %}
{{ block.super }}
<script>
    $(function () {
        $('[data-toggle="tooltip"]').tooltip()
    })
</script>
{% endblock extra_js %}

================
File: templates/agents/crewai_home.html
================
{% extends "layouts/base.html" %}
{% load static %}

{% block title %} Dashboard {% endblock %}

{% block content %}

<div class="container-fluid py-4">
  <!-- Client Selection Dropdown -->
  <div class="row mb-4">
    <div class="col-6">
      <div class="card">
        <div class="card-body p-3">
          <form id="client-select-form" method="get">
            <div class="row align-items-center">
              <div class="col-md-3">
                <label for="client-select" class="form-label mb-0">Select Client:</label>
              </div>
              <div class="col-md-9">
                <select class="form-select" name="client_id" id="client-select">
                  <option value="">None</option>
                  {% for client in clients %}
                    <option value="{{ client.id }}" {% if client.id|stringformat:"s" == selected_client_id %}selected{% endif %}>
                      {{ client.name }}
                    </option>
                  {% endfor %}
                </select>
              </div>
            </div>
          </form>
        </div>
      </div>
    </div>

    <div class="col-xl-3 col-sm-6 mb-xl-0 mb-4">
      <div class="card">
        <div class="card-body p-3">
          <div class="row">
            <div class="col-8">
              <div class="numbers">
                <p class="text-sm mb-0 text-capitalize font-weight-bold">Total Crews</p>
                <h5 class="font-weight-bolder mb-0">
                  {{ crews.count }}
                </h5>
              </div>
            </div>
            <div class="col-4 text-end">
              <div class="icon icon-shape bg-gradient-primary shadow text-center border-radius-md">
                <i class="ni ni-money-coins text-lg opacity-10" aria-hidden="true"></i>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
    <div class="col-xl-3 col-sm-6 mb-xl-0 mb-4">
      <div class="card">
        <div class="card-body p-3">
          <div class="row">
            <div class="col-8">
              <div class="numbers">
                <p class="text-sm mb-0 text-capitalize font-weight-bold">Recent Executions</p>
                <h5 class="font-weight-bolder mb-0">
                  {{ recent_executions.count }}
                </h5>
              </div>
            </div>
            <div class="col-4 text-end">
              <div class="icon icon-shape bg-gradient-primary shadow text-center border-radius-md">
                <i class="ni ni-world text-lg opacity-10" aria-hidden="true"></i>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div> 

  <div class="row mt-4">
    <div class="col-lg-7 mb-lg-0 mb-4">
      <div class="card">
        <div class="card-body p-3">
          <div class="row">
            <div class="col-lg-6">
              <div class="d-flex flex-column h-100">
                <p class="mb-1 pt-2 text-bold">Welcome back, {{ request.user.username|capfirst }}</p>
                <h5 class="font-weight-bolder">Crew Dashboard</h5>
                <p class="mb-5">What do you want to do with your crews today.</p>
                <a class="text-body text-sm font-weight-bold mb-0 icon-move-right mt-auto" href="{% url 'agents:manage_crews_card_view' %}">
                  View All Crews
                  <i class="fas fa-arrow-right text-sm ms-1" aria-hidden="true"></i>
                </a>
              </div>
            </div>
            <div class="col-lg-5 ms-auto text-center mt-5 mt-lg-0">
              <div class="bg-gradient-primary border-radius-lg h-100">
                <img src="{% static 'assets/img/shapes/waves-white.svg' %}" class="position-absolute h-100 w-50 top-0 d-lg-block d-none" alt="waves">
                <div class="position-relative d-flex align-items-center justify-content-center h-100">
                  <img class="w-100 position-relative z-index-2 pt-4" src="{% static 'assets/img/illustrations/rocket-white.png' %}" alt="rocket">
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
    <div class="col-lg-5">
      <div class="card h-100 p-3">
        <div class="overflow-hidden position-relative border-radius-lg bg-cover h-100" style="background-image: url('{% static 'assets/img/ivancik.jpg' %}');">
          <span class="mask bg-gradient-dark"></span>
          <div class="card-body position-relative z-index-1 d-flex flex-column h-100 p-3">
            <h5 class="text-white font-weight-bolder mb-4 pt-2">Manage Your Crews</h5>
            <p class="text-white">Create, edit, and manage your crews and their executions.</p>
            <a class="text-white text-sm font-weight-bold mb-0 icon-move-right mt-auto" href="{% url 'agents:manage_crews' %}">
              Read More
              <i class="fas fa-arrow-right text-sm ms-1" aria-hidden="true"></i>
            </a>
          </div>
        </div>
      </div>
    </div>
  </div>

  <!-- Crews List -->
  <div class="row mt-4">
    <div class="col-12">
      <div class="card mb-4">
        <div class="card-header pb-0">
          <h6>Your Crews</h6>
        </div>
        <div class="card-body px-0 pt-0 pb-2">
          <div class="table-responsive p-0">
            <table class="table align-items-center mb-0">
              <thead>
                <tr>
                  <th class="text-uppercase text-secondary text-xxs font-weight-bolder opacity-7">Crew</th>
                  <th class="text-uppercase text-secondary text-xxs font-weight-bolder opacity-7 ps-2">Process</th>
                  <th class="text-uppercase text-secondary text-xxs font-weight-bolder opacity-7 ps-2">Language</th>
                  <th class="text-uppercase text-secondary text-xxs font-weight-bolder opacity-7 ps-2">Actions</th>
                </tr>
              </thead>
              <tbody>
                {% for crew in crews %}
                <tr>
                  <td>
                    <div class="d-flex px-3 py-1">
                      <div>
                        <img src="{% static 'assets/img/team-3.jpg' %}" class="avatar avatar-sm me-3" alt="crew">
                      </div>
                      <div class="d-flex flex-column justify-content-center">
                        <h6 class="mb-0 text-sm">
                          {% if selected_client_id %}
                            <a href="{% url 'agents:crew_kanban' crew.id %}?client_id={{ selected_client_id }}" class="text-sm mb-0">{{ crew.name }}</a>
                          {% else %}
                            {{ crew.name }}
                          {% endif %}
                        </h6>
                        <p class="text-xs text-secondary mb-0">{{ crew.agents.count }} Agents</p>
                      </div>
                    </div>
                  </td>
                  <td>
                    <p class="text-xs font-weight-bold mb-0">{{ crew.get_process_display }}</p>
                  </td>
                  <td>
                    <p class="text-xs font-weight-bold mb-0">{{ crew.language }}</p>
                  </td>
                  <td class="align-middle">
                    {% if selected_client_id %}
                    <a href="{% url 'agents:execution_list' %}?client_id={{ selected_client_id }}" class="btn btn-link text-dark px-3 mb-0">
                      <i class="fas fa-info-circle text-dark me-2"></i>Details
                    </a>
                    {% else %}
                    <span class="text-xs text-secondary">Select a client first</span>
                    {% endif %}
                  </td>
                </tr>
                {% empty %}
                <tr>
                  <td colspan="4" class="text-center py-4">
                    <p class="text-sm mb-0">No crews found.</p>
                  </td>
                </tr>
                {% endfor %}
              </tbody>
            </table>
          </div>
        </div>
      </div>
    </div>
  </div>
</div>

{% endblock content %}

{% block extra_js %}
<!-- Add jQuery if not already included in base template -->
<script src="https://code.jquery.com/jquery-3.6.0.min.js"></script>
<script>
  document.addEventListener('DOMContentLoaded', function() {
    // Handle client selection change
    document.getElementById('client-select').addEventListener('change', function() {
      document.getElementById('client-select-form').submit();
    });
  });
</script>
{% endblock extra_js %}

================
File: templates/agents/dashboard_home.html
================
{% extends "layouts/base.html" %}
{% load static %}

{% block title %} Dashboard {% endblock %}

{% block content %}

<div class="container-fluid py-4">
  <div class="row">
    <!-- New Client Selection Card -->
    <div class="col-xl-3 col-sm-6 mb-xl-0 mb-4">
      <div class="card">
        <div class="card-body p-3">
          <div class="row">
            <div class="col-8">
              <div class="numbers">
                <p class="text-sm mb-0 text-capitalize font-weight-bold">Select Client</p>
                <form id="client-select-form" method="get">
                  <select class="form-control" name="client_id" id="client-select">
                    <option value="">All Clients</option>
                    {% for client in clients %}
                      <option value="{{ client.id }}" {% if client.id|stringformat:"s" == selected_client_id %}selected{% endif %}>
                        {{ client.name }}
                      </option>
                    {% endfor %}
                  </select>
                </form>
              </div>
            </div>
            <div class="col-4 text-end">
              <div class="icon icon-shape bg-gradient-primary shadow text-center border-radius-md">
                <i class="ni ni-building text-lg opacity-10" aria-hidden="true"></i>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
    <div class="col-xl-3 col-sm-6 mb-xl-0 mb-4">
      <div class="card">
        <div class="card-body p-3">
          <div class="row">
            <div class="col-8">
              <div class="numbers">
                <p class="text-sm mb-0 text-capitalize font-weight-bold">Total Crews</p>
                <h5 class="font-weight-bolder mb-0">
                  {{ crews.count }}
                </h5>
              </div>
            </div>
            <div class="col-4 text-end">
              <div class="icon icon-shape bg-gradient-primary shadow text-center border-radius-md">
                <i class="ni ni-money-coins text-lg opacity-10" aria-hidden="true"></i>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
    <div class="col-xl-3 col-sm-6 mb-xl-0 mb-4">
      <div class="card">
        <div class="card-body p-3">
          <div class="row">
            <div class="col-8">
              <div class="numbers">
                <p class="text-sm mb-0 text-capitalize font-weight-bold">Recent Executions</p>
                <h5 class="font-weight-bolder mb-0">
                  {{ recent_executions.count }}
                </h5>
              </div>
            </div>
            <div class="col-4 text-end">
              <div class="icon icon-shape bg-gradient-primary shadow text-center border-radius-md">
                <i class="ni ni-world text-lg opacity-10" aria-hidden="true"></i>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>

  <div class="row mt-4">
    <div class="col-lg-7 mb-lg-0 mb-4">
      <div class="card">
        <div class="card-body p-3">
          <div class="row">
            <div class="col-lg-6">
              <div class="d-flex flex-column h-100">
                <p class="mb-1 pt-2 text-bold">Welcome back, {{ request.user.username }}</p>
                <h5 class="font-weight-bolder">CrewAI Dashboard</h5>
                <p class="mb-5">Here's what's happening with your CrewAI today.</p>
                <a class="text-body text-sm font-weight-bold mb-0 icon-move-right mt-auto" href="{% url 'agents:manage_crews' %}">
                  View All Crews
                  <i class="fas fa-arrow-right text-sm ms-1" aria-hidden="true"></i>
                </a>
              </div>
            </div>
            <div class="col-lg-5 ms-auto text-center mt-5 mt-lg-0">
              <div class="bg-gradient-primary border-radius-lg h-100">
                <img src="{% static 'assets/img/shapes/waves-white.svg' %}" class="position-absolute h-100 w-50 top-0 d-lg-block d-none" alt="waves">
                <div class="position-relative d-flex align-items-center justify-content-center h-100">
                  <img class="w-100 position-relative z-index-2 pt-4" src="{% static 'assets/img/illustrations/rocket-white.png' %}" alt="rocket">
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
    <div class="col-lg-5">
      <div class="card h-100 p-3">
        <div class="overflow-hidden position-relative border-radius-lg bg-cover h-100" style="background-image: url('{% static 'assets/img/ivancik.jpg' %}');">
          <span class="mask bg-gradient-dark"></span>
          <div class="card-body position-relative z-index-1 d-flex flex-column h-100 p-3">
            <h5 class="text-white font-weight-bolder mb-4 pt-2">Quick Actions</h5>
            <a class="text-white text-sm font-weight-bold mb-0 icon-move-right mt-auto" href="{% url 'agents:add_crew' %}">
              Create New Crew
              <i class="fas fa-arrow-right text-sm ms-1" aria-hidden="true"></i>
            </a>
            <a class="text-white text-sm font-weight-bold mb-0 icon-move-right mt-auto" href="{% url 'agents:execution_list' %}">
              View Executions
              <i class="fas fa-arrow-right text-sm ms-1" aria-hidden="true"></i>
            </a>
          </div>
        </div>
      </div>
    </div>
  </div>

  <div class="row mt-4">
    <div class="col-lg-7 mb-lg-0 mb-4">
      <div class="card">
        <div class="card-header pb-0 p-3">
          <h6 class="mb-0">Crew Summaries</h6>
        </div>
        <div class="card-body p-3">
          {% for crew in crews %}
          <div class="d-flex mb-3">
            <div class="icon icon-shape bg-gradient-dark shadow text-center border-radius-md">
              <i class="ni ni-mobile-button text-lg opacity-10" aria-hidden="true"></i>
            </div>
            <div class="ms-3">
              <div class="numbers">
                <h6 class="mb-1 text-dark text-sm">{{ crew.name }}</h6>
                <span class="text-sm">Agents: {{ crew.agent_set.count }}, Tasks: {{ crew.task_set.count }}</span>
              </div>
            </div>
            <div class="ms-auto">
              <a class="btn btn-link text-dark px-3 mb-0" href="{% url 'agents:crew_detail' crew.id %}">
                <i class="fas fa-pencil-alt text-dark me-2" aria-hidden="true"></i>View
              </a>
            </div>
          </div>
          {% endfor %}
        </div>
      </div>
    </div>
    <div class="col-lg-5">
      <div class="card">
        <div class="card-header pb-0 p-3">
          <h6 class="mb-0">Recent Executions</h6>
        </div>
        <div class="card-body p-3">
          <ul class="list-group">
            {% for execution in recent_executions %}
            <li class="list-group-item border-0 d-flex justify-content-between ps-0 mb-2 border-radius-lg">
              <div class="d-flex align-items-center">
                <div class="icon icon-shape icon-sm me-3 bg-gradient-dark shadow text-center">
                  <i class="ni ni-mobile-button text-white opacity-10"></i>
                </div>
                <div class="d-flex flex-column">
                  <h6 class="mb-1 text-dark text-sm">{{ execution.crew.name }}</h6>
                  <span class="text-xs">{{ execution.created_at|date:"SHORT_DATETIME_FORMAT" }}</span>
                </div>
              </div>
              <div class="d-flex">
                <a class="btn btn-link btn-icon-only btn-rounded btn-sm text-dark icon-move-right my-auto" href="{% url 'agents:execution_detail' execution.id %}">
                  <i class="ni ni-bold-right" aria-hidden="true"></i>
                </a>
              </div>
            </li>
            {% endfor %}
          </ul>
        </div>
      </div>
    </div>
  </div>

  <!-- Add links to existing pages -->
  <div class="row mt-4">
    <div class="col-12">
      <div class="card">
        <div class="card-header pb-0 p-3">
          <h6 class="mb-0">Navigation</h6>
        </div>
        <div class="card-body p-3">
          <ul class="list-group">
            <li class="list-group-item border-0 d-flex justify-content-between ps-0 mb-2 border-radius-lg">
              <div class="d-flex align-items-center">
                <div class="icon icon-shape icon-sm me-3 bg-gradient-dark shadow text-center">
                  <i class="ni ni-bullet-list-67 text-white opacity-10"></i>
                </div>
                <div class="d-flex flex-column">
                  <h6 class="mb-1 text-dark text-sm">Manage Crews</h6>
                </div>
              </div>
              <div class="d-flex">
                <a class="btn btn-link btn-icon-only btn-rounded btn-sm text-dark icon-move-right my-auto" href="{% url 'agents:manage_crews' %}">
                  <i class="ni ni-bold-right" aria-hidden="true"></i>
                </a>
              </div>
            </li>
            <li class="list-group-item border-0 d-flex justify-content-between ps-0 mb-2 border-radius-lg">
              <div class="d-flex align-items-center">
                <div class="icon icon-shape icon-sm me-3 bg-gradient-dark shadow text-center">
                  <i class="ni ni-calendar-grid-58 text-white opacity-10"></i>
                </div>
                <div class="d-flex flex-column">
                  <h6 class="mb-1 text-dark text-sm">Execution List</h6>
                </div>
              </div>
              <div class="d-flex">
                <a class="btn btn-link btn-icon-only btn-rounded btn-sm text-dark icon-move-right my-auto" href="{% url 'agents:execution_list' %}">
                  <i class="ni ni-bold-right" aria-hidden="true"></i>
                </a>
              </div>
            </li>
            <!-- Add more links to other existing pages as needed -->
          </ul>
        </div>
      </div>
    </div>
  </div>
</div>

{% endblock content %}

{% block extra_js %}
{{ block.super }}
<script src="{% static 'assets/js/plugins/chartjs.min.js' %}"></script>

<script>
  $(function() {
    $('#client-select').change(function() {
      $('#client-select-form').submit();
    });
  });
</script>
{% endblock extra_js %}

================
File: templates/agents/execution_detail.html
================
{% extends "layouts/base.html" %}
{% load static %}

{% block title %} Execution Detail {% endblock %}

{% block extrastyle %}
{{ block.super }}
<!-- jKanban styles -->
<!-- <link rel="stylesheet" href="{% static 'assets/css/plugins/jkanban/jkanban.min.css' %}"/> -->
<style>
.kanban-container {
  padding: 1.25rem;
  display: flex;
  overflow-x: auto;
}

.kanban-board {
  min-width: 320px;
  max-width: 640px;
  margin: 0 0.9375rem;
}

.kanban-drag {
  min-height: 200px;
  padding: 1.25rem;
}

.kanban-item {
  margin-bottom: 0.9375rem;
}

/* Custom scrollbar for better visibility */
.kanban-container::-webkit-scrollbar {
  height: 0.5rem;
}

.kanban-container::-webkit-scrollbar-track {
  background: rgba(0, 0, 0, 0.1);
}

.kanban-container::-webkit-scrollbar-thumb {
  background: var(--bs-primary);
  border-radius: 0.25rem;
}

.kanban-container::-webkit-scrollbar-thumb:hover {
  background: var(--bs-primary-darker);
}

/* Stage status indicators */
.stage-status {
  display: inline-block;
  padding: 0.25rem 0.5rem;
  border-radius: 0.25rem;
  font-size: 0.875rem;
  font-weight: 600;
}

.status-completed { background-color: #28a745; color: white; }
.status-in_progress { background-color: #007bff; color: white; }
.status-pending { background-color: #6c757d; color: white; }
.status-error { background-color: #dc3545; color: white; }

.stage-item {
  border: 1px solid #e9ecef;
  border-radius: 0.5rem;
  padding: 1rem;
  margin-bottom: 1rem;
  background-color: white;
  box-shadow: 0 2px 4px rgba(0,0,0,0.05);
  transition: all 0.3s ease;
}

.stage-item:hover {
  box-shadow: 0 4px 6px rgba(0,0,0,0.1);
  transform: translateY(-2px);
}

.stage-content {
  margin-top: 1rem;
}

.stage-metadata {
  margin-top: 0.5rem;
  font-size: 0.875rem;
  color: #6c757d;
}

.stage-agent {
  display: inline-flex;
  align-items: center;
  margin-top: 0.5rem;
  font-size: 0.875rem;
  color: #495057;
}

.stage-agent i {
  margin-right: 0.25rem;
}

/* Progress bar styles */
.progress-wrapper {
  margin-top: 1rem;
}

.progress {
  height: 8px;
  margin-bottom: 0.5rem;
  overflow: hidden;
  background-color: #e9ecef;
  border-radius: 0.25rem;
  box-shadow: inset 0 1px 2px rgba(0,0,0,0.1);
}

.progress-bar {
  height: 100%;
  background-color: var(--bs-primary);
  transition: width .6s ease;
}

.progress-percentage {
  font-size: 0.75rem;
  color: #6c757d;
  text-align: right;
}

/* Task description styles */
.task-description {
  cursor: pointer;
  position: relative;
  padding-right: 1.5rem;
}

.task-description:after {
  content: '\f107';
  font-family: 'Font Awesome 5 Free';
  font-weight: 900;
  position: absolute;
  right: 0;
  top: 50%;
  transform: translateY(-50%);
  transition: transform .2s;
}

.task-description[aria-expanded="true"]:after {
  transform: translateY(-50%) rotate(180deg);
}

/* Modal styles */
.modal-content {
  border: none;
  border-radius: 0.5rem;
  box-shadow: 0 10px 15px -3px rgba(0,0,0,0.1);
}

.modal-header {
  border-bottom: 1px solid #e9ecef;
  padding: 1.25rem;
}

.modal-body {
  padding: 1.25rem;
}

.modal-footer {
  border-top: 1px solid #e9ecef;
  padding: 1.25rem;
}

/* Button styles */
.btn-icon {
  padding: 0.5rem;
  display: inline-flex;
  align-items: center;
  justify-content: center;
  border-radius: 0.375rem;
  transition: all .15s ease-in-out;
}

.btn-icon i {
  font-size: 1rem;
}

.btn-icon:hover {
  transform: translateY(-1px);
}

/* Utility classes */
.text-xs {
  font-size: 0.75rem !important;
}

.text-sm {
  font-size: 0.875rem !important;
}

.font-weight-bold {
  font-weight: 600 !important;
}

.text-truncate-2 {
  display: -webkit-box;
  -webkit-line-clamp: 2;
  -webkit-box-orient: vertical;
  overflow: hidden;
}
</style>
{% endblock extrastyle %}

{% block content %}
<div class="container-fluid py-4">
  <!-- Execution Header -->
  <div class="row mb-4">
    <div class="col-12">
      <div class="card">
        <div class="card-body">
          <div class="row align-items-center">
            <div class="col-auto">
              <div class="avatar avatar-xl position-relative">
                <img src="{% static 'assets/img/team-1.jpg' %}" alt="profile_image" class="w-100 border-radius-lg shadow-sm">
              </div>
            </div>
            <div class="col">
              <div class="h-100">
                <h5 class="mb-1">Crew: {{ crew.name }}</h5>
                <p class="mb-0 font-weight-bold text-sm">Execution #{{ execution.id }}</p>
                <p class="mb-0 text-sm">Started: {{ execution.created_at|date:"Y-m-d H:i:s" }}</p>
                <p class="mb-0 text-sm">Client: {{client.name}} - {{client.website_url}}</p>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>

  <!-- Kanban Board -->
  <div class="row">
    <div class="col-12">
      <div class="card">
        <div class="card-header pb-0">
          <h6>Tasks</h6>
        </div>
        <div class="card-body px-0 pt-0 pb-2">
          <div class="kanban-container">
            {% for column in columns %}
            <div class="kanban-board card">
              <header class="kanban-board-header bg-gradient-primary p-3">
                <div class="d-flex align-items-center">
                  <h6 class="text-white mb-0">{{ column.name }}</h6>
                </div>
              </header>
              <div class="kanban-drag p-3">
                {% for stage in column.stages %}
                <div class="stage-item">
                  <div class="d-flex justify-content-between align-items-center">
                    <span class="stage-status status-{{ stage.status|lower }}">{{ stage.status }}</span>
                    <small class="text-muted">{{ stage.created_at|date:"H:i:s" }}</small>
                  </div>
                  <h6 class="mt-2 mb-1">{{ stage.title }}</h6>
                  <div class="stage-content">
                    <div class="content-preview">
                      <p class="text-sm mb-2">{{ stage.content|truncatechars:150 }}</p>
                      {% if stage.content|length > 150 %}
                      <button class="btn btn-link btn-sm p-0 toggle-content" 
                              data-bs-toggle="collapse" 
                              data-bs-target="#content-{{ stage.id }}" 
                              aria-expanded="false">
                        Show More
                      </button>
                      <div class="collapse" id="content-{{ stage.id }}">
                        <div class="pt-2">
                          {{ stage.content|linebreaks }}
                          {% if stage.metadata %}
                          <div class="stage-metadata">
                            <h6 class="text-sm font-weight-bold">Metadata:</h6>
                            {% if stage.type == 'output' and stage.metadata.json_output %}
                            <pre class="text-sm">{{ stage.metadata.json_output|pprint }}</pre>
                            {% if stage.metadata.token_usage %}
                            <div class="mt-2">
                              <h6 class="text-sm font-weight-bold">Token Usage:</h6>
                              <pre class="text-sm">{{ stage.metadata.token_usage|pprint }}</pre>
                            </div>
                            {% endif %}
                            {% else %}
                            <pre class="text-sm">{{ stage.metadata|pprint }}</pre>
                            {% endif %}
                          </div>
                          {% endif %}
                        </div>
                      </div>
                      {% endif %}
                    </div>
                  </div>
                  {% if stage.agent %}
                  <div class="stage-agent">
                    <i class="fas fa-{% if stage.type == 'message' %}comment{% else %}robot{% endif %}"></i>
                    {{ stage.agent }}
                  </div>
                  {% endif %}
                </div>
                {% endfor %}
              </div>
            </div>
            {% endfor %}
          </div>
        </div>
      </div>
    </div>
  </div>
</div>
{% endblock content %}

{% block extra_js %}
{{block.super}}
<script src="https://cdnjs.cloudflare.com/ajax/libs/markdown-it/13.0.1/markdown-it.min.js"></script>
<script>
document.addEventListener('DOMContentLoaded', function() {
    const md = new markdownit();
    document.querySelectorAll('.stage-content .content-preview p').forEach(function(el) {
        const markdownContent = el.textContent;
        el.innerHTML = md.render(markdownContent);
    });

    // Add event listeners for content toggling
    document.querySelectorAll('.toggle-content').forEach(button => {
        button.addEventListener('click', function() {
            const expanded = this.getAttribute('aria-expanded') === 'true';
            this.textContent = expanded ? 'Show More' : 'Show Less';
        });
    });
});
</script>
{% endblock extra_js %}

================
File: templates/agents/execution_list.html
================
{% extends "agents/base_agents.html" %}
{% load static %}

{% block main_content %}
<div class="container mt-4">
    <h2>Executions</h2>

    <div class="card mb-4">
        <div class="card-header">
            <h3>Filter Executions</h3>
        </div>
        <div class="card-body">
            <form method="get" class="form-inline">
                <div class="form-group mr-2">
                    <label for="crew" class="mr-2">Crew:</label>
                    <select name="crew" id="crew" class="form-control">
                        <option value="">All Crews</option>
                        {% for crew in crews %}
                        <option value="{{ crew.id }}" {% if request.GET.crew == crew.id|stringformat:"s" %}selected{% endif %}>{{ crew.name }}</option>
                        {% endfor %}
                    </select>
                </div>
                <div class="form-group mr-2">
                    <label for="status" class="mr-2">Status:</label>
                    <select name="status" id="status" class="form-control">
                        <option value="">All Statuses</option>
                        <option value="PENDING" {% if request.GET.status == 'PENDING' %}selected{% endif %}>Pending</option>
                        <option value="RUNNING" {% if request.GET.status == 'RUNNING' %}selected{% endif %}>Running</option>
                        <option value="COMPLETED" {% if request.GET.status == 'COMPLETED' %}selected{% endif %}>Completed</option>
                        <option value="FAILED" {% if request.GET.status == 'FAILED' %}selected{% endif %}>Failed</option>
                    </select>
                </div>
                <button type="submit" class="btn btn-primary">Filter</button>
            </form>
        </div>
    </div>

    <div class="card">
        <div class="card-header">
            <h3>Execution List</h3>
        </div>
        <div class="card-body">
            <table class="table table-striped">
                <thead>
                    <tr>
                        <th>Crew</th>
                        <th>Status</th>
                        <th>Started</th>
                        <th>Last Updated</th>
                        <th>Actions</th>
                    </tr>
                </thead>
                <tbody>
                    {% for execution in executions %}
                    <tr>
                        <td>{{ execution.crew.name }}</td>
                        <td>
                            <span class="badge badge-{% if execution.status == 'COMPLETED' %}success{% elif execution.status == 'FAILED' %}danger{% elif execution.status == 'RUNNING' %}warning{% else %}secondary{% endif %}">
                                {{ execution.get_status_display }}
                            </span>
                        </td>
                        <td>{{ execution.created_at|date:"Y-m-d H:i:s" }}</td>
                        <td>{{ execution.updated_at|date:"Y-m-d H:i:s" }}</td>
                        <td>
                            <a href="{% url 'agents:execution_detail' execution.id %}" class="btn btn-sm btn-info">View Details</a>
                        </td>
                    </tr>
                    {% empty %}
                    <tr>
                        <td colspan="5">No executions found.</td>
                    </tr>
                    {% endfor %}
                </tbody>
            </table>

            {% if is_paginated %}
            <nav aria-label="Execution list pagination">
                <ul class="pagination justify-content-center">
                    {% if page_obj.has_previous %}
                    <li class="page-item">
                        <a class="page-link" href="?page={{ page_obj.previous_page_number }}{% for key, value in request.GET.items %}{% if key != 'page' %}&{{ key }}={{ value }}{% endif %}{% endfor %}" aria-label="Previous">
                            <span aria-hidden="true">&laquo;</span>
                        </a>
                    </li>
                    {% endif %}

                    {% for num in page_obj.paginator.page_range %}
                    {% if page_obj.number == num %}
                    <li class="page-item active"><a class="page-link" href="#">{{ num }}</a></li>
                    {% elif num > page_obj.number|add:'-3' and num < page_obj.number|add:'3' %}
                    <li class="page-item"><a class="page-link" href="?page={{ num }}{% for key, value in request.GET.items %}{% if key != 'page' %}&{{ key }}={{ value }}{% endif %}{% endfor %}">{{ num }}</a></li>
                    {% endif %}
                    {% endfor %}

                    {% if page_obj.has_next %}
                    <li class="page-item">
                        <a class="page-link" href="?page={{ page_obj.next_page_number }}{% for key, value in request.GET.items %}{% if key != 'page' %}&{{ key }}={{ value }}{% endif %}{% endfor %}" aria-label="Next">
                            <span aria-hidden="true">&raquo;</span>
                        </a>
                    </li>
                    {% endif %}
                </ul>
            </nav>
            {% endif %}
        </div>
    </div>
</div>
{% endblock %}

{% block extra_js %}
{{ block.super }}
<script>
    $(function () {
        $('[data-toggle="tooltip"]').tooltip()
    })
</script>
{% endblock extra_js %}

================
File: templates/agents/manage_agents_card_view.html
================
{% extends "layouts/base.html" %}
{% load static %}

{% block title %} Manage Agents - Card View {% endblock %}

{% block content %}

<div class="container-fluid py-4">
  <div class="row">
    <div class="col-12">
      <div class="card mb-4">
        <div class="card-header pb-0">
          <div class="d-flex justify-content-between align-items-center">
            <div>
            <h6 class="mb-0">Agents</h6>
            <p class="text-sm mb-0">
                View and manage your AI agents.
            </p>
            </div>
            <div class="d-flex align-items-center">
            <a href="{% url 'agents:manage_agents' %}" class="btn btn-sm  me-2" title="Table View">
                <i class="fas fa-table fs-5"></i>
            </a>
            <a href="{% url 'agents:manage_agents_card_view' %}" class="btn btn-sm  me-2" title="Card View">
                <i class="fas fa-id-card fs-5"></i>
            </a>
            <a href="{% url 'agents:add_agent' %}?next={{ request.path|urlencode }}" class="btn btn-primary btn-sm">Add Agent</a>
            </div>
          </div>
        </div>
        <div class="card-body px-0 pt-0 pb-2">
          <div class="p-3">
            <div class="row g-3 mb-4">
              <div class="col-md-6">
                <input type="text" id="searchInput" class="form-control" placeholder="Search agents...">
              </div>
              <div class="col-md-6">
                <select id="roleFilter" class="form-select">
                  <option value="">All Roles</option>
                  <option value="Analyst">Analyst</option>
                  <option value="Support">Support</option>
                  <option value="Creator">Creator</option>
                  <option value="Engineer">Engineer</option>
                  <option value="Manager">Manager</option>
                </select>
              </div>
            </div>
            <div class="row" id="agentCards">
              {% for agent in agents %}
              <div class="col-lg-4 col-md-6 mb-4">
                <div class="card h-100">
                  <div class="card-header p-3 pb-0">
                    <div class="d-flex justify-content-between align-items-center">
                      <div>
                        <h5 class="mb-0">{{ agent.name }}</h5>
                        <p class="text-sm mb-0">{{ agent.role }}</p>
                      </div>
                      <div class="avatar avatar-xl position-relative">
                        <img src="{% static 'assets/img/'|add:agent.avatar %}" alt="Agent avatar" class="w-100 border-radius-lg shadow-sm">
                      </div>
                    </div>
                  </div>
                  <div class="card-body p-3">
                    <p class="text-sm mb-2"><strong>Goal:</strong> {{ agent.goal|truncatechars:100 }}</p>
                    <p class="text-sm mb-2"><strong>LLM:</strong> {{ agent.llm }}</p>
                    <p class="text-sm mb-2"><strong>Crews:</strong> 
                      {% for crew in agent.crew_set.all %}
                        <span class="badge bg-gradient-info"><a href="{% url 'agents:edit_crew' crew.id %}?next={{ request.path|urlencode }}" class="text-white font-weight-bold text-xs" data-toggle="tooltip" data-original-title="Edit crew">{{ crew.name }}</a></span>
                      {% empty %}
                        <span class="text-muted">No crews</span>
                      {% endfor %}
                    </p>
                    <p class="text-sm mb-2"><strong>Tasks:</strong> 
                      {% for task in agent.task_set.all %}
                        <span class="badge bg-gradient-dark"><a href="{% url 'agents:edit_task' task.id %}?next={{ request.path|urlencode }}" class="text-white font-weight-bold text-xs" data-toggle="tooltip" data-original-title="Edit task">{{ task.description|truncatechars:20 }}</a></span>
                      {% empty %}
                        <span class="text-muted">No tasks</span>
                      {% endfor %}
                    </p>
                    <p class="text-sm mb-0"><strong>Tools:</strong></p>
                    <div class="d-flex flex-wrap gap-1 mb-2">
                      {% for tool in agent.tools.all %}
                        <span class="badge bg-gradient-success">{{ tool.name }}</span>
                      {% empty %}
                        <span class="text-muted">No tools</span>
                      {% endfor %}
                    </div>
                  </div>
                  <div class="card-footer p-3">
                    <div class="d-flex justify-content-between">
                        <a href="{% url 'agents:edit_agent' agent.id %}?next={{ request.path|urlencode }}" class="btn btn-link text-dark mb-0 ps-0" data-toggle="tooltip" data-original-title="Edit agent">
                          <i class="fas fa-pencil-alt text-dark me-2" aria-hidden="true"></i>Edit
                        </a>
                        <form action="{% url 'agents:duplicate_agent' agent.id %}" method="POST" class="d-inline">
                          {% csrf_token %}
                          <input type="hidden" name="next" value="{{ request.path }}">
                          <button type="submit" class="btn btn-link text-info mb-0" data-toggle="tooltip" data-original-title="Duplicate agent">
                            <i class="fas fa-clone me-2"></i>Duplicate
                          </button>
                        </form>
                        <a href="{% url 'agents:delete_agent' agent.id %}" class="btn btn-link text-danger mb-0 pe-0" data-toggle="tooltip" data-original-title="Delete agent">
                          <i class="far fa-trash-alt me-2"></i>Delete
                        </a>
                      </div>
                  </div>
                </div>
              </div>
              {% endfor %}
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</div>

<!-- Create/Edit Agent Modal -->
<div class="modal fade" id="agentModal" tabindex="-1" role="dialog" aria-labelledby="agentModalLabel" aria-hidden="true">
  <div class="modal-dialog modal-dialog-centered" role="document">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title" id="agentModalLabel">Create New Agent</h5>
        <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
      </div>
      <div class="modal-body">
        <form id="agentForm">
          <div class="form-group mb-3">
            <label for="agentName" class="form-control-label">Name</label>
            <input type="text" class="form-control" id="agentName" required>
          </div>
          <div class="form-group mb-3">
            <label for="agentRole" class="form-control-label">Role</label>
            <input type="text" class="form-control" id="agentRole" required>
          </div>
          <div class="form-group mb-3">
            <label for="agentGoal" class="form-control-label">Goal</label>
            <textarea class="form-control" id="agentGoal" rows="3" required></textarea>
          </div>
          <div class="form-group mb-3">
            <label for="agentLLM" class="form-control-label">LLM</label>
            <input type="text" class="form-control" id="agentLLM" required>
          </div>
          <div class="form-group mb-3">
            <label for="agentAvatar" class="form-control-label">Avatar</label>
            <select class="form-control" id="agentAvatar" name="avatar" required>
              {% for avatar in form.avatar.field.choices %}
                <option value="{{ avatar.0 }}" data-img="{% static 'assets/img/'|add:avatar.0 %}">Avatar {{ forloop.counter }}</option>
              {% endfor %}
            </select>
          </div>
          <div class="text-center">
            <img id="avatarPreview" src="" alt="Avatar preview" class="img-fluid rounded-circle" style="width: 100px; height: 100px; object-fit: cover;">
          </div>
        </form>
      </div>
      <div class="modal-footer">
        <button type="button" class="btn btn-secondary" data-bs-dismiss="modal">Close</button>
        <button type="button" class="btn btn-primary" onclick="saveAgent()">Save Agent</button>
      </div>
    </div>
  </div>
</div>

{% endblock content %}

{% block extra_js %}
{{ block.super }}
<script>
  let currentAgentId = null;

  function editAgent(agentId) {
    currentAgentId = agentId;
    // Fetch agent details and populate the form
    // This is a placeholder - you'll need to implement the actual data fetching
    $('#agentModalLabel').text('Edit Agent');
    $('#agentModal').modal('show');
  }

  function saveAgent() {
    const agentData = {
      name: $('#agentName').val(),
      role: $('#agentRole').val(),
      goal: $('#agentGoal').val(),
      llm: $('#agentLLM').val(),
      avatar: $('#agentAvatar').val(),
      // Add more fields as needed
    };

    const url = currentAgentId ? `/agents/manage/agents/${currentAgentId}/update/` : '/agents/manage/agents/add/';
    const method = currentAgentId ? 'PUT' : 'POST';

    $.ajax({
      url: url,
      method: method,
      data: JSON.stringify(agentData),
      contentType: 'application/json',
      success: function(response) {
        $('#agentModal').modal('hide');
        // Refresh the page or update the cards
        location.reload();
      },
      error: function(error) {
        console.error('Error saving agent:', error);
      }
    });
  }

  function deleteAgent(agentId) {
    if (confirm('Are you sure you want to delete this agent?')) {
      $.ajax({
        url: `/agents/manage/agents/${agentId}/delete/`,
        method: 'DELETE',
        success: function(response) {
          // Remove the agent card or refresh the page
          location.reload();
        },
        error: function(error) {
          console.error('Error deleting agent:', error);
        }
      });
    }
  }

  $(document).ready(function() {
    $('#searchInput').on('keyup', function() {
      var value = $(this).val().toLowerCase();
      $("#agentCards .col-md-4").filter(function() {
        $(this).toggle($(this).text().toLowerCase().indexOf(value) > -1)
      });
    });

    $('#roleFilter, #statusFilter').on('change', function() {
      var roleValue = $('#roleFilter').val().toLowerCase();
      var statusValue = $('#statusFilter').val().toLowerCase();
      $("#agentCards .col-md-4").filter(function() {
        var roleMatch = roleValue === '' || $(this).find('.text-capitalize').text().toLowerCase().indexOf(roleValue) > -1;
        var statusMatch = statusValue === '' || $(this).find('.badge').text().toLowerCase().indexOf(statusValue) > -1;
        $(this).toggle(roleMatch && statusMatch);
      });
    });

    // Avatar preview functionality
    $('#agentAvatar').change(function() {
      const selectedOption = $(this).find('option:selected');
      const imgSrc = selectedOption.data('img');
      $('#avatarPreview').attr('src', imgSrc);
    });

    // Trigger change event to show initial avatar
    $('#agentAvatar').trigger('change');
  });
</script>
{% endblock extra_js %}

================
File: templates/agents/manage_agents.html
================
{% extends "layouts/base.html" %}
{% load static %}

{% block title %} Manage Agents {% endblock %}

{% block content %}
<div class="container-fluid py-4">
  <div class="row">
    <div class="col-12">
      <div class="card mb-4">
        <!-- Card header -->
        <div class="card-header d-flex justify-content-between align-items-center">
          <div>
              <h5 class="mb-0">Agents</h5>
              <p class="text-sm mb-0">
                  View and manage your AI agents.
              </p>
          </div>
          <div class="d-flex align-items-center">
              <!-- Removed btn-group to separate the icons -->
              <a href="{% url 'agents:manage_agents' %}" class="btn btn-sm  me-2" title="Table View">
                  <i class="fas fa-table fs-5"></i>
              </a>
              <a href="{% url 'agents:manage_agents_card_view' %}" class="btn btn-sm  me-2" title="Card View">
                  <i class="fas fa-id-card fs-5"></i>
              </a>
              <a href="{% url 'agents:add_agent' %}?next={{ request.path|urlencode }}" class="btn btn-primary btn-sm">Add Agent</a>
          </div>
      </div>
        <div class="table-responsive">
          <table class="table table-flush" id="agents-table">
            <thead class="thead-light">
              <tr>
                <th class="text-uppercase text-secondary text-xxs font-weight-bolder opacity-7">Avatar</th>
                <th class="text-uppercase text-secondary text-xxs font-weight-bolder opacity-7">Name</th>
                <th class="text-uppercase text-secondary text-xxs font-weight-bolder opacity-7">Role</th>
                <th class="text-uppercase text-secondary text-xxs font-weight-bolder opacity-7">LLM</th>
                <th class="text-uppercase text-secondary text-xxs font-weight-bolder opacity-7">Actions</th>
              </tr>
            </thead>
            <tbody>
              {% for agent in agents %}
              <tr>
                <td class="text-sm font-weight-normal">
                  <img src="{% static 'assets/img/'|add:agent.avatar %}" alt="{{ agent.name }}'s avatar" class="avatar avatar-sm rounded-circle me-2">
                </td>
                <td class="text-sm font-weight-normal">
                  {{ agent.name }}
                </td>
                <td class="text-sm font-weight-normal">{{ agent.role }}</td>
                <td class="text-sm font-weight-normal">{{ agent.llm }}</td>
                <td class="text-sm font-weight-normal">
                  <div class="d-flex align-items-center gap-2">
                    <a href="{% url 'agents:edit_agent' agent.id %}?next={{ request.path|urlencode }}" class="text-secondary font-weight-bold text-xs" data-toggle="tooltip" data-original-title="Edit agent">
                      Edit
                    </a>
                    <form action="{% url 'agents:duplicate_agent' agent.id %}" method="POST" class="d-inline mx-2">
                      {% csrf_token %}
                      <input type="hidden" name="next" value="{{ request.path }}">
                      <button type="submit" class="btn btn-link text-info font-weight-bold text-xs p-0 m-0" data-toggle="tooltip" data-original-title="Duplicate agent">
                        Duplicate
                      </button>
                    </form>
                    <a href="{% url 'agents:delete_agent' agent.id %}" class="text-danger font-weight-bold text-xs" data-toggle="tooltip" data-original-title="Delete agent">
                      Delete
                    </a>
                  </div>
                </td>
              </tr>
              {% empty %}
              <tr>
                <td colspan="5" class="text-sm font-weight-normal">No agents found.</td>
              </tr>
              {% endfor %}
            </tbody>
          </table>
        </div>
      </div>
    </div>
  </div>

  {% include 'includes/footer.html' %}
</div>

{% endblock content %}

{% block extra_js %}
  <script src="{% static 'assets/js/plugins/sweetalert.min.js' %}"></script>

  <script src="{% static 'assets/js/plugins/datatables.js' %}"></script>
  <script>
    const dataTableSearch = new simpleDatatables.DataTable("#agents-table", {
      searchable: true,
      fixedHeight: true,
      perPage: 25,
      perPageSelect: [25, 50, 100, 150]
    });
  </script>
{% endblock extra_js %}

================
File: templates/agents/manage_crews_card_view.html
================
{% extends "layouts/base.html" %}
{% load static %}

{% block title %} Manage Crews {% endblock %}

{% block content %}

<div class="container-fluid py-4">
  {% if selected_client %}
    <div class="alert alert-info" role="alert">
      Selected Client: {{ selected_client.name }}
    </div>
  {% else %}
    <div class="alert alert-warning" role="alert">
      No client selected. Showing all crews.
    </div>
  {% endif %}
  
  <div class="row">
    <div class="col-12">
      <div class="card mb-4">
        <div class="card-header pb-0">
          <div class="d-flex justify-content-between align-items-center">
            <div>
              <h6 class="mb-0">Crews</h6>
              <p class="text-sm mb-0">
                View and manage your AI agent crews.
              </p>
            </div>
            <div class="d-flex align-items-center">
              <a href="{% url 'agents:manage_crews' %}" class="btn btn-sm me-2" title="Table View">
                <i class="fas fa-table fs-5"></i>
              </a>
              <a href="{% url 'agents:manage_crews_card_view' %}" class="btn btn-sm me-2" title="Card View">
                <i class="fas fa-id-card fs-5"></i>
              </a>
              <a href="{% url 'agents:add_crew' %}?next={{ request.path|urlencode }}" class="btn btn-primary btn-sm">Add Crew</a>
            </div>
          </div>
        </div>
        <div class="card-body px-0 pt-0 pb-2">
          <div class="p-3">
            <div class="row g-3 mb-4">
              <div class="col-md-6">
                <input type="text" id="searchInput" class="form-control" placeholder="Search crews...">
              </div>
              <div class="col-md-6">
                <select id="processFilter" class="form-select">
                  <option value="">All Processes</option>
                  <option value="Sequential">Sequential</option>
                  <option value="Parallel">Parallel</option>
                  <option value="Hierarchical">Hierarchical</option>
                </select>
              </div>
            </div>
            <div class="row" id="crewCards">
              {% for crew in crews %}
              <div class="col-lg-4 col-md-6 mb-4">
                <div class="card h-100">
                  <div class="card-header p-3 pb-0">
                    <div class="d-flex justify-content-between align-items-center">
                      <div>
                        <h5 class="mb-0">
                          <a href="{% url 'agents:crew_kanban' crew.id %}{% if selected_client %}?client_id={{ selected_client.id }}{% endif %}" class="text-dark">
                            {{ crew.name }}
                            <i class="fas fa-play ms-1" aria-hidden="true"></i>
                          </a>
                        </h5>
                        <p class="text-sm mb-0">{{ crew.get_process_display }}</p>
                      </div>
                      <div class="avatar-group">
                        {% for agent in crew.agents.all|slice:":3" %}
                          <a href="javascript:;" class="avatar avatar-sm rounded-circle" data-bs-toggle="tooltip" data-bs-placement="bottom" title="{{ agent.name }}">
                            <img src="{% static 'assets/img/'|add:agent.avatar %}" alt="{{ agent.name }}">
                          </a>
                        {% endfor %}
                        {% if crew.agents.count > 3 %}
                          <a href="javascript:;" class="avatar avatar-sm rounded-circle" data-bs-toggle="tooltip" data-bs-placement="bottom" title="{{ crew.agents.count|add:'-3' }} more">
                            <span class="avatar-text bg-gradient-primary">+{{ crew.agents.count|add:'-3' }}</span>
                          </a>
                        {% endif %}
                      </div>
                    </div>
                  </div>
                  <div class="card-body p-3">
                    <p class="text-sm mb-2"><strong>Agents:</strong> 
                      {% for agent in crew.agents.all %}
                        <span class="badge bg-gradient-info"><a href="{% url 'agents:edit_agent' agent.id %}?next={{ request.path|urlencode }}" class="text-white font-weight-bold text-xs" data-toggle="tooltip" data-original-title="Edit agent">{{ agent.name }}</a></span>
                      {% empty %}
                        <span class="text-muted">No agents</span>
                      {% endfor %}
                    </p>
                    <p class="text-sm mb-2"><strong>Tasks:</strong> 
                      {% for task in crew.tasks.all %}
                        <span class="badge bg-gradient-dark"><a href="{% url 'agents:edit_task' task.id %}?next={{ request.path|urlencode }}" class="text-white" font-weight-bold text-xs" data-toggle="tooltip" data-original-title="Edit task">{{ task.description|truncatechars:20 }}</a></span>
                      {% empty %}
                        <span class="text-muted">No tasks</span>
                      {% endfor %}
                    </p>
                  </div>
                  <div class="card-footer p-3">
                    <div class="d-flex justify-content-between">
                      <a href="{% url 'agents:edit_crew' crew.id %}?next={{ request.path|urlencode }}" class="btn btn-link text-dark mb-0 ps-0" data-toggle="tooltip" data-original-title="Edit crew">
                        <i class="fas fa-pencil-alt text-dark me-2" aria-hidden="true"></i>Edit
                      </a>

                      <form action="{% url 'agents:duplicate_crew' crew.id %}" method="POST" class="d-inline">
                        {% csrf_token %}
                        <input type="hidden" name="next" value="{{ request.path }}">
                        <button type="submit" class="btn btn-link text-info mb-0" data-toggle="tooltip" data-original-title="Duplicate crew">
                          <i class="fas fa-clone me-2"></i>Duplicate
                        </button>
                      </form>

                      <a href="{% url 'agents:delete_crew' crew.id %}" class="btn btn-link text-danger mb-0 pe-0" data-toggle="tooltip" data-original-title="Delete crew">
                        <i class="far fa-trash-alt me-2"></i>Delete
                      </a>
                    </div>
                  </div>
                </div>
              </div>
              {% endfor %}
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</div>

{% endblock content %}

{% block extra_js %}
{{ block.super }}
<!-- Load jQuery first -->
<script src="https://code.jquery.com/jquery-3.6.0.min.js"></script>
<script>
  $(document).ready(function() {
    $('#searchInput').on('keyup', function() {
      var value = $(this).val().toLowerCase();
      $("#crewCards .col-lg-4").filter(function() {
        $(this).toggle($(this).text().toLowerCase().indexOf(value) > -1)
      });
    });

    $('#processFilter').on('change', function() {
      var processValue = $(this).val().toLowerCase();
      $("#crewCards .col-lg-4").filter(function() {
        var processMatch = processValue === '' || $(this).find('.text-sm').text().toLowerCase().indexOf(processValue) > -1;
        $(this).toggle(processMatch);
      });
    });

    // Initialize tooltips
    var tooltipTriggerList = [].slice.call(document.querySelectorAll('[data-bs-toggle="tooltip"]'))
    var tooltipList = tooltipTriggerList.map(function (tooltipTriggerEl) {
      return new bootstrap.Tooltip(tooltipTriggerEl)
    });
  });
</script>
{% endblock extra_js %}

================
File: templates/agents/manage_crews.html
================
{% extends "layouts/base.html" %}
{% load static %}

{% block title %} Manage Crews {% endblock %}

{% block content %}
<div class="container-fluid py-4">
  {% if selected_client %}
    <div class="alert alert-info" role="alert">
      Selected Client: {{ selected_client.name }}
    </div>
  {% else %}
    <div class="alert alert-warning" role="alert">
      No client selected. Showing all crews.
    </div>
  {% endif %}

  <div class="row">
    <div class="col-12">
      <div class="card mb-4">
        <div class="card-header pb-0">
          <div class="d-flex justify-content-between align-items-center">
            <div>
              <h6 class="mb-0">Crews</h6>
              <p class="text-sm mb-0">
                Manage your AI agent crews
              </p>
            </div>
            <div class="d-flex align-items-center">
              <a href="{% url 'agents:manage_crews' %}" class="btn btn-sm me-2" title="Table View">
                <i class="fas fa-table fs-5"></i>
              </a>
              <a href="{% url 'agents:manage_crews_card_view' %}" class="btn btn-sm me-2" title="Card View">
                <i class="fas fa-id-card fs-5"></i>
              </a>
              <a href="{% url 'agents:add_crew' %}?next={{ request.path|urlencode }}" class="btn btn-primary btn-sm">Add Crew</a>
            </div>
          </div>
        </div>
        <div class="card-body px-0 pt-0 pb-2">
          <div class="table-responsive p-0">
            <table class="table align-items-center mb-0">
              <thead>
                <tr>
                  <th class="text-uppercase text-secondary text-xxs font-weight-bolder opacity-7">Crew</th>
                  <th class="text-uppercase text-secondary text-xxs font-weight-bolder opacity-7 ps-2">Process</th>
                  <th class="text-center text-uppercase text-secondary text-xxs font-weight-bolder opacity-7">Agents</th>
                  <th class="text-center text-uppercase text-secondary text-xxs font-weight-bolder opacity-7">Tasks</th>
                  <th class="text-secondary opacity-7"></th>
                </tr>
              </thead>
              <tbody>
                {% for crew in crews %}
                <tr>
                  <td>
                    <div class="d-flex px-2 py-1">
                      <div class="d-flex flex-column justify-content-center">
                        <h6 class="mb-0 text-sm">
                          <a href="{% url 'agents:crew_kanban' crew.id %}{% if selected_client %}?client_id={{ selected_client.id }}{% endif %}" class="text-dark font-weight-bold">
                            {{ crew.name }}
                          </a>
                        </h6>
                        <p class="text-xs text-secondary mb-0">{{ crew.description|truncatechars:50 }}</p>
                      </div>
                  </td>
                  <td>
                    <p class="text-xs font-weight-bold mb-0">{{ crew.get_process_display }}</p>
                  </td>
                  <td class="align-middle text-center text-sm">
                    <span class="badge badge-sm bg-gradient-success">{{ crew.agents.count }}</span>
                  </td>
                  <td class="align-middle text-center">
                    <span class="text-secondary text-xs font-weight-bold">{{ crew.tasks.count }}</span>
                  </td>
                  <td class="align-middle">
                    <div class="d-flex align-items-center gap-2">
                      <a href="{% url 'agents:edit_crew' crew.id %}?next={{ request.path|urlencode }}" class="text-secondary font-weight-bold text-xs" data-toggle="tooltip" data-original-title="Edit crew">
                        Edit
                      </a>
                      <form action="{% url 'agents:duplicate_crew' crew.id %}" method="POST" class="d-inline mx-2">
                        {% csrf_token %}
                        <input type="hidden" name="next" value="{{ request.path }}">
                        <button type="submit" class="btn btn-link text-info font-weight-bold text-xs p-0 m-0" data-toggle="tooltip" data-original-title="Duplicate crew">
                          Duplicate
                        </button>
                      </form>
                      <a href="{% url 'agents:delete_crew' crew.id %}" class="text-danger font-weight-bold text-xs" data-toggle="tooltip" data-original-title="Delete crew">
                        Delete
                      </a>
                    </div>
                  </td>
                </tr>
                {% endfor %}
              </tbody>
            </table>
          </div>
        </div>
      </div>
    </div>
  </div>
</div>

{% endblock content %}

{% block extra_js %}
{{ block.super }}
<script src="{% static 'assets/js/plugins/datatables.js' %}"></script>
{% endblock extra_js %}

================
File: templates/agents/manage_tasks.html
================
{% extends "layouts/base.html" %}
{% load static %}

{% block title %} Manage Tasks {% endblock %}

{% block content %}
<div class="container-fluid py-4">
  <div class="row">
    <div class="col-12">
      <div class="card mb-4">
        <!-- Card header -->
        <div class="card-header d-flex justify-content-between align-items-center">
          <div>
            <h5 class="mb-0">Tasks</h5>
            <p class="text-sm mb-0">
              View and manage your AI agent tasks.
            </p>
          </div>
          <div>
            <a href="{% url 'agents:add_task' %}" class="btn btn-primary btn-sm">Add New Task</a>
          </div>
        </div>
        <div class="table-responsive">
          <table class="table table-flush" id="tasks-table">
            <thead class="thead-light">
              <tr>
                <th class="text-uppercase text-secondary text-xxs font-weight-bolder opacity-7">Description</th>
                <th class="text-uppercase text-secondary text-xxs font-weight-bolder opacity-7">Agent</th>
                <th class="text-uppercase text-secondary text-xxs font-weight-bolder opacity-7">Async Execution</th>
                <th class="text-uppercase text-secondary text-xxs font-weight-bolder opacity-7">Human Input</th>
                <th class="text-uppercase text-secondary text-xxs font-weight-bolder opacity-7">Output Type</th>
                <th class="text-uppercase text-secondary text-xxs font-weight-bolder opacity-7">Actions</th>
              </tr>
            </thead>
            <tbody>
              {% for task in tasks %}
              <tr>
                <td class="text-sm font-weight-normal">
                  <a href="{% url 'agents:edit_task' task.id %}?next={{ request.path|urlencode }}">{{ task.description|truncatechars:50 }}</a>
                </td>
                <td class="text-sm font-weight-normal">{{ task.agent.name|default:"N/A" }}</td>
                <td class="text-sm font-weight-normal">{% if task.async_execution %}Yes{% else %}No{% endif %}</td>
                <td class="text-sm font-weight-normal">{% if task.human_input %}Yes{% else %}No{% endif %}</td>
                <td class="text-sm font-weight-normal">
                  {% if task.output_json %}JSON
                  {% elif task.output_pydantic %}Pydantic
                  {% elif task.output_file %}File
                  {% else %}Default
                  {% endif %}
                </td>
                <td class="text-sm font-weight-normal">
                  <div class="d-flex align-items-center gap-2">
                    <a href="{% url 'agents:edit_task' task.id %}?next={{ request.path|urlencode }}" class="text-secondary font-weight-bold text-xs" data-toggle="tooltip" data-original-title="Edit task">
                      Edit
                    </a>
                    <form action="{% url 'agents:duplicate_task' task.id %}" method="POST" class="d-inline mx-2">
                      {% csrf_token %}
                      <input type="hidden" name="next" value="{{ request.path }}">
                      <button type="submit" class="btn btn-link text-info font-weight-bold text-xs p-0 m-0" data-toggle="tooltip" data-original-title="Duplicate task">
                        Duplicate
                      </button>
                    </form>
                    <a href="{% url 'agents:delete_task' task.id %}" class="text-danger font-weight-bold text-xs" data-toggle="tooltip" data-original-title="Delete task">
                      Delete
                    </a>
                  </div>
                </td>
              </tr>
              {% empty %}
              <tr>
                <td colspan="6" class="text-sm font-weight-normal">No tasks found.</td>
              </tr>
              {% endfor %}
            </tbody>
          </table>
        </div>
      </div>
    </div>
  </div>

  {% include 'includes/footer.html' %}
</div>
{% endblock content %}

{% block extra_js %}
  <script src="{% static 'assets/js/plugins/datatables.js' %}"></script>
  <script>
    const dataTableSearch = new simpleDatatables.DataTable("#tasks-table", {
      searchable: true,
      fixedHeight: true,
      perPage: 50,
      perPageSelect: [25, 50, 100, 150]
    });
  </script>
{% endblock extra_js %}

================
File: templates/agents/manage_tools.html
================
{% extends "layouts/base.html" %}
{% load static %}

{% block title %} Manage Tools {% endblock %}

{% block content %}
<div class="container-fluid py-4">
  <div class="row">
    <div class="col-12">
      <div class="card mb-4">
        <!-- Card header -->
        <div class="card-header d-flex justify-content-between align-items-center">
          <div>
            <h5 class="mb-0">Tools</h5>
            <p class="text-sm mb-0">
              View and manage your AI agent tools.
            </p>
          </div>
          <a href="{% url 'agents:add_tool' %}" class="btn btn-primary btn-sm">Add New Tool</a>
        </div>
        <div class="table-responsive">
          <table class="table table-flush" id="tools-table">
            <thead class="thead-light">
              <tr>
                <th class="text-uppercase text-secondary text-xxs font-weight-bolder opacity-7">Name</th>
                <th class="text-uppercase text-secondary text-xxs font-weight-bolder opacity-7">Description</th>
                <th class="text-uppercase text-secondary text-xxs font-weight-bolder opacity-7">Tool Class</th>
                <th class="text-uppercase text-secondary text-xxs font-weight-bolder opacity-7">Actions</th>
              </tr>
            </thead>
            <tbody>
              {% for tool in tools %}
              <tr>
                <td class="text-sm font-weight-normal">
                  <a href="{% url 'agents:edit_tool' tool.id %}">{{ tool.name }}</a>
                </td>
                <td class="text-sm font-weight-normal">{{ tool.description|truncatechars:50 }}</td>
                <td class="text-sm font-weight-normal">{{ tool.tool_class }}</td>
                <td class="text-sm font-weight-normal">
                  <a href="{% url 'agents:edit_tool' tool.id %}" class="text-secondary font-weight-bold text-xs" data-toggle="tooltip" data-original-title="Edit tool">
                    Edit
                  </a>
                  |
                  <a href="#" class="text-primary font-weight-bold text-xs test-tool-btn" data-tool-id="{{ tool.id }}" data-bs-toggle="modal" data-bs-target="#testToolModal">
                    Test
                  </a>
                  |
                  <a href="{% url 'agents:delete_tool' tool.id %}" class="text-danger font-weight-bold text-xs" data-toggle="tooltip" data-original-title="Delete tool">
                    Delete
                  </a>
                </td>
              </tr>
              {% empty %}
              <tr>
                <td colspan="4" class="text-sm font-weight-normal">No tools found.</td>
              </tr>
              {% endfor %}
            </tbody>
          </table>
        </div>
      </div>
    </div>
  </div>
</div>

<!-- Test Tool Modal -->
<div class="modal fade" id="testToolModal" tabindex="-1" aria-labelledby="testToolModalLabel" aria-hidden="true">
  <div class="modal-dialog modal-xl modal-dialog-scrollable">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title" id="testToolModalLabel">Test Tool</h5>
        <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
      </div>
      <div class="modal-body">
        <form id="toolTestForm" onsubmit="return false;">
          {% csrf_token %}
          <div id="toolInputs" class="mb-3">
            <!-- Tool inputs will be dynamically added here -->
          </div>
          <div class="mb-3">
            <label class="form-label">Output:</label>
            <div id="toolOutput" class="border rounded p-3 bg-light overflow-auto" style="min-height: 100px; max-height: 400px;">
              <!-- Tool output will appear here -->
            </div>
          </div>
          <div id="outputTableContainer" style="display: none;"></div>
        </form>
      </div>
      <div class="modal-footer">
        <button type="button" class="btn btn-secondary" data-bs-dismiss="modal">Close</button>
        <button type="submit" class="btn btn-primary" id="testToolBtn">Test</button>
      </div>
    </div>
  </div>
</div>


{% include 'includes/footer.html' %}
{% endblock content %}
{% block extrastyle %}
  {{ block.super }}
  
<style>
  /* Ensure modal doesn't exceed viewport height */
  .modal-dialog-scrollable {
    max-height: 90vh;
    margin-top: 5vh;
    margin-bottom: 5vh;
  }
  
  /* Make modal wider on larger screens */
  @media (min-width: 1200px) {
    .modal-xl {
      max-width: 1140px;
    }
  }

  /* For extra large screens */
  @media (min-width: 1400px) {
    .modal-xl {
      max-width: 1320px;
    }
  }
  
  /* Style for pre-formatted output */
  #toolOutput pre {
    margin: 0;
    white-space: pre-wrap;
    word-wrap: break-word;
  }
  
  /* Custom scrollbar styling for better visibility */
  #toolOutput::-webkit-scrollbar {
    width: 8px;
  }
  
  #toolOutput::-webkit-scrollbar-track {
    background: #f1f1f1;
    border-radius: 4px;
  }
  
  #toolOutput::-webkit-scrollbar-thumb {
    background: #888;
    border-radius: 4px;
  }
  
  #toolOutput::-webkit-scrollbar-thumb:hover {
    background: #555;
  }
  </style>
{% endblock extrastyle %}
{% block extra_js %}
  <script src="{% static 'assets/js/plugins/datatables.js' %}"></script>
  <script>
    const dataTableSearch = new simpleDatatables.DataTable("#tools-table", {
      searchable: true,
      fixedHeight: true,
      perPage: 25,
      pageLength: [25, 50, 100, 200]
    });
  </script>
  <script>
    document.addEventListener('DOMContentLoaded', function() {
      const toolInputs = document.getElementById('toolInputs');
      const toolOutput = document.getElementById('toolOutput');
      const testToolBtn = document.getElementById('testToolBtn');
      const testToolModal = document.getElementById('testToolModal');
      const toolTestForm = document.getElementById('toolTestForm');
      let currentToolId = null;

      // Helper function to check if string is JSON
      function isJSON(str) {
        try {
          JSON.parse(str);
          return true;
        } catch (e) {
          return false;
        }
      }

      // Helper function to parse JSON safely
      function parseJSON(jsonStr) {
        try {
          return JSON.parse(jsonStr);
        } catch (e) {
          return null;
        }
      }

      // Helper function to check if string is CSV
      function isCSV(str) {
        return str.includes(',') && str.includes('\n') && !str.includes('{') && !str.includes('[');
      }

      // Helper function to parse CSV
      function parseCSV(csv) {
        const lines = csv.trim().split('\n');
        const headers = lines[0].split(',').map(h => h.trim());
        const rows = lines.slice(1).map(line => {
          const values = line.split(',').map(v => v.trim());
          return headers.reduce((obj, header, i) => {
            obj[header] = values[i];
            return obj;
          }, {});
        });
        return rows;
      }

      // Function to create a table from data
      function createTable(data, tableName) {
        if (!Array.isArray(data) || data.length === 0) return null;
        
        // Get all unique keys from all objects
        const keys = [...new Set(data.flatMap(obj => Object.keys(obj)))];
        
        const table = document.createElement('table');
        table.className = 'table table-striped table-bordered mt-3';
        
        // Create table header
        const thead = document.createElement('thead');
        const headerRow = document.createElement('tr');
        keys.forEach(key => {
          const th = document.createElement('th');
          th.textContent = key;
          th.className = 'text-xs font-weight-bold';
          headerRow.appendChild(th);
        });
        thead.appendChild(headerRow);
        table.appendChild(thead);
        
        // Create table body
        const tbody = document.createElement('tbody');
        data.forEach(row => {
          const tr = document.createElement('tr');
          keys.forEach(key => {
            const td = document.createElement('td');
            const value = row[key];
            if (value === undefined || value === null) {
              td.textContent = '';
            } else if (typeof value === 'object') {
              if (Array.isArray(value)) {
                td.textContent = value.map(item => {
                  if (typeof item === 'object') {
                    return JSON.stringify(item, null, 2);
                  }
                  return item;
                }).join(', ');
              } else {
                td.textContent = JSON.stringify(value, null, 2);
              }
            } else {
              td.textContent = value.toString();
            }
            td.className = 'text-xs';
            tr.appendChild(td);
          });
          tbody.appendChild(tr);
        });
        table.appendChild(tbody);
        
        // Add table title
        const titleDiv = document.createElement('div');
        titleDiv.className = 'h6 mb-2';
        titleDiv.textContent = tableName;
        
        const container = document.createElement('div');
        container.appendChild(titleDiv);
        container.appendChild(table);
        
        return container;
      }

      // Function to display multiple tables
      function displayMultipleTables(data) {
        const container = document.getElementById('outputTableContainer');
        container.innerHTML = '';
        container.style.display = 'block';
        
        if (Array.isArray(data)) {
          if (data.length > 0 && typeof data[0] === 'object') {
            const table = createTable(data, 'Data Table');
            if (table) container.appendChild(table);
          }
        } else if (typeof data === 'object') {
          for (const [key, value] of Object.entries(data)) {
            if (Array.isArray(value) && value.length > 0 && typeof value[0] === 'object') {
              const table = createTable(value, key);
              if (table) container.appendChild(table);
            } else if (typeof value === 'object' && value !== null) {
              // Handle nested objects
              for (const [nestedKey, nestedValue] of Object.entries(value)) {
                if (Array.isArray(nestedValue) && nestedValue.length > 0 && typeof nestedValue[0] === 'object') {
                  const table = createTable(nestedValue, `${key}.${nestedKey}`);
                  if (table) container.appendChild(table);
                }
              }
            }
          }
        }
      }

      // Function to fetch tool schema
      async function fetchToolSchema(toolId) {
        try {
          const response = await fetch(`/agents/tool-schema/${toolId}/`, {
            headers: {
              'Accept': 'application/json',
              'X-Requested-With': 'XMLHttpRequest'
            }
          });
          
          if (!response.ok) {
            throw new Error(`HTTP error! status: ${response.status}`);
          }
          
          const contentType = response.headers.get("content-type");
          if (!contentType || !contentType.includes("application/json")) {
            throw new TypeError("Oops, we haven't got JSON!");
          }
          
          const data = await response.json();
          console.log('Received schema:', data);  // Debug log
          
          if (data.error) {
            throw new Error(data.error);
          }
          
          toolInputs.innerHTML = '';
          
          // Create input fields based on schema
          Object.entries(data.properties || {}).forEach(([key, prop]) => {
            const div = document.createElement('div');
            div.className = 'mb-3';
            
            const label = document.createElement('label');
            label.className = 'form-label';
            label.textContent = prop.title || key;
            
            if (prop.description) {
              const description = document.createElement('small');
              description.className = 'form-text text-muted d-block';
              description.textContent = prop.description;
              div.appendChild(label);
              div.appendChild(description);
            } else {
              div.appendChild(label);
            }
            
            const input = document.createElement('input');
            input.className = 'form-control';
            input.name = key;
            input.type = prop.type === 'number' ? 'number' : 'text';
            input.required = (data.required || []).includes(key);
            
            div.appendChild(input);
            toolInputs.appendChild(div);
          });
          
          toolOutput.innerHTML = '';
        } catch (error) {
          console.error('Error fetching schema:', error);
          toolInputs.innerHTML = `<div class="alert alert-danger">${error.message}</div>`;
        }
      }

      // Handle test button click in the table
      document.querySelectorAll('.test-tool-btn').forEach(btn => {
        btn.addEventListener('click', function(e) {
          e.preventDefault();
          currentToolId = this.dataset.toolId;
          fetchToolSchema(currentToolId);
        });
      });

      // Function to run tool test
      async function runToolTest(e) {
        e.preventDefault();
        if (!currentToolId) return;
        
        const formData = new FormData(toolTestForm);
        toolOutput.innerHTML = `
          <div class="d-flex align-items-center">
            <div class="spinner-border text-primary me-2" role="status">
              <span class="visually-hidden">Loading...</span>
            </div>
            <span>Testing tool...</span>
          </div>
        `;
        
        try {
          const response = await fetch(`/agents/test-tool/${currentToolId}/`, {
            method: 'POST',
            body: formData,
            headers: {
              'X-Requested-With': 'XMLHttpRequest'
            }
          });
          
          if (!response.ok) {
            throw new Error(`HTTP error! status: ${response.status}`);
          }
          
          const data = await response.json();
          
          if (data.error) {
            throw new Error(data.error);
          }
          
          if (data.task_id) {
            pollStatus(data.task_id);
          } else {
            toolOutput.innerHTML = `<pre>${JSON.stringify(data.result, null, 2)}</pre>`;
          }
        } catch (error) {
          console.error('Error testing tool:', error);
          toolOutput.innerHTML = `<div class="alert alert-danger">${error.message}</div>`;
        }
      }

      // Handle form submission (both button click and Enter key)
      toolTestForm.addEventListener('submit', runToolTest);
      testToolBtn.addEventListener('click', runToolTest);

      // Function to poll task status
      async function pollStatus(taskId) {
        try {
          const response = await fetch(`/agents/tool-status/${taskId}/`);
          const data = await response.json();
          
          if (data.error) {
            throw new Error(data.error);
          }
          
          if (data.status === 'PENDING' || data.status === 'STARTED') {
            toolOutput.innerHTML = `
              <div class="d-flex align-items-center">
                <div class="spinner-border text-primary me-2" role="status">
                  <span class="visually-hidden">Loading...</span>
                </div>
                <span>Tool is running...</span>
              </div>
            `;
            setTimeout(() => pollStatus(taskId), 1000);
          } else if (data.status === 'SUCCESS') {
            const result = data.result;
            
            // Clear any previous output
            toolOutput.innerHTML = '';
            const outputTableContainer = document.getElementById('outputTableContainer');
            outputTableContainer.innerHTML = '';
            outputTableContainer.style.display = 'none';
            
            // Handle different types of output
            if (typeof result === 'string') {
              if (isJSON(result)) {
                const jsonData = parseJSON(result);
                displayMultipleTables(jsonData);
                toolOutput.textContent = result;
              } else if (isCSV(result)) {
                const csvData = parseCSV(result);
                displayTable(csvData);
                toolOutput.textContent = result;
              } else {
                toolOutput.textContent = result;
              }
            } else if (result && typeof result === 'object') {
              displayMultipleTables(result);
              toolOutput.textContent = JSON.stringify(result, null, 2);
            } else {
              toolOutput.textContent = 'Task completed successfully';
            }
          } else if (data.status === 'FAILURE') {
            throw new Error(data.error || 'Task failed');
          }
        } catch (error) {
          console.error('Error polling status:', error);
          toolOutput.innerHTML = `<div class="alert alert-danger">${error.message}</div>`;
        }
      }
    });
  </script>
{% endblock %}

================
File: templates/agents/task_form.html
================
{% extends "layouts/base.html" %}
{% load static %}

{% block title %} {% if task %}Edit Task{% else %}Add Task{% endif %} {% endblock %}

{% block content %}
<div class="container-fluid py-4">
    <div class="row">
        <div class="col-12">
            <div class="card">
                <div class="card-header pb-0">
                    <h6 class="mb-0">{% if task %}Edit Task{% else %}Add Task{% endif %}</h6>
                </div>
                <div class="card-body">
                    <form method="post">
                        {% csrf_token %}
                        <div class="row">
                            <div class="col-md-6">
                                <div class="form-group">
                                    <label for="{{ form.description.id_for_label }}" class="form-control-label">Description</label>
                                    {{ form.description }}
                                    {% if form.description.errors %}
                                        <div class="text-danger">
                                            {{ form.description.errors|join:", " }}
                                        </div>
                                    {% endif %}
                                </div>
                            </div>
                            <div class="col-md-6">
                                <div class="form-group">
                                    <label for="{{ form.agent.id_for_label }}" class="form-control-label">Agent</label>
                                    {{ form.agent }}
                                    {% if form.agent.errors %}
                                        <div class="text-danger">
                                            {{ form.agent.errors|join:", " }}
                                        </div>
                                    {% endif %}
                                </div>
                            </div>
                        </div>
                        <div class="row">
                            <div class="col-md-6">
                                <div class="form-group">
                                    <label for="{{ form.expected_output.id_for_label }}" class="form-control-label">Expected Output</label>
                                    {{ form.expected_output }}
                                    {% if form.expected_output.errors %}
                                        <div class="text-danger">
                                            {{ form.expected_output.errors|join:", " }}
                                        </div>
                                    {% endif %}
                                </div>
                            </div>
                            <div class="col-md-6">
                                <div class="form-group">
                                    <label for="{{ form.tools.id_for_label }}" class="form-control-label">Tools</label>
                                    {{ form.tools }}
                                    {% if form.tools.errors %}
                                        <div class="text-danger">
                                            {{ form.tools.errors|join:", " }}
                                        </div>
                                    {% endif %}
                                </div>
                            </div>
                        </div>
                        <div class="row">
                            <div class="col-md-12">
                                <div class="form-group">
                                    <label for="{{ form.context.id_for_label }}" class="form-control-label">Context</label>
                                    {{ form.context }}
                                    {% if form.context.errors %}
                                        <div class="text-danger">
                                            {{ form.context.errors|join:", " }}
                                        </div>
                                    {% endif %}
                                </div>
                            </div>
                        </div>
                        <div class="row">
                            <div class="col-md-6">
                                <div class="form-group">
                                    <label for="{{ form.config.id_for_label }}" class="form-control-label">Config (JSON)</label>
                                    {{ form.config }}
                                    {% if form.config.errors %}
                                        <div class="text-danger">
                                            {{ form.config.errors|join:", " }}
                                        </div>
                                    {% endif %}
                                </div>
                            </div>
                            <div class="col-md-6">
                                <div class="form-group">
                                    <label for="{{ form.converter_cls.id_for_label }}" class="form-control-label">Converter Class</label>
                                    {{ form.converter_cls }}
                                    {% if form.converter_cls.errors %}
                                        <div class="text-danger">
                                            {{ form.converter_cls.errors|join:", " }}
                                        </div>
                                    {% endif %}
                                </div>
                            </div>
                        </div>
                        <div class="row">
                            <div class="col-md-4">
                                <div class="form-group">
                                    <label for="{{ form.output_json.id_for_label }}" class="form-control-label">Output JSON</label>
                                    {{ form.output_json }}
                                    {% if form.output_json.errors %}
                                        <div class="text-danger">
                                            {{ form.output_json.errors|join:", " }}
                                        </div>
                                    {% endif %}
                                </div>
                            </div>
                            <div class="col-md-4">
                                <div class="form-group">
                                    <label for="{{ form.output_pydantic.id_for_label }}" class="form-control-label">Output Pydantic</label>
                                    {{ form.output_pydantic }}
                                    {% if form.output_pydantic.errors %}
                                        <div class="text-danger">
                                            {{ form.output_pydantic.errors|join:", " }}
                                        </div>
                                    {% endif %}
                                </div>
                            </div>
                            <div class="col-md-4">
                                <div class="form-group">
                                    <label for="{{ form.output_file.id_for_label }}" class="form-control-label">Output File Path</label>
                                    {{ form.output_file }}
                                    {% if form.output_file.errors %}
                                        <div class="text-danger">
                                            {{ form.output_file.errors|join:", " }}
                                        </div>
                                    {% endif %}
                                    <small class="form-text text-muted">Enter the relative path in the media directory (e.g., 'outputs/task_result.txt')</small>
                                </div>
                            </div>
                        </div>
                        <div class="row mt-3">
                            <div class="col-md-6">
                                <div class="form-check form-switch">
                                    {{ form.async_execution }}
                                    <label class="form-check-label" for="{{ form.async_execution.id_for_label }}">Async Execution</label>
                                    {% if form.async_execution.errors %}
                                        <div class="text-danger">
                                            {{ form.async_execution.errors|join:", " }}
                                        </div>
                                    {% endif %}
                                </div>
                            </div>
                            <div class="col-md-6">
                                <div class="form-check form-switch">
                                    {{ form.human_input }}
                                    <label class="form-check-label" for="{{ form.human_input.id_for_label }}">Human Input</label>
                                    {% if form.human_input.errors %}
                                        <div class="text-danger">
                                            {{ form.human_input.errors|join:", " }}
                                        </div>
                                    {% endif %}
                                </div>
                            </div>
                        </div>
                        <div class="row mt-4">
                            <div class="col-12 text-end">
                                <a href="{% if request.META.HTTP_REFERER %}{{ request.META.HTTP_REFERER }}{% else %}{% url 'agents:manage_tasks' %}{% endif %}" class="btn btn-secondary me-2">Cancel</a>
                                <button type="submit" class="btn bg-gradient-primary">Save Task</button>
                            </div>
                        </div>
                    </form>
                </div>
            </div>
        </div>
    </div>
</div>
{% endblock content %}

{% block extra_js %}
<script src="{% static 'assets/js/plugins/choices.min.js' %}"></script>
<script>
    document.addEventListener('DOMContentLoaded', function() {
        // Initialize Choices.js for select fields
        var selectFields = document.querySelectorAll('select');
        selectFields.forEach(function(select) {
            new Choices(select, {
                removeItemButton: true,
                placeholder: true,
                placeholderValue: 'Select an option'
            });
        });

        // Add classes to form elements
        var formElements = document.querySelectorAll('input:not([type="checkbox"]):not([type="radio"]), select, textarea');
        formElements.forEach(function(element) {
            element.classList.add('form-control');
        });

        var selectElements = document.querySelectorAll('select');
        selectElements.forEach(function(element) {
            element.classList.add('form-select');
        });

        var checkboxInputs = document.querySelectorAll('input[type="checkbox"], input[type="radio"]');
        checkboxInputs.forEach(function(element) {
            element.classList.add('form-check-input');
        });

        // Form validation
        const form = document.querySelector('form');
        form.addEventListener('submit', function(event) {
            const requiredFields = form.querySelectorAll('[required]');
            let isValid = true;

            requiredFields.forEach(function(field) {
                if (!field.value.trim()) {
                    isValid = false;
                    field.classList.add('is-invalid');
                } else {
                    field.classList.remove('is-invalid');
                }
            });

            if (!isValid) {
                event.preventDefault();
                alert('Please fill in all required fields.');
            }
        });

        // JSON validation for config field
        var configField = document.getElementById('{{ form.config.id_for_label }}');
        if (configField) {
            configField.addEventListener('blur', function() {
                try {
                    JSON.parse(this.value);
                    this.classList.remove('is-invalid');
                } catch (error) {
                    this.classList.add('is-invalid');
                    alert('Invalid JSON format in Config field');
                }
            });
        }
    });
</script>
{% endblock extra_js %}

================
File: templates/agents/tool_form.html
================
{% extends "layouts/base.html" %}
{% load static %}

{% block title %} {% if tool %}Edit Tool{% else %}Add Tool{% endif %} {% endblock %}

{% block content %}
<div class="container-fluid py-4">
    <div class="row justify-content-center">
        <div class="col-lg-12 col-xl-12">
            <div class="card mb-4">
                <div class="card-header">
                    <h5 class="mb-0">{% if tool %}Edit Tool{% else %}Add Tool{% endif %}</h5>
                </div>
                <div class="card-body">
                    <form method="post" id="toolForm">
                        {% csrf_token %}
                        {% if form.errors %}
                            <div class="alert alert-danger">
                                <ul>
                                    {% for field in form %}
                                        {% for error in field.errors %}
                                            <li>{{ field.label }}: {{ error }}</li>
                                        {% endfor %}
                                    {% endfor %}
                                    {% for error in form.non_field_errors %}
                                        <li>{{ error }}</li>
                                    {% endfor %}
                                </ul>
                            </div>
                        {% endif %}
                        <div class="mb-4">
                            <label for="{{ form.tool_class.id_for_label }}" class="form-label">Tool Class</label><br>
                            {{ form.tool_class }}
                        </div>
                        <div class="mb-4">
                            <label for="{{ form.tool_subclass.id_for_label }}" class="form-label">Tool Subclass</label><br>
                            {{ form.tool_subclass }}
                        </div>
                        <div class="mb-4">
                            <label class="form-label">Description</label><br>
                            <textarea id="tool_description" name="description" class="form-control" readonly rows="2"></textarea>
                        </div>
                        <div id="errorMessage" class="alert alert-danger" style="display: none;"></div>
                        <div class="d-flex justify-content-end">
                            <a href="{% url 'agents:manage_tools' %}" class="btn btn-secondary me-2">Cancel</a>
                            <button type="submit" id="submitButton" class="btn btn-primary" disabled>Save</button>
                        </div>
                    </form>
                </div>
            </div>
        </div>
            {% if tool %}
            <div class="row">
                <div class="col-12">
                    <div class="card">
                        <div class="card-header">
                            <h5 class="mb-0">Test Tool</h5>
                        </div>
                        <div class="card-body">
                            <div class="row">
                                <div class="col-md-3">
                                    <div class="card">
                                        <div class="card-header">
                                            <h6 class="mb-0">Tool Inputs</h6>
                                        </div>
                                        <div class="card-body">
                                            <form id="toolTestForm">
                                                <!-- Tool input fields will be dynamically added here -->
                                                <div id="toolInputs"></div>
                                                <button type="button" id="testToolBtn" class="btn btn-primary mt-3">Test</button>
                                            </form>
                                        </div>
                                    </div>
                                </div>
                                <div class="col-md-9">
                                    <div class="card">
                                        <div class="card-header d-flex justify-content-between align-items-center">
                                            <h6 class="mb-0">Tool Output</h6>
                                            <span id="tokenCount">Token Count: 0</span>
                                            <button id="copyOutputBtn" class="btn btn-sm btn-outline-primary">Copy to clipboard</button>
                                        </div>
                                        <div class="card-body">
                                            <div id="toolOutput" class="border p-3" style="height: 300px; overflow-y: auto;"></div>
                                        </div>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            <!-- Add this new container for output tables -->
            <div id="outputTableContainer" class="col-12 mt-4" style="display: none;">
                <!-- Tables will be dynamically inserted here -->
            </div>
            {% endif %}
        </div>
    </div>
</div>
{% endblock content %}

{% block extrastyle %}
{{ block.super }}
<style>
    .card {
        box-shadow: 0 4px 6px rgba(50, 50, 93, 0.11), 0 1px 3px rgba(0, 0, 0, 0.08);
        border: 0;
    }
    .card-header {
        background-color: #f8f9fa;
        border-bottom: 1px solid rgba(0,0,0,.125);
        padding: 1rem 1.5rem;
    }
    .card-body {
        padding: 1.5rem;
    }
    .form-label {
        font-weight: 600;
        color: #344767;
        margin-bottom: 0.5rem;
        display: block;
    }
    .form-control, .form-select {
        width: 100%;
        padding: 0.5rem 0.75rem;
        font-size: 0.875rem;
        border: 1px solid #d2d6da;
        border-radius: 0.375rem;
        margin-top: 0.25rem;
    }
    .form-control:focus, .form-select:focus {
        border-color: #5e72e4;
        box-shadow: 0 0 0 0.2rem rgba(94, 114, 228, 0.25);
    }
    textarea.form-control {
        min-height: 150px;
    }
    .btn {
        font-size: 0.875rem;
        font-weight: 600;
        padding: 0.625rem 1.25rem;
        border-radius: 0.375rem;
    }
    .btn-primary {
        background-color: #5e72e4;
        border-color: #5e72e4;
    }
    .btn-secondary {
        background-color: #8392ab;
        border-color: #8392ab;
    }
    .loading {
        display: inline-block;
        width: 20px;
        height: 20px;
        border: 3px solid rgba(0,0,0,.3);
        border-radius: 50%;
        border-top-color: #fff;
        animation: spin 1s ease-in-out infinite;
        -webkit-animation: spin 1s ease-in-out infinite;
    }
    @keyframes spin {
        to { -webkit-transform: rotate(360deg); }
    }
    @-webkit-keyframes spin {
        to { -webkit-transform: rotate(360deg); }
    }
    #toolOutput {
        white-space: pre-wrap;
        word-wrap: break-word;
        font-family: monospace;
        font-size: 0.9rem;
    }
</style>
{% endblock extrastyle %}

{% block extra_js %}
{{ block.super }}
<script src="{% static 'assets/js/plugins/choices.min.js' %}"></script>
<script src="{% static 'assets/js/plugins/datatables.js' %}"></script>
<script>
    document.addEventListener('DOMContentLoaded', function() {
        var toolClassSelect = document.getElementById('{{ form.tool_class.id_for_label }}');
        var toolSubclassSelect = document.getElementById('{{ form.tool_subclass.id_for_label }}');
        var toolDescriptionInput = document.getElementById('tool_description');
        var submitButton = document.getElementById('submitButton');
        var errorMessageDiv = document.getElementById('errorMessage');
        var outputTableContainer = document.getElementById('outputTableContainer');
        var outputTables = [];
        const tokenCountSpan = document.getElementById('tokenCount');

        function setLoading(isLoading) {
            if (isLoading) {
                toolSubclassSelect.innerHTML = '<option value="">Loading...</option>';
                toolDescriptionInput.value = 'Loading...';
                submitButton.innerHTML = '<span class="loading"></span> Loading';
            } else {
                submitButton.innerHTML = 'Save';
            }
            submitButton.disabled = isLoading;
        }

        function showError(message) {
            errorMessageDiv.textContent = message;
            errorMessageDiv.style.display = 'block';
        }

        function hideError() {
            errorMessageDiv.style.display = 'none';
        }

        toolClassSelect.addEventListener('change', function() {
            var selectedTool = this.value;
            if (selectedTool) {
                setLoading(true);
                hideError();
                fetch(`/agents/get_tool_info/?tool_class=${selectedTool}`)
                    .then(response => response.json())
                    .then(data => {
                        if (data.error) {
                            throw new Error(data.error);
                        }
                        toolSubclassSelect.innerHTML = '';
                        data.classes.forEach(cls => {
                            var option = document.createElement('option');
                            option.value = cls.name;
                            option.textContent = cls.name;
                            option.setAttribute('data-description', cls.description);
                            toolSubclassSelect.appendChild(option);
                        });
                        toolSubclassSelect.dispatchEvent(new Event('change'));
                        submitButton.disabled = false;
                    })
                    .catch(error => {
                        console.error('Error:', error);
                        showError(`Failed to load tool information: ${error.message}`);
                        toolSubclassSelect.innerHTML = '';
                        toolDescriptionInput.value = '';
                        submitButton.disabled = true;
                    })
                    .finally(() => {
                        setLoading(false);
                    });
            } else {
                toolSubclassSelect.innerHTML = '';
                toolDescriptionInput.value = '';
                submitButton.disabled = true;
                hideError();
            }
        });

        toolSubclassSelect.addEventListener('change', function() {
            var selectedOption = this.options[this.selectedIndex];
            if (selectedOption) {
                toolDescriptionInput.value = selectedOption.getAttribute('data-description') || '';
            } else {
                toolDescriptionInput.value = '';
            }
        });

        // Trigger the change event on page load if a tool is already selected (for edit mode)
        if (toolClassSelect.value) {
            toolClassSelect.dispatchEvent(new Event('change'));
        }

        {% if tool %}
        // Tool testing functionality
        const toolInputs = document.getElementById('toolInputs');
        const testToolBtn = document.getElementById('testToolBtn');
        const toolOutput = document.getElementById('toolOutput');
        const copyOutputBtn = document.getElementById('copyOutputBtn');

        // Function to fetch tool schema and create input fields
        function fetchToolSchema() {
            fetch(`/agents/get_tool_schema/{{ tool.id }}/`)
                .then(response => {
                    if (!response.ok) {
                        return response.json().then(err => { throw err; });
                    }
                    return response.json();
                })
                .then(schema => {
                    toolInputs.innerHTML = '';
                    if (schema.error) {
                        throw new Error(schema.error);
                    } else if (schema.properties) {
                        for (const [key, value] of Object.entries(schema.properties)) {
                            const inputGroup = document.createElement('div');
                            inputGroup.className = 'mb-3';
                            
                            const label = document.createElement('label');
                            label.className = 'form-label';
                            label.textContent = value.title || key;
                            
                            const input = document.createElement('input');
                            input.className = 'form-control';
                            input.name = key;
                            input.type = value.type === 'number' ? 'number' : 'text';
                            if (value.description) {
                                input.placeholder = value.description;
                            }
                            
                            inputGroup.appendChild(label);
                            inputGroup.appendChild(input);
                            toolInputs.appendChild(inputGroup);
                        }
                    } else {
                        throw new Error('Invalid schema structure');
                    }
                })
                .catch(error => {
                    console.error('Error fetching tool schema:', error);
                    toolInputs.innerHTML = `<p class="text-danger">Error loading tool inputs: ${error.message}</p>`;
                });
        }

        // Fetch tool schema on page load
        fetchToolSchema();

        function isJSON(str) {
            try {
                JSON.parse(str);
                return true;
            } catch (e) {
                return false;
            }
        }

        function parseJSON(jsonStr) {
            return JSON.parse(jsonStr);
        }

        function createTable(data, tableName) {
            if (!Array.isArray(data) || data.length === 0) return null;
            
            const tableContainer = document.createElement('div');
            tableContainer.className = 'col-12 mt-4';
            
            // Get all unique keys from all objects
            const keys = [...new Set(data.flatMap(obj => Object.keys(obj)))];
            
            tableContainer.innerHTML = `
                <div class="card mb-4">
                    <div class="card-header pb-0">
                        <h6>${tableName}</h6>
                    </div>
                    <div class="card-body px-0 pt-0 pb-2">
                        <div class="table-responsive p-0">
                            <table class="table align-items-center mb-0" id="${tableName.replace(/\s+/g, '-').toLowerCase()}">
                                <thead>
                                    <tr>
                                        ${keys.map(key => `<th class="text-uppercase text-secondary text-xxs font-weight-bolder opacity-7">${key}</th>`).join('')}
                                    </tr>
                                </thead>
                                <tbody>
                                    ${data.map(row => `
                                        <tr>
                                            ${keys.map(key => {
                                                const value = row[key];
                                                let displayValue = '';
                                                if (value === undefined || value === null) {
                                                    displayValue = '';
                                                } else if (typeof value === 'object') {
                                                    displayValue = JSON.stringify(value, null, 2);
                                                } else {
                                                    displayValue = value.toString();
                                                }
                                                return `<td class="text-sm font-weight-normal"><pre style="white-space: pre-wrap;">${displayValue}</pre></td>`;
                                            }).join('')}
                                        </tr>
                                    `).join('')}
                                </tbody>
                            </table>
                        </div>
                    </div>
                </div>
            `;
            return tableContainer;
        }

        function flattenObject(obj, prefix = '') {
            let tables = {};
            for (const [key, value] of Object.entries(obj)) {
                const newKey = prefix ? `${prefix}.${key}` : key;
                if (Array.isArray(value)) {
                    if (value.length > 0) {
                        if (typeof value[0] === 'object') {
                            // Handle array of objects that have nested arrays
                            const flattenedData = value.map(item => {
                                const flattened = {};
                                for (const [k, v] of Object.entries(item)) {
                                    if (Array.isArray(v)) {
                                        if (v.length > 0 && typeof v[0] === 'object') {
                                            flattened[k] = v.map(obj => JSON.stringify(obj, null, 2)).join('\n');
                                        } else {
                                            flattened[k] = v.join(', ');
                                        }
                                    } else {
                                        flattened[k] = v;
                                    }
                                }
                                return flattened;
                            });
                            tables[newKey] = flattenedData;
                        }
                    }
                } else if (typeof value === 'object' && value !== null) {
                    Object.assign(tables, flattenObject(value, newKey));
                }
            }
            return tables;
        }

        function displayMultipleTables(data) {
            console.log('Displaying multiple tables. Data:', data);
            if (!outputTableContainer) {
                outputTableContainer = document.getElementById('outputTableContainer');
                if (!outputTableContainer) {
                    console.error('Output table container not found');
                    return;
                }
            }
            outputTableContainer.innerHTML = '';

            // Get all possible tables from the nested structure
            const tables = flattenObject(data);
            
            for (const [key, value] of Object.entries(tables)) {
                if (Array.isArray(value) && value.length > 0 && typeof value[0] === 'object') {
                    const table = createTable(value, key);
                    if (table) {
                        outputTableContainer.appendChild(table);

                        const tableId = `#${key.replace(/\s+/g, '-').toLowerCase()}`;
                        try {
                            const tableElement = document.querySelector(tableId);
                            if (tableElement) {
                                outputTables.push(new simpleDatatables.DataTable(tableId, {
                                    searchable: true,
                                    fixedHeight: false,
                                    perPage: 10
                                }));
                            }
                        } catch (error) {
                            console.warn(`Failed to initialize DataTable for ${tableId}:`, error);
                        }
                    }
                }
            }

            outputTableContainer.style.display = 'block';
        }

        function isCSV(str) {
            const lines = str.trim().split('\n');
            return lines.length > 1 && lines[0].includes(',') && lines[1].includes(',');
        }

        function parseCSV(csv) {
            const lines = csv.trim().split('\n');
            return lines.map(line => line.split(',').map(cell => cell.trim()));
        }

        function displayTable(data, tableName = 'CSV Data') {
            if (!outputTableContainer) {
                console.error('Output table container not found');
                return;
            }
            outputTableContainer.innerHTML = '';

            const tableData = data.slice(1).map(row => {
                const obj = {};
                data[0].forEach((header, index) => {
                    obj[header] = row[index];
                });
                return obj;
            });

            const table = createTable(tableData, tableName);
            outputTableContainer.appendChild(table);

            outputTables.push(new simpleDatatables.DataTable(`#${tableName.replace(/\s+/g, '-').toLowerCase()}`, {
                searchable: true,
                fixedHeight: false,
                perPage: 10
            }));

            outputTableContainer.style.display = 'block';
        }

        testToolBtn.addEventListener('click', function() {
            console.log('Test button clicked');
            const formData = new FormData(document.getElementById('toolTestForm'));
            
            // Show loading state
            toolOutput.innerHTML = `
                <div class="d-flex align-items-center">
                    <div class="spinner-border text-primary me-2" role="status">
                        <span class="visually-hidden">Loading...</span>
                    </div>
                    <span>Testing tool...</span>
                </div>
            `;
            
            fetch(`/agents/test_tool/{{ tool.id }}/`, {
                method: 'POST',
                body: formData,
                headers: {
                    'X-CSRFToken': document.querySelector('[name=csrfmiddlewaretoken]').value
                }
            })
            .then(response => response.json())
            .then(data => {
                if (data.error) {
                    throw new Error(data.error);
                }
                
                // Tool execution started successfully
                console.log('Tool execution started:', data);
                const taskId = data.task_id;
                
                // Function to check task status
                function checkStatus() {
                    fetch(`/agents/tool-status/${taskId}/`)
                        .then(response => response.json())
                        .then(statusData => {
                            console.log('Received status update:', statusData);
                            if (statusData.error) {
                                throw new Error(statusData.error);
                            }
                            
                            if (statusData.status === 'PENDING' || statusData.status === 'STARTED') {
                                // Still running, update UI and check again in 1 second
                                toolOutput.innerHTML = `
                                    <div class="d-flex align-items-center">
                                        <div class="spinner-border text-primary me-2" role="status">
                                            <span class="visually-hidden">Loading...</span>
                                        </div>
                                        <span>Tool is running...</span>
                                    </div>
                                `;
                                setTimeout(checkStatus, 1000);
                            } else if (statusData.status === 'SUCCESS') {
                                console.log('Token count received:', statusData.token_count);
                                tokenCountSpan.textContent = `Token Count: ${statusData.token_count}`;
                                
                                // Existing output handling remains unchanged
                                const result = statusData.result;
                                
                                // Clear any previous output
                                toolOutput.innerHTML = '';
                                
                                // Handle different types of output
                                if (typeof result === 'string') {
                                    if (isJSON(result)) {
                                        const jsonData = parseJSON(result);
                                        displayMultipleTables(jsonData);
                                        toolOutput.textContent = result;
                                    } else if (isCSV(result)) {
                                        const csvData = parseCSV(result);
                                        displayTable(csvData);
                                        toolOutput.textContent = result;
                                    } else {
                                        toolOutput.textContent = result;
                                    }
                                } else if (result && typeof result === 'object') {
                                    displayMultipleTables(result);
                                    toolOutput.textContent = JSON.stringify(result, null, 2);
                                } else {
                                    toolOutput.textContent = 'Task completed successfully';
                                }
                            } else if (statusData.status === 'FAILURE') {
                                throw new Error(statusData.error || 'Task failed');
                            }
                        })
                        .catch(error => {
                            toolOutput.innerHTML = `<div class="alert alert-danger">${error.message}</div>`;
                        });
                }
                
                // Start checking status
                checkStatus();
            })
            .catch(error => {
                toolOutput.innerHTML = `<div class="alert alert-danger">${error.message}</div>`;
            });
        });

        // Copy output to clipboard
        copyOutputBtn.addEventListener('click', function() {
            navigator.clipboard.writeText(toolOutput.textContent)
                .then(() => {
                    alert('Output copied to clipboard!');
                })
                .catch(err => {
                    console.error('Failed to copy text: ', err);
                });
        });

        {% endif %}
    });
</script>
{% endblock extra_js %}

================
File: templatetags/agent_filters.py
================
from django import template

register = template.Library()

@register.filter
def has_force_output_enabled(agent, tool):
    """Template filter to check if force output is enabled for a tool."""
    if not agent:
        return False
    tool_setting = agent.tool_settings.filter(tool=tool).first()
    return tool_setting.force_output_as_result if tool_setting else False

================
File: templatetags/agent_tags.py
================
from django import template

register = template.Library()

@register.filter
def get_item(dictionary, key):
    return dictionary.get(key)

================
File: tests/integration/test_callback_flow.py
================


================
File: tests/test_file_writer_tool.py
================
import os
import sys
import logging
import json
from unittest.mock import patch, MagicMock
from functools import wraps
from dotenv import load_dotenv
from crewai import Agent, Task, Crew, Process
from crewai.agents.crew_agent_executor import CrewAgentExecutor
from apps.agents.tools.file_writer_tool.file_writer_tool import FileWriterTool
from apps.agents.tools.file_read_tool.file_read_tool import FileReadTool

# Load environment variables first
load_dotenv()

# Add the project root directory to Python path
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '../../..'))
sys.path.append(project_root)

# Set up Django environment
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'core.settings')
import django
django.setup()

# Reset to default OpenAI API and clear proxy token
os.environ['OPENAI_API_BASE'] = 'https://api.openai.com/v1'
os.environ['LITELLM_MASTER_KEY'] = ''

# Configure logging
logging.basicConfig(level=logging.DEBUG)  # Set to DEBUG for maximum verbosity
logger = logging.getLogger(__name__)

def debug_crew_executor(func):
    @wraps(func)
    def wrapper(*args, **kwargs):
        try:
            # Get the instance (self) from args
            instance = args[0] if args else None
            
            # Log entry point
            logger.debug(f" Entering {func.__name__}")
            
            # Special logging for specific methods
            if func.__name__ == '_format_answer':
                logger.debug(f"Raw answer to parse: {args[1]}")  # args[1] is the answer string
            elif func.__name__ == '_execute_tool_and_check_finality':
                agent_action = args[1]  # args[1] is AgentAction
                logger.debug(f"Tool to execute: {agent_action.tool}")
                logger.debug(f"Tool input (raw): {repr(agent_action.tool_input)}")
                logger.debug(f"Tool input (type): {type(agent_action.tool_input)}")
            
            result = func(*args, **kwargs)
            
            # Special logging for results
            if func.__name__ == '_format_answer':
                logger.debug(f"Parsed result type: {type(result)}")
                if hasattr(result, 'tool_input'):
                    logger.debug(f"Parsed tool_input: {repr(result.tool_input)}")
            elif func.__name__ == '_execute_tool_and_check_finality':
                logger.debug(f"Tool execution result: {result}")
            
            return result
        except Exception as e:
            logger.error(f"Error in {func.__name__}: {str(e)}", exc_info=True)
            raise
    return wrapper

def create_file_handling_crew():
    # Patch the critical methods in CrewAgentExecutor
    patches = [
        patch('crewai.agents.crew_agent_executor.CrewAgentExecutor._format_answer'),
        patch('crewai.agents.crew_agent_executor.CrewAgentExecutor._execute_tool_and_check_finality'),
        patch('crewai.agents.crew_agent_executor.CrewAgentParser.parse'),
        patch('crewai.agents.crew_agent_executor.ToolUsage.parse'),
        patch('crewai.agents.crew_agent_executor.ToolUsage.use')
    ]
    
    with patch.multiple('crewai.agents.crew_agent_executor.CrewAgentExecutor',
                       _format_answer=debug_crew_executor(CrewAgentExecutor._format_answer),
                       _execute_tool_and_check_finality=debug_crew_executor(CrewAgentExecutor._execute_tool_and_check_finality)):
        
        # Initialize tools
        file_reader = FileReadTool()
        file_writer = FileWriterTool()
        
        # Create the agent with both tools
        file_handler_agent = Agent(
            role="File Handler",
            goal="Read and write files accurately",
            backstory="I am a specialized agent that handles file operations with precision and care.",
            tools=[file_reader, file_writer],
            verbose=True
        )

        # Create tasks (keep existing task definitions)
        read_task = Task(
            description="Read the content of the file '{input_file}'",
            expected_output="The complete content of the {input_file} file",
            agent=file_handler_agent,
        )

        write_task = Task(
            description="Write the content to a new file named '{output_file}'",
            expected_output="Confirmation that the file was written successfully",
            agent=file_handler_agent,
        )

        # Create the crew
        crew = Crew(
            agents=[file_handler_agent],
            tasks=[read_task, write_task],
            process=Process.sequential,
            verbose=True
        )

        try:
            result = crew.kickoff(
                inputs={
                    "input_file": "fluffy.txt",
                    "output_file": "fluffy1.txt",
                    "user_id": 1
                }
            )
            logger.info("File operations completed successfully")
            return result
        except Exception as e:
            logger.error(f"Error during file operations: {str(e)}", exc_info=True)
            raise

if __name__ == "__main__":
    # Configure logging
    logging.basicConfig(
        level=logging.DEBUG,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    # Set specific loggers to DEBUG
    logging.getLogger('crewai.agents.crew_agent_executor').setLevel(logging.DEBUG)
    logging.getLogger('crewai.agents.agent_executor').setLevel(logging.DEBUG)
    
    result = create_file_handling_crew()
    print("\nResult:", result)

================
File: tools/browser_tool/browser_tool.py
================
import json
import os
from typing import Any, Type, Set, Dict
import logging
import re
from tenacity import retry, stop_after_attempt, wait_exponential

import requests
from pydantic import BaseModel, Field
import html2text
from crewai.tools import BaseTool
from urllib.parse import urljoin, urlparse
import dotenv
from bs4 import BeautifulSoup
import trafilatura
from readability.readability import Document

dotenv.load_dotenv()

logger = logging.getLogger(__name__)

class BrowserToolSchema(BaseModel):
  """Input for BrowserTool."""
  website: str = Field(..., title="Website", description="Full URL of the website to scrape (e.g., https://google.com)")
  output_type: str = Field(
      default="text",
      title="Output Type",
      description="Type of output desired: 'text' for cleaned content or 'raw' for HTML"
  )

class BrowserTool(BaseTool):
  name: str = "Scrape website content"
  description: str = "A tool that can be used to scrape website content. Pass a string with only the full URL, no need for a final slash `/`. output_type can be 'text' for cleaned content or 'raw' for HTML."
  output_type: str = "text"
  tags: Set[str] = {"browser", "scrape", "website", "content"}
  args_schema: Type[BaseModel] = BrowserToolSchema
  api_key: str = Field(default=os.environ.get('BROWSERLESS_API_KEY'))
  base_url: str = Field(default="https://browserless.rijsinghani.us/scrape")

  def __init__(self, **data):
      super().__init__(**data)
      if not self.api_key:
          logger.error("BROWSERLESS_API_KEY is not set in the environment variables.")

  def _run(
      self,
      website: str,
      output_type: str = "text",
      **kwargs: Any,
  ) -> Any:
      """Scrape website content."""
      website = self.normalize_url(website)
      #logger.info(f"Scraping website: {website} with output type: {output_type}")
      content = self.get_content(website, output_type)
      if output_type == "raw":
          return content  # Return raw HTML directly
      return content  # Return processed text directly

  def normalize_url(self, url: str) -> str:
      """Normalize the URL by adding the protocol if missing."""
      if not re.match(r'^\w+://', url):
          return f"https://{url}"
      return url

  def clean_content(self, content: str) -> str:
      """Clean and structure extracted content"""
      if not content:
          return ""
          
      # Remove excessive whitespace
      content = re.sub(r'\s+', ' ', content)
      
      # Remove common boilerplate phrases
      boilerplate = [
          'cookie policy',
          'accept cookies',
          'privacy policy',
          'terms of service',
          'subscribe to our newsletter',
          'sign up for our newsletter',
          'all rights reserved',
      ]
      for phrase in boilerplate:
          content = re.sub(rf'(?i){phrase}.*?[\.\n]', '', content)
      
      # Remove email addresses and phone numbers
    #   content = re.sub(r'\S+@\S+', '[EMAIL]', content)
    #   content = re.sub(r'\+?\d{1,3}[-.\s]?$?\d{3}$?[-.\s]?\d{3}[-.\s]?\d{4}', '[PHONE]', content)
      
      return content.strip()

  def detect_content_type(self, url: str, html_content: str) -> str:
      """Detect type of content for specialized handling"""
      patterns = {
          'article': r'article|post|blog',
          'product': r'product|item|price',
          'documentation': r'docs|documentation|api|reference',
      }
      
      for content_type, pattern in patterns.items():
          if re.search(pattern, url, re.I) or re.search(pattern, html_content, re.I):
              return content_type
      return 'general'

  def extract_content(self, url: str, html_content: str) -> dict:
      """Multi-strategy content extraction"""
      content = {
          'title': '',
          'text': '',
          'metadata': {}
      }
      
      try:
          # Strategy 1: Trafilatura
          trafilatura_content = trafilatura.extract(html_content, include_comments=False, 
                                                  include_tables=True, 
                                                  include_links=False)
          
          # Strategy 2: Readability
          doc = Document(html_content)
          readable_article = doc.summary()
          doc_title = doc.title()
          
          # Strategy 3: BeautifulSoup fallback
          soup = BeautifulSoup(html_content, 'lxml')
          
          # Combine results with priority
          if trafilatura_content:
              content['text'] = trafilatura_content
          elif readable_article:
              soup_readable = BeautifulSoup(readable_article, 'lxml')
              content['text'] = soup_readable.get_text(separator=' ', strip=True)
          else:
              content['text'] = soup.get_text(separator=' ', strip=True)
              
          # Extract title
          content['title'] = doc_title or soup.title.string if soup.title else ''
          
          # Extract basic metadata
          meta_tags = soup.find_all('meta')
          content['metadata'] = {
              'description': next((tag.get('content', '') for tag in meta_tags if tag.get('name', '').lower() == 'description'), ''),
              'keywords': next((tag.get('content', '').split(',') for tag in meta_tags if tag.get('name', '').lower() == 'keywords'), []),
              'author': next((tag.get('content', '') for tag in meta_tags if tag.get('name', '').lower() == 'author'), '')
          }
          
      except Exception as e:
          logger.error(f"Error in content extraction: {str(e)}")
          # Fallback to basic HTML extraction
          content['text'] = html2text.html2text(html_content)
              
      return content

  @retry(
      stop=stop_after_attempt(3),
      wait=wait_exponential(multiplier=1, min=4, max=10),
      reraise=True
  )
  def get_content(self, url: str, output_type: str = "text") -> str:
      """Scrape website content with retry mechanism."""
      # Check if URL is an image or other non-HTML content
      parsed_url = urlparse(url)
      path = parsed_url.path.lower()
      if any(path.endswith(ext) for ext in ['.jpg', '.jpeg', '.png', '.gif', '.svg', '.webp', '.ico', '.pdf']):
          logger.info(f"Skipping content extraction for non-HTML file: {url}")
          return f"Non-HTML content: {url}"

      payload = {
          "url": url,
          "elements": [{"selector": "html"}]  # Changed from 'body' to 'html' to get full document
      }
      headers = {'cache-control': 'no-cache', 'content-type': 'application/json'}
      
      response = None
      try:
          #logger.info(f"Attempting to fetch content from {url}")
          response = requests.post(
              f"{self.base_url}?token={self.api_key}", 
              headers=headers, 
              json=payload,
              timeout=30
          )
          response.raise_for_status()
          
          try:
              data = response.json()
          except ValueError as e:
              logger.error(f"Failed to parse JSON response for {url}: {str(e)}")
              logger.error(f"Response content: {response.text[:500]}...")  # Log first 500 chars
              return ""

          if not data.get('data') or not data['data'][0].get('results'):
              logger.error(f"Unexpected response structure for {url}")
              logger.error(f"Response data: {json.dumps(data)[:500]}...")  # Log first 500 chars
              return ""

          html_content = data['data'][0]['results'][0]['html']
          if not html_content:
              logger.warning(f"Empty HTML content received for {url}")
              return ""

          # Add doctype if missing to ensure proper parsing
          if not html_content.lower().startswith('<!doctype'):
              html_content = '<!DOCTYPE html>\n' + html_content

          # Return raw HTML if requested
          if output_type.lower() == "raw":
              return html_content

          # Otherwise process the content as before
          try:
              content_type = self.detect_content_type(url, html_content)
              extracted_content = self.extract_content(url, html_content)
          except Exception as e:
              logger.error(f"Error processing content for {url}: {str(e)}")
              return html_content  # Fallback to raw HTML on processing error

          # Format the final output
          result = f"Title: {extracted_content['title']}\n\n"
          result += f"Content Type: {content_type}\n\n"
          result += extracted_content['text']

          # Add metadata if available
          if extracted_content['metadata'].get('description'):
              result += f"\n\nDescription: {extracted_content['metadata']['description']}"
          if extracted_content['metadata'].get('author'):
              result += f"\nAuthor: {extracted_content['metadata']['author']}"
          if extracted_content['metadata'].get('keywords'):
              result += f"\nKeywords: {', '.join(extracted_content['metadata']['keywords'])}"
          
          #logger.info(f"Successfully extracted content from {url}")
          return result

      except requests.exceptions.Timeout as e:
          logger.error(f"Timeout while fetching content from {url}: {str(e)}")
          return ""  # Return empty string after all retries are exhausted
          
      except requests.exceptions.RequestException as e:
          logger.error(f"Failed to fetch content for {url}: {str(e)}")
          if response is not None:
              logger.error(f"Response status code: {response.status_code}")
              logger.error(f"Response content: {response.text[:500]}...")  # Log first 500 chars
          return ""
          
      except Exception as e:
          logger.error(f"Unexpected error while processing {url}: {str(e)}")
          return ""

  def get_links(self, url: str) -> Set[str]:
      """Extract links from the webpage."""
      payload = {
          "url": url,
          "elements": [
              {"selector": "a"}
          ]
      }
      headers = {'Cache-Control': 'no-cache', 'Content-Type': 'application/json'}
      try:
          response = requests.post(f"{self.base_url}?token={self.api_key}", 
                                headers=headers, 
                                json=payload,
                                timeout=30)
          response.raise_for_status()
          data = response.json()
          links = set()
          base_domain = urlparse(url).netloc
          for element in data['data'][0]['results']:
              for attr in element['attributes']:
                  if attr['name'] == 'href':
                      full_url = urljoin(url, attr['value'])
                      if urlparse(full_url).netloc == base_domain:
                          links.add(full_url)
          return links
      except requests.exceptions.RequestException as e:
          logger.error(f"Failed to fetch links for {url}: {str(e)}")
          logger.error(f"Response status code: {getattr(response, 'status_code', 'N/A')}")
          logger.error(f"Response content: {getattr(response, 'text', 'N/A')}")
          return set()

  def check_url_status(self, url: str) -> Dict[str, Any]:
      """Check if a URL is accessible and return its status."""
      try:
          response = self._run(url, output_type="status")
          return {
              'status_code': response.get('status_code', 500),
              'error': None
          }
      except Exception as e:
          return {
              'status_code': 500,
              'error': str(e)
          }

================
File: tools/browser_tool/test_browser_tool.py
================
import logging
import sys
import os

# Add the project root to the Python path
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..', '..', '..'))
sys.path.insert(0, project_root)

from apps.agents.tools.browser_tool.browser_tool import BrowserTool

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def test_browser_tool():
    # Initialize the tool
    browser = BrowserTool()

    # Test get_content
    test_url = "https://brandon.neuralami.com"
    logger.info(f"Testing get_content for {test_url}")
    content = browser.get_content(test_url)
    logger.info(f"Content length: {len(content)}")
    logger.info(f"Content preview: {content[:200]}...")
    print(content[:200])

    # Test get_links
    logger.info(f"Testing get_links for {test_url}")
    links = browser.get_links(test_url)
    logger.info(f"Number of links found: {len(links)}")
    logger.info(f"Links: {links}")
    print(links)
if __name__ == "__main__":
    test_browser_tool()

================
File: tools/business_credibility_tool/business_credibility_tool.py
================
from typing import Dict, Any, Type
from pydantic import BaseModel, Field
from crewai.tools import BaseTool
import json
import logging
from django.conf import settings
from langchain.prompts import ChatPromptTemplate
from langchain.schema import StrOutputParser
from apps.common.utils import get_llm
import re
from bs4 import BeautifulSoup

logger = logging.getLogger(__name__)

class BusinessCredibilityToolSchema(BaseModel):
    """Input schema for BusinessCredibilityTool."""
    text_content: str = Field(..., description="The text content to analyze")
    html_content: str = Field(..., description="The HTML content to analyze")

class BusinessCredibilityTool(BaseTool):
    name: str = "Business Credibility Detector Tool"
    description: str = """
    Analyzes website content to detect business credibility signals including
    contact information, years in business, certifications, reviews, and services.
    """
    args_schema: Type[BaseModel] = BusinessCredibilityToolSchema

    def _preprocess_content(self, text_content: str, html_content: str) -> Dict[str, Any]:
        """Pre-process content to detect common business information patterns."""
        # Phone number patterns
        phone_patterns = [
            r'\b\d{3}[-.]?\d{3}[-.]?\d{4}\b',  # 123-456-7890 or 1234567890
            r'\(\d{3}\)\s*\d{3}[-.]?\d{4}',     # (123) 456-7890
            r'\b\d{3}\s+\d{3}\s+\d{4}\b'        # 123 456 7890
        ]
        
        # Address patterns
        address_patterns = [
            r'\d+\s+[A-Za-z0-9\s,]+(?:Road|Rd|Street|St|Avenue|Ave|Boulevard|Blvd|Drive|Dr|Lane|Ln|Court|Ct|Way|Circle|Cir|Trail|Trl|Highway|Hwy|Route|Rte)[,.\s]+(?:[A-Za-z\s]+,\s*)?[A-Z]{2}\s+\d{5}(?:-\d{4})?',
            r'\d+\s+[A-Za-z\s]+(?:Road|Rd|Street|St|Avenue|Ave|Boulevard|Blvd|Drive|Dr|Lane|Ln|Court|Ct|Way|Circle|Cir|Trail|Trl|Highway|Hwy|Route|Rte)'
        ]
        
        # Business hours patterns
        hours_patterns = [
            r'\b(?:Mon|Tue|Wed|Thu|Fri|Sat|Sun)[a-z]*(?:day)?[-:\s]+(?:\d{1,2}(?::\d{2})?\s*(?:am|pm|AM|PM)[-\s]+\d{1,2}(?::\d{2})?\s*(?:am|pm|AM|PM))',
            r'\b(?:\d{1,2}:\d{2}|(?:1[0-2]|0?[1-9])(?::\d{2})?\s*(?:am|pm|AM|PM))[-\s]+(?:\d{1,2}:\d{2}|(?:1[0-2]|0?[1-9])(?::\d{2})?\s*(?:am|pm|AM|PM))'
        ]

        # Initialize results
        results = {
            "has_phone": False,
            "has_address": False,
            "has_hours": False,
            "found_patterns": {
                "phones": [],
                "addresses": [],
                "hours": []
            }
        }

        # Check footer and contact sections first
        if html_content:
            soup = BeautifulSoup(html_content, 'html.parser')
            footer = soup.find('footer')
            contact_section = soup.find(id=lambda x: x and 'contact' in x.lower()) or \
                            soup.find(class_=lambda x: x and 'contact' in x.lower())
            
            priority_sections = []
            if footer:
                priority_sections.append(footer.get_text())
            if contact_section:
                priority_sections.append(contact_section.get_text())
            
            # Check priority sections first
            for section in priority_sections:
                # Check phone patterns
                for pattern in phone_patterns:
                    phones = re.findall(pattern, section)
                    if phones:
                        results["has_phone"] = True
                        results["found_patterns"]["phones"].extend(phones)
                
                # Check address patterns
                for pattern in address_patterns:
                    addresses = re.findall(pattern, section)
                    if addresses:
                        results["has_address"] = True
                        results["found_patterns"]["addresses"].extend(addresses)
                
                # Check hours patterns
                for pattern in hours_patterns:
                    hours = re.findall(pattern, section)
                    if hours:
                        results["has_hours"] = True
                        results["found_patterns"]["hours"].extend(hours)

        # If not found in priority sections, check entire content
        if not (results["has_phone"] and results["has_address"] and results["has_hours"]):
            # Check phone patterns
            for pattern in phone_patterns:
                phones = re.findall(pattern, text_content)
                if phones:
                    results["has_phone"] = True
                    results["found_patterns"]["phones"].extend(phones)
            
            # Check address patterns
            for pattern in address_patterns:
                addresses = re.findall(pattern, text_content)
                if addresses:
                    results["has_address"] = True
                    results["found_patterns"]["addresses"].extend(addresses)
            
            # Check hours patterns
            for pattern in hours_patterns:
                hours = re.findall(pattern, text_content)
                if hours:
                    results["has_hours"] = True
                    results["found_patterns"]["hours"].extend(hours)

        # Remove duplicates
        results["found_patterns"]["phones"] = list(set(results["found_patterns"]["phones"]))
        results["found_patterns"]["addresses"] = list(set(results["found_patterns"]["addresses"]))
        results["found_patterns"]["hours"] = list(set(results["found_patterns"]["hours"]))

        return results

    def _run(
        self,
        text_content: str,
        html_content: str
    ) -> str:
        try:    
            # Pre-process content for business info
            preprocessed = self._preprocess_content(text_content, html_content)
            
            # If we found business info through regex, we can skip the LLM for this part
            if preprocessed["has_phone"] or preprocessed["has_address"] or preprocessed["has_hours"]:
                has_business_info = True
                business_info_details = preprocessed["found_patterns"]
            else:
                has_business_info = False
                business_info_details = {}

            # Get LLM for other credibility signals
            llm, _ = get_llm(model_name=settings.GENERAL_MODEL, temperature=0.0)

            # Create prompt for credibility analysis
            expertise_prompt = ChatPromptTemplate.from_messages([
                ("system", """You are an expert business analyst detecting credibility signals from website content.
                Pay special attention to footer sections, contact pages, and about sections where business information is typically located.
                Return your analysis as a clean JSON object without any markdown formatting."""),
                ("human", """
                Analyze the provided content for business credibility signals.
                Focus on these signals (ignore business contact info as it's handled separately):
                - Years in business/establishment date
                - Customer reviews/testimonials
                - Services/products offered
                - Professional certifications/licenses

                Return a JSON object with:
                1. credibility_signals: Dictionary of boolean indicators for each signal
                2. signal_details: Specific details found for each signal

                Text Content:
                {text_content}

                HTML Content:
                {html_content}
                """)
            ])

            # Run analysis for other signals
            other_signals = analysis_chain = expertise_prompt | llm | StrOutputParser()
            other_signals_result = other_signals.invoke({
                "text_content": text_content,
                "html_content": html_content
            })
            
            # Clean the result of any markdown formatting
            other_signals_result = other_signals_result.strip()
            if other_signals_result.startswith("```json"):
                other_signals_result = other_signals_result[7:]
            if other_signals_result.endswith("```"):
                other_signals_result = other_signals_result[:-3]
            other_signals_result = other_signals_result.strip()
            
            # Parse other signals result
            other_signals_data = json.loads(other_signals_result)
            
            # Combine results
            final_result = {
                "credibility_signals": {
                    "business_info": has_business_info,
                    **other_signals_data.get("credibility_signals", {})
                },
                "signal_details": {
                    "business_info": business_info_details if has_business_info else None,
                    **other_signals_data.get("signal_details", {})
                }
            }
            
            logger.debug(f"Business credibility analysis result: {json.dumps(final_result)[:200]}...")
            return json.dumps(final_result)

        except Exception as e:
            logger.error(f"Error in BusinessCredibilityTool: {str(e)}")
            return json.dumps({
                "error": "Credibility analysis failed",
                "message": str(e)
            })

================
File: tools/client_profile_tool/client_profile_tool.py
================
import logging
from typing import Type
from pydantic import BaseModel, Field
from crewai.tools import BaseTool
from apps.agents.tools.website_distiller_tool.website_distiller_tool import WebsiteDistillerTool
from apps.common.utils import get_llm
from apps.seo_manager.models import Client
from langchain.prompts.chat import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
import json
from django.conf import settings
from markdown_it import MarkdownIt


logger = logging.getLogger(__name__)

class ClientProfileToolSchema(BaseModel):
    """Input schema for ClientProfileTool."""
    client_id: int = Field(..., description="The ID of the client to update")

    model_config = {
        "extra": "forbid"
    }

class ClientProfileTool(BaseTool):
    name: str = "Client Profile Generator Tool"
    description: str = """
    Analyzes a website to generate a comprehensive client profile by crawling the site,
    processing its content, and using AI to create a structured profile.
    """
    args_schema: Type[BaseModel] = ClientProfileToolSchema

    def _run(
        self,
        client_id: int
    ) -> str:
        try:
            # Step 1: Get the client
            try:
                client = Client.objects.get(id=client_id)
            except Client.DoesNotExist:
                return json.dumps({
                    "error": "Client not found",
                    "message": f"No client found with ID {client_id}"
                })
            website_url=client.website_url
            
            # Step 2: Get website content using WebsiteDistillerTool
            logger.info(f"Getting website content for: {website_url}")
            distiller = WebsiteDistillerTool()
            distilled_content = distiller._run(website_url=website_url)
            
            if not distilled_content:
                return json.dumps({
                    "error": "Content extraction failed",
                    "message": "No content was retrieved from the website"
                })

            # Parse the distilled content
            content_data = json.loads(distilled_content)
            if "error" in content_data:
                return json.dumps({
                    "error": "Content processing failed",
                    "message": content_data["message"]
                })

            website_text = content_data.get("processed_content", "")

            # Step 3: Generate profile using LLM
            logger.info("Generating client profile")
            model_name=settings.GENERAL_MODEL
            llm, _ = get_llm(model_name=model_name,temperature=0.0)  # Lower temperature for more focused output

            profile_prompt = ChatPromptTemplate.from_messages([
                ("system", "You are a business analyst creating detailed company profiles."),
                ("human", """
                <context>
                {text}
                </context>

                Generate Company Profile - Process the provided website crawl data to create a comprehensive yet concise company profile suitable for use as background context for LLM agents. The profile should provide a detailed and accurate overview of the company, its operations, mission, values, target audience, and unique selling propositions (USPs). The information must be factual, objective, and readily usable.

                Specific Instructions:

                Key Information Extraction: Identify and extract crucial details from the website text, including:

                Company Mission and Vision: Summarize the company's mission statement and long-term vision.

                Products/Services: Provide a clear and concise description of the company's offerings, highlighting key features and benefits. Categorize and organize these effectively.

                Target Audience: Describe the company's ideal customer profile(s), including demographics, psychographics, and needs.

                Unique Selling Propositions (USPs): Identify what sets the company apart from competitors and articulates its value proposition to customers.

                Company History (optional): If available, include a brief overview of the company's history and milestones.

                Company Culture and Values (optional): If evident on the website, describe the company's culture and values. This might be inferred from its communication style and messaging.

                Brand Voice and Tone: Analyze the website's overall tone and writing style to determine the appropriate voice for future communications.

                Concise and Structured Output: The profile should be well-organized and easy to read, using clear headings and bullet points where appropriate to improve readability and usability for the subsequent writing agent. Avoid unnecessary details and focus on delivering crucial information efficiently.

                Factual Accuracy: Ensure all information is factual and accurately reflects the content of the provided website data.
                
                Refrain from appending commentary. Be pithy.
                
                """)
            ])

            profile_chain = profile_prompt | llm | StrOutputParser()
            profile_content = profile_chain.invoke({"text": website_text})

            # Step 4: Save to client profile
            md=MarkdownIt()
            profile_content_html = md.render(profile_content)
            client.client_profile = profile_content_html
            client.distilled_website = website_text
            client.save()

            return json.dumps({
                "success": True,
                "profile": profile_content,
                "client_id": client_id,
                "website_url": website_url
            })

        except Exception as e:
            logger.error(f"Error in ClientProfileTool: {str(e)}")
            return json.dumps({
                "error": "Profile generation failed",
                "message": str(e)
            })

================
File: tools/code_interpreter_tool/code_interpreter_tool.py
================
import importlib.util
import os
from typing import List, Optional, Type
import json
import logging
from django.conf import settings

import docker
from pydantic import BaseModel, Field

from crewai.tools import BaseTool

logger = logging.getLogger(__name__)


class CodeInterpreterSchema(BaseModel):
    """Input for CodeInterpreterTool."""
    code: str = Field(
        ...,
        description="Python3 code used to be interpreted in the Docker container. ALWAYS PRINT the final result and the output of the code",
    )

    libraries_used: List[str] = Field(
        ...,
        description="List of libraries used in the code with proper installing names separated by commas. Example: numpy,pandas,beautifulsoup4",
    )


class CodeInterpreterTool(BaseTool):
    name: str = "Code Interpreter"
    description: str = "Interprets Python3 code strings with a final print statement."
    args_schema: Type[BaseModel] = CodeInterpreterSchema
    default_image_tag: str = "code-interpreter:latest"
    code: Optional[str] = None
    user_dockerfile_path: Optional[str] = None

    @staticmethod
    def _get_installed_package_path():
        spec = importlib.util.find_spec("crewai_tools")
        return os.path.dirname(spec.origin)

    def _verify_docker_image(self) -> None:
        """
        Verify if the Docker image is available. Optionally use a user-provided Dockerfile.
        """
        client = docker.from_env()

        try:
            client.images.get(self.default_image_tag)

        except docker.errors.ImageNotFound:
            if self.user_dockerfile_path and os.path.exists(self.user_dockerfile_path):
                dockerfile_path = self.user_dockerfile_path
            else:
                package_path = self._get_installed_package_path()
                dockerfile_path = os.path.join(
                    package_path, "tools/code_interpreter_tool"
                )
                if not os.path.exists(dockerfile_path):
                    raise FileNotFoundError(
                        f"Dockerfile not found in {dockerfile_path}"
                    )

            client.images.build(
                path=dockerfile_path,
                tag=self.default_image_tag,
                rm=True,
            )

    def _run(self, code: str, libraries_used: List[str]) -> str:
        """Run code in Docker container with explicit parameters"""
        return self.run_code_in_docker(code, libraries_used)

    def _install_libraries(
        self, container: docker.models.containers.Container, libraries: List[str]
    ) -> None:
        """
        Install missing libraries in the Docker container
        """
        for library in libraries:
            container.exec_run(f"pip install {library}")

    def _init_docker_container(self) -> docker.models.containers.Container:
        container_name = "code-interpreter"
        client = docker.from_env()
        current_path = os.getcwd()

        # Check if the container is already running
        try:
            existing_container = client.containers.get(container_name)
            existing_container.stop()
            existing_container.remove()
        except docker.errors.NotFound:
            pass  # Container does not exist, no need to remove

        return client.containers.run(
            self.default_image_tag,
            detach=True,
            tty=True,
            working_dir="/workspace",
            name=container_name,
            volumes={current_path: {"bind": "/workspace", "mode": "rw"}},  # type: ignore
        )

    def run_code_in_docker(self, code: str, libraries_used: List[str]) -> str:
        self._verify_docker_image()
        container = self._init_docker_container()
        self._install_libraries(container, libraries_used)

        cmd_to_run = f'python3 -c "{code}"'
        exec_result = container.exec_run(cmd_to_run)

        container.stop()
        container.remove()

        if exec_result.exit_code != 0:
            return f"Something went wrong while running the code: \n{exec_result.output.decode('utf-8')}"
        return exec_result.output.decode("utf-8")

================
File: tools/code_interpreter_tool/Dockerfile
================
FROM python:3.11-slim

# Install common utilities
RUN apt-get update && apt-get install -y \
    build-essential \
    curl \
    wget \
    software-properties-common

# Clean up
RUN apt-get clean && rm -rf /var/lib/apt/lists/*

# Set the working directory
WORKDIR /workspace

================
File: tools/code_interpreter_tool/README.md
================
# CodeInterpreterTool

## Description
This tool is used to give the Agent the ability to run code (Python3) from the code generated by the Agent itself. The code is executed in a sandboxed environment, so it is safe to run any code.

It is incredible useful since it allows the Agent to generate code, run it in the same environment, get the result and use it to make decisions.

## Requirements

- Docker

## Installation
Install the crewai_tools package
```shell
pip install 'crewai[tools]'
```

## Example

Remember that when using this tool, the code must be generated by the Agent itself. The code must be a Python3 code. And it will take some time for the first time to run because it needs to build the Docker image.

```python
from crewai_tools import CodeInterpreterTool

Agent(
    ...
    tools=[CodeInterpreterTool()],
)
```

Or if you need to pass your own Dockerfile just do this

```python
from crewai_tools import CodeInterpreterTool

Agent(
    ...
    tools=[CodeInterpreterTool(user_dockerfile_path="<Dockerfile_path>")],
)
```

================
File: tools/competitor_tools/competitor_tools.py
================
import os
import requests
from typing import Any, Type, List, Dict, Optional
from pydantic import BaseModel, Field, ConfigDict
from crewai.tools import BaseTool
import logging
import pandas as pd
from urllib.parse import urlparse

logger = logging.getLogger(__name__)

BASE_URL = os.getenv('DATAFORSEO_BASE_URL', 'https://api.dataforseo.com')

class CompetitorsDomainInput(BaseModel):
    model_config = ConfigDict(
        extra='forbid',
        arbitrary_types_allowed=True
    )
    
    website_url: str = Field(description="Fully qualified domain name (FQDN) for competitor analysis")
    location_code: int = Field(default=2840, description="Location code for the analysis")
    language_code: str = Field(default="en", description="Language code for the analysis")

    @classmethod
    def get_fqdn(cls, url: str) -> str:
        parsed_url = urlparse(url)
        return parsed_url.netloc or parsed_url.path

class CompetitorsDomainTool(BaseTool):
    model_config = ConfigDict(
        extra='forbid',
        arbitrary_types_allowed=True
    )
    
    name: str = "Competitors Domain"
    description: str = "Provides a list of competitor domains with various metrics"
    args_schema: Type[BaseModel] = CompetitorsDomainInput

    def _run(self, website_url: str, location_code: int = 2840, language_code: str = "en", **kwargs: Any) -> Any:
        login, password = KeywordTools._dataforseo_credentials()
        cred = (login, password)
        url = f"{BASE_URL}/v3/dataforseo_labs/google/competitors_domain/live"
        
        # Extract FQDN from the provided URL
        fqdn = CompetitorsDomainInput.get_fqdn(website_url)
        
        payload = [
            {
                "target": fqdn,
                "location_code": location_code,
                "language_code": language_code,
                "exclude_top_domains": False,
                "include_clickstream_data": False,
                "item_types": ["organic"],
                "limit": 100,
                "order_by": ["intersections,desc"]
            }
        ]
        headers = {"Content-Type": "application/json"}
        try:
            response = requests.post(url, json=payload, headers=headers, auth=cred)
            response.raise_for_status()
        except Exception as e:
            logger.error(f"Error making request to DataForSEO: {e}")
            raise e

        try:
            results = self._transform_competitor_data(response.json())
        except Exception as e:
            logger.error(f"Error transforming competitor data: {e}")
            raise e

        return results

    def _transform_competitor_data(self, data: Dict) -> str:
        try:
            if data.get('tasks_error', 0) > 0:
                error_message = data.get('tasks', [{}])[0].get('status_message', 'Unknown error')
                return f"Error: {error_message}"

            all_results = data.get('tasks', [])[0].get('result', [])[0].get('items', [])
            if not all_results:
                return "Error: No results found in the response"

            # Create a DataFrame from the results
            df = pd.DataFrame(all_results)

            # Extract necessary fields and calculate additional metrics
            df['avg_position'] = df['avg_position'].round(2)
            df['etv'] = df['full_domain_metrics'].apply(lambda x: x['organic']['etv'])
            df['estimated_paid_traffic_cost'] = df['full_domain_metrics'].apply(lambda x: x['organic']['estimated_paid_traffic_cost'])
            df['rank_distribution_top_10'] = df['full_domain_metrics'].apply(lambda x: x['organic']['pos_4_10'])
            df['rank_distribution_11_20'] = df['full_domain_metrics'].apply(lambda x: x['organic']['pos_11_20'])
            df['rank_distribution_21_100'] = df['full_domain_metrics'].apply(lambda x: sum(x['organic'][f'pos_{i}_{i+9}'] for i in range(21, 100, 10)))

            # Define the columns to include in the output
            columns = [
                'domain', 'avg_position', 'intersections', 'etv', 
                'estimated_paid_traffic_cost', 'rank_distribution_top_10', 
                'rank_distribution_11_20', 'rank_distribution_21_100'
            ]
            result_df = df[columns]

            # Convert the DataFrame to CSV format
            csv_output = result_df.to_csv(index=False)
            return csv_output

        except Exception as e:
            logger.error(f"Error transforming competitor data: {e}")
            return f"Error: {str(e)}"

class KeywordTools:
    @staticmethod
    def _dataforseo_credentials():
        login = os.environ["DATAFORSEO_EMAIL"]
        password = os.environ["DATAFORSEO_PASSWORD"]
        return login, password

================
File: tools/compression_tool/compression_tool.py
================
import os
from typing import Any, Type, List, Dict, Optional
from pydantic import BaseModel, Field
from crewai.tools import BaseTool
from apps.common.utils import get_llm, tokenize
from langchain.prompts.chat import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain.text_splitter import RecursiveCharacterTextSplitter
import tiktoken
from django.conf import settings
import json
import logging

logger = logging.getLogger(__name__)

class CompressionToolSchema(BaseModel):
    """Input schema for CompressionTool."""
    content: str = Field(..., description="The text content to process and organize")
    max_tokens: int = Field(default=16384, description="Maximum number of tokens in the processed output")
    detail_level: str = Field(
        default="comprehensive",
        description="Detail level: 'comprehensive' (preserve all details), 'detailed' (preserve most details), or 'focused' (key details only)"
    )

class CompressionTool(BaseTool):
    name: str = "Advanced Text Processing and Organization Tool"
    description: str = """
    Processes and organizes text content while preserving important information using advanced NLP techniques.
    Features semantic chunking, intelligent note-taking, and configurable detail levels.
    """
    args_schema: Type[BaseModel] = CompressionToolSchema
    
    modelname: str = Field(default=settings.SUMMARIZER)
    llm: Optional[Any] = Field(default=None)
    token_counter_callback: Optional[Any] = Field(default=None)
    tokenizer: Any = Field(default_factory=lambda: tiktoken.get_encoding("cl100k_base"))

    def __init__(self, **data):
        super().__init__(**data)
        self.llm, self.token_counter_callback = get_llm(self.modelname, temperature=0.0)

    def _create_semantic_chunks(self, content: str, chunk_size: int) -> List[str]:
        """Split content into semantic chunks using recursive character splitting."""
        splitter = RecursiveCharacterTextSplitter(
            chunk_size=chunk_size,
            chunk_overlap=100,
            length_function=lambda x: len(self.tokenizer.encode(x)),
            separators=["\n\n", "\n", ". ", ", ", " "]
        )
        return splitter.split_text(content)

    def _get_processing_prompt(self, detail_level: str) -> str:
        """Get the appropriate processing prompt based on detail level."""
        prompts = {
            "comprehensive": """
            You are a meticulous note-taker with perfect recall. Your task is to process this text into detailed, organized notes:

            Guidelines:
            - Capture EVERY piece of information, no matter how small
            - Maintain all technical details, numbers, and specific examples
            - Preserve exact terminology and domain-specific language
            - Keep all dates, names, and references
            - Structure information in a clear, hierarchical format
            - Use bullet points and sub-bullets for organization
            - Remove ONLY exact duplicates of information
            - Keep all nuances and contextual details
            - Maintain the original meaning and implications
            - Include ALL supporting evidence and explanations
            
            Text to process:
            ```{content}```
            """,
            
            "detailed": """
            You are a thorough note-taker with excellent attention to detail. Your task is to process this text into well-organized notes:

            Guidelines:
            - Capture all significant information and supporting details
            - Maintain technical details and specific examples
            - Keep all important terminology and domain-specific language
            - Preserve relevant dates, names, and references
            - Structure information in a clear, logical format
            - Use bullet points and sub-bullets for organization
            - Remove only clearly redundant information
            - Maintain important nuances and context
            - Keep the original meaning and key implications
            - Include relevant supporting evidence
            
            Text to process:
            ```{content}```
            """,
            
            "focused": """
            You are a precise note-taker focusing on key information. Your task is to process this text into clear, focused notes:

            Guidelines:
            - Capture all key information and essential details
            - Maintain critical technical details and examples
            - Keep important terminology and specialized language
            - Preserve crucial dates, names, and references
            - Structure information in a clear, concise format
            - Use bullet points and sub-bullets for organization
            - Remove redundant information while keeping unique details
            - Maintain critical nuances and context
            - Preserve the core meaning and implications
            - Include key supporting evidence
            
            Text to process:
            ```{content}```
            """
        }
        return prompts.get(detail_level, prompts["comprehensive"])

    def _process_chunk(self, chunk: str, detail_level: str) -> str:
        """Process a single chunk of text into detailed notes."""
        process_prompt = ChatPromptTemplate.from_messages([
            ("system", "You are a detail-oriented note-taker who never loses information. Your notes should be thorough and well-organized."),
            ("human", self._get_processing_prompt(detail_level))
        ])
        
        process_chain = process_prompt | self.llm | StrOutputParser()
        return process_chain.invoke({'content': chunk})

    def _deduplicate_content(self, chunks: List[str]) -> List[str]:
        """Remove exact duplicates while preserving unique information."""
        dedup_prompt = ChatPromptTemplate.from_messages([
            ("system", """You are a detail-preserving content organizer. Your task is to:
            1. Identify and remove ONLY exact duplicates of information
            2. Preserve ALL unique details, even if similar
            3. Maintain ALL specific examples, numbers, and technical details
            4. Keep ALL contextual information and nuances
            5. Ensure no information is lost in the process
            6. Organize related information together logically
            """),
            ("human", "Text sections to organize:\n{chunks}")
        ])
        
        dedup_chain = dedup_prompt | self.llm | StrOutputParser()
        combined_chunks = "\n=====\n".join(chunks)
        result = dedup_chain.invoke({'chunks': combined_chunks})
        return result.split("\n=====\n")

    def _run(
        self,
        content: str,
        max_tokens: int = 16384,
        detail_level: str = "comprehensive",
        **kwargs: Any
    ) -> str:
        try:
            # Validate input
            if not content or not isinstance(content, str):
                return json.dumps({
                    "error": "Invalid input",
                    "message": "Content must be a non-empty string"
                })

            content_tokens = tokenize(content, self.tokenizer)
            logger.info(f"Original content tokens: {content_tokens}")

            if content_tokens <= max_tokens:
                processed_content = self._process_chunk(content, detail_level)
                final_tokens = tokenize(processed_content, self.tokenizer)
                logger.info(f"Processed content tokens (single chunk): {final_tokens}")
                return json.dumps({
                    "processed_content": processed_content,
                    "original_tokens": content_tokens,
                    "final_tokens": final_tokens,
                    "reduction_ratio": final_tokens / content_tokens,
                    "llm_input_tokens": self.token_counter_callback.input_tokens,
                    "llm_output_tokens": self.token_counter_callback.output_tokens
                })

            # Calculate chunk size based on max_tokens
            chunk_size = max_tokens 
            
            # Create semantic chunks
            chunks = self._create_semantic_chunks(content, chunk_size)
            logger.info(f"Created {len(chunks)} semantic chunks")
            
            # Process chunks
            processed_chunks = []
            for i, chunk in enumerate(chunks):
                logger.info(f"Processing chunk {i+1}/{len(chunks)}")
                processed_chunk = self._process_chunk(chunk, detail_level)
                processed_chunks.append(processed_chunk)
                logger.info(f"Chunk {i+1} tokens: {tokenize(processed_chunk, self.tokenizer)}")
            
            # Deduplicate if needed
            if len(processed_chunks) > 1:
                logger.info("Deduplicating chunks")
                processed_chunks = self._deduplicate_content(processed_chunks)
            
            # Join chunks and check final token count
            processed_content = "\n\n".join(processed_chunks)
            final_tokens = tokenize(processed_content, self.tokenizer)
            logger.info(f"Final tokens after joining chunks: {final_tokens}")
            
            # If still too long, process again with focused detail level
            if final_tokens > max_tokens:
                logger.info("Performing second processing pass")
                processed_content = self._process_chunk(processed_content, "focused")
                final_tokens = tokenize(processed_content, self.tokenizer)
                logger.info(f"Final tokens after second pass: {final_tokens}")
            
            result = {
                "processed_content": processed_content,
                "original_tokens": content_tokens,
                "final_tokens": final_tokens,
                "reduction_ratio": final_tokens / content_tokens,
                "llm_input_tokens": self.token_counter_callback.input_tokens,
                "llm_output_tokens": self.token_counter_callback.output_tokens
            }
            
            # Reset the token counter for the next run
            self.token_counter_callback.input_tokens = 0
            self.token_counter_callback.output_tokens = 0
            
            return json.dumps(result)

        except Exception as e:
            logger.error(f"Error in CompressionTool: {str(e)}")
            return json.dumps({
                "error": "Processing failed",
                "message": str(e)
            })

================
File: tools/content_expertise_tool/content_expertise_tool.py
================
from typing import Dict, Any, Type
from pydantic import BaseModel, Field
from crewai.tools import BaseTool
import json
import logging
from django.conf import settings
from langchain.prompts import ChatPromptTemplate
from langchain.schema import StrOutputParser
from apps.common.utils import get_llm

logger = logging.getLogger(__name__)

class ContentExpertiseToolSchema(BaseModel):
    """Input schema for ContentExpertiseTool."""
    text_content: str = Field(..., description="The text content to analyze")
    html_content: str = Field(..., description="The HTML content to analyze")
    content_type: str = Field(..., description="Type of content (blog, article, news)")
    url: str = Field(..., description="URL of the content")

class ContentExpertiseTool(BaseTool):
    name: str = "Content Expertise Detector Tool"
    description: str = """
    Analyzes content to detect expertise, authority, and trust signals including
    author expertise, content quality, citations, factual accuracy, and more.
    """
    args_schema: Type[BaseModel] = ContentExpertiseToolSchema

    def _run(
        self,
        text_content: str,
        html_content: str,
        content_type: str,
        url: str
    ) -> str:
        try:
            # Get LLM
            llm, _ = get_llm(model_name=settings.GENERAL_MODEL, temperature=0.0)

            # Create prompt for expertise analysis
            expertise_prompt = ChatPromptTemplate.from_messages([
                ("system", """You are an expert content analyst evaluating content quality and expertise signals.
                Return your analysis as a clean JSON object without any markdown formatting."""),
                ("human", """
                Analyze the provided content for expertise, authority, and trust signals.
                Return a JSON object with two sections:
                1. expertise_signals: Dictionary of boolean indicators for each signal
                2. signal_details: Specific details found for each signal

                Focus on:
                - Author Information (name, bio, credentials, links to profile)
                - Content Quality (depth, comprehensiveness, technical accuracy)
                - Citations and References (academic citations, expert quotes, data sources)
                - Factual Accuracy (fact-checking elements, source attribution)
                - Content Structure (organization, table of contents, section headers)
                - Topic Coverage (depth vs. superficial)
                - Schema Markup (Article, BlogPosting, NewsArticle)
                - Content Freshness (publish/update dates)
                
                Content Type: {content_type}
                URL: {url}
                
                Text Content:
                {text_content}
                
                HTML Content:
                {html_content}
                """)
            ])

            # Run analysis
            analysis_chain = expertise_prompt | llm | StrOutputParser()
            result = analysis_chain.invoke({
                "content_type": content_type,
                "url": url,
                "text_content": text_content,
                "html_content": html_content
            })
            
            # Clean the result of any markdown formatting
            result = result.strip()
            if result.startswith("```json"):
                result = result[7:]  # Remove ```json prefix
            if result.endswith("```"):
                result = result[:-3]  # Remove ``` suffix
            result = result.strip()
            
            logger.debug(f"Content expertise analysis result: {result[:200]}...")
            
            # Validate JSON before returning
            json.loads(result)  # This will raise an exception if invalid
            return result

        except Exception as e:
            logger.error(f"Error in ContentExpertiseTool: {str(e)}")
            return json.dumps({
                "error": "Expertise analysis failed",
                "message": str(e)
            })

================
File: tools/crawl_website_tool/crawl_website_tool.py
================
import logging
import aiohttp
import asyncio
from typing import Optional, Dict, Any, Type, List, Literal
from enum import Enum
from pydantic import BaseModel, Field
from crewai.tools import BaseTool
from celery import shared_task
from celery.contrib.abortable import AbortableTask
from django.contrib.auth.models import User
from django.conf import settings
from apps.crawl_website.models import CrawlResult
from .utils import sanitize_url
import requests
import time
import json
import os
from datetime import datetime
import base64
from urllib.parse import urlparse
from django.core.files.storage import default_storage
from django.core.files.base import ContentFile
import re

logger = logging.getLogger(__name__)

# Define all possible CrawlResult attributes
CrawlResultAttribute = Literal[
    "url",
    "html",
    "success",
    "cleaned_html",
    "media",
    "links",
    "downloaded_files",
    "screenshot",
    "markdown",
    "markdown_v2",
    "fit_markdown",
    "fit_html",
    "extracted_content",
    "metadata",
    "error_message",
    "session_id",
    "response_headers",
    "status_code"
]

class CrawlWebsiteToolSchema(BaseModel):
    """Input for CrawlWebsiteTool."""
    website_url: str = Field(..., description="Mandatory website URL to crawl and read content")
    user_id: int = Field(..., description="ID of the user initiating the crawl")
    max_pages: int = Field(default=100, description="Maximum number of pages to crawl")
    css_selector: Optional[str] = Field(default=None, description="CSS selector for content extraction")
    wait_for: Optional[str] = Field(default=None, description="Wait for element/condition before extraction")
    result_attributes: Optional[List[CrawlResultAttribute]] = Field(
        default=["url", "markdown", "success", "metadata", "error_message", "session_id", "status_code"],
        description="List of CrawlResult attributes to return in the results. Available attributes: url, html, success, cleaned_html, media, links, downloaded_files, screenshot, markdown, markdown_v2, fit_markdown, fit_html, extracted_content, metadata, error_message, session_id, response_headers, status_code"
    )
    save_files: bool = Field(default=False, description="Whether to save crawl results to files")

    model_config = {
        "extra": "forbid"
    }

def get_safe_filename(url: str, max_length: int = 50) -> str:
    """
    Create a safe filename from URL.
    
    Args:
        url: The URL to convert to a filename
        max_length: Maximum length of the filename
        
    Returns:
        str: A safe filename
    """
    return "".join(c if c.isalnum() else "_" for c in url)[-max_length:]

def create_output_directory(website_url: str, user_id: int) -> tuple[str, str]:
    """Create output directory structure for crawl results in cloud storage."""
    try:
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        domain = re.sub(r'[^\w\-]', '_', urlparse(website_url).netloc)
        
        # Create base path - using consistent naming
        base_path = os.path.join(
            str(user_id),
            'crawled_websites',  # Lowercase, consistent with model
            f"{domain}_{timestamp}"
        )
        
        # Create subdirectories
        subdirs = ['screenshots', 'html', 'markdown']
        for subdir in subdirs:
            dir_path = os.path.join(base_path, subdir)
            # Create a marker file to ensure directory exists
            marker_path = os.path.join(dir_path, '.keep')
            default_storage.save(marker_path, ContentFile(''))
        
        logger.info(f"Created output directory structure at: {base_path}")
        return base_path, timestamp
        
    except Exception as e:
        error_msg = f"Error creating output directory structure: {str(e)}"
        logger.error(error_msg)
        raise

def get_storage_url(relative_path: str) -> str:
    """
    Get the URL for accessing a file in storage.
    
    Args:
        relative_path: The relative path to the file
        
    Returns:
        str: The URL to access the file
    """
    try:
        return default_storage.url(relative_path)
    except Exception as e:
        logger.error(f"Error getting storage URL: {str(e)}")
        return None

def ensure_directory_exists(relative_path: str) -> bool:
    """
    Ensure a directory exists in cloud storage.
    
    Args:
        relative_path: The relative path to ensure exists
        
    Returns:
        bool: True if successful, False otherwise
    """
    try:
        marker_path = os.path.join(relative_path, '.keep')
        if not default_storage.exists(marker_path):
            default_storage.save(marker_path, ContentFile(''))
        return True
    except Exception as e:
        logger.error(f"Error ensuring directory exists: {str(e)}")
        return False

def save_crawl_files(output_dir: str, website_url: str, crawl_results: list, timestamp: str) -> dict:
    """Save crawl results to files."""
    try:
        logger.debug(f"Starting save_crawl_files for dir: {output_dir}")
        file_paths = {}

        # Save sitemap
        sitemap_path = os.path.join(output_dir, f"sitemap_{timestamp}.txt")
        logger.debug(f"Saving sitemap to: {sitemap_path}")
        sitemap_content = []
        sitemap_content.append(f"Sitemap for {website_url}")
        sitemap_content.append(f"Generated on: {datetime.now().isoformat()}\n")
        
        # Write successful URLs and their titles
        sitemap_content.append("Successfully crawled pages:")
        successful_results = [r for r in crawl_results if r.get('success')]
        for result in successful_results:
            title = result.get('metadata', {}).get('title', 'Unknown Title')
            sitemap_content.append(f"- {result['url']}\n    Title: {title}")
        
        # Write failed URLs
        failed_results = [r for r in crawl_results if not r.get('success')]
        if failed_results:
            sitemap_content.append("\nFailed pages:")
            for result in failed_results:
                sitemap_content.append(f"- {result['url']}\n    Error: {result.get('error_message', 'Unknown error')}")

        # Join content and log length
        content = '\n'.join(sitemap_content)
        logger.debug(f"Sitemap content length: {len(content)}")
        
        # Save the content
        default_storage.save(sitemap_path, ContentFile(content))
        logger.debug(f"Saved sitemap file")
        
        # Save individual files
        for result in successful_results:
            safe_name = get_safe_filename(result['url'])
            logger.debug(f"Processing files for URL: {safe_name}")
            
            if result.get('screenshot'):
                screenshot_path = os.path.join(output_dir, 'screenshots', f"{safe_name}.png")
                logger.debug(f"Saving screenshot to: {screenshot_path}")
                screenshot_data = base64.b64decode(result['screenshot'])
                default_storage.save(screenshot_path, ContentFile(screenshot_data))
                
            if result.get('cleaned_html'):
                html_path = os.path.join(output_dir, 'html', f"{safe_name}.html")
                logger.debug(f"Saving HTML to: {html_path}")
                default_storage.save(html_path, ContentFile(result['cleaned_html']))
                
            if result.get('markdown'):
                markdown_path = os.path.join(output_dir, 'markdown', f"{safe_name}.md")
                logger.debug(f"Saving markdown to: {markdown_path}")
                default_storage.save(markdown_path, ContentFile(result['markdown']))
                
        logger.debug("Completed save_crawl_files")
        return file_paths
    except Exception as e:
        logger.error(f"Error in save_crawl_files: {str(e)}", exc_info=True)
        raise


class CrawlWebsiteTool(BaseTool):
    name: str = "Crawl and Read Website Content"
    description: str = """A tool that can crawl a website and read its content, including content from internal links on the same page.
    
    Example usage:
    1. Basic crawl with default attributes:
       {
           "website_url": "https://example.com",
           "user_id": 1
       }
    
    2. Crawl with custom attributes and limits:
       {
           "website_url": "https://example.com",
           "user_id": 1,
           "max_pages": 50,
           "result_attributes": ["url", "html", "links", "markdown"]
       }
    
    3. Crawl with CSS selector and wait condition:
       {
           "website_url": "https://example.com",
           "user_id": 1,
           "css_selector": "article.content",
           "wait_for": "#main-content",
           "result_attributes": ["url", "markdown", "metadata", "status_code"]
       }
    
    Available result_attributes:
    - url: The page URL
    - html: Raw HTML content
    - success: Whether the crawl was successful
    - cleaned_html: Processed HTML content
    - media: Media elements found
    - links: Internal and external links
    - downloaded_files: Any downloaded files
    - screenshot: Page screenshot
    - markdown: Content in markdown format
    - markdown_v2: Alternative markdown format
    - fit_markdown: Fitted markdown content
    - fit_html: Fitted HTML content
    - extracted_content: Extracted text content
    - metadata: Page metadata
    - error_message: Any error messages
    - session_id: Crawl session ID
    - response_headers: HTTP response headers
    - status_code: HTTP status code
    """
    args_schema: Type[BaseModel] = CrawlWebsiteToolSchema
    
    def _run(
        self,
        website_url: str,
        user_id: int,
        max_pages: int = 100,
        css_selector: Optional[str] = None,
        wait_for: Optional[str] = None,
        result_attributes: Optional[List[str]] = None,
        save_files: bool = False,
        **kwargs: Any
    ) -> str:
        """Run the tool and return crawl results as a JSON string."""
        return crawl_website_task(
            website_url=website_url,
            user_id=user_id,
            max_pages=max_pages,
            wait_for=wait_for,
            css_selector=css_selector,
            result_attributes=result_attributes,
            save_files=save_files
        )

@shared_task(bind=True, base=AbortableTask)
def crawl_website_task(self, website_url: str, user_id: int, max_pages: int = 100, 
                      save_files: bool = True, wait_for: Optional[str] = None, 
                      css_selector: Optional[str] = None, 
                      result_attributes: Optional[List[str]] = None) -> str:
    """Celery task to crawl website using Crawl4AI service."""
    try:
        logger.info(f"Starting crawl for URL: {website_url}")
        
        # Use default result attributes if none provided
        if result_attributes is None:
            result_attributes = ["url", "markdown", "success", "metadata", 
                               "error_message", "session_id", "status_code"]
        
        # Initialize progress - with safe state update
        try:
            if hasattr(self.request, 'id') and self.request.id:
                self.update_state(state='PROGRESS', meta={
                    'current': 0,
                    'total': max_pages,
                    'status_message': 'Starting crawl...'
                })
        except Exception as e:
            logger.warning(f"Could not update task state: {e}")

        # Prepare request data
        request_data = {
            "url": website_url,
            "max_pages": max_pages,
            "max_depth": 3,
            "batch_size": 10,
            "crawler_params": {
                **settings.CRAWL4AI_CRAWLER_PARAMS,
                "wait_for": wait_for,
                "remove_overlay_elements": True,
                "delay_before_return_html": 2.0,
            },
            "extraction_config": {
                "type": "basic",
                "params": {
                    "word_count_threshold": settings.CRAWL4AI_EXTRA_PARAMS.get("word_count_threshold", 10),
                    "only_text": settings.CRAWL4AI_EXTRA_PARAMS.get("only_text", True),
                    "bypass_cache": settings.CRAWL4AI_EXTRA_PARAMS.get("bypass_cache", False),
                    "process_iframes": settings.CRAWL4AI_EXTRA_PARAMS.get("process_iframes", True),
                    "excluded_tags": settings.CRAWL4AI_EXTRA_PARAMS.get("excluded_tags", ['nav', 'aside', 'footer']),
                    "html2text": {
                        "ignore_links": False,
                        "ignore_images": True,
                        "body_width": 0,
                        "unicode_snob": True,
                        "protect_links": True
                    }
                }
            }
        }

        headers = {"Authorization": f"Bearer {settings.CRAWL4AI_API_KEY}"} if settings.CRAWL4AI_API_KEY else {}
        
        # Make the request and process the stream directly in the task
        response = requests.post(
            f"{settings.CRAWL4AI_URL}/spider",
            headers=headers,
            json=request_data,
            stream=True
        )
        
        if not response.ok:
            raise Exception(f"Failed to start crawl: {response.text}")
        
        logger.debug(f"Initial response status: {response.status_code}")
        
        # Process the streaming response
        all_content = []  # Change to list to collect content
        all_links = set()
        crawl_results = []
        pages_crawled = 0
        
        for line in response.iter_lines():
            if line:
                try:
                    result_data = json.loads(line)
                    
                    # Safe progress update when we receive any data
                    try:
                        if hasattr(self.request, 'id') and self.request.id:
                            self.update_state(state='PROGRESS', meta={
                                'current': pages_crawled,
                                'total': max_pages,
                                'status_message': f'Processing stream data: {list(result_data.keys())}'
                            })
                    except Exception as e:
                        logger.warning(f"Could not update task state during processing: {e}")

                    # Handle results
                    if "results" in result_data:
                        for url, page_result in result_data["results"].items():
                            all_links.add(url)
                            
                            # Create filtered result with all necessary data
                            filtered_result = {
                                "url": url,
                                "success": True,
                                "markdown": page_result.get('markdown', ''),
                                "cleaned_html": page_result.get('cleaned_html', ''),
                                "metadata": page_result.get('metadata', {}),
                                "screenshot": page_result.get('screenshot'),
                            }
                            crawl_results.append(filtered_result)
                            
                            # Add content to all_content list
                            content = f"URL: {url}\n\n"
                            if filtered_result['metadata'].get('title'):
                                content += f"Title: {filtered_result['metadata']['title']}\n\n"
                            content += filtered_result['markdown']
                            content += "\n\n---\n\n"
                            all_content.append(content)
                    
                    # Handle explicit progress updates
                    if "crawled_count" in result_data:
                        pages_crawled = result_data["crawled_count"]
                        logger.info(f"External progress update: {pages_crawled}")
                        self.update_state(state='PROGRESS', meta={
                            'current': pages_crawled,
                            'total': max_pages,
                            'status_message': f'External report: {pages_crawled} pages'
                        })

                    # Add small delay to allow state updates to propagate
                    time.sleep(0.1)

                except Exception as e:
                    logger.error(f"Error processing line: {e}")

        # Convert set to list for JSON serialization
        links_list = list(all_links)
        
        # Create crawl result in database with combined content
        crawl_result = CrawlResult.create_with_content(
            user=User.objects.get(id=user_id),
            website_url=website_url,
            content='\n'.join(all_content),
            links_visited={"internal": links_list},
            total_links=len(links_list)
        )

        # Build result
        result = {
            "status": "success",
            "website_url": website_url,
            "crawl_results": crawl_results,
            "total_pages": len(crawl_results),
            "links_visited": links_list,
            "total_links": len(links_list),
            "file_url": crawl_result.get_file_url(),
            "crawl_result_id": crawl_result.id
        }

        logger.info(f"Returning final result with {len(crawl_results)} pages crawled and {len(links_list)} unique links")
        return json.dumps(result)

    except Exception as e:
        logger.error(f"Error in crawl_website_task: {e}", exc_info=True)
        return json.dumps({
            "status": "error",
            "message": str(e)
        })

================
File: tools/crawl_website_tool/test_crawl_website_tool.py
================
import logging
import sys
import os

# Add the project root to the Python path
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..', '..', '..'))
sys.path.insert(0, project_root)

from apps.agents.tools.crawl_website_tool.crawl_website_tool import CrawlWebsiteTool

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def test_crawl_website():
    # Initialize the tool
    crawler = CrawlWebsiteTool()

    # Test with a real website
    test_url = "https://proplankohio.com"
    logger.info(f"Starting crawl of {test_url}")
    print(f"Starting crawl of {test_url}")
    result = crawler._run(test_url)

    # Print the result
    logger.info(f"Crawl result for {test_url}:")
    logger.info(result)
    print(result)

    # You can add more assertions here to verify the output

if __name__ == "__main__":
    test_crawl_website()

================
File: tools/crawl_website_tool/utils.py
================
from django.core.files.storage import default_storage
from django.core.files.base import ContentFile
from django.contrib.auth.models import User
from datetime import datetime
import re
import os
import logging
from typing import List
from apps.crawl_website.models import CrawlResult

logger = logging.getLogger(__name__)

def sanitize_url(url: str) -> str:
    """Sanitize the URL to create a valid folder name."""
    url = re.sub(r'^https?://(www\.)?', '', url)
    return re.sub(r'[^a-zA-Z0-9]', '_', url)

def get_crawl_result_url(relative_path: str) -> str:
    """Get the URL for accessing a crawl result file."""
    try:
        if relative_path:
            # For S3/B2, this will return a proper S3/B2 URL
            return default_storage.url(relative_path)
        return None
    except Exception as e:
        logger.error(f"Error getting URL for crawl result: {str(e)}")
        return None

def ensure_crawl_directory_exists(user_id: int) -> str:
    """Ensure the crawl directory exists in cloud storage."""
    try:
        # For S3/B2, we don't need to create directory markers
        relative_path = os.path.join(str(user_id), 'crawled_websites')
        logger.debug(f"Using crawl directory path: {relative_path}")
        return relative_path
        
    except Exception as e:
        logger.error(f"Error with crawl directory path: {str(e)}")
        raise

def get_crawl_results(user_id: int) -> List[str]:
    """Get list of crawl results from cloud storage."""
    try:
        directory_path = ensure_crawl_directory_exists(user_id)
        results = []
        
        # Use S3/B2 style listing
        prefix = f"{directory_path}/"
        for obj in default_storage.bucket.objects.filter(Prefix=prefix):
            if obj.key.endswith('.txt'):  # Only include .txt files
                results.append(obj.key)
                    
        # Sort by last modified time
        results.sort(key=lambda x: default_storage.get_modified_time(x), reverse=True)
        return results
        
    except Exception as e:
        logger.error(f"Error getting crawl results: {str(e)}")
        return []

================
File: tools/crewai_file_writer/crewai_file_writer.py
================
import os
from distutils.util import strtobool
from typing import Any, Optional, Type

from crewai.tools import BaseTool
from pydantic import BaseModel


class FileWriterToolInput(BaseModel):
    filename: str
    directory: Optional[str] = "./"
    overwrite: str = "False"
    content: str


class FileWriterTool(BaseTool):
    name: str = "File Writer Tool"
    description: str = "A tool to write content to a specified file. Accepts filename, content, and optionally a directory path and overwrite flag as input."
    args_schema: Type[BaseModel] = FileWriterToolInput

    def _run(self, **kwargs: Any) -> str:
        try:
            # Create the directory if it doesn't exist
            if kwargs.get("directory") and not os.path.exists(kwargs["directory"]):
                os.makedirs(kwargs["directory"])

            # Construct the full path
            filepath = os.path.join(kwargs.get("directory") or "", kwargs["filename"])

            # Convert overwrite to boolean
            kwargs["overwrite"] = bool(strtobool(kwargs["overwrite"]))

            # Check if file exists and overwrite is not allowed
            if os.path.exists(filepath) and not kwargs["overwrite"]:
                return f"File {filepath} already exists and overwrite option was not passed."

            # Write content to the file
            mode = "w" if kwargs["overwrite"] else "x"
            with open(filepath, mode) as file:
                file.write(kwargs["content"])
            return f"Content successfully written to {filepath}"
        except FileExistsError:
            return (
                f"File {filepath} already exists and overwrite option was not passed."
            )
        except KeyError as e:
            return f"An error occurred while accessing key: {str(e)}"
        except Exception as e:
            return f"An error occurred while writing to the file: {str(e)}"

================
File: tools/csv_search_tool/csv_search_tool.py
================
from typing import Any, Optional, Type

from embedchain.models.data_type import DataType
from pydantic import BaseModel, Field

from ..rag.rag_tool import RagTool


class FixedCSVSearchToolSchema(BaseModel):
    """Input for CSVSearchTool."""

    search_query: str = Field(
        ...,
        description="Mandatory search query you want to use to search the CSV's content",
    )


class CSVSearchToolSchema(FixedCSVSearchToolSchema):
    """Input for CSVSearchTool."""

    csv: str = Field(..., description="Mandatory csv path you want to search")


class CSVSearchTool(RagTool):
    name: str = "Search a CSV's content"
    description: str = (
        "A tool that can be used to semantic search a query from a CSV's content."
    )
    args_schema: Type[BaseModel] = CSVSearchToolSchema

    def __init__(self, csv: Optional[str] = None, **kwargs):
        super().__init__(**kwargs)
        if csv is not None:
            self.add(csv)
            self.description = f"A tool that can be used to semantic search a query the {csv} CSV's content."
            self.args_schema = FixedCSVSearchToolSchema
            self._generate_description()

    def add(
        self,
        *args: Any,
        **kwargs: Any,
    ) -> None:
        kwargs["data_type"] = DataType.CSV
        super().add(*args, **kwargs)

    def _before_run(
        self,
        query: str,
        **kwargs: Any,
    ) -> Any:
        if "csv" in kwargs:
            self.add(kwargs["csv"])

    def _run(
        self,
        search_query: str,
        **kwargs: Any,
    ) -> Any:
        return super()._run(query=search_query, **kwargs)

================
File: tools/csv_search_tool/README.md
================
# CSVSearchTool

## Description

This tool is used to perform a RAG (Retrieval-Augmented Generation) search within a CSV file's content. It allows users to semantically search for queries in the content of a specified CSV file. This feature is particularly useful for extracting information from large CSV datasets where traditional search methods might be inefficient. All tools with "Search" in their name, including CSVSearchTool, are RAG tools designed for searching different sources of data.

## Installation

Install the crewai_tools package

```shell
pip install 'crewai[tools]'
```

## Example

```python
from crewai_tools import CSVSearchTool

# Initialize the tool with a specific CSV file. This setup allows the agent to only search the given CSV file.
tool = CSVSearchTool(csv='path/to/your/csvfile.csv')

# OR

# Initialize the tool without a specific CSV file. Agent  will need to provide the CSV path at runtime.
tool = CSVSearchTool()
```

## Arguments

- `csv` : The path to the CSV file you want to search. This is a mandatory argument if the tool was initialized without a specific CSV file; otherwise, it is optional.

## Custom model and embeddings

By default, the tool uses OpenAI for both embeddings and summarization. To customize the model, you can use a config dictionary as follows:

```python
tool = CSVSearchTool(
    config=dict(
        llm=dict(
            provider="ollama", # or google, openai, anthropic, llama2, ...
            config=dict(
                model="llama2",
                # temperature=0.5,
                # top_p=1,
                # stream=true,
            ),
        ),
        embedder=dict(
            provider="google",
            config=dict(
                model="models/embedding-001",
                task_type="retrieval_document",
                # title="Embeddings",
            ),
        ),
    )
)
```

================
File: tools/directory_read_tool/directory_read_tool.py
================
import os
from typing import Any, Optional, Type
from pydantic import BaseModel, Field
from crewai.tools import BaseTool
import logging
from apps.file_manager.storage import PathManager

logger = logging.getLogger(__name__)


class DirectoryReadToolSchema(BaseModel):
    """Input for DirectoryReadTool."""
    directory: str = Field(default="/", description="Directory to list content within user's media directory")
    user_id: int = Field(..., description="The ID of the user making the request")


class DirectoryReadTool(BaseTool):
    name: str = "List files in directory"
    description: str = (
        "A tool that can be used to list contents within user's media directory."
    )
    args_schema: Type[BaseModel] = DirectoryReadToolSchema

    def _run(self, directory: str, user_id: int) -> str:
        try:
            path_manager = PathManager(user_id=user_id)
            
            # Get directory contents using storage system
            contents = path_manager.list_contents(directory)
            
            if not contents:
                return f"No files or directories found in {directory}"
            
            # Format directory listing
            formatted = []
            for item in contents:
                entry = f"{item['path']}/" if item['type'] == 'directory' else item['path']
                formatted.append(entry)
            
            return "Directory contents:\n- " + "\n- ".join(sorted(formatted))
            
        except Exception as e:
            error_msg = f"Error listing directory: {str(e)}"
            logger.error(error_msg)
            return error_msg

================
File: tools/directory_read_tool/README.md
================
```markdown
# DirectoryReadTool

## Description
The DirectoryReadTool is a highly efficient utility designed for the comprehensive listing of directory contents. It recursively navigates through the specified directory, providing users with a detailed enumeration of all files, including those nested within subdirectories. This tool is indispensable for tasks requiring a thorough inventory of directory structures or for validating the organization of files within directories.

## Installation
Install the `crewai_tools` package to use the DirectoryReadTool in your project. If you haven't added this package to your environment, you can easily install it with pip using the following command:

```shell
pip install 'crewai[tools]'
```

This installs the latest version of the `crewai_tools` package, allowing access to the DirectoryReadTool and other utilities.

## Example
The DirectoryReadTool is simple to use. The code snippet below shows how to set up and use the tool to list the contents of a specified directory:

```python
from crewai_tools import DirectoryReadTool

# Initialize the tool with the directory you want to explore
tool = DirectoryReadTool(directory='/path/to/your/directory')

# Use the tool to list the contents of the specified directory
directory_contents = tool.run()
print(directory_contents)
```

This example demonstrates the essential steps to utilize the DirectoryReadTool effectively, highlighting its simplicity and user-friendly design.

## Arguments
The DirectoryReadTool requires minimal configuration for use. The essential argument for this tool is as follows:

- `directory`: A mandatory argument that specifies the path to the directory whose contents you wish to list. It accepts both absolute and relative paths, guiding the tool to the desired directory for content listing.

The DirectoryReadTool provides a user-friendly and efficient way to list directory contents, making it an invaluable tool for managing and inspecting directory structures.
```

This revised documentation for the DirectoryReadTool maintains the structure and content requirements as outlined, with adjustments made for clarity, consistency, and adherence to the high-quality standards exemplified in the provided documentation example.

================
File: tools/directory_search_tool/directory_search_tool.py
================
from typing import Any, Optional, Type

from embedchain.loaders.directory_loader import DirectoryLoader
from pydantic import BaseModel, Field

from ..rag.rag_tool import RagTool


class FixedDirectorySearchToolSchema(BaseModel):
    """Input for DirectorySearchTool."""

    search_query: str = Field(
        ...,
        description="Mandatory search query you want to use to search the directory's content",
    )


class DirectorySearchToolSchema(FixedDirectorySearchToolSchema):
    """Input for DirectorySearchTool."""

    directory: str = Field(..., description="Mandatory directory you want to search")


class DirectorySearchTool(RagTool):
    name: str = "Search a directory's content"
    description: str = (
        "A tool that can be used to semantic search a query from a directory's content."
    )
    args_schema: Type[BaseModel] = DirectorySearchToolSchema

    def __init__(self, directory: Optional[str] = None, **kwargs):
        super().__init__(**kwargs)
        if directory is not None:
            self.add(directory)
            self.description = f"A tool that can be used to semantic search a query the {directory} directory's content."
            self.args_schema = FixedDirectorySearchToolSchema
            self._generate_description()

    def add(
        self,
        *args: Any,
        **kwargs: Any,
    ) -> None:
        kwargs["loader"] = DirectoryLoader(config=dict(recursive=True))
        super().add(*args, **kwargs)

    def _before_run(
        self,
        query: str,
        **kwargs: Any,
    ) -> Any:
        if "directory" in kwargs:
            self.add(kwargs["directory"])

    def _run(
        self,
        search_query: str,
        **kwargs: Any,
    ) -> Any:
        return super()._run(query=search_query, **kwargs)

================
File: tools/directory_search_tool/README.md
================
# DirectorySearchTool

## Description
This tool is designed to perform a semantic search for queries within the content of a specified directory. Utilizing the RAG (Retrieval-Augmented Generation) methodology, it offers a powerful means to semantically navigate through the files of a given directory. The tool can be dynamically set to search any directory specified at runtime or can be pre-configured to search within a specific directory upon initialization.

## Installation
To start using the DirectorySearchTool, you need to install the crewai_tools package. Execute the following command in your terminal:

```shell
pip install 'crewai[tools]'
```

## Example
The following examples demonstrate how to initialize the DirectorySearchTool for different use cases and how to perform a search:

```python
from crewai_tools import DirectorySearchTool

# To enable searching within any specified directory at runtime
tool = DirectorySearchTool()

# Alternatively, to restrict searches to a specific directory
tool = DirectorySearchTool(directory='/path/to/directory')
```

## Arguments
- `directory` : This string argument specifies the directory within which to search. It is mandatory if the tool has not been initialized with a directory; otherwise, the tool will only search within the initialized directory.

## Custom model and embeddings

By default, the tool uses OpenAI for both embeddings and summarization. To customize the model, you can use a config dictionary as follows:

```python
tool = DirectorySearchTool(
    config=dict(
        llm=dict(
            provider="ollama", # or google, openai, anthropic, llama2, ...
            config=dict(
                model="llama2",
                # temperature=0.5,
                # top_p=1,
                # stream=true,
            ),
        ),
        embedder=dict(
            provider="google",
            config=dict(
                model="models/embedding-001",
                task_type="retrieval_document",
                # title="Embeddings",
            ),
        ),
    )
)
```

================
File: tools/docx_search_tool/docx_search_tool.py
================
from typing import Any, Optional, Type

from embedchain.models.data_type import DataType
from pydantic import BaseModel, Field

from ..rag.rag_tool import RagTool


class FixedDOCXSearchToolSchema(BaseModel):
    """Input for DOCXSearchTool."""

    docx: Optional[str] = Field(
        ..., description="Mandatory docx path you want to search"
    )
    search_query: str = Field(
        ...,
        description="Mandatory search query you want to use to search the DOCX's content",
    )


class DOCXSearchToolSchema(FixedDOCXSearchToolSchema):
    """Input for DOCXSearchTool."""

    search_query: str = Field(
        ...,
        description="Mandatory search query you want to use to search the DOCX's content",
    )


class DOCXSearchTool(RagTool):
    name: str = "Search a DOCX's content"
    description: str = (
        "A tool that can be used to semantic search a query from a DOCX's content."
    )
    args_schema: Type[BaseModel] = DOCXSearchToolSchema

    def __init__(self, docx: Optional[str] = None, **kwargs):
        super().__init__(**kwargs)
        if docx is not None:
            self.add(docx)
            self.description = f"A tool that can be used to semantic search a query the {docx} DOCX's content."
            self.args_schema = FixedDOCXSearchToolSchema
            self._generate_description()

    def add(
        self,
        *args: Any,
        **kwargs: Any,
    ) -> None:
        kwargs["data_type"] = DataType.DOCX
        super().add(*args, **kwargs)

    def _before_run(
        self,
        query: str,
        **kwargs: Any,
    ) -> Any:
        if "docx" in kwargs:
            self.add(kwargs["docx"])

    def _run(
        self,
        **kwargs: Any,
    ) -> Any:
        search_query = kwargs.get("search_query")
        if search_query is None:
            search_query = kwargs.get("query")

        docx = kwargs.get("docx")
        if docx is not None:
            self.add(docx)
        return super()._run(query=search_query, **kwargs)

================
File: tools/docx_search_tool/README.md
================
# DOCXSearchTool

## Description
The DOCXSearchTool is a RAG tool designed for semantic searching within DOCX documents. It enables users to effectively search and extract relevant information from DOCX files using query-based searches. This tool is invaluable for data analysis, information management, and research tasks, streamlining the process of finding specific information within large document collections.

## Installation
Install the crewai_tools package by running the following command in your terminal:

```shell
pip install 'crewai[tools]'
```

## Example
The following example demonstrates initializing the DOCXSearchTool to search within any DOCX file's content or with a specific DOCX file path.

```python
from crewai_tools import DOCXSearchTool

# Initialize the tool to search within any DOCX file's content
tool = DOCXSearchTool()

# OR

# Initialize the tool with a specific DOCX file, so the agent can only search the content of the specified DOCX file
tool = DOCXSearchTool(docx='path/to/your/document.docx')
```

## Arguments
- `docx`: An optional file path to a specific DOCX document you wish to search. If not provided during initialization, the tool allows for later specification of any DOCX file's content path for searching.

## Custom model and embeddings

By default, the tool uses OpenAI for both embeddings and summarization. To customize the model, you can use a config dictionary as follows:

```python
tool = DOCXSearchTool(
    config=dict(
        llm=dict(
            provider="ollama", # or google, openai, anthropic, llama2, ...
            config=dict(
                model="llama2",
                # temperature=0.5,
                # top_p=1,
                # stream=true,
            ),
        ),
        embedder=dict(
            provider="google",
            config=dict(
                model="models/embedding-001",
                task_type="retrieval_document",
                # title="Embeddings",
            ),
        ),
    )
)
```

================
File: tools/file_read_tool/file_read_tool.py
================
from typing import Any, Type
from pydantic import BaseModel, Field
from langchain.schema import StrOutputParser
from crewai.tools import BaseTool
import logging
from django.conf import settings
from django.core.files.storage import default_storage
from apps.file_manager.storage import PathManager

logger = logging.getLogger(__name__)

class FileReadToolSchema(BaseModel):
    """Input schema for FileReadTool."""
    file_path: str = Field(..., description="File path within user's media directory")
    user_id: int = Field(..., description="The ID of the user making the request")

class FileReadTool(BaseTool):
    name: str = "File Read Tool"
    description: str = "A tool that can be used to read a file's content within user's media directory."
    args_schema: Type[BaseModel] = FileReadToolSchema

    def _run(self, file_path: str, user_id: int) -> str:
        try:
            # Initialize PathManager with user_id
            path_manager = PathManager(user_id=user_id)
            logger.debug("reading file with file_reader")
            
            # Get full path using PathManager
            full_path = path_manager._get_full_path(file_path)
            logger.debug(f"Reading from path: {full_path}")
            
            # Check if file exists
            if not default_storage.exists(full_path):
                error_msg = f"File {file_path} does not exist"
                logger.error(error_msg)
                return error_msg
            
            # Read content using default_storage
            with default_storage.open(full_path, 'r') as file:
                content = file.read()
                
            logger.debug(f"Successfully read file: {file_path}")
            return content
            
        except Exception as e:
            error_msg = f"Failed to read the file {file_path}. Error: {str(e)}"
            logger.error(error_msg)
            return error_msg

================
File: tools/file_read_tool/README.md
================
# FileReadTool

## Description
The FileReadTool is a versatile component of the crewai_tools package, designed to streamline the process of reading and retrieving content from files. It is particularly useful in scenarios such as batch text file processing, runtime configuration file reading, and data importation for analytics. This tool supports various text-based file formats including `.txt`, `.csv`, `.json`, and adapts its functionality based on the file type, for instance, converting JSON content into a Python dictionary for easy use.

## Installation
Install the crewai_tools package to use the FileReadTool in your projects:

```shell
pip install 'crewai[tools]'
```

## Example
To get started with the FileReadTool:

```python
from crewai_tools import FileReadTool

# Initialize the tool to read any files the agents knows or lean the path for
file_read_tool = FileReadTool()

# OR

# Initialize the tool with a specific file path, so the agent can only read the content of the specified file
file_read_tool = FileReadTool(file_path='path/to/your/file.txt')
```

## Arguments
- `file_path`: The path to the file you want to read. It accepts both absolute and relative paths. Ensure the file exists and you have the necessary permissions to access it.

================
File: tools/file_writer_tool/file_writer_tool.py
================
import os
from typing import Any, Optional, Type, Dict
from pydantic import BaseModel, Field
from crewai.tools import BaseTool
import logging
from django.core.files.storage import default_storage
from django.core.files.base import ContentFile
from apps.file_manager.storage import PathManager
from distutils.util import strtobool

logger = logging.getLogger(__name__)


class FileWriterToolSchema(BaseModel):
    """Input schema for the FileWriterTool."""
    filename: str = Field(..., description="The name of the file to write to.")
    content: str = Field(..., description="The content to write to the file.")
    user_id: int = Field(..., description="The ID of the user making the request.")
    directory: Optional[str] = Field(None, description="Optional directory path within user's media directory.")
    overwrite: str = "False" # String type, default "False"


class FileWriterTool(BaseTool):
    name: str = "File Writer Tool"
    description: str = (
        "A tool to write content to a specified file within user's media directory. "
        "Accepts filename, content, and optionally a directory path and overwrite flag as input."
        "Returns a success message if the file is written successfully, otherwise returns an error message."
    )
    args_schema: Type[FileWriterToolSchema] = FileWriterToolSchema

    def _run(self, **kwargs: Any) -> str:
        logger.debug(f"FileWriterTool received RAW kwargs: {repr(kwargs)}") # Log RAW kwargs
        logger.debug(f"FileWriterTool received kwargs TYPE: {type(kwargs)}") # Log kwargs type
        logger.debug(f"FileWriterTool received kwargs KEYS: {kwargs.keys()}") # Log the keys
        try:
            filename = kwargs["filename"]
            content = kwargs["content"]
            user_id = kwargs["user_id"]
            directory = kwargs.get('directory', '/')  # Default to '/' if not provided
            
            # Handle cases where directory is explicitly 'None' as string
            if directory is None or directory == 'None':
                directory = '/'
                
            overwrite_str = kwargs["overwrite"]
            overwrite = bool(strtobool(overwrite_str))

            # Log the input parameters
            logger.debug(f"Writing file: {filename}, directory: {directory}, user_id: {user_id}, overwrite: {overwrite}")
            logger.debug(f"Content preview: {content[:100]}...")

            # Initialize PathManager with user_id
            path_manager = PathManager(user_id=user_id)

            # Construct the file path
            filepath = os.path.join(str(directory), str(filename)).lstrip('/')
            full_path = path_manager._get_full_path(filepath)

            logger.debug(f"Writing to path: {full_path}")

            # Check if file exists and overwrite is not allowed
            if default_storage.exists(full_path) and not overwrite:
                logger.error(f"File {filename} already exists and overwrite option was not passed.")
                return f"Error: File {filename} already exists and overwrite option was not passed."

            # Write content to the file using default_storage
            try:
                content_file = ContentFile(content.encode('utf-8'))
                if overwrite and default_storage.exists(full_path):
                    default_storage.delete(full_path)

                saved_path = default_storage.save(full_path, content_file)
                logger.debug(f"Successfully wrote content to {saved_path}")
                return f"SUCCESS: File '{filename}' written to {saved_path} (Length: {len(content)} chars)"

            except UnicodeEncodeError as ue:
                error_msg = f"Error encoding content: {str(ue)}"
                logger.error(error_msg)
                return f"ERROR: {error_msg}"

        except KeyError as ke:
            error_msg = f"Missing required key in input: {str(ke)}"
            logger.error(error_msg)
            return f"Error: {error_msg}"
        except Exception as e:
            error_msg = f"An error occurred while writing to the file: {str(e)}"
            logger.error(error_msg)
            return f"Error: {error_msg}"

================
File: tools/file_writer_tool/README.md
================
Here's the rewritten README for the `FileWriterTool`:

# FileWriterTool Documentation

## Description
The `FileWriterTool` is a component of the crewai_tools package, designed to simplify the process of writing content to files. It is particularly useful in scenarios such as generating reports, saving logs, creating configuration files, and more. This tool supports creating new directories if they don't exist, making it easier to organize your output.

## Installation
Install the crewai_tools package to use the `FileWriterTool` in your projects:

```shell
pip install 'crewai[tools]'
```

## Example
To get started with the `FileWriterTool`:

```python
from crewai_tools import FileWriterTool

# Initialize the tool
file_writer_tool = FileWriterTool()

# Write content to a file in a specified directory
result = file_writer_tool._run('example.txt', 'This is a test content.', 'test_directory')
print(result)
```

## Arguments
- `filename`: The name of the file you want to create or overwrite.
- `content`: The content to write into the file.
- `directory` (optional): The path to the directory where the file will be created. Defaults to the current directory (`.`). If the directory does not exist, it will be created.

## Conclusion
By integrating the `FileWriterTool` into your crews, the agents can execute the process of writing content to files and creating directories. This tool is essential for tasks that require saving output data, creating structured file systems, and more. By adhering to the setup and usage guidelines provided, incorporating this tool into projects is straightforward and efficient.

================
File: tools/google_analytics_tool/generic_google_analytics_tool.py
================
import os
import json
import logging
import sys
from typing import Any, Type, List, Optional, ClassVar
from pydantic import BaseModel, Field, field_validator
from google.analytics.data_v1beta.types import DateRange, Metric, Dimension, RunReportRequest, OrderBy, RunReportResponse
from datetime import datetime
from crewai.tools import BaseTool
from google.analytics.data_v1beta import BetaAnalyticsDataClient
from google.analytics.data_v1beta.types import CheckCompatibilityRequest
from enum import Enum
from typing import Optional, List, Union
import pandas as pd
from datetime import datetime, timedelta
from apps.common.utils import DateProcessor

# Import Django models (assuming this is your setup)
from django.core.exceptions import ObjectDoesNotExist
from apps.seo_manager.models import Client, GoogleAnalyticsCredentials

logger = logging.getLogger(__name__)

"""
Generic Google Analytics Tool for fetching customizable GA4 data.

Example usage:
    tool = GenericGoogleAnalyticsTool()
    
    # Basic usage with defaults
    result = tool._run(client_id=123)
    
    # Custom query
    result = tool._run(
        client_id=123,
        start_date="7daysAgo",
        end_date="today", 
        metrics="totalUsers,sessions,bounceRate",
        dimensions="date,country,deviceCategory",
        dimension_filter="country==United States",
        metric_filter="sessions>100",
        currency_code="USD",
        limit=2000
    )
"""

class TimeGranularity(str, Enum):
    DAILY = "daily"
    WEEKLY = "weekly"
    MONTHLY = "monthly"
    AUTO = "auto"

class DataFormat(str, Enum):
    RAW = "raw"
    SUMMARY = "summary"
    COMPACT = "compact"

class MetricAggregation(str, Enum):
    SUM = "sum"
    AVERAGE = "average"
    MIN = "min"
    MAX = "max"

class GoogleAnalyticsRequest(BaseModel):
    """Input schema for the generic Google Analytics Request tool."""
    start_date: str = Field(
        default="28daysAgo",
        description="""
        Start date in one of these formats:
        - YYYY-MM-DD (e.g., 2024-03-15)
        - Relative days: 'today', 'yesterday', 'NdaysAgo' (e.g., 7daysAgo)
        - Relative months: 'NmonthsAgo' (e.g., 3monthsAgo)
        
        Note: While GA4 API only supports days, this tool automatically converts
        month-based dates to the appropriate day format.
        """
    )
    end_date: str = Field(
        default="yesterday",
        description="""
        End date in one of these formats:
        - YYYY-MM-DD (e.g., 2024-03-15)
        - Relative days: 'today', 'yesterday', 'NdaysAgo' (e.g., 7daysAgo)
        - Relative months: 'NmonthsAgo' (e.g., 3monthsAgo)
        """
    )
    client_id: int = Field(
        description="The ID of the client."
    )
    metrics: str = Field(
        default="totalUsers,sessions",
        description="Comma-separated list of metric names."
    )
    dimensions: str = Field(
        default="date",
        description="Comma-separated list of dimension names (e.g., 'date,country,deviceCategory')."
    )
    dimension_filter: Optional[str] = Field(
        default=None,
        description="Filter expression for dimensions (e.g., 'country==United States')."
    )
    metric_filter: Optional[str] = Field(
        default=None,
        description="Filter expression for metrics (e.g., 'sessions>100')."
    )
    currency_code: Optional[str] = Field(
        default=None,
        description="The currency code for metrics involving currency (e.g., 'USD')."
    )
    keep_empty_rows: Optional[bool] = Field(
        default=False,
        description="Whether to keep empty rows in the response."
    )
    limit: Optional[int] = Field(
        default=1000,
        description="Optional limit on the number of rows to return (default 1000, max 100000)."
    )
    offset: Optional[int] = Field(
        default=None,
        description="Optional offset for pagination."
    )
    data_format: DataFormat = Field(
        default=DataFormat.RAW,
        description="""
        How to format the returned data:
        - 'raw': Returns all data points (use for detailed analysis)
        - 'summary': Returns statistical summary (min/max/mean/median) - best for high-level insights
        - 'compact': Returns top N results (good for finding top performers)
        
        Example use cases:
        - For trend analysis: use 'raw' with date dimension
        - For performance overview: use 'summary'
        - For top traffic sources: use 'compact' with top_n=5
        """
    )
    top_n: Optional[int] = Field(
        default=None,
        description="""
        Return only top N results by primary metric.
        
        Example use cases:
        - top_n=5 with dimensions="country"  top 5 countries
        - top_n=10 with dimensions="pagePath"  top 10 pages
        - top_n=3 with dimensions="sessionSource"  top 3 traffic sources
        """
    )
    time_granularity: TimeGranularity = Field(
        default=TimeGranularity.AUTO,
        description="""
        Time period to aggregate data by:
        - 'daily': Keep daily granularity (best for 1-7 day ranges)
        - 'weekly': Group by weeks (best for 8-60 day ranges)
        - 'monthly': Group by months (best for 60+ day ranges)
        - 'auto': Automatically choose based on date range
        
        Example use cases:
        - For last week analysis: use 'daily'
        - For quarterly trends: use 'monthly'
        - For year-over-year: use 'monthly'
        """
    )
    aggregate_by: Optional[List[str]] = Field(
        default=None,
        description="""
        Dimensions to group data by. Combines all other dimensions.
        
        Example use cases:
        - ['country']  aggregate all metrics by country
        - ['deviceCategory']  combine data across all devices
        - ['sessionSource', 'country']  group by both source and country
        
        Common combinations:
        - Traffic analysis: ['sessionSource', 'sessionMedium']
        - Geographic insights: ['country', 'city']
        - Device analysis: ['deviceCategory', 'browser']
        """
    )
    metric_aggregation: MetricAggregation = Field(
        default=MetricAggregation.SUM,
        description="How to aggregate metrics when grouping data"
    )
    include_percentages: bool = Field(
        default=False,
        description="""
        Add percentage calculations relative to totals.
        Adds '_pct' suffix to metric names (e.g., 'sessions_pct').
        
        Example use cases:
        - Traffic distribution: see % of sessions by country
        - Device share: % of users by deviceCategory
        - Source attribution: % of conversions by source
        """
    )
    normalize_metrics: bool = Field(
        default=False,
        description="""
        Scale numeric metrics to 0-1 range for easier comparison.
        Adds '_normalized' suffix to metric names.
        
        Use when:
        - Comparing metrics with different scales
        - Looking for relative performance
        - Creating visualizations
        """
    )
    round_digits: Optional[int] = Field(
        default=None,
        description="Round numeric values to specified digits"
    )
    include_period_comparison: bool = Field(
        default=False,
        description="""
        Include comparison with previous period.
        
        Example use cases:
        - Month-over-month growth
        - Year-over-year comparison
        - Week-over-week performance
        
        Returns additional fields:
        - previous_period_value
        - percentage_change
        """
    )
    detect_anomalies: bool = Field(
        default=False,
        description="Identify significant deviations from normal patterns"
    )
    moving_average_window: Optional[int] = Field(
        default=None,
        description="""
        Calculate moving averages over specified number of periods.
        Only applies when data includes the 'date' dimension.
        
        Example use cases:
        - 7-day moving average for smoothing daily fluctuations
        - 30-day moving average for trend analysis
        - 90-day moving average for long-term patterns
        
        Adds '_ma{window}' suffix to metric names (e.g., 'sessions_ma7')
        """
    )

    @field_validator("start_date", "end_date")
    @classmethod
    def validate_dates(cls, value: str) -> str:
        return DateProcessor.process_relative_date(value)

class GenericGoogleAnalyticsTool(BaseTool):
    name: str = "GA4 Analytics Data Tool"
    description: str = """
    Fetches data from Google Analytics 4 (GA4) with powerful data processing capabilities.
    
    Key Features:
    - Flexible date ranges (e.g., '7daysAgo', '3monthsAgo', 'YYYY-MM-DD')
    - Common metrics: sessions, users, pageviews, bounce rate, etc.
    - Dimensions: date, country, device, source, medium, etc.
    - Data processing: aggregation, filtering, summaries
    
    Example Commands:
    1. Basic traffic data:
       tool._run(client_id=123, metrics="sessions,users", dimensions="date")
    
    2. Top countries by sessions:
       tool._run(
           client_id=123,
           metrics="sessions",
           dimensions="country",
           data_format="compact",
           top_n=5
       )
    
    3. Monthly trend with comparisons:
       tool._run(
           client_id=123,
           start_date="6monthsAgo",
           time_granularity="monthly",
           include_period_comparison=True
       )
    """
    args_schema: Type[BaseModel] = GoogleAnalyticsRequest
    
    def __init__(self, **kwargs):
        super().__init__()
        logger.info("GenericGoogleAnalyticsTool initialized")
        self._initialize_dimensions_metrics()

    def _initialize_dimensions_metrics(self):
        """Initialize the available dimensions and metrics"""
        self._available_metrics = [
            "totalUsers",
            "sessions",
            "averageSessionDuration",
            "screenPageViews",
            "screenPageViewsPerSession",
            "newUsers",
            "firstVisit",
            "bounceRate",
            "engagedSessions",
            "engagementRate",
            "activeUsers",
            "eventCount",
            "eventsPerSession",
            "keyEvents",
            "conversions",
            "userEngagementDuration",
            "grossPurchaseRevenue",
            "averagePurchaseRevenuePerPayingUser",
            "averageRevenuePerUser",
            "addToCarts",
            "ecommercePurchases",
            "advertiserAdCost",
            "advertiserAdCostPerClick",
            "advertiserAdImpressions",
            "advertiserAdClicks",
            "totalRevenue"
        ]
        
        # Add metric type classifications
        self._summable_metrics = {
            "totalUsers",
            "sessions",
            "screenPageViews",
            "newUsers",
            "firstVisit",
            "engagedSessions",
            "activeUsers",
            "eventCount",
            "keyEvents",
            "conversions",
            "userEngagementDuration",
            "totalRevenue",
            "advertiserAdClicks",
            "advertiserAdImpressions",
            "advertiserAdCost",
            "grossPurchaseRevenue",
            "totalRevenue",
 

        }
        
        self._averaged_metrics = {
            "averageSessionDuration",
            "screenPageViewsPerSession",
            "bounceRate",
            "engagementRate",
            "eventsPerSession",
            "averagePurchaseRevenuePerPayingUser",
            "averageRevenuePerUser",
            "advertiserAdCostPerClick",
            "averageSessionDuration"
        }

        self._available_dimensions = [
            "date",
            "deviceCategory",
            "platform",
            "sessionSource",
            "sessionMedium",
            "sessionCampaignName",
            "sessionDefaultChannelGroup",
            "country",
            "city",
            "landingPage",
            "pagePath",
            "browser",
            "operatingSystem",
            "sessionCampaignName",
            "sessionGoogleAdsAdGroupName",
            "firstUserGoogleAdsGroupName",
            "defaultChannelGroup",
            "sessionSourceMedium",
            "userGender",
            "city",
            "country",
            "continent",
            "region",
            "metro",
            "brandingInterests",
            "dayOfWeek",
            "dayofWeekName",
            "Hour",
            "newVsReturning",
            "userAgeBracket",
            "eventName",
            "landingPage",
            "firstUserSourceMedium",
            "firstUserMedium",
            "firstUserPrimaryChannelGroup",
            "firstUserDefaultChannelGroup",
            "firstUserSource",
            "firstUserSourcePlatform",
            "firstUserCampaignName",
            "sessiongoogleAdsAdGroupName",
            "firstUserGoogleAdsKeyword",
            "firstuserGoogleAdsQuery",
            "googleAdsKeyword",
            "googleAdsQuery"
        ]

    def _check_compatibility(self, service, property_id: str, metrics: List[str], dimensions: List[str]) -> tuple[bool, str]:
        """
        Check if the requested metrics and dimensions are compatible.
        Returns a tuple of (is_compatible: bool, error_message: str)
        """
        try:
            # Create separate metric and dimension objects
            metric_objects = [Metric(name=m.strip()) for m in metrics]
            dimension_objects = [Dimension(name=d.strip()) for d in dimensions]

            request = CheckCompatibilityRequest(
                property=f"properties/{property_id}",
                metrics=metric_objects,
                dimensions=dimension_objects
            )
            
            response = service.check_compatibility(request=request)

            # Check for dimension errors
            if response.dimension_compatibilities:
                for dim_compat in response.dimension_compatibilities:
                    dim_name = getattr(dim_compat.dimension_metadata, 'api_name', 'unknown')
                    if dim_name in dimensions:
                        if dim_compat.compatibility == 'INCOMPATIBLE':
                            error_msg = f"Incompatible dimension: {dim_name}"
                            logger.error(error_msg)
                            return False, error_msg
            
            # Check for metric errors
            if response.metric_compatibilities:
                for metric_compat in response.metric_compatibilities:
                    metric_name = getattr(metric_compat.metric_metadata, 'api_name', 'unknown')
                    if metric_name in metrics:
                        if metric_compat.compatibility == 'INCOMPATIBLE':
                            error_msg = f"Incompatible metric: {metric_name}"
                            logger.error(error_msg)
                            return False, error_msg
            
            return True, "Compatible"

        except Exception as e:
            logger.error(f"Error checking compatibility: {str(e)}", exc_info=True)
            # Return a more graceful fallback - assume compatible if check fails
            return True, "Compatibility check failed, proceeding with request"

    def _run(self,
             client_id: int,
             start_date: str = "28daysAgo",
             end_date: str = "today",
             metrics: str = "totalUsers,sessions",
             dimensions: str = "date",
             dimension_filter: Optional[str] = None,
             metric_filter: Optional[str] = None,
             currency_code: Optional[str] = None,
             keep_empty_rows: bool = False,
             limit: int = 1000,
             offset: Optional[int] = None,
             data_format: DataFormat = DataFormat.RAW,
             top_n: Optional[int] = None,
             time_granularity: TimeGranularity = TimeGranularity.AUTO,
             aggregate_by: Optional[List[str]] = None,
             metric_aggregation: MetricAggregation = MetricAggregation.SUM,
             include_percentages: bool = False,
             normalize_metrics: bool = False,
             round_digits: Optional[int] = None,
             include_period_comparison: bool = False,
             detect_anomalies: bool = False,
             moving_average_window: Optional[int] = None) -> dict:
        try:
            # Convert kwargs to GoogleAnalyticsRequest
            request_params = GoogleAnalyticsRequest(
                client_id=client_id,
                start_date=start_date,
                end_date=end_date,
                metrics=metrics,
                dimensions=dimensions,
                dimension_filter=dimension_filter,
                metric_filter=metric_filter,
                currency_code=currency_code,
                keep_empty_rows=keep_empty_rows,
                limit=limit,
                offset=offset,
                data_format=data_format,
                top_n=top_n,
                time_granularity=time_granularity,
                aggregate_by=aggregate_by,
                metric_aggregation=metric_aggregation,
                include_percentages=include_percentages,
                normalize_metrics=normalize_metrics,
                round_digits=round_digits,
                include_period_comparison=include_period_comparison,
                detect_anomalies=detect_anomalies,
                moving_average_window=moving_average_window
            )
            
            # Get client and credentials
            client = Client.objects.get(id=request_params.client_id)
            ga_credentials = client.ga_credentials
            if not ga_credentials:
                raise ValueError("Missing Google Analytics credentials")
            
            service = ga_credentials.get_service()
            if not service:
                raise ValueError("Failed to initialize Analytics service")
            
            property_id = ga_credentials.get_property_id()
            if not property_id:
                raise ValueError("Missing or invalid Google Analytics property ID")

            # Check compatibility before running the report
            metrics_list = [m.strip() for m in request_params.metrics.split(',')]
            dimensions_list = [d.strip() for d in request_params.dimensions.split(',')]
            
            # Validate metrics and dimensions against available lists
            for metric in metrics_list:
                if metric not in self._available_metrics:
                    return {
                        'success': False,
                        'error': f"Invalid metric: {metric}. Available metrics: {', '.join(self._available_metrics)}",
                        'analytics_data': []
                    }
            
            for dimension in dimensions_list:
                if dimension not in self._available_dimensions:
                    return {
                        'success': False,
                        'error': f"Invalid dimension: {dimension}. Available dimensions: {', '.join(self._available_dimensions)}",
                        'analytics_data': []
                    }
            
            is_compatible, error_message = self._check_compatibility(
                service, 
                property_id, 
                metrics_list, 
                dimensions_list
            )
            
            if not is_compatible:
                return {
                    'success': False,
                    'error': error_message,
                    'analytics_data': []
                }
            # Log the request parameters for debugging
            logger.debug("Creating RunReportRequest with parameters: %s", {
                "property": f"properties/{property_id}",
                "date_ranges": [{
                    "start_date": request_params.start_date,
                    "end_date": request_params.end_date
                }],
                "metrics": [{"name": m.strip()} for m in request_params.metrics.split(',')],
                "dimensions": [{"name": d.strip()} for d in request_params.dimensions.split(',')],
                "dimension_filter": request_params.dimension_filter,
                "metric_filter": request_params.metric_filter,
                "currency_code": request_params.currency_code,
                "keep_empty_rows": request_params.keep_empty_rows,
                "limit": request_params.limit,
                "offset": request_params.offset,
                "order_bys": [
                    {
                        "dimension": {
                            "dimension_name": "date"
                        },
                        "desc": False
                    }
                ] if "date" in dimensions_list else None,
                "return_property_quota": True
            })
            # Create the RunReportRequest
            request = RunReportRequest({
                "property": f"properties/{property_id}",
                "date_ranges":[DateRange(
                    start_date=request_params.start_date,
                    end_date=request_params.end_date
                )],
                "metrics": [{"name": m.strip()} for m in request_params.metrics.split(',')],
                "dimensions": [{"name": d.strip()} for d in request_params.dimensions.split(',')],
                "dimension_filter": self._parse_filter(request_params.dimension_filter) if request_params.dimension_filter else None,
                "metric_filter": self._parse_filter(request_params.metric_filter) if request_params.metric_filter else None,
                "currency_code": request_params.currency_code,
                "keep_empty_rows": request_params.keep_empty_rows,
                "limit": request_params.limit,
                "offset": request_params.offset,
                "order_bys": [
                    {
                        "dimension": {
                            "dimension_name": "date"
                        },
                        "desc": False
                    }
                ] if "date" in dimensions_list else None,
                "return_property_quota": True
            })

            # Get the raw response
            response = service.run_report(request)
            
            # Format the raw response
            raw_data = self._format_response(response, 
                                           request_params.metrics.split(','), 
                                           request_params.dimensions.split(','))
            
            # Process the data according to the request parameters
            if raw_data['success']:
                processed_data = DataProcessor.process_data(
                    raw_data['analytics_data'], 
                    request_params,
                    self._averaged_metrics
                )
                
                # Handle period comparison format
                if isinstance(processed_data, dict) and 'period_comparison' in processed_data:
                    return {
                        'success': True,
                        'analytics_data': processed_data['data'],
                        'period_comparison': processed_data['period_comparison']
                    }
                
                return {
                    'success': True,
                    'analytics_data': processed_data
                }
            
            return raw_data

        except Exception as e:
            logger.error(f"Error in Google Analytics tool: {str(e)}", exc_info=True)
            return {
                'success': False,
                'error': str(e),
                'analytics_data': []
            }

    def _parse_filter(self, filter_string: str) -> dict:
        """
        Parse filter string into GA4 filter object.
        Examples:
            - "country==United States" -> exact string match
            - "sessions>100" -> numeric greater than
        """
        try:
            if '==' in filter_string:
                field, value = filter_string.split('==')
                return {
                    "filter": {
                        "field_name": field.strip(),
                        "string_filter": {
                            "value": value.strip(),
                            "match_type": "EXACT",
                            "case_sensitive": False
                        }
                    }
                }
            elif '>' in filter_string:
                field, value = filter_string.split('>')
                return {
                    "filter": {
                        "field_name": field.strip(),
                        "numeric_filter": {
                            "operation": "GREATER_THAN",
                            "value": {
                                "int64_value": int(float(value.strip()))
                            }
                        }
                    }
                }
            
            raise ValueError(f"Unsupported filter format: {filter_string}")
        except Exception as e:
            logger.error(f"Error parsing filter: {str(e)}")
            return None
        
    def _format_response(self, response, metrics: List[str], dimensions: List[str]) -> dict:
        try:
            analytics_data = []
            # Clean dimension names - strip whitespace
            dimensions = [d.strip() for d in dimensions]



            if not hasattr(response, 'rows'):
                return {
                    'success': False,
                    'error': 'No rows in response',
                    'analytics_data': []
                }

            for row in response.rows:
                data_point = {}
                for i, dim in enumerate(dimensions):
                    value = row.dimension_values[i].value
                    if dim == 'date':
                        value = f"{value[:4]}-{value[4:6]}-{value[6:]}"
                    data_point[dim] = value
                for i, metric in enumerate(metrics):
                    try:
                        data_point[metric] = float(row.metric_values[i].value) if row.metric_values[i].value else 0
                    except (ValueError, TypeError):
                        data_point[metric] = 0
                analytics_data.append(data_point)

            return {
                'success': True,
                'analytics_data': analytics_data
            }
        except Exception as e:
            logger.error(f"Error formatting response: {str(e)}", exc_info=True)
            return {
                'success': False,
                'error': f"Failed to format response: {str(e)}",
                'analytics_data': []
            }

class DataProcessor:
    @staticmethod
    def determine_granularity(start_date: str, end_date: str) -> TimeGranularity:
        """Automatically determine appropriate time granularity"""
        try:
            start = datetime.strptime(start_date[:10], "%Y-%m-%d")
            end = datetime.strptime(end_date[:10], "%Y-%m-%d")
            days_difference = (end - start).days
            
            if days_difference <= 7:
                return TimeGranularity.DAILY
            elif days_difference <= 60:
                return TimeGranularity.WEEKLY
            return TimeGranularity.MONTHLY
        except ValueError:
            return TimeGranularity.DAILY

    @staticmethod
    def _calculate_moving_averages(df: pd.DataFrame, window: int, metrics: List[str]) -> pd.DataFrame:
        """Calculate moving averages for specified metrics"""
        if 'date' not in df.columns:
            return df
            
        # Ensure date is datetime for proper sorting
        df['date'] = pd.to_datetime(df['date'])
        df = df.sort_values('date')
        
        for metric in metrics:
            if metric in df.columns:
                df[f'{metric}_ma{window}'] = df[metric].rolling(
                    window=window,
                    min_periods=1  # Allow partial windows at the start
                ).mean()
        
        return df

    @staticmethod
    def _add_period_comparison(df: pd.DataFrame, metrics: List[str]) -> pd.DataFrame:
        """Add period-over-period comparison metrics"""
        if 'date' not in df.columns:
            return df
        
        # Ensure date is datetime for proper sorting
        df['date'] = pd.to_datetime(df['date'])
        df = df.sort_values('date')
        
        # Calculate the period length
        total_days = (df['date'].max() - df['date'].min()).days
        period_length = total_days // 2
        
        # Create a cutoff date for splitting current and previous periods
        cutoff_date = df['date'].max() - pd.Timedelta(days=period_length)
        
        # Split into current and previous periods
        current_period = df[df['date'] > cutoff_date].copy()
        previous_period = df[df['date'] <= cutoff_date].copy()
        
        # Calculate metrics for both periods
        comparison_data = {}
        
        for metric in metrics:
            if metric in df.columns:
                current_value = float(current_period[metric].mean())  # Convert to float
                previous_value = float(previous_period[metric].mean())  # Convert to float
                
                # Add comparison metrics
                df[f'{metric}_previous'] = previous_value
                df[f'{metric}_change'] = ((current_value - previous_value) / previous_value * 100 
                                        if previous_value != 0 else 0)
                
                comparison_data[metric] = {
                    'current_period': current_value,
                    'previous_period': previous_value,
                    'percent_change': float((current_value - previous_value) / previous_value * 100 
                                         if previous_value != 0 else 0)
                }
        
        # Add comparison summary to the DataFrame
        df.attrs['period_comparison'] = comparison_data
        
        return df

    @staticmethod
    def process_data(data: List[dict], params: GoogleAnalyticsRequest, averaged_metrics: set) -> List[dict]:
        """Process the analytics data based on request parameters"""
        if not data:
            return data

        df = pd.DataFrame(data)

        # Convert date column to datetime if it exists and isn't already datetime
        if 'date' in df.columns and not pd.api.types.is_datetime64_any_dtype(df['date']):
            df['date'] = pd.to_datetime(df['date'])

        # Apply time granularity aggregation if needed
        if params.time_granularity != TimeGranularity.DAILY and 'date' in df.columns:
            df = DataProcessor._aggregate_by_time(df, params.time_granularity, averaged_metrics)

        # Calculate moving averages if requested
        if params.moving_average_window and 'date' in df.columns:
            df = DataProcessor._calculate_moving_averages(
                df,
                params.moving_average_window,
                params.metrics.split(',')
            )

        # Add period comparison if requested
        if params.include_period_comparison and 'date' in df.columns:
            df = DataProcessor._add_period_comparison(
                df,
                params.metrics.split(',')
            )

        # Apply dimension aggregation if specified
        if params.aggregate_by:
            df = DataProcessor._aggregate_by_dimensions(
                df, 
                params.aggregate_by, 
                params.metric_aggregation
            )

        # Apply top N filter
        if params.data_format == DataFormat.COMPACT and params.top_n:
            primary_metric = params.metrics.split(',')[0]
            df = df.nlargest(params.top_n, primary_metric)

        # Add percentages if requested
        if params.include_percentages:
            DataProcessor._add_percentages(df, params.metrics.split(','))

        # Normalize metrics if requested
        if params.normalize_metrics:
            DataProcessor._normalize_metrics(df, params.metrics.split(','))

        # Round values if specified
        if params.round_digits is not None:
            numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns
            df[numeric_cols] = df[numeric_cols].round(params.round_digits)

        # Generate summary if requested
        if params.data_format == DataFormat.SUMMARY:
            return DataProcessor._generate_summary(df, params)

        # Before returning, convert datetime objects to strings if they exist
        if 'date' in df.columns:
            if pd.api.types.is_datetime64_any_dtype(df['date']):
                df['date'] = df['date'].dt.strftime('%Y-%m-%d')
            elif isinstance(df['date'].iloc[0], str) and 'W' in df['date'].iloc[0]:
                # Already in week format, leave as is
                pass
            elif isinstance(df['date'].iloc[0], str) and len(df['date'].iloc[0].split('-')) == 2:
                # Already in month format, leave as is
                pass
            else:
                # Try to format as date string if possible
                try:
                    df['date'] = pd.to_datetime(df['date']).dt.strftime('%Y-%m-%d')
                except:
                    pass  # Keep original format if conversion fails

        # Format the response to include period comparison data if it exists
        result = df.to_dict('records')
        if params.include_period_comparison and hasattr(df, 'attrs') and 'period_comparison' in df.attrs:
            # Ensure datetime objects in comparison data are converted to strings
            comparison_data = df.attrs['period_comparison']
            for metric, values in comparison_data.items():
                if isinstance(values.get('current_period'), pd.Timestamp):
                    values['current_period'] = values['current_period'].strftime('%Y-%m-%d')
                if isinstance(values.get('previous_period'), pd.Timestamp):
                    values['previous_period'] = values['previous_period'].strftime('%Y-%m-%d')
            
            return {
                'data': result,
                'period_comparison': comparison_data
            }
        
        return result

    @staticmethod
    def _aggregate_by_time(df: pd.DataFrame, granularity: TimeGranularity, 
                          averaged_metrics: set) -> pd.DataFrame:
        """
        Aggregate time-based data with proper handling of averaged metrics.
        
        Args:
            df: DataFrame to aggregate
            granularity: TimeGranularity enum value
            averaged_metrics: Set of metrics that should be averaged (weighted)
        """
        # Ensure date is datetime
        df = df.copy()  # Create a copy to avoid modifying original
        df['date'] = pd.to_datetime(df['date'])
        
        # Get all non-date columns that should be preserved in grouping
        group_cols = [col for col in df.columns if col != 'date' and not pd.api.types.is_numeric_dtype(df[col])]
        
        # Create a grouping date column while preserving original
        if granularity == TimeGranularity.WEEKLY:
            df['grouping_date'] = df['date'].dt.strftime('%Y-W%W')
        elif granularity == TimeGranularity.MONTHLY:
            df['grouping_date'] = df['date'].dt.strftime('%Y-%m')
        else:
            df['grouping_date'] = df['date'].dt.strftime('%Y-%m-%d')
        
        # Add grouping_date to group columns
        group_cols.append('grouping_date')
        
        # Create aggregation dictionary based on metric type
        agg_dict = {}
        
        for col in df.select_dtypes(include=['float64', 'int64']).columns:
            # For metrics like bounceRate, we need to calculate weighted average
            if col in averaged_metrics:
                # For bounce rate and engagement rate, weight by sessions
                if col in ['bounceRate', 'engagementRate']:
                    # Calculate weighted sum
                    df[f'{col}_weighted'] = df[col] * df['sessions']
                    agg_dict[f'{col}_weighted'] = 'sum'
                    agg_dict['sessions'] = 'sum'
                # For averageSessionDuration, weight by number of sessions
                elif col == 'averageSessionDuration':
                    df[f'{col}_weighted'] = df[col] * df['sessions']
                    agg_dict[f'{col}_weighted'] = 'sum'
                    agg_dict['sessions'] = 'sum'
                # For screenPageViewsPerSession, weight by sessions
                elif col == 'screenPageViewsPerSession':
                    df[f'{col}_weighted'] = df[col] * df['sessions']
                    agg_dict[f'{col}_weighted'] = 'sum'
                    agg_dict['sessions'] = 'sum'
            else:
                # For regular summable metrics, just sum
                agg_dict[col] = 'sum'
        
        # Perform the grouping
        grouped_df = df.groupby(group_cols).agg(agg_dict).reset_index()
        
        # Calculate final weighted averages
        for col in averaged_metrics:
            if col in df.columns:
                if col in ['bounceRate', 'engagementRate', 'averageSessionDuration', 'screenPageViewsPerSession']:
                    grouped_df[col] = grouped_df[f'{col}_weighted'] / grouped_df['sessions']
                    grouped_df.drop(f'{col}_weighted', axis=1, inplace=True)
        
        # Rename grouping_date back to date
        grouped_df = grouped_df.rename(columns={'grouping_date': 'date'})
        
        # Sort by date
        grouped_df = grouped_df.sort_values('date')
        
        return grouped_df

    @staticmethod
    def _aggregate_by_dimensions(df: pd.DataFrame, dimensions: List[str], 
                               agg_method: MetricAggregation) -> pd.DataFrame:
        numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns
        
        if agg_method == MetricAggregation.SUM:
            return df.groupby(dimensions)[numeric_cols].sum().reset_index()
        elif agg_method == MetricAggregation.AVERAGE:
            return df.groupby(dimensions)[numeric_cols].mean().reset_index()
        elif agg_method == MetricAggregation.MIN:
            return df.groupby(dimensions)[numeric_cols].min().reset_index()
        elif agg_method == MetricAggregation.MAX:
            return df.groupby(dimensions)[numeric_cols].max().reset_index()

    @staticmethod
    def _add_percentages(df: pd.DataFrame, metrics: List[str]):
        for metric in metrics:
            if metric in df.columns:
                total = df[metric].sum()
                if total > 0:
                    df[f'{metric}_pct'] = (df[metric] / total) * 100

    @staticmethod
    def _normalize_metrics(df: pd.DataFrame, metrics: List[str]):
        for metric in metrics:
            if metric in df.columns:
                min_val = df[metric].min()
                max_val = df[metric].max()
                if max_val > min_val:
                    df[f'{metric}_normalized'] = (df[metric] - min_val) / (max_val - min_val)

    @staticmethod
    def _generate_summary(df: pd.DataFrame, params: GoogleAnalyticsRequest) -> dict:
        metrics = params.metrics.split(',')
        summary = {
            'summary_stats': {},
            'total_rows': len(df)
        }

        for metric in metrics:
            if metric in df.columns:
                summary['summary_stats'][metric] = {
                    'min': float(df[metric].min()),
                    'max': float(df[metric].max()),
                    'mean': float(df[metric].mean()),
                    'median': float(df[metric].median()),
                    'total': float(df[metric].sum())
                }

        return summary

================
File: tools/google_analytics_tool/google_analytics_tool.py
================
import os
import json
import logging
import sys
from typing import Any, Type, List, Optional
from pydantic import BaseModel, Field, field_validator
from crewai.tools import BaseTool
from google.analytics.data_v1beta.types import DateRange, Metric, Dimension, RunReportRequest, OrderBy
from datetime import datetime

# Import Django models
from django.core.exceptions import ObjectDoesNotExist
from apps.seo_manager.models import Client, GoogleAnalyticsCredentials

logger = logging.getLogger(__name__)

class GoogleAnalyticsToolInput(BaseModel):
    """Input schema for GoogleAnalyticsTool."""
    start_date: str = Field(
        default="28daysAgo",
        description="Start date (YYYY-MM-DD) or relative date ('today', 'yesterday', 'NdaysAgo', etc)."
    )
    end_date: str = Field(
        default="today",
        description="End date (YYYY-MM-DD) or relative date ('today', 'yesterday', 'NdaysAgo', etc)."
    )
    client_id: int = Field(
        description="The ID of the client."
    )

    @field_validator("start_date", "end_date")
    @classmethod
    def validate_dates(cls, value: str) -> str:
        # Allow relative dates
        relative_dates = ['today', 'yesterday', '7daysAgo', '14daysAgo', '28daysAgo', '30daysAgo', '90daysAgo']
        if value in relative_dates or cls.is_relative_date(value):
            return value
        
        # Validate actual dates
        try:
            datetime.strptime(value, "%Y-%m-%d")
            return value
        except ValueError:
            raise ValueError("Invalid date format. Use YYYY-MM-DD or relative dates (today, yesterday, NdDaysAgo, etc)")

    @classmethod
    def is_relative_date(cls, value: str) -> bool:
        """Check if the value is in the format of NdDaysAgo."""
        if len(value) > 8 and value.endswith("daysAgo"):
            try:
                int(value[:-8])  # Check if the prefix is an integer
                return True
            except ValueError:
                return False
        return False
    
class GoogleAnalyticsTool(BaseTool):
    name: str = "Google Analytics Data Fetcher"
    description: str = "Fetches Google Analytics data for a specified client and date range."
    args_schema: Type[BaseModel] = GoogleAnalyticsToolInput
    
    def __init__(self, **kwargs):
        super().__init__()
        logger.info("GoogleAnalyticsTool initialized")
        self._initialize_dimensions_metrics()

    def _initialize_dimensions_metrics(self):
        """Initialize the dimensions and metrics for GA4 reporting"""
        self._dimensions = [
            Dimension(name="date")
        ]
        
        self._metrics = [
            Metric(name="totalUsers"),
            Metric(name="sessions"),
            Metric(name="averageSessionDuration"),
            Metric(name="screenPageViews"),
            Metric(name="screenPageViewsPerSession"),
            Metric(name="newUsers"),
            Metric(name="bounceRate"),
            Metric(name="engagedSessions")
        ]

    def _run(self, start_date: str, end_date: str, client_id: int) -> dict:
        try:
            # Get client and credentials
            client = Client.objects.get(id=client_id)
            ga_credentials = client.ga_credentials
            
            if not ga_credentials:
                raise ValueError("Missing Google Analytics credentials")
            
            # Get authenticated service using model method
            service = ga_credentials.get_service()
            if not service:
                raise ValueError("Failed to initialize Analytics service")
            
            # Get property ID using model method
            property_id = ga_credentials.get_property_id()
            if not property_id:
                raise ValueError("Missing or invalid Google Analytics property ID")

            request = RunReportRequest(
                property=f"properties/{property_id}",
                dimensions=self._dimensions,
                metrics=self._metrics,
                date_ranges=[DateRange(
                    start_date=start_date,
                    end_date=end_date
                )],
                order_bys=[
                    OrderBy(
                        dimension=OrderBy.DimensionOrderBy(
                            dimension_name="date"
                        ),
                        desc=False
                    )
                ]
            )

            response = service.run_report(request)
            analytics_data = []
            
            for row in response.rows:
                date_str = row.dimension_values[0].value
                formatted_date = f"{date_str[:4]}-{date_str[4:6]}-{date_str[6:]}"
                
                try:
                    data_point = {
                        'date': formatted_date,
                        'active_users': int(float(row.metric_values[0].value or 0)),
                        'sessions': int(float(row.metric_values[1].value or 0)),
                        'avg_session_duration': float(row.metric_values[2].value or 0),
                        'page_views': int(float(row.metric_values[3].value or 0)),
                        'pages_per_session': float(row.metric_values[4].value or 0),
                        'new_users': int(float(row.metric_values[5].value or 0)),
                        'bounce_rate': float(row.metric_values[6].value or 0) * 100,
                        'engaged_sessions': int(float(row.metric_values[7].value or 0))
                    }
                    analytics_data.append(data_point)
                except (ValueError, IndexError) as e:
                    logger.error(f"Error processing row {date_str}: {str(e)}")
                    continue

            analytics_data.sort(key=lambda x: x['date'])

            return {
                'success': True,
                'analytics_data': analytics_data,
                'start_date': start_date,
                'end_date': end_date
            }

        except Exception as e:
            logger.error(f"Error fetching GA4 data: {str(e)}")
            logger.error("Full error details:", exc_info=True)
            return {
                'success': False,
                'error': str(e),
                'analytics_data': []
            }

================
File: tools/google_overview_tool/google_overview_tool.py
================
import logging
from typing import Any, Type, List, Optional
from pydantic import BaseModel, Field, field_validator
from crewai.tools import BaseTool
from google.analytics.data_v1beta import BetaAnalyticsDataClient
from google.analytics.data_v1beta.types import (
    DateRange, 
    Metric, 
    Dimension, 
    RunReportRequest,
    OrderBy
)
from datetime import datetime, timedelta
import json
from googleapiclient.errors import HttpError

# Import Django models
from django.core.exceptions import ObjectDoesNotExist
from apps.seo_manager.models import Client

logger = logging.getLogger(__name__)

class GoogleOverviewToolInput(BaseModel):
    """Input schema for GoogleOverviewTool."""
    client_id: int = Field(description="The ID of the client to fetch Google Analytics data for.")
    days_ago: int = Field(
        default=90,
        description="Number of days to look back (default: 90)",
        ge=1,
        le=365
    )

class GoogleOverviewTool(BaseTool):
    name: str = "Google Analytics and Search Console Overview Tool"
    description: str = "Fetches comprehensive overview reports from Google Analytics and Search Console for agents."
    args_schema: Type[BaseModel] = GoogleOverviewToolInput

    def _run(self, client_id: int, days_ago: int = 90) -> str:
        try:
            # Calculate dates
            end_date = datetime.now().strftime("%Y-%m-%d")
            start_date = (datetime.now() - timedelta(days=days_ago)).strftime("%Y-%m-%d")

            # Get client and credentials
            client = Client.objects.get(id=client_id)
            ga_credentials = client.ga_credentials
            sc_credentials = client.sc_credentials
            
            if not ga_credentials or not sc_credentials:
                raise ValueError("Missing Google Analytics or Search Console credentials")

            # Initialize services
            analytics_service = ga_credentials.get_service()
            search_console_service = sc_credentials.get_service()
            property_id = ga_credentials.get_property_id()
            property_url = sc_credentials.get_property_url()

            if not all([analytics_service, search_console_service, property_id, property_url]):
                raise ValueError("Failed to initialize required services")

            # 1. Device & Engagement Analysis
            device_engagement = self._fetch_analytics_report(
                analytics_service,
                property_id,
                start_date,
                end_date,
                ["deviceCategory"],
                ["sessions", "bounceRate", "engagementRate", "averageSessionDuration"]
            )

            # 2. Traffic Sources Analysis
            traffic_sources = self._fetch_analytics_report(
                analytics_service,
                property_id,
                start_date,
                end_date,
                ["sessionSource", "sessionMedium"],
                ["sessions", "newUsers", "engagementRate"]
            )

            # 3. Page Performance Analysis
            page_performance = self._fetch_analytics_report(
                analytics_service,
                property_id,
                start_date,
                end_date,
                ["pagePath"],
                ["screenPageViews", "averageSessionDuration", "bounceRate"]
            )

            # 4. Geographic Performance
            geo_performance = self._fetch_analytics_report(
                analytics_service,
                property_id,
                start_date,
                end_date,
                ["country"],
                ["sessions", "newUsers", "engagementRate", "averageSessionDuration"]
            )

            # 5. Daily Trend Analysis
            daily_trends = self._fetch_analytics_report(
                analytics_service,
                property_id,
                start_date,
                end_date,
                ["date"],
                ["sessions", "newUsers", "activeUsers", "engagementRate"]
            )

            # 6. Landing Page Performance
            landing_performance = self._fetch_analytics_report(
                analytics_service,
                property_id,
                start_date,
                end_date,
                ["landingPage"],
                ["sessions", "bounceRate", "engagementRate", "screenPageViews"]
            )

            # 7. Browser & Platform Analysis
            tech_analysis = self._fetch_analytics_report(
                analytics_service,
                property_id,
                start_date,
                end_date,
                ["browser", "operatingSystem"],
                ["sessions", "screenPageViews", "bounceRate"]
            )

            # 8. Channel Performance
            channel_performance = self._fetch_analytics_report(
                analytics_service,
                property_id,
                start_date,
                end_date,
                ["sessionDefaultChannelGroup"],
                ["sessions", "newUsers", "engagementRate", "averageSessionDuration"]
            )

            # 9. Search Console Overview Report
            keyword_data = self._fetch_search_console_report(
                search_console_service,
                property_url,
                start_date,
                end_date,
                ["query", "country"],
                row_limit=50
            )

            # 10. Search Performance by Page Report
            landing_page_data = self._fetch_search_console_report(
                search_console_service,
                property_url,
                start_date,
                end_date,
                ["page"]
            )

            # 11. Search Performance by Device Report
            device_performance_sc = self._fetch_search_console_report(
                search_console_service,
                property_url,
                start_date,
                end_date,
                ["device"]
            )

            # Return all data in a structured format
            return json.dumps({
                'success': True,
                'device_engagement': device_engagement,
                'traffic_sources': traffic_sources,
                'page_performance': page_performance,
                'geo_performance': geo_performance,
                'daily_trends': daily_trends,
                'landing_performance': landing_performance,
                'tech_analysis': tech_analysis,
                'channel_performance': channel_performance,
                'keyword_data': keyword_data,
                'landing_page_data': landing_page_data,
                'device_performance_sc': device_performance_sc,
                'start_date': start_date,
                'end_date': end_date,
                'client_id': client_id
            })

        except Exception as e:
            error_message = f"Error fetching overview data: {str(e)}"
            logger.error(error_message)
            logger.error("Full error details:", exc_info=True)
            return json.dumps({
                'success': False,
                'error': str(e),
                'analytics_data': []
            })

    def _fetch_analytics_report(self, service, property_id: str, start_date: str, end_date: str, 
                              dimensions: List[str], metrics: List[str]) -> List[dict]:
        try:
            dimension_objects = [Dimension(name=dim) for dim in dimensions]
            metric_objects = [Metric(name=metric) for metric in metrics]

            request = RunReportRequest(
                property=f"properties/{property_id}",
                date_ranges=[DateRange(start_date=start_date, end_date=end_date)],
                dimensions=dimension_objects,
                metrics=metric_objects,
                limit=1000
            )

            response = service.run_report(request)
            
            results = []
            for row in response.rows:
                result = {}
                for i, dimension in enumerate(dimensions):
                    result[dimension] = row.dimension_values[i].value
                for i, metric in enumerate(metrics):
                    # Keep numeric values as numbers, don't format as strings
                    value = float(row.metric_values[i].value)
                    if metrics[i] in ['totalUsers', 'sessions']:
                        value = int(value)
                    result[metrics[i]] = value
                results.append(result)
                
            return results

        except Exception as e:
            logger.error(f"Error fetching analytics report: {str(e)}")
            return []

    def _fetch_search_console_report(self, service, property_url: str, start_date: str, 
                                   end_date: str, dimensions: List[str], row_limit: int = 100) -> List[dict]:
        try:
            response = service.searchanalytics().query(
                siteUrl=property_url,
                body={
                    'startDate': start_date,
                    'endDate': end_date,
                    'dimensions': dimensions,
                    'rowLimit': row_limit
                }
            ).execute()
            
            results = []
            for row in response.get('rows', []):
                result = {}
                for i, dimension in enumerate(dimensions):
                    result[dimension] = row['keys'][i]
                result.update({
                    'Clicks': int(row['clicks']),
                    'Impressions': int(row['impressions']),
                    'CTR': f"{round(row['ctr'] * 100, 2)}%",
                    'Position': round(row['position'], 1)
                })
                results.append(result)
            
            return results

        except Exception as e:
            logger.error(f"Error fetching Search Console report: {str(e)}")
            return []

================
File: tools/google_report_tool/google_rankings_tool.py
================
import logging
from typing import Any, Type, List, Optional
from pydantic import BaseModel, Field, field_validator
from crewai.tools import BaseTool
from datetime import datetime
import json
from googleapiclient.errors import HttpError

# Import Django models
from django.core.exceptions import ObjectDoesNotExist
from apps.seo_manager.models import (
    Client, 
    KeywordRankingHistory,
    TargetedKeyword
)
from django.db import transaction
from apps.seo_manager.utils import get_monthly_date_ranges

logger = logging.getLogger(__name__)

class GoogleRankingsToolInput(BaseModel):
    """Input schema for GoogleRankingsTool."""
    start_date: str = Field(description="The start date for the analytics data (YYYY-MM-DD).")
    end_date: str = Field(description="The end date for the analytics data (YYYY-MM-DD).")
    client_id: int = Field(description="The ID of the client to fetch Google Analytics data for.")

    @field_validator("start_date", "end_date")
    @classmethod
    def validate_dates(cls, value: str) -> str:
        try:
            datetime.strptime(value, "%Y-%m-%d")
            return value
        except ValueError:
            raise ValueError("Invalid date format. Use YYYY-MM-DD.")

class GoogleRankingsTool(BaseTool):
    name: str = "Google Search Console Rankings Fetcher"
    description: str = "Fetches and stores Google Search Console ranking data for a specified client and date range."
    args_schema: Type[BaseModel] = GoogleRankingsToolInput

    def _run(self, start_date: str, end_date: str, client_id: int, **kwargs: Any) -> Any:
        total_stored_rankings = 0
        try:
            client = Client.objects.get(id=client_id)
            sc_credentials = client.sc_credentials
            
            if not sc_credentials:
                raise ValueError("Missing Search Console credentials")
            
            # Get authenticated service using model method
            search_console_service = sc_credentials.get_service()
            if not search_console_service:
                raise ValueError("Failed to initialize Search Console service")
                
            # Get property URL using model method
            property_url = sc_credentials.get_property_url()
            if not property_url:
                raise ValueError("Missing or invalid Search Console property URL")
            
            # Check if specific dates were provided (for collect_rankings)
            if start_date and end_date:
                date_ranges = [(
                    datetime.strptime(start_date, '%Y-%m-%d').date(),
                    datetime.strptime(end_date, '%Y-%m-%d').date()
                )]
            else:
                # For backfill_rankings, get last 12 months
                date_ranges = get_monthly_date_ranges(12)
            
            for start_date, end_date in date_ranges:
                try:
                    logger.info(f"Fetching data for period: {start_date} to {end_date}")
                    
                    keyword_data = self._get_search_console_data(
                        search_console_service, 
                        property_url, 
                        start_date.strftime('%Y-%m-%d'),
                        end_date.strftime('%Y-%m-%d'),
                        'query'
                    )
                    
                    if keyword_data:  # Only process if we got data
                        # Calculate monthly averages and store
                        stored_count = self._log_monthly_rankings(client, keyword_data, start_date)
                        total_stored_rankings += stored_count
                    else:
                        logger.warning(f"No keyword data returned for period {start_date} to {end_date}")
                    
                except Exception as e:
                    logger.error(f"Error fetching data for period {start_date} to {end_date}: {str(e)}")
                    if 'invalid_grant' in str(e) or 'expired' in str(e):
                        raise  # Re-raise auth errors to be handled above
                    continue
            
            if total_stored_rankings > 0:
                return {
                    'success': True,
                    'message': f"Processed ranking data for {len(date_ranges)} period(s)",
                    'stored_rankings_count': total_stored_rankings
                }
            else:
                return {
                    'success': False,
                    'error': "No ranking data was collected",
                    'stored_rankings_count': 0
                }
            
        except Exception as e:
            logger.error(f"Error in ranking tool: {str(e)}")
            return {
                'success': False,
                'error': str(e),
                'stored_rankings_count': total_stored_rankings
            }

    @transaction.atomic
    def _log_monthly_rankings(self, client, keyword_data, month_date):
        """Log monthly average rankings"""
        try:
            # Get all targeted keywords for this client
            targeted_keywords = {
                kw.keyword.lower(): kw 
                for kw in TargetedKeyword.objects.filter(client=client)
            }
            
            # Delete existing rankings for this month
            KeywordRankingHistory.objects.filter(
                client=client,
                date__year=month_date.year,
                date__month=month_date.month
            ).delete()
            
            # Process and store rankings
            rankings_to_create = []
            
            for data in keyword_data:
                keyword_text = data['Keyword']
                
                ranking = KeywordRankingHistory(
                    client=client,
                    keyword_text=keyword_text,
                    date=month_date,  # Use first day of month as reference date
                    impressions=data['Impressions'],
                    clicks=data['Clicks'],
                    ctr=data['CTR (%)'] / 100,
                    average_position=data['Avg Position']
                )
                
                # Link to TargetedKeyword if exists
                targeted_keyword = targeted_keywords.get(keyword_text.lower())
                if targeted_keyword:
                    ranking.keyword = targeted_keyword
                
                rankings_to_create.append(ranking)
            
            # Bulk create new rankings
            KeywordRankingHistory.objects.bulk_create(
                rankings_to_create,
                batch_size=1000
            )
            
            logger.info(
                f"Stored {len(rankings_to_create)} rankings for {month_date.strftime('%B %Y')}"
            )
            
            return len(rankings_to_create)  # Return count of stored rankings
            
        except Exception as e:
            logger.error(f"Error logging monthly rankings: {str(e)}")
            raise

    def _get_search_console_data(self, service, property_url, start_date, end_date, dimension):
        try:
            # Parse the property URL if needed
            if isinstance(property_url, str) and '{' in property_url:
                try:
                    data = json.loads(property_url.replace("'", '"'))  # Replace single quotes with double quotes
                    site_url = data['url']
                except (json.JSONDecodeError, KeyError):
                    site_url = property_url
            elif isinstance(property_url, dict):
                site_url = property_url['url']
            else:
                site_url = property_url

            logger.info(f"Using Search Console property URL: {site_url}")

            response = service.searchanalytics().query(
                siteUrl=site_url,
                body={
                    'startDate': start_date,
                    'endDate': end_date,
                    'dimensions': [dimension],
                    'rowLimit': 1000
                }
            ).execute()
            
            search_console_data = []
            for row in response.get('rows', []):
                search_console_data.append({
                    'Keyword' if dimension == 'query' else 'Landing Page': row['keys'][0],
                    'Clicks': row['clicks'],
                    'Impressions': row['impressions'],
                    'CTR (%)': round(row['ctr'] * 100, 2),
                    'Avg Position': round(row['position'], 1)
                })
            
            search_console_data.sort(key=lambda x: x['Impressions'], reverse=True)
            return search_console_data[:1000]
        except HttpError as error:
            logger.error(f"An error occurred while fetching Search Console data: {error}")
            print(f"An error occurred while fetching Search Console data: {error}")
            return []

================
File: tools/google_report_tool/google_report_tool.py
================
import logging
from typing import Any, Type, List, Optional
from pydantic import BaseModel, Field, field_validator
from crewai.tools import BaseTool
from google.analytics.data_v1beta import BetaAnalyticsDataClient
from google.analytics.data_v1beta.types import (
    DateRange, 
    Metric, 
    Dimension, 
    RunReportRequest, 
    OrderBy
)
from datetime import datetime
import json
from googleapiclient.errors import HttpError

# Import Django models
from django.core.exceptions import ObjectDoesNotExist
from apps.seo_manager.models import (
    Client, 
    KeywordRankingHistory,
    TargetedKeyword
)
from django.db import transaction

logger = logging.getLogger(__name__)

class GoogleReportToolInput(BaseModel):
    """Input schema for GoogleReportTool."""
    start_date: str = Field(description="The start date for the analytics data (YYYY-MM-DD).")
    end_date: str = Field(description="The end date for the analytics data (YYYY-MM-DD).")
    client_id: int = Field(description="The ID of the client to fetch Google Analytics data for.")

    @field_validator("start_date", "end_date")
    @classmethod
    def validate_dates(cls, value: str) -> str:
        try:
            datetime.strptime(value, "%Y-%m-%d")
            return value
        except ValueError:
            raise ValueError("Invalid date format. Use YYYY-MM-DD.")

class GoogleReportTool(BaseTool):
    name: str = "Google Analytics and Search Console Report Fetcher"
    description: str = "Fetches Google Analytics and Search Console reports for a specified client and date range."
    args_schema: Type[BaseModel] = GoogleReportToolInput

    def _run(self, start_date: str, end_date: str, client_id: int) -> str:
        try:
            # Get client and credentials
            client = Client.objects.get(id=client_id)
            ga_credentials = client.ga_credentials
            sc_credentials = client.sc_credentials
            
            if not ga_credentials or not sc_credentials:
                raise ValueError("Missing Google Analytics or Search Console credentials")

            # Get authenticated services using model methods
            analytics_service = ga_credentials.get_service()
            if not analytics_service:
                raise ValueError("Failed to initialize Analytics service")
                
            property_id = ga_credentials.get_property_id()
            if not property_id:
                raise ValueError("Missing or invalid Google Analytics property ID")

            search_console_service = sc_credentials.get_service()
            if not search_console_service:
                raise ValueError("Failed to initialize Search Console service")
                
            property_url = sc_credentials.get_property_url()
            if not property_url:
                raise ValueError("Missing or invalid Search Console property URL")

            # Fetch analytics data
            analytics_data = []
            try:
                general_request = RunReportRequest(
                    property=f"properties/{property_id}",
                    date_ranges=[DateRange(start_date=start_date, end_date=end_date)],
                    dimensions=[
                        Dimension(name="sessionSourceMedium"),
                    ],
                    metrics=[
                        Metric(name="totalUsers"),
                        Metric(name="sessions"),
                        Metric(name="bounceRate"),
                        Metric(name="averageSessionDuration"),
                    ],
                    order_bys=[
                        OrderBy(metric=OrderBy.MetricOrderBy(metric_name="totalUsers"), desc=True)
                    ],
                    limit=10
                )        
                general_response = analytics_service.run_report(general_request)
                analytics_data = self._process_analytics_data(general_response)
                
                if not analytics_data:
                    logger.warning("No analytics data returned from Google Analytics")
                
            except Exception as e:
                logger.error(f"Failed to fetch analytics data: {str(e)}")
                if 'invalid_grant' in str(e) or 'expired' in str(e):
                    raise ValueError(f"Google Analytics credentials have expired: {str(e)}")
                raise
            
            # Fetch Search Console data
            keyword_data = []
            landing_page_data = []
            try:
                keyword_data = self._get_search_console_data(search_console_service, property_url, start_date, end_date, 'query')
                landing_page_data = self._get_search_console_data(search_console_service, property_url, start_date, end_date, 'page')
                
                if not keyword_data and not landing_page_data:
                    logger.warning("No data returned from Search Console")
                    
            except Exception as e:
                logger.error(f"Failed to fetch Search Console data: {str(e)}")
                if 'invalid_grant' in str(e) or 'expired' in str(e):
                    raise ValueError(f"Search Console credentials have expired: {str(e)}")
                raise
            
            # Check if we got any data at all
            if not analytics_data and not keyword_data and not landing_page_data:
                return json.dumps({
                    'success': False,
                    'error': "No data was collected from either Google Analytics or Search Console",
                    'analytics_data': [],
                    'keyword_data': [],
                    'landing_page_data': [],
                    'start_date': start_date,
                    'end_date': end_date,
                    'client_id': client_id
                })
            
            return json.dumps({
                'success': True,
                'analytics_data': analytics_data,
                'keyword_data': keyword_data,
                'landing_page_data': landing_page_data,
                'start_date': start_date,
                'end_date': end_date,
                'client_id': client_id
            })
            
        except Exception as e:
            error_message = f"Error fetching GA4 data: {str(e)}"
            logger.error(error_message)
            logger.error("Full error details:", exc_info=True)
            # Return error as string
            return json.dumps({
                'success': False,
                'error': str(e),
                'analytics_data': []
            })

    def _process_analytics_data(self, response):
        processed_data = []
        try:
            for row in response.rows:
                source_medium = row.dimension_values[0].value
                total_users = int(row.metric_values[0].value)
                sessions = int(row.metric_values[1].value)
                bounce_rate = float(row.metric_values[2].value)
                avg_session_duration = float(row.metric_values[3].value)
                
                processed_data.append({
                    'source_medium': source_medium,
                    'total_users': total_users,
                    'sessions': sessions,
                    'bounce_rate': bounce_rate,
                    'avg_session_duration': avg_session_duration
                })
            
            processed_data.sort(key=lambda x: x['total_users'], reverse=True)
        except Exception as e:
            logger.error(f"Error processing analytics data: {str(e)}", exc_info=True)
        return processed_data

    def _get_search_console_data(self, service, property_url, start_date, end_date, dimension):
        try:
            response = service.searchanalytics().query(
                siteUrl=property_url,
                body={
                    'startDate': start_date,
                    'endDate': end_date,
                    'dimensions': [dimension],
                    'rowLimit': 1000
                }
            ).execute()
            
            search_console_data = []
            for row in response.get('rows', []):
                search_console_data.append({
                    'Keyword' if dimension == 'query' else 'Landing Page': row['keys'][0],
                    'Clicks': row['clicks'],
                    'Impressions': row['impressions'],
                    'CTR (%)': round(row['ctr'] * 100, 2),
                    'Avg Position': round(row['position'], 1)
                })
            
            search_console_data.sort(key=lambda x: x['Impressions'], reverse=True)
            return search_console_data[:50]
        except HttpError as error:
            logger.error(f"An error occurred while fetching Search Console data: {error}")
            return []
        except Exception as e:
            logger.error(f"Unexpected error fetching Search Console data: {str(e)}")
            return []

================
File: tools/google_search_console_tool/generic_google_search_console_tool.py
================
import logging
from typing import Any, Type, List, Optional, ClassVar
from pydantic import (
    BaseModel, 
    ConfigDict, 
    Field, 
    field_validator,
    BaseModel as PydanticBaseModel
)
from crewai.tools.base_tool import BaseTool
from datetime import datetime
import json
from googleapiclient.errors import HttpError
from enum import Enum
import pandas as pd

# Import Django models
from django.core.exceptions import ObjectDoesNotExist
from apps.seo_manager.models import Client, SearchConsoleCredentials

from apps.common.utils import DateProcessor

logger = logging.getLogger(__name__)

class TimeGranularity(str, Enum):
    DAILY = "daily"
    WEEKLY = "weekly"
    MONTHLY = "monthly"
    AUTO = "auto"

class DataFormat(str, Enum):
    RAW = "raw"
    SUMMARY = "summary"
    COMPACT = "compact"

class MetricAggregation(str, Enum):
    SUM = "sum"
    AVERAGE = "average"
    MIN = "min"
    MAX = "max"

class GoogleSearchConsoleRequest(BaseModel):
    """Schema for Google Search Console data requests."""
    
    class Config:
        """Pydantic config"""
        use_enum_values = True
        extra = "forbid"
    
    client_id: int = Field(
        ...,  # ... means required
        description="The ID of the client to fetch data for",
        gt=0
    )
    start_date: str = Field(
        ...,
        description="Start date (YYYY-MM-DD or relative like '7daysAgo')"
    )
    end_date: str = Field(
        ...,
        description="End date (YYYY-MM-DD or relative like 'today')"
    )
    dimensions: List[str] = Field(
        default=["query"],
        description="Dimensions to fetch (query, page, country, device, date)"
    )
    search_type: str = Field(
        default="web",
        description="Type of search results (web, discover, news, etc.)"
    )
    row_limit: int = Field(
        default=250,
        description="Number of rows to return (1-25000)"
    )
    start_row: int = Field(
        default=0,
        description="Starting row for pagination"
    )
    aggregation_type: str = Field(
        default="auto",
        description="How to aggregate results (auto, byPage, byProperty)"
    )
    data_state: str = Field(
        default="final",
        description="Data state to return (all, final)"
    )
    dimension_filters: Optional[List[dict]] = Field(
        default=None,
        description="List of dimension filters"
    )

    # Data Processing Options
    data_format: DataFormat = Field(
        default=DataFormat.RAW,
        description="""
        How to format the returned data:
        - 'raw': Returns all data points (use for detailed analysis)
        - 'summary': Returns statistical summary (min/max/mean/median) - best for high-level insights
        - 'compact': Returns top N results (good for finding top performers)
        
        Example use cases:
        - For keyword analysis: use 'raw' with query dimension
        - For performance overview: use 'summary'
        - For top pages: use 'compact' with top_n=10
        """
    )

    top_n: Optional[int] = Field(
        default=None,
        description="""
        Return only top N results by clicks or impressions.
        
        Example use cases:
        - top_n=10 with dimensions=['query']  top 10 keywords
        - top_n=5 with dimensions=['page']  top 5 pages
        - top_n=3 with dimensions=['country']  top 3 countries
        """
    )

    time_granularity: TimeGranularity = Field(
        default=TimeGranularity.AUTO,
        description="""
        Time period to aggregate data by:
        - 'daily': Keep daily granularity (best for 1-7 day ranges)
        - 'weekly': Group by weeks (best for 8-60 day ranges)
        - 'monthly': Group by months (best for 60+ day ranges)
        - 'auto': Automatically choose based on date range
        
        Example use cases:
        - For daily CTR fluctuations: use 'daily'
        - For weekly performance trends: use 'weekly'
        - For long-term position changes: use 'monthly'
        """
    )

    metric_aggregation: MetricAggregation = Field(
        default=MetricAggregation.SUM,
        description="""
        How to aggregate metrics when grouping data.
        
        Note: 
        - 'sum' for clicks and impressions
        - 'average' for CTR and position
        """
    )

    include_percentages: bool = Field(
        default=False,
        description="""
        Add percentage calculations relative to totals.
        Adds '_pct' suffix to metrics (e.g., 'clicks_pct').
        
        Example use cases:
        - Click distribution across pages
        - Impression share by country
        - CTR comparison across devices
        """
    )

    normalize_metrics: bool = Field(
        default=False,
        description="""
        Scale numeric metrics to 0-1 range for easier comparison.
        Adds '_normalized' suffix to metrics.
        
        Use when:
        - Comparing high-impression vs low-impression queries
        - Analyzing position vs CTR correlation
        - Creating visualizations
        """
    )

    round_digits: Optional[int] = Field(
        default=2,
        description="Round numeric values to specified digits"
    )

    include_period_comparison: bool = Field(
        default=False,
        description="""
        Include comparison with previous period.
        
        Example use cases:
        - Month-over-month ranking changes
        - Year-over-year click growth
        - Week-over-week CTR improvement
        
        Returns additional fields:
        - previous_period_value
        - percentage_change
        """
    )

    moving_average_window: Optional[int] = Field(
        default=None,
        description="""
        Calculate moving averages over specified number of periods.
        Only applies when data includes the 'date' dimension.
        
        Example use cases:
        - 7-day moving average for smoothing daily fluctuations
        - 30-day moving average for trend analysis
        - 90-day moving average for long-term patterns
        
        Adds '_ma{window}' suffix to metric names (e.g., 'sessions_ma7')
        """
    )

    @field_validator("start_date", "end_date")
    @classmethod
    def validate_dates(cls, value: str) -> str:
        return DateProcessor.process_relative_date(value)

    @field_validator("dimensions")
    @classmethod
    def validate_dimensions(cls, value: List[str]) -> List[str]:
        valid_dimensions = ["country", "device", "page", "query", "searchAppearance", "date"]
        for dim in value:
            if dim not in valid_dimensions:
                raise ValueError(f"Invalid dimension: {dim}. Must be one of {valid_dimensions}")
        return value

    @field_validator("search_type")
    @classmethod
    def validate_search_type(cls, value: str) -> str:
        valid_types = ["web", "discover", "googleNews", "news", "image", "video"]
        if value not in valid_types:
            raise ValueError(f"Invalid search type. Must be one of {valid_types}")
        return value

    @field_validator("row_limit")
    @classmethod
    def validate_row_limit(cls, value: int) -> int:
        if not 1 <= value <= 25000:
            raise ValueError("Row limit must be between 1 and 25000")
        return value

class SearchConsoleDataProcessor:
    @staticmethod
    def _add_period_comparison(df: pd.DataFrame) -> pd.DataFrame:
        """Add period-over-period comparison metrics"""
        if 'date' not in df.columns:
            return df
            
        # Ensure date is datetime for proper sorting
        df['date'] = pd.to_datetime(df['date'])
        df = df.sort_values('date')
        
        # Calculate the period length
        total_days = (df['date'].max() - df['date'].min()).days
        period_length = total_days // 2
        
        # Create a cutoff date for splitting current and previous periods
        cutoff_date = df['date'].max() - pd.Timedelta(days=period_length)
        
        # Split into current and previous periods
        current_period = df[df['date'] > cutoff_date].copy()
        previous_period = df[df['date'] <= cutoff_date].copy()
        
        # Calculate metrics for both periods
        metrics = ['clicks', 'impressions', 'ctr', 'position']
        comparison_data = {}
        
        for metric in metrics:
            if metric in df.columns:
                current_value = current_period[metric].mean()
                previous_value = previous_period[metric].mean()
                
                # Add comparison metrics
                df[f'{metric}_previous'] = previous_value
                df[f'{metric}_change'] = ((current_value - previous_value) / previous_value * 100 
                                        if previous_value != 0 else 0)
                
                comparison_data[metric] = {
                    'current_period': current_value,
                    'previous_period': previous_value,
                    'percent_change': ((current_value - previous_value) / previous_value * 100 
                                     if previous_value != 0 else 0)
                }
        
        # Add comparison summary to the DataFrame
        df.attrs['period_comparison'] = comparison_data
        
        return df

    @staticmethod
    def process_data(data: List[dict], params: GoogleSearchConsoleRequest) -> List[dict]:
        """Process the search console data based on request parameters"""
        if not data:
            return data

        df = pd.DataFrame(data)

        # Apply time granularity aggregation if needed
        if params.time_granularity != TimeGranularity.DAILY and 'date' in df.columns:
            df = SearchConsoleDataProcessor._aggregate_by_time(df, params.time_granularity)

        # Calculate moving averages if requested
        if params.moving_average_window and 'date' in df.columns:
            df = SearchConsoleDataProcessor._calculate_moving_averages(
                df,
                params.moving_average_window
            )

        # Add period comparison if requested
        if params.include_period_comparison and 'date' in df.columns:
            df = SearchConsoleDataProcessor._add_period_comparison(df)

        # Apply top N filter
        if params.data_format == DataFormat.COMPACT and params.top_n:
            df = df.nlargest(params.top_n, 'clicks')  # Default to sorting by clicks

        # Add percentages if requested
        if params.include_percentages:
            for metric in ['clicks', 'impressions']:
                total = df[metric].sum()
                if total > 0:
                    df[f'{metric}_pct'] = (df[metric] / total) * 100

        # Normalize metrics if requested
        if params.normalize_metrics:
            for metric in ['clicks', 'impressions', 'position']:
                min_val = df[metric].min()
                max_val = df[metric].max()
                if max_val > min_val:
                    df[f'{metric}_normalized'] = (df[metric] - min_val) / (max_val - min_val)

        # Round values
        if params.round_digits is not None:
            numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns
            df[numeric_cols] = df[numeric_cols].round(params.round_digits)

        # Generate summary if requested
        if params.data_format == DataFormat.SUMMARY:
            return SearchConsoleDataProcessor._generate_summary(df)

        # Format the response to include period comparison data if it exists
        result = df.to_dict('records')
        if params.include_period_comparison and hasattr(df, 'attrs') and 'period_comparison' in df.attrs:
            return {
                'data': result,
                'period_comparison': df.attrs['period_comparison']
            }
        
        return result

    @staticmethod
    def _aggregate_by_time(df: pd.DataFrame, granularity: TimeGranularity) -> pd.DataFrame:
        df['date'] = pd.to_datetime(df['date'])
        
        # Get all non-date columns that should be preserved in grouping
        group_cols = [col for col in df.columns if col != 'date' and not pd.api.types.is_numeric_dtype(df[col])]
        
        if granularity == TimeGranularity.WEEKLY:
            df['date'] = df['date'].dt.strftime('%Y-W%W')
        elif granularity == TimeGranularity.MONTHLY:
            df['date'] = df['date'].dt.strftime('%Y-%m')
        
        # Add date back to group columns
        group_cols.append('date')
        
        # Define aggregation rules for different metric types
        agg_dict = {
            'clicks': 'sum',
            'impressions': 'sum',
            'ctr': 'mean',
            'position': 'mean'
        }
        
        # Group by all dimension columns including date
        return df.groupby(group_cols).agg(agg_dict).reset_index()

    @staticmethod
    def _generate_summary(df: pd.DataFrame) -> dict:
        """Generate statistical summary of the data"""
        metrics = ['clicks', 'impressions', 'ctr', 'position']
        summary = {
            'summary_stats': {},
            'total_rows': len(df)
        }

        for metric in metrics:
            summary['summary_stats'][metric] = {
                'min': float(df[metric].min()),
                'max': float(df[metric].max()),
                'mean': float(df[metric].mean()),
                'median': float(df[metric].median()),
                'total': float(df[metric].sum()) if metric in ['clicks', 'impressions'] else None
            }

        return summary

    @staticmethod
    def _calculate_moving_averages(df: pd.DataFrame, window: int) -> pd.DataFrame:
        """Calculate moving averages for core metrics"""
        if 'date' not in df.columns:
            return df
            
        # Ensure date is datetime for proper sorting
        df['date'] = pd.to_datetime(df['date'])
        df = df.sort_values('date')
        
        # Calculate moving averages for all numeric metrics
        metrics = ['clicks', 'impressions', 'ctr', 'position']
        for metric in metrics:
            if metric in df.columns:
                df[f'{metric}_ma{window}'] = df[metric].rolling(
                    window=window,
                    min_periods=1  # Allow partial windows at the start
                ).mean()
        
        return df

class GenericGoogleSearchConsoleTool(BaseTool):
    """
    Google Search Console data fetching tool.
    """
    name: str = "Search Console Data Tool"
    description: str = """
    Fetches data from Google Search Console with advanced processing capabilities.
    
    Key Features:
    - Flexible date ranges (e.g., '7daysAgo', '3monthsAgo', 'YYYY-MM-DD')
    - Core metrics: clicks, impressions, CTR, position
    - Dimensions: query, page, country, device, date
    - Data processing: aggregation, filtering, summaries
    """
    
    args_schema: type[BaseModel] = Field(default=GoogleSearchConsoleRequest)

    def _run(self, **kwargs: Any) -> dict:
        """Execute the tool with validated parameters"""
        try:
            params = self.args_schema(**kwargs)
            
            # Get client and credentials
            client = Client.objects.get(id=params.client_id)
            sc_credentials = client.sc_credentials
            if not sc_credentials:
                raise ValueError("Missing Search Console credentials")

            service = sc_credentials.get_service()
            if not service:
                raise ValueError("Failed to initialize Search Console service")

            property_url = sc_credentials.get_property_url()
            if not property_url:
                raise ValueError("Missing or invalid Search Console property URL")

            # Prepare the request body
            request_body = {
                'startDate': params.start_date,
                'endDate': params.end_date,
                'dimensions': params.dimensions,
                'type': params.search_type,
                'rowLimit': params.row_limit,
                'startRow': params.start_row,
                'aggregationType': params.aggregation_type,
                'dataState': params.data_state
            }

            # Add dimension filters if provided
            if params.dimension_filters:
                filters = []
                for filter_dict in params.dimension_filters:
                    if isinstance(filter_dict['expression'], list):
                        # For notEquals/notContains, create an OR group of NOT conditions
                        if filter_dict['operator'] in ['notEquals', 'notContains']:
                            filters.append({
                                'groupType': 'or',
                                'filters': [{
                                    'dimension': filter_dict['dimension'],
                                    'operator': 'notContains' if filter_dict['operator'] == 'notContains' else 'notEquals',
                                    'expression': expr.lower()  # Case-insensitive matching
                                } for expr in filter_dict['expression']]
                            })
                        else:
                            # For other operators, create individual filters
                            for expr in filter_dict['expression']:
                                filters.append({
                                    'dimension': filter_dict['dimension'],
                                    'operator': filter_dict['operator'],
                                    'expression': expr.lower()  # Case-insensitive matching
                                })
                    else:
                        filters.append({
                            'dimension': filter_dict['dimension'],
                            'operator': filter_dict['operator'],
                            'expression': filter_dict['expression'].lower()  # Case-insensitive matching
                        })

                # Create the final filter group structure
                request_body['dimensionFilterGroups'] = [{
                    'groupType': 'and',
                    'filters': filters
                }]

            # Execute the request
            response = service.searchanalytics().query(
                siteUrl=property_url,
                body=request_body
            ).execute()

            # Process the response
            raw_data = self._format_response(response, params.dimensions)
            
            if raw_data['success']:
                processed_data = SearchConsoleDataProcessor.process_data(
                    raw_data['search_console_data'],
                    params
                )
                
                # Handle period comparison format
                if isinstance(processed_data, dict) and 'period_comparison' in processed_data:
                    return {
                        'success': True,
                        'search_console_data': processed_data['data'],
                        'period_comparison': processed_data['period_comparison']
                    }
                
                return {
                    'success': True,
                    'search_console_data': processed_data
                }
            
            return raw_data

        except Exception as e:
            logger.error(f"Search Console tool error: {str(e)}", exc_info=True)
            return {
                'success': False,
                'error': str(e),
                'search_console_data': []
            }

    def _format_response(self, response: dict, dimensions: List[str]) -> dict:
        """Format the Search Console API response into a structured format."""
        search_console_data = []
        
        # Clean dimension names - strip whitespace
        dimensions = [d.strip() for d in dimensions]
        
        for row in response.get('rows', []):
            data_point = {}
            
            # Process dimension values
            for i, dimension in enumerate(dimensions):
                value = row['keys'][i]
                data_point[dimension] = value
            
            # Add metrics
            data_point.update({
                'clicks': row.get('clicks', 0),
                'impressions': row.get('impressions', 0),
                'ctr': round(row.get('ctr', 0) * 100, 2),
                'position': round(row.get('position', 0), 2)
            })
            
            search_console_data.append(data_point)

        return {
            'success': True,
            'search_console_data': search_console_data
        }

================
File: tools/google_suggestions_tool/google_suggestions_tool.py
================
from typing import Any, Type, Optional
from pydantic import BaseModel, Field, ConfigDict
from crewai.tools import BaseTool
import requests
import xml.etree.ElementTree as ET

class GoogleSuggestionsInput(BaseModel):
    model_config = ConfigDict(
        extra='forbid',
        arbitrary_types_allowed=True
    )
    
    keyword: str = Field(description="The keyword to get suggestions for")
    country_code: str = Field(default="us", description="The country code for localized suggestions")

class GoogleSuggestionsTool(BaseTool):
    model_config = ConfigDict(
        extra='forbid',
        arbitrary_types_allowed=True
    )
    
    name: str = "Google Suggestions Fetcher"
    description: str = "Retrieves Google search suggestions for a given keyword."
    args_schema: Type[BaseModel] = GoogleSuggestionsInput

    def _run(self, keyword: str, country_code: str = "us", **kwargs: Any) -> Any:
        """Use the tool to get Google search suggestions."""
        # Build the Google Search query URL
        search_query = f"is {keyword}"
        google_search_url = f"http://google.com/complete/search?output=toolbar&gl={country_code}&q={search_query}"

        # Call the URL and read the data
        result = requests.get(google_search_url)
        tree = ET.ElementTree(ET.fromstring(result.content))
        root = tree.getroot()

        # Extract the suggestions from the XML response
        suggestions = []
        for suggestion in root.findall('CompleteSuggestion'):
            question = suggestion.find('suggestion').attrib.get('data')
            suggestions.append(question)

        # Return the suggestions as a comma-separated string
        return ", ".join(suggestions)

    async def _arun(self, keyword: str, country_code: str = "us", **kwargs: Any) -> Any:
        """Use the tool asynchronously."""
        raise NotImplementedError("GoogleSuggestionsTool does not support async")

================
File: tools/keyword_tools/keyword_tools.py
================
import os
import requests
from typing import Any, Type, List, Dict, Tuple, Optional, Union
from pydantic import BaseModel, Field, ConfigDict, field_validator
from crewai.tools import BaseTool
import logging
import json
import csv
import io
import pandas as pd
import numpy as np
from urllib.parse import urlparse

logger = logging.getLogger(__name__)

BASE_URL = os.getenv('DATAFORSEO_BASE_URL', 'https://api.dataforseo.com')

class KeywordsForSiteInput(BaseModel):
    model_config = ConfigDict(
        extra='forbid',
        arbitrary_types_allowed=True
    )
    
    website_url: str = Field(description="Fully qualified domain name (FQDN) for keyword analysis")

    @classmethod
    def get_fqdn(cls, url: str) -> str:
        parsed_url = urlparse(url)
        return parsed_url.netloc or parsed_url.path

class KeywordSuggestionsInput(BaseModel):
    model_config = ConfigDict(
        extra='forbid',
        arbitrary_types_allowed=True
    )
    
    seed_keyword: str = Field(description="Seed keyword for suggestions")
    filters: List[Tuple[str, str, float]] = Field(description="List of filters", default=[])

class KeywordIdeasInput(BaseModel):
    model_config = ConfigDict(
        extra='forbid',
        arbitrary_types_allowed=True
    )
    
    keywords: List[str] = Field(description="Single keyword or list of keywords")
    filters: List[Tuple[str, str, float]] = Field(description="List of filters", default=[])

    @field_validator('keywords', mode='before')
    @classmethod
    def validate_keywords(cls, value):
        if isinstance(value, str):
            return [value]
        return value

class SearchVolumeInput(BaseModel):
    model_config = ConfigDict(
        extra='forbid',
        arbitrary_types_allowed=True
    )
    
    keywords: List[str] = Field(description="Single keyword or list of keywords to get search volume for")
    sort_by: str = Field(default="relevance", description="Sort results by this field")

    @field_validator('keywords', mode='before')
    @classmethod
    def validate_keywords(cls, value):
        if isinstance(value, str):
            return [value]
        return value

class KeywordsForSiteTool(BaseTool):
    model_config = ConfigDict(
        extra='forbid',
        arbitrary_types_allowed=True
    )
    
    name: str = "Keywords for Site"
    description: str = "Provides a list of keywords relevant to the target domain. Each keyword is supplied with relevant categories, search volume data for the last month, cost-per-click, competition, and search volume trend values for the past 12 months"
    args_schema: Type[BaseModel] = KeywordsForSiteInput

    def _run(self, website_url: str, **kwargs: Any) -> Any:
        login, password = KeywordTools._dataforseo_credentials()
        cred = (login, password)
        url = f"{BASE_URL}/v3/keywords_data/google_ads/keywords_for_site/live"
        
        fqdn = KeywordsForSiteInput.get_fqdn(website_url)
        
        payload = [
            {
                "target": fqdn,
                "language_code": "en",
                "location_code": 2840,
            }
        ]
        headers = {"Content-Type": "application/json"}
        try:
            response = requests.post(url, json=payload, headers=headers, auth=cred)
            response.raise_for_status()

        except Exception as e:
            logger.error(f"Error making request to DataForSEO: {e}")
            raise e

        try:
            results = KeywordTools._transform_keyword_data(response.json())
        except Exception as e:
            logger.error(f"Error transforming keyword data: {e}")
            raise e

        return results

    async def _arun(self, target: str, **kwargs: Any) -> Any:
        raise NotImplementedError("KeywordsForSiteTool does not support async")

class KeywordSuggestionsTool(BaseTool):
    model_config = ConfigDict(
        extra='forbid',
        arbitrary_types_allowed=True
    )
    
    name: str = "Keyword Suggestions"
    description: str = "Provides a list of keywords relevant to the target domain. Each keyword is supplied with relevant categories, search volume data for the last month, cost-per-click, competition, and search volume trend values for the past 12 months"
    args_schema: Type[BaseModel] = KeywordSuggestionsInput

    def _run(self, seed_keyword: str, filters: List = None, **kwargs: Any) -> Any:
        login, password = KeywordTools._dataforseo_credentials()
        cred = (login, password)
        url = f"{BASE_URL}/v3/dataforseo_labs/google/keyword_suggestions/live"
        payload = [
            {
                "keyword": seed_keyword,
                "location_code": 2840,
                "language_code": "en",
                "include_serp_info": True,
                "include_seed_keyword": True,
                "limit": 50,
            }
        ]
        if filters:
            payload[0]["filters"] = filters
        headers = {"Content-Type": "application/json"}
        response = requests.post(url, json=payload, headers=headers, auth=cred)
        response.raise_for_status()
        
        try:
            results = KeywordTools._transform_keyword_data(response.json())
        except Exception as e:
            logger.error(f"Error transforming keyword data: {e}")
            raise e
        
        return results

    async def _arun(self, seed_keyword: str, filters: List = None, **kwargs: Any) -> Any:
        raise NotImplementedError("KeywordSuggestionsTool does not support async")

class KeywordIdeasTool(BaseTool):
    model_config = ConfigDict(
        extra='forbid',
        arbitrary_types_allowed=True
    )
    
    name: str = "Keyword Ideas"
    description: str = "Provides search terms that are relevant to the product or service categories of the specified keywords. The algorithm selects the keywords which fall into the same categories as the seed keywords specified"
    args_schema: Type[BaseModel] = KeywordIdeasInput

    def _run(self, keywords: List[str], filters: List[Tuple[str, str, float]] = None, **kwargs: Any) -> Any:
        login, password = KeywordTools._dataforseo_credentials()
        cred = (login, password)
        url = f"{BASE_URL}/v3/dataforseo_labs/google/keyword_ideas/live"
        payload = [
            {
                "keywords": keywords,
                "location_code": 2840,
                "language_code": "en",
                "include_serp_info": True,
                "limit": 100,
            }
        ]
        if filters:
            payload[0]["filters"] = filters
        headers = {"Content-Type": "application/json"}
        response = requests.post(url, json=payload, headers=headers, auth=cred)
        response.raise_for_status()

        try:
            results = KeywordTools._transform_keyword_data(response.json())
        except Exception as e:
            logger.error(f"Error transforming keyword data: {e}")
            raise e
        return results

    async def _arun(self, keywords: List[str], filters: List[Tuple[str, str, float]] = None, **kwargs: Any) -> Any:
        raise NotImplementedError("KeywordIdeasTool does not support async")

class SearchVolumeTool(BaseTool):
    model_config = ConfigDict(
        extra='forbid',
        arbitrary_types_allowed=True
    )
    
    name: str = "Search Volume"
    description: str = "Provides search volume data for a list of keywords"
    args_schema: Type[BaseModel] = SearchVolumeInput

    def _run(self, keywords: List[str], sort_by: str = "relevance", **kwargs: Any) -> Any:
        login, password = KeywordTools._dataforseo_credentials()
        cred = (login, password)
        url = f"{BASE_URL}/v3/keywords_data/google_ads/search_volume/live"
        payload = [
            {
                "keywords": keywords,
                "sort_by": sort_by
            }
        ]
        headers = {"Content-Type": "application/json"}
        try:
            response = requests.post(url, json=payload, headers=headers, auth=cred)
            response.raise_for_status()
        except Exception as e:
            logger.error(f"Error making request to DataForSEO: {e}")
            raise e

        try:
            results = KeywordTools._transform_keyword_data(response.json())
        except Exception as e:
            logger.error(f"Error transforming keyword data: {e}")
            raise e
        return results

    async def _arun(self, keywords: List[str], sort_by: str = "relevance", **kwargs: Any) -> Any:
        raise NotImplementedError("SearchVolumeTool does not support async")

class KeywordTools:
    @staticmethod
    def tools():
        return [KeywordsForSiteTool(), KeywordSuggestionsTool(), KeywordIdeasTool(), SearchVolumeTool()]

    @staticmethod
    def _dataforseo_credentials():
        login = os.environ["DATAFORSEO_EMAIL"]
        password = os.environ["DATAFORSEO_PASSWORD"]
        return login, password

    @staticmethod
    def _transform_keyword_data(data: Dict) -> str:
        try:
            if data.get('tasks_error', 0) > 0:
                error_message = data.get('tasks', [{}])[0].get('status_message', 'Unknown error')
                return f"Error: {error_message}"

            path = data.get('tasks', [{}])[0].get('path', [])
            if len(path) >= 4:
                tool_type = path[3]
            else:
                return "Error: Unable to determine tool type from response"

            if tool_type == "keywords_for_site":
                all_results = data.get('tasks', [])[0].get('result', [])
            elif tool_type in ["keyword_suggestions", "keyword_ideas"]:
                result = data.get('tasks', [])[0].get('result', [])
                if result:
                    all_results = result[0].get('items', [])
                else:
                    return "Error: No results found in the response"
            elif tool_type == "search_volume":
                all_results = data.get('tasks', [])[0].get('result', [])
            else:
                return f"Error: Unknown tool type: {tool_type}"

            if not all_results:
                return "Error: No results found in the response"

            df = pd.DataFrame(all_results)

            columns = ['keyword', 'search_volume', 'cpc', 'competition']
            if 'keyword_info' in df.columns:
                df['search_volume'] = df['keyword_info'].apply(lambda x: x.get('search_volume', 0))
                df['cpc'] = df['keyword_info'].apply(lambda x: x.get('cpc', 0))
                df['competition'] = df['keyword_info'].apply(lambda x: x.get('competition', 0))
            if 'keyword_properties' in df.columns:
                df['keyword_difficulty'] = df['keyword_properties'].apply(lambda x: x.get('keyword_difficulty', 0))
                columns.append('keyword_difficulty')
            if 'low_top_of_page_bid' in df.columns:
                columns.extend(['low_top_of_page_bid', 'high_top_of_page_bid'])

            result_df = df[columns]
            result_df = result_df.rename(columns={
                'search_volume': 'avg_search_volume',
                'keyword_difficulty': 'difficulty',
                'low_top_of_page_bid': 'low_top_bid',
                'high_top_of_page_bid': 'high_top_bid'
            })

            if 'competition' in result_df.columns and result_df['competition'].dtype == 'object':
                competition_map = {'LOW': 0, 'MEDIUM': 0.5, 'HIGH': 1}
                result_df['competition'] = result_df['competition'].map(competition_map)

            fill_values = {col: 0 for col in result_df.columns if col != 'keyword'}
            fill_values['keyword'] = 'N/A'
            result_df = result_df.fillna(fill_values)

            result_df = result_df.sort_values('cpc', ascending=False)
            result_df = result_df[result_df['avg_search_volume'] >= 500]

            csv_output = result_df.to_csv(index=False)
            return csv_output

        except Exception as e:
            logger.error(f"Error transforming keyword data: {e}")
            return f"Error: {str(e)}"

================
File: tools/keyword_tools/ranked_keywords_tool.py
================
import os
import requests
from typing import Any, Type, List, Dict
from pydantic import BaseModel, Field
from crewai.tools import BaseTool
import logging
import pandas as pd
from urllib.parse import urlparse

logger = logging.getLogger(__name__)

BASE_URL = os.getenv('DATAFORSEO_BASE_URL', 'https://api.dataforseo.com')

class RankedKeywordsInput(BaseModel):
    """Input model for ranked keywords tool"""
    website_url: str = Field(description="Domain or webpage for keyword ranking analysis")
    model_config = {
        "arbitrary_types_allowed": True
    }

    @classmethod
    def get_fqdn(cls, url: str) -> str:
        parsed_url = urlparse(url)
        return parsed_url.netloc or parsed_url.path

class RankedKeywordsTool(BaseTool):
    name: str = "Ranked Keywords"
    description: str = "Provides a list of ranked keywords with various metrics"
    args_schema: Type[BaseModel] = RankedKeywordsInput

    def _run(self, website_url: str, location_code: int = 2840, language_code: str = "en", **kwargs: Any) -> Any:
        login, password = KeywordTools._dataforseo_credentials()
        cred = (login, password)
        url = f"{BASE_URL}/v3/dataforseo_labs/google/ranked_keywords/live"
        fqdn = RankedKeywordsInput.get_fqdn(website_url)

        payload = [
            {
                "target": fqdn,
                "location_code": location_code,
                "language_code": language_code,
                "limit": 100,
                "order_by": ["keyword_data.keyword_info.search_volume,desc"]
            }
        ]
        headers = {"Content-Type": "application/json"}
        try:
            response = requests.post(url, json=payload, headers=headers, auth=cred)
            response.raise_for_status()
        except Exception as e:
            logger.error(f"Error making request to DataForSEO: {e}")
            raise e

        try:
            results = self._transform_keyword_data(response.json())
        except Exception as e:
            logger.error(f"Error transforming keyword data: {e}")
            raise e

        return results

    def _transform_keyword_data(self, data: Dict) -> str:
        try:
            if data.get('tasks_error', 0) > 0:
                error_message = data.get('tasks', [{}])[0].get('status_message', 'Unknown error')
                return f"Error: {error_message}"

            all_results = data.get('tasks', [])[0].get('result', [])[0].get('items', [])
            if not all_results:
                return "Error: No results found in the response"

            # Create a DataFrame from the results
            df = pd.DataFrame(all_results)

            # Extract necessary fields and calculate additional metrics
            df['keyword'] = df['keyword_data'].apply(lambda x: x.get('keyword', 'N/A'))
            df['search_volume'] = df['keyword_data'].apply(lambda x: x.get('keyword_info', {}).get('search_volume', 0))
            df['keyword_difficulty'] = df['keyword_data'].apply(lambda x: x.get('keyword_properties', {}).get('keyword_difficulty', 0))
            df['competition_level'] = df['keyword_data'].apply(lambda x: x.get('keyword_info', {}).get('competition_level', 'N/A'))
            df['main_intent'] = df['keyword_data'].apply(lambda x: x.get('search_intent_info', {}).get('main_intent', 'N/A'))
            df['absolute_rank'] = df['ranked_serp_element'].apply(lambda x: x.get('serp_item', {}).get('rank_absolute', 0))
            df['etv'] = df['ranked_serp_element'].apply(lambda x: x.get('serp_item', {}).get('etv', 0))
            df['cpc'] = df['keyword_data'].apply(lambda x: x.get('keyword_info', {}).get('cpc', 0))

            # Define the columns to include in the output
            columns = [
                'keyword', 'search_volume', 'keyword_difficulty', 'competition_level',
                'main_intent', 'absolute_rank', 'etv'
            ]
            result_df = df[columns]

            # Convert the DataFrame to CSV format
            csv_output = result_df.to_csv(index=False, lineterminator='\n')
            return csv_output

        except Exception as e:
            logger.error(f"Error transforming keyword data: {e}")
            return f"Error: {str(e)}"

class KeywordTools:
    @staticmethod
    def _dataforseo_credentials():
        login = os.environ["DATAFORSEO_EMAIL"]
        password = os.environ["DATAFORSEO_PASSWORD"]
        return login, password

================
File: tools/neuralami_api_tool/neuralami_api_tool.py
================
import os
from typing import Any, Type, Set, Dict, Optional, List
import logging
from tenacity import retry, stop_after_attempt, wait_exponential
import requests
from pydantic import BaseModel, Field
from crewai.tools import BaseTool
import dotenv
import json

dotenv.load_dotenv()
logger = logging.getLogger(__name__)

class AgentSchema(BaseModel):
    """Schema for Agent operations"""
    name: str = Field(..., description="Name of the agent")
    role: str = Field(..., description="Role of the agent")
    goal: str = Field(..., description="Goal of the agent")
    backstory: str = Field(..., description="Backstory of the agent")
    llm: Optional[str] = Field(None, description="LLM model to use")
    verbose: Optional[bool] = Field(False, description="Enable verbose mode")

class TaskSchema(BaseModel):
    """Schema for Task operations"""
    description: str = Field(..., description="Description of the task")
    agent_id: Optional[int] = Field(None, description="ID of the agent assigned to this task")
    expected_output: str = Field(..., description="Expected output of the task")
    async_execution: Optional[bool] = Field(False, description="Enable async execution")

class CrewSchema(BaseModel):
    """Schema for Crew operations"""
    name: str = Field(..., description="Name of the crew")
    agent_ids: List[int] = Field(..., description="List of agent IDs in the crew")
    process: str = Field("sequential", description="Process type: 'sequential' or 'hierarchical'")
    verbose: Optional[bool] = Field(False, description="Enable verbose mode")

class ToolSchema(BaseModel):
    """Schema for Tool operations"""
    tool_class: str = Field(..., description="Class of the tool")
    tool_subclass: str = Field(..., description="Subclass of the tool")
    name: str = Field(..., description="Name of the tool")
    description: str = Field("", description="Description of the tool")
    module_path: str = Field(..., description="Module path of the tool")

class NeuralAMIAPISchema(BaseModel):
    """Input schema for NeuralAMI API Tool"""
    operation: str = Field(
        ...,
        description="Operation to perform: list_agents, get_agent, create_agent, update_agent, delete_agent, "
                   "list_tasks, get_task, create_task, update_task, delete_task, "
                   "list_crews, get_crew, create_crew, update_crew, delete_crew"
                   "list_tools, get_tool, create_tool, update_tool, delete_tool"

    )
    resource_id: Optional[int] = Field(None, description="ID of the resource for get/update/delete operations")
    data: Optional[dict] = Field(None, description="Data for create/update operations")

class NeuralAMIAPITool(BaseTool):
    name: str = "NeuralAMI API Tool"
    description: str = "A tool for interacting with NeuralAMI API to manage agents, tasks, tools, and crews"
    args_schema: Type[BaseModel] = NeuralAMIAPISchema
    tags: Set[str] = {"api", "agents", "tasks", "crews", "management"}

    # Add these as Pydantic fields
    base_url: str = Field(
        default_factory=lambda: os.getenv('CSRF_TRUSTED_ORIGINS', 'https://manager.neuralami.com').rstrip('/'),
        description="Base URL for the API"
    )
    api_token: str = Field(
        default_factory=lambda: os.getenv('NEURALAMI_API_TOKEN'),
        description="API token for authentication"
    )

    def __init__(self, **data):
        super().__init__(**data)
        if not self.api_token:
            logger.error("NEURALAMI_API_TOKEN is not set in environment variables")
            raise ValueError("NEURALAMI_API_TOKEN is required")

    def _get_headers(self):
        """Get headers for API requests"""
        return {
            'Authorization': f'Token {self.api_token}',
            'Content-Type': 'application/json'
        }

    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=4, max=10),
        reraise=True
    )
    def _make_request(self, method: str, endpoint: str, data: dict = None) -> Dict[str, Any]:
        """Make API request with retry mechanism"""
        url = f"{self.base_url}/api/{endpoint}"
        headers = self._get_headers()

        try:
            response = requests.request(
                method=method,
                url=url,
                headers=headers,
                json=data if data else None
            )
            response.raise_for_status()
            return response.json() if response.content else {}

        except requests.exceptions.RequestException as e:
            logger.error(f"API request failed: {str(e)}")
            if hasattr(e.response, 'text'):
                logger.error(f"Response content: {e.response.text[:500]}...")
            raise

    def _run(
        self,
        operation: str,
        resource_id: Optional[int] = None,
        data: Optional[dict] = None,
        **kwargs: Any,
    ) -> Dict[str, Any]:
        """Execute the API operation"""

        # Map operations to HTTP methods and endpoints
        operation_map = {
            # Agent operations
            'list_agents': ('GET', 'agents/'),
            'get_agent': ('GET', f'agents/{resource_id}/'),
            'create_agent': ('POST', 'agents/'),
            'update_agent': ('PUT', f'agents/{resource_id}/'),
            'delete_agent': ('DELETE', f'agents/{resource_id}/'),

            # Task operations
            'list_tasks': ('GET', 'tasks/'),
            'get_task': ('GET', f'tasks/{resource_id}/'),
            'create_task': ('POST', 'tasks/'),
            'update_task': ('PUT', f'tasks/{resource_id}/'),
            'delete_task': ('DELETE', f'tasks/{resource_id}/'),

            # Crew operations
            'list_crews': ('GET', 'crews/'),
            'get_crew': ('GET', f'crews/{resource_id}/'),
            'create_crew': ('POST', 'crews/'),
            'update_crew': ('PUT', f'crews/{resource_id}/'),
            'delete_crew': ('DELETE', f'crews/{resource_id}/'),

            # Tool operations
            'list_tools': ('GET', 'tools/'),
            'get_tool': ('GET', f'tools/{resource_id}/'),
            'create_tool': ('POST', 'tools/'),
            'update_tool': ('PUT', f'tools/{resource_id}/'),
            'delete_tool': ('DELETE', f'tools/{resource_id}/'),
        }

        if operation not in operation_map:
            raise ValueError(f"Invalid operation: {operation}")

        method, endpoint = operation_map[operation]

        # Validate resource_id for operations that require it
        if 'get_' in operation or 'update_' in operation or 'delete_' in operation:
            if not resource_id:
                raise ValueError(f"resource_id is required for operation: {operation}")

        # Validate data for create/update operations
        if method in ['POST', 'PUT'] and not data:
            raise ValueError(f"data is required for operation: {operation}")

        return self._make_request(method, endpoint, data)

================
File: tools/pagespeed_tool/pagespeed_tool.py
================
import os
from typing import Any, Type, Set, Dict, Optional
import logging
from tenacity import retry, stop_after_attempt, wait_exponential
import requests
from pydantic import BaseModel, Field
from crewai.tools import BaseTool
import dotenv
import time
from django.core.cache import cache

dotenv.load_dotenv()
logger = logging.getLogger(__name__)

class PageSpeedToolSchema(BaseModel):
    """Input for PageSpeedTool."""
    url: str = Field(..., title="URL", description="Full URL of the page to analyze (e.g., https://example.com)")
    strategy: str = Field(
        default="mobile",
        title="Strategy",
        description="The analysis strategy: 'mobile' or 'desktop'"
    )
    categories: list = Field(
        default=["performance"],
        title="Categories",
        description="Categories to analyze: 'performance', 'accessibility', 'best-practices', 'seo', 'pwa'"
    )

class PageSpeedTool(BaseTool):
    name: str = "PageSpeed Analysis Tool"
    description: str = "A tool that analyzes web pages using Google PageSpeed Insights API to get Core Web Vitals and other performance metrics."
    args_schema: Type[BaseModel] = PageSpeedToolSchema
    tags: Set[str] = {"performance", "seo", "web vitals", "pagespeed"}
    api_key: str = Field(default=os.environ.get('PAGESPEED_API_KEY'))
    base_url: str = Field(default="https://www.googleapis.com/pagespeedonline/v5/runPagespeed")

    def __init__(self, **data):
        super().__init__(**data)
        if not self.api_key:
            logger.error("PAGESPEED_API_KEY is not set in the environment variables.")

    def _run(
        self,
        url: str,
        strategy: str = "mobile",
        categories: list = ["performance"],
        **kwargs: Any,
    ) -> Dict[str, Any]:
        """Run PageSpeed analysis."""
        return self.get_pagespeed_data(url, strategy, categories)

    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=4, max=10),
        reraise=True
    )
    def get_pagespeed_data(
        self, 
        url: str, 
        strategy: str = "mobile",
        categories: list = ["performance"]
    ) -> Dict[str, Any]:
        """Get PageSpeed Insights data with retry mechanism."""
        if not self.api_key:
            raise ValueError("PageSpeed API key is not set")

        # Check cache first
        cache_key = f"pagespeed_{url}_{strategy}"
        cached_data = cache.get(cache_key)
        if cached_data:
            return self._process_pagespeed_data(cached_data)

        params = {
            'url': url,
            'key': self.api_key,
            'strategy': strategy,
            'category': categories
        }

        try:
            response = requests.get(
                self.base_url,
                params=params,
                timeout=None  # No timeout, wait for response
            )
            response.raise_for_status()
            data = response.json()

            # Cache the raw data
            cache.set(cache_key, data, timeout=3600)  # Cache for 1 hour

            # Process and return the data
            return self._process_pagespeed_data(data)

        except requests.exceptions.RequestException as e:
            logger.error(f"Error fetching PageSpeed data for {url}: {str(e)}")
            if hasattr(e.response, 'text'):
                logger.error(f"Response content: {e.response.text[:500]}...")
            raise

    def _process_pagespeed_data(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """Process and structure PageSpeed data."""
        try:
            result = {
                'core_web_vitals': {
                    'lab_data': self._extract_lab_data(data),
                    'field_data': self._extract_field_data(data)
                },
                'performance_score': self._extract_performance_score(data),
                'opportunities': self._extract_opportunities(data),
                'diagnostics': self._extract_diagnostics(data),
                'passed_audits': self._extract_passed_audits(data)
            }
            # Add additional categories if present
            for category in ['accessibility', 'best-practices', 'seo', 'pwa']:
                score = self._extract_category_score(data, category)
                if score is not None:
                    result[f'{category}_score'] = score

            return result

        except Exception as e:
            logger.error(f"Error processing PageSpeed data: {str(e)}")
            return {}

    def _extract_lab_data(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """Extract lab data metrics."""
        try:
            lab_data = data.get('lighthouseResult', {}).get('audits', {})
            metrics = {}
            
            metric_mapping = {
                'largest-contentful-paint': 'lcp',
                'cumulative-layout-shift': 'cls',
                'total-blocking-time': 'tbt',
                'interactive': 'tti',
                'speed-index': 'speed_index',
                'first-contentful-paint': 'fcp'
            }
            
            for audit_name, metric_name in metric_mapping.items():
                if audit_name in lab_data:
                    metrics[metric_name] = {
                        'value': lab_data[audit_name].get('numericValue'),
                        'score': lab_data[audit_name].get('score'),
                        'display_value': lab_data[audit_name].get('displayValue')
                    }
            
            return metrics
        except Exception as e:
            logger.error(f"Error extracting lab data: {str(e)}")
            return {}

    def _extract_field_data(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """Extract CrUX field data if available."""
        try:
            field_data = data.get('loadingExperience', {}).get('metrics', {})
            metrics = {}
            
            metric_mapping = {
                'LARGEST_CONTENTFUL_PAINT_MS': 'lcp',
                'CUMULATIVE_LAYOUT_SHIFT_SCORE': 'cls',
                'FIRST_INPUT_DELAY_MS': 'fid',
                'INTERACTION_TO_NEXT_PAINT': 'inp'
            }
            
            for api_name, metric_name in metric_mapping.items():
                if api_name in field_data:
                    metrics[metric_name] = {
                        'percentile': field_data[api_name]['percentile'],
                        'distributions': field_data[api_name]['distributions'],
                        'category': field_data[api_name].get('category')
                    }
            
            return metrics
        except Exception as e:
            logger.error(f"Error extracting field data: {str(e)}")
            return {}

    def _extract_performance_score(self, data: Dict[str, Any]) -> Optional[float]:
        """Extract overall performance score."""
        try:
            return data.get('lighthouseResult', {}).get('categories', {}).get('performance', {}).get('score')
        except Exception:
            return None

    def _extract_category_score(self, data: Dict[str, Any], category: str) -> Optional[float]:
        """Extract score for a specific category."""
        try:
            return data.get('lighthouseResult', {}).get('categories', {}).get(category, {}).get('score')
        except Exception:
            return None

    def _extract_opportunities(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """Extract improvement opportunities."""
        try:
            audits = data.get('lighthouseResult', {}).get('audits', {})
            opportunities = {}
            
            for audit_id, audit_data in audits.items():
                if audit_data.get('details', {}).get('type') == 'opportunity':
                    opportunities[audit_id] = {
                        'title': audit_data.get('title'),
                        'description': audit_data.get('description'),
                        'score': audit_data.get('score'),
                        'numeric_value': audit_data.get('numericValue'),
                        'display_value': audit_data.get('displayValue'),
                        'details': audit_data.get('details')
                    }
            
            return opportunities
        except Exception as e:
            logger.error(f"Error extracting opportunities: {str(e)}")
            return {}

    def _extract_diagnostics(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """Extract diagnostic information."""
        try:
            audits = data.get('lighthouseResult', {}).get('audits', {})
            diagnostics = {}
            
            for audit_id, audit_data in audits.items():
                if audit_data.get('details', {}).get('type') == 'diagnostic':
                    diagnostics[audit_id] = {
                        'title': audit_data.get('title'),
                        'description': audit_data.get('description'),
                        'score': audit_data.get('score'),
                        'details': audit_data.get('details')
                    }
            
            return diagnostics
        except Exception as e:
            logger.error(f"Error extracting diagnostics: {str(e)}")
            return {}

    def _extract_passed_audits(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """Extract passed audits."""
        try:
            audits = data.get('lighthouseResult', {}).get('audits', {})
            passed = {}
            
            for audit_id, audit_data in audits.items():
                if audit_data.get('score') == 1:
                    passed[audit_id] = {
                        'title': audit_data.get('title'),
                        'description': audit_data.get('description')
                    }
            
            return passed
        except Exception as e:
            logger.error(f"Error extracting passed audits: {str(e)}")
            return {}

================
File: tools/pandas_ai_tool/pandas_ai_tool.py
================
# apps/agents/tools/pandas_ai_tool/pandas_ai_tool.py

import os
from typing import Any, Type, List, Dict, Optional
from pydantic import BaseModel, Field
from crewai.tools import BaseTool
from apps.common.utils import get_llm
from pandasai import Agent as PandasAgent
from pandasai.llm import BambooLLM
import pandas as pd
from django.conf import settings
import json
import logging

logger = logging.getLogger(__name__)

class PandasAIToolSchema(BaseModel):
    """Input schema for PandasAITool."""
    query: str = Field(
        ..., 
        description="The natural language query to analyze the data"
    )
    data_source: str = Field(
        ..., 
        description="Path to data file or DataFrame variable name"
    )
    data_format: str = Field(
        default="csv",
        description="Format of data source (csv, excel, parquet)"
    )
    analysis_depth: str = Field(
        default="detailed",
        description="Analysis depth: 'basic' (simple stats), 'detailed' (comprehensive analysis), or 'advanced' (complex insights)"
    )

class PandasAITool(BaseTool):
    name: str = "PandasAI Data Analysis Tool"
    description: str = """
    Analyzes data using natural language queries through PandasAI.
    Supports multiple data formats and various analysis depths.
    Features intelligent data loading, error handling, and detailed responses.
    """
    args_schema: Type[BaseModel] = PandasAIToolSchema
    
    modelname: str = Field(default=settings.PANDAS_AI_MODEL)
    llm: Optional[Any] = Field(default=None)
    pandas_agent: Optional[Any] = Field(default=None)

    def __init__(self, **data):
        super().__init__(**data)
        self.llm = BambooLLM(api_key=os.getenv("PANDASAI_API_KEY"))
        
    def _load_data(self, data_source: str, data_format: str) -> pd.DataFrame:
        """Load data from various sources with error handling."""
        try:
            loaders = {
                "csv": pd.read_csv,
                "excel": pd.read_excel,
                "parquet": pd.read_parquet
            }
            
            if data_format not in loaders:
                raise ValueError(f"Unsupported data format: {data_format}")
                
            loader = loaders[data_format]
            df = loader(data_source)
            
            logger.info(f"Successfully loaded data from {data_source}")
            logger.debug(f"DataFrame shape: {df.shape}")
            
            return df
            
        except Exception as e:
            logger.error(f"Error loading data: {str(e)}")
            raise

    def _get_analysis_prompt(self, analysis_depth: str, query: str) -> str:
        """Get the appropriate analysis prompt based on depth."""
        prompts = {
            "basic": f"""
            Perform a basic analysis of the data:
            - Focus on simple descriptive statistics
            - Provide clear, concise results
            - Answer the specific query: {query}
            """,
            
            "detailed": f"""
            Perform a comprehensive analysis of the data:
            - Include detailed statistical measures
            - Identify trends and patterns
            - Provide visualizations if relevant
            - Answer the specific query: {query}
            """,
            
            "advanced": f"""
            Perform an advanced analysis of the data:
            - Use sophisticated statistical methods
            - Conduct deep pattern analysis
            - Provide complex visualizations
            - Include predictive insights
            - Answer the specific query: {query}
            """
        }
        return prompts.get(analysis_depth, prompts["detailed"])

    def _run(
        self,
        query: str,
        data_source: str,
        data_format: str = "csv",
        analysis_depth: str = "detailed",
        **kwargs: Any
    ) -> str:
        try:
            # Input validation
            if not query or not data_source:
                return json.dumps({
                    "error": "Invalid input",
                    "message": "Query and data_source must be non-empty strings"
                })

            # Load the data
            df = self._load_data(data_source, data_format)
            
            # Initialize PandasAI agent if not already initialized
            if not self.pandas_agent:
                self.pandas_agent = PandasAgent(df, config={"llm": self.llm})
            
            # Get analysis prompt
            enhanced_query = self._get_analysis_prompt(analysis_depth, query)
            
            # Execute analysis
            logger.info(f"Executing analysis with depth: {analysis_depth}")
            response = self.pandas_agent.chat(enhanced_query)
            
            result = {
                "analysis_result": str(response),
                "data_info": {
                    "rows": df.shape[0],
                    "columns": df.shape[1],
                    "data_source": data_source,
                    "format": data_format
                },
                "analysis_depth": analysis_depth
            }
            
            return json.dumps(result)

        except Exception as e:
            logger.error(f"Error in PandasAITool: {str(e)}")
            return json.dumps({
                "error": "Analysis failed",
                "message": str(e)
            })

================
File: tools/pandas_ai_tool/README.md
================
# PandasAI Tool

A CrewAI tool for data analysis using PandasAI with natural language queries.

## Features

- Natural language data analysis
- Multiple data format support (CSV, Excel, Parquet)
- Configurable analysis depth
- Comprehensive error handling
- Detailed logging
- Structured JSON responses

## Usage
python
from apps.agents.tools.pandas_ai_tool import PandasAITool

tool = PandasAITool()
result = tool.run(
    query="What is the average age by category?",
    data_source="path/to/data.csv",
    data_format="csv",
    analysis_depth="detailed"
)


## Configuration

Set the following environment variables:
- PANDASAI_API_KEY: Your PandasAI API key
- PANDAS_AI_MODEL: The model to use for analysis (optional)

This implementation:
Follows the same structural patterns as the compression tool
Includes comprehensive error handling
Provides detailed logging
Uses structured input/output schemas
Supports different analysis depths
Includes proper documentation
Follows Django project conventions
Implements proper type hinting
Uses environment variables for configuration

================
File: tools/rag/rag_tool.py
================
from abc import ABC, abstractmethod
from typing import Any

from pydantic import BaseModel, Field, model_validator

from crewai.tools import BaseTool


class Adapter(BaseModel, ABC):
    class Config:
        arbitrary_types_allowed = True

    @abstractmethod
    def query(self, question: str) -> str:
        """Query the knowledge base with a question and return the answer."""

    @abstractmethod
    def add(
        self,
        *args: Any,
        **kwargs: Any,
    ) -> None:
        """Add content to the knowledge base."""


class RagTool(BaseTool):
    class _AdapterPlaceholder(Adapter):
        def query(self, question: str) -> str:
            raise NotImplementedError

        def add(self, *args: Any, **kwargs: Any) -> None:
            raise NotImplementedError

    name: str = "Knowledge base"
    description: str = "A knowledge base that can be used to answer questions."
    summarize: bool = False
    adapter: Adapter = Field(default_factory=_AdapterPlaceholder)
    config: dict[str, Any] | None = None

    @model_validator(mode="after")
    def _set_default_adapter(self):
        if isinstance(self.adapter, RagTool._AdapterPlaceholder):
            from embedchain import App

            from crewai_tools.adapters.embedchain_adapter import EmbedchainAdapter

            app = App.from_config(config=self.config) if self.config else App()
            self.adapter = EmbedchainAdapter(
                embedchain_app=app, summarize=self.summarize
            )

        return self

    def add(
        self,
        *args: Any,
        **kwargs: Any,
    ) -> None:
        self.adapter.add(*args, **kwargs)

    def _run(
        self,
        query: str,
        **kwargs: Any,
    ) -> Any:
        self._before_run(query, **kwargs)

        return f"Relevant Content:\n{self.adapter.query(query)}"

    def _before_run(self, query, **kwargs):
        pass

================
File: tools/rag/README.md
================
# RagTool: A Dynamic Knowledge Base Tool

RagTool is designed to answer questions by leveraging the power of RAG by leveraging (EmbedChain). It integrates seamlessly with the CrewAI ecosystem, offering a versatile and powerful solution for information retrieval.

## **Overview**

RagTool enables users to dynamically query a knowledge base, making it an ideal tool for applications requiring access to a vast array of information. Its flexible design allows for integration with various data sources, including files, directories, web pages, yoututbe videos and custom configurations.

## **Usage**

RagTool can be instantiated with data from different sources, including:

-  PDF file
-  CSV file
-  JSON file
-  Text
-  Directory/ Folder
-  HTML Web page
-  Youtube Channel
-  Youtube Video
-  Docs website
-  MDX file
-  DOCX file
-  XML file
-  Gmail
-  Github
-  Postgres
-  MySQL
-  Slack
-  Discord
-  Discourse
-  Substack
-  Beehiiv
-  Dropbox
-  Image
-  Custom

#### **Creating an Instance**

```python
from crewai_tools.tools.rag_tool import RagTool

# Example: Loading from a file
rag_tool = RagTool().from_file('path/to/your/file.txt')

# Example: Loading from a directory
rag_tool = RagTool().from_directory('path/to/your/directory')

# Example: Loading from a web page
rag_tool = RagTool().from_web_page('https://example.com')
```

## **Contribution**

Contributions to RagTool and the broader CrewAI tools ecosystem are welcome. To contribute, please follow the standard GitHub workflow for forking the repository, making changes, and submitting a pull request.

## **License**

RagTool is open-source and available under the MIT license.

Thank you for considering RagTool for your knowledge base needs. Your contributions and feedback are invaluable to making RagTool even better.

================
File: tools/screenshot_tool/screenshot_tool.py
================
import os
import requests
import json
from typing import Any, Type
from pydantic import BaseModel, Field, ConfigDict
from crewai.tools import BaseTool
from django.conf import settings
from django.core.files.storage import default_storage
from django.core.files.base import ContentFile
from urllib.parse import urlparse
import re
import logging
"""
You can use the ScreenshotTool by 
 1. importing 'from apps.agents.tools.screenshot_tool import screenshot_tool'' and 
 2. calling its run method with a URL as the argument: 'result = screenshot_tool.run(url=url)'
 """

logger = logging.getLogger(__name__)

class ScreenshotToolSchema(BaseModel):
    """Input schema for ScreenshotTool."""
    model_config = ConfigDict(
        extra='forbid',
        arbitrary_types_allowed=True
    )
    
    url: str = Field(description="The URL of the website to capture a screenshot.")

class ScreenshotTool(BaseTool):
    model_config = ConfigDict(
        extra='forbid',
        arbitrary_types_allowed=True
    )
    
    name: str = "Capture Website Screenshot"
    description: str = "Captures a screenshot of a given website URL."
    args_schema: Type[BaseModel] = ScreenshotToolSchema
    
    def _run(
        self, 
        url: str, 
        **kwargs: Any
    ) -> Any:
        """
        Run the screenshot tool and save to cloud storage.
        
        Args:
            url: The URL to screenshot
            **kwargs: Additional arguments
            
        Returns:
            dict: Contains either the screenshot URL or an error message
        """
        try:
            browserless_url = os.getenv('BROWSERLESS_BASE_URL')
            api_key = os.getenv('BROWSERLESS_API_KEY')
            
            if not browserless_url or not api_key:
                logger.error("Browserless configuration is missing")
                return {'error': 'Browserless configuration is missing'}
            
            screenshot_url = f"{browserless_url}/screenshot?token={api_key}"
            
            payload = {
                "url": url,
                "options": {
                    "fullPage": False,
                    "type": "png"
                }
            }
            
            response = requests.post(screenshot_url, json=payload)
            
            if response.status_code == 200:
                # Generate a sanitized filename based on the URL
                parsed_url = urlparse(url)
                sanitized_name = re.sub(r'[^\w\-_\. ]', '_', parsed_url.netloc + parsed_url.path)
                filename = f"{sanitized_name[:200]}.png"  # Limit filename length
                
                # Create the relative path for cloud storage
                relative_path = os.path.join('crawled_screenshots', filename)
                
                try:
                    # Save the image using default_storage
                    default_storage.save(relative_path, ContentFile(response.content))
                    
                    # Generate the URL for the saved image
                    image_url = default_storage.url(relative_path)
                    
                    logger.info(f"Screenshot saved successfully: {relative_path}")
                    return {'screenshot_url': image_url}
                    
                except Exception as e:
                    error_msg = f"Error saving screenshot: {str(e)}"
                    logger.error(error_msg)
                    return {'error': error_msg}
            else:
                error_msg = f'Failed to get screenshot. Status code: {response.status_code}'
                logger.error(error_msg)
                return {'error': error_msg}
                
        except Exception as e:
            error_msg = f"Error in screenshot tool: {str(e)}"
            logger.error(error_msg)
            return {'error': error_msg}

    def _check_screenshot_exists(self, url: str) -> str:
        """
        Check if a screenshot already exists for the given URL.
        
        Args:
            url: The URL to check
            
        Returns:
            str: The existing screenshot URL if found, None otherwise
        """
        try:
            parsed_url = urlparse(url)
            sanitized_name = re.sub(r'[^\w\-_\. ]', '_', parsed_url.netloc + parsed_url.path)
            filename = f"{sanitized_name[:200]}.png"
            relative_path = os.path.join('crawled_screenshots', filename)
            
            if default_storage.exists(relative_path):
                return default_storage.url(relative_path)
            return None
            
        except Exception as e:
            logger.error(f"Error checking screenshot existence: {str(e)}")
            return None

# Initialize the tool
screenshot_tool = ScreenshotTool()

================
File: tools/search_context_tool/search_context_tool.py
================
import os
from typing import Any, Type, List, Dict
from pydantic import BaseModel, Field
from crewai.tools import BaseTool
from apps.agents.tools.searxng_tool.searxng_tool import SearxNGSearchTool
from apps.agents.tools.browser_tool.browser_tool import BrowserTool
from apps.common.utils import get_llm as utils_get_llm
from langchain.prompts.chat import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
import json
import logging

logger = logging.getLogger(__name__)

class SearchContextToolSchema(BaseModel):
    """Input schema for SearchContextTool."""
    question: str = Field(
        ..., 
        description="The user's question to research and answer.",
        examples=["What is the capital of France?"]
    )

    @classmethod
    def get_schema(cls) -> Dict:
        """Return a simplified schema for agent consumption"""
        return {
            "question": {
                "type": "string",
                "description": "The user's question to research and answer."
            }
        }
    
    class Config:
        json_schema_extra = {
            "examples": [
                {
                    "question": "What is the capital of France?"
                }
            ]
        }

class SearchContextTool(BaseTool):
    name: str = "Search and provide contextual answer"
    description: str = "Searches the internet, gathers context from multiple sources, and provides a detailed answer with follow-up questions."
    args_schema: Type[BaseModel] = SearchContextToolSchema
    
    # Define the tools as fields
    search_tool: SearxNGSearchTool = Field(default_factory=SearxNGSearchTool)
    browser_tool: BrowserTool = Field(default_factory=BrowserTool)
    model_name: str = Field(default="anthropic/claude-3-haiku-20240307")
    llm: Any = None
    token_counter_callback: Any = None

    def __init__(self, **data):
        super().__init__(**data)
        self.llm, self.token_counter_callback = utils_get_llm(self.model_name, temperature=0.7)

# Add this method to the SearchContextTool class:
    def _reformulate_question(self, original_question: str) -> str:
        "Reformulate the user's question into an optimized search query."
        
        reformulation_prompt = ChatPromptTemplate.from_messages([
            ("system", """You are an expert at reformulating questions into optimal search queries. 
            Your task is to analyze the user's question and create a more effective search query that will yield the most relevant results.
            
            Follow these guidelines:
            1. Identify Core Concepts:
                - Extract the main topics and key concepts
                - Identify any implicit assumptions or context
            
            2. Add Critical Context:
                - Include relevant technical terms
                - Add synonyms for important concepts
                - Specify time period if relevant (e.g., "2024", "recent", "latest")
            
            3. Optimize for Search:
                - Use boolean operators when helpful (AND, OR)
                - Include specific phrases in quotes for exact matches
                - Remove unnecessary words (articles, prepositions)
                - Add clarifying terms to disambiguate
            
            4. Enhance Specificity:
                - Add domain-specific terminology
                - Include relevant qualifiers
                - Specify desired information type (research, news, analysis, etc.)
            
            Return only the reformulated search query, without explanation or additional text."""),
            ("human", """Original question: {question}
            
            Create an optimized search query that will find the most relevant and comprehensive information to answer this question.""")
        ])

        reformulation_chain = reformulation_prompt | self.llm | StrOutputParser()

        try:
            optimized_query = reformulation_chain.invoke({
                'question': original_question
            })
            logger.info(f"Reformulated question: {optimized_query}")
            return optimized_query
        except Exception as e:
            logger.error(f"Error reformulating question: {str(e)}")
            return original_question

# Then modify the _run method to use the reformulated question:

    def _extract_urls(self, search_results: str) -> List[str]:
        """Extract URLs from search results."""
        urls = []
        for line in search_results.split('\n'):
            if line.startswith('Link: '):
                urls.append(line.replace('Link: ', '').strip())
        return urls[:7]  # Get top 6 results

    def _gather_context(self, urls: List[str]) -> str:
        """Gather context from URLs."""
        contexts = []
        for url in urls:
            try:
                content = self.browser_tool._run(website=url)
                if content and len(content) > 100:  # Basic validation
                    contexts.append(f"Source ({url}):\n{content}")
            except Exception as e:
                logger.error(f"Error scraping {url}: {str(e)}")
        return "\n\n".join(contexts)

    def _generate_answer(self, question: str, context: str) -> str:
        """Generate answer using LLM."""
        answer_prompt = ChatPromptTemplate.from_messages([
            ("system", """You are a helpful AI assistant. Using the provided context, 
            answer the user's question thoroughly and accurately. Cite sources when possible.
            Format your response in markdown."""),
            ("human", """
            Question: {question}
            
            Context: {context}
            
            Please provide a detailed answer based on the context provided.
            """)
        ])
        
        answer_chain = answer_prompt | self.llm | StrOutputParser()
        return answer_chain.invoke({
            'question': question,
            'context': context
        })

    def _generate_follow_up_questions(self, question: str, answer: str) -> List[str]:
        """Generate follow-up questions based on the answer."""
        followup_prompt = ChatPromptTemplate.from_messages([
            ("system", """Based on the original question and answer provided, 
            generate exactly 3 relevant follow-up questions that would help explore 
            the topic further. Format as a markdown list."""),
            ("human", """
            Original Question: {question}
            Answer: {answer}
            
            Generate 3 follow-up questions:
            """)
        ])
        
        followup_chain = followup_prompt | self.llm | StrOutputParser()
        return followup_chain.invoke({
            'question': question,
            'answer': answer
        })

    def _run(
        self,
        question: str,
        **kwargs: Any
        ) -> Any:
        """Execute the search context tool pipeline."""
        try:
            # 0. Reformulate the question for better search results
            optimized_query = self._reformulate_question(question)
            logger.info(f"Original question: {question}")
            logger.info(f"Optimized query: {optimized_query}")
            
            # 1. Search for relevant results using optimized query
            search_results = self.search_tool._run(search_query=optimized_query)
            
            # 2. Extract URLs and gather context
            urls = self._extract_urls(search_results)
            context = self._gather_context(urls)
            
            # 3. Generate answer (using original question for better context)
            answer = self._generate_answer(question, context)
            
            # 4. Generate follow-up questions
            follow_up = self._generate_follow_up_questions(question, answer)
            
            # 5. Format and return results
            result = {
                "original_question": question,
                "optimized_query": optimized_query,
                "answer": answer,
                "follow_up_questions": follow_up,
                "sources": urls
            }
            
            return json.dumps(result, indent=2)

        except Exception as e:
            logger.error(f"Error in SearchContextTool: {str(e)}")
            return f"An error occurred while processing your request: {str(e)}"

================
File: tools/search_context_tool/test_search_context_tool.py
================
import logging
import sys
import os

# Add the project root to the Python path
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..', '..', '..'))
sys.path.insert(0, project_root)

# Set up Django settings
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'core.settings')  # Adjust this to your project's settings module
import django
django.setup()

from apps.agents.tools.search_context_tool.search_context_tool import SearchContextTool

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def test_search_context():
  # Initialize the tool
  search_tool = SearchContextTool()

  # Test question
  test_question = "as of october 29, 2024 what are the latest flooring trends in ottumwa that consumers are looking for and elaborate on the reasons why?"
  
  logger.info(f"Starting search context analysis for question: {test_question}")
  print(f"Starting search context analysis for question: {test_question}")
  
  try:
      # Get results
      result = search_tool._run(test_question)
      
      # Log and print the results
      logger.info("Search Context Results:")
      logger.info(result)
      print("\nSearch Context Results:")
      print(result)
      
  except Exception as e:
      logger.error(f"Error during search context analysis: {str(e)}")
      print(f"Error: {str(e)}")

if __name__ == "__main__":
  test_search_context()

================
File: tools/searxng_tool/searxng_tool.py
================
import os
import requests
import json
from typing import Any, Type, Optional
from pydantic import BaseModel, Field, ConfigDict
from crewai.tools import BaseTool

class SearxNGToolSchema(BaseModel):
    """Input schema for SearxNGSearchTool."""
    model_config = ConfigDict(
        extra='forbid',
        arbitrary_types_allowed=True
    )
    
    search_query: str = Field(description="The search query to be used.")

class SearxNGSearchTool(BaseTool):
    model_config = ConfigDict(
        extra='forbid',
        arbitrary_types_allowed=True
    )
    
    name: str = "Search the internet"
    description: str = "Searches the internet displaying titles, links, snippets, engines, and categories."
    args_schema: Type[BaseModel] = SearxNGToolSchema
    search_url: str = "https://search.neuralami.com"
    n_results: Optional[int] = None

    def _run(
        self, 
        search_query: str, 
        **kwargs: Any
    ) -> Any:
        payload = {        
            'q': search_query,
            'format': 'json',
            'pageno': '1',
            'language': 'en-US'
        }
        response = requests.get(self.search_url, params=payload)
        if response.ok:
            results = response.json()['results']
            formatted_results = []
            for result in results:
                try:
                    engines = ', '.join(result['engines']) if 'engines' in result else 'N/A'
                    formatted_results.append('\n'.join([
                        f"Title: {result.get('title', 'No Title')}",
                        f"Link: {result.get('url', 'No Link')}",
                        f"Score: {result.get('score', 'No Score')}",
                        f"Snippet: {result.get('content', 'No Snippet')}",
                        f"Engines: {engines}",
                        f"Category: {result.get('category', 'No Category')}",
                        "---"
                    ]))
                except KeyError as e:
                    print(f"Skipping an entry due to missing key: {e}")
                    continue

            content = '\n'.join(formatted_results)
            return f"Search results:\n{content}"
        else:
            return f"Failed to fetch search results. Status code: {response.status_code}"

================
File: tools/seo_audit_tool/content_type_detector.py
================
"""Content type detection for SEO audit tool."""
from typing import Dict, Any
from urllib.parse import urlparse

def determine_content_type(page_data: Dict[str, Any]) -> str:
    """
    Determine the content type of a page based on various signals.
    
    Args:
        page_data: Dictionary containing page information including URL, schema, meta tags, etc.
        
    Returns:
        str: Detected content type (e.g., "business_homepage", "blog", "article", etc.)
    """
    url = page_data.get("url", "")
    parsed_url = urlparse(url)
    path = parsed_url.path.lower()
    
    # Check if it's homepage
    if path in ['', '/']:
        return "business_homepage"
    
    # Check URL patterns
    url_indicators = {
        "blog": ['/blog/', '/posts/', '/articles/'],
        "news": ['/news/', '/press/', '/updates/'],
        "article": ['/article/', '/story/'],
        "product": ['/product/', '/item/', '/goods/'],
        "category": ['/category/', '/collection/', '/catalog/'],
        "contact": ['/contact/', '/reach-us/', '/location/'],
        "about": ['/about/', '/about-us/', '/company/']
    }
    
    # Check URL patterns
    for content_type, patterns in url_indicators.items():
        if any(pattern in path for pattern in patterns):
            return content_type
            
    # Check page structure and content
    html_structure = {
        "has_blog_schema": bool(page_data.get("schema_type") == "BlogPosting"),
        "has_article_schema": bool(page_data.get("schema_type") == "Article"),
        "has_news_schema": bool(page_data.get("schema_type") == "NewsArticle"),
        "has_product_schema": bool(page_data.get("schema_type") == "Product"),
    }
    
    # Check for schema.org markup
    if html_structure["has_blog_schema"]:
        return "blog"
    elif html_structure["has_news_schema"]:
        return "news"
    elif html_structure["has_article_schema"]:
        return "article"
    elif html_structure["has_product_schema"]:
        return "product"
    
    # Check meta tags
    meta_type = page_data.get("meta_type", "").lower()
    if meta_type:
        if "blog" in meta_type:
            return "blog"
        elif "news" in meta_type:
            return "news"
        elif "article" in meta_type:
            return "article"
        elif "product" in meta_type:
            return "product"
    
    # Default to generic content page if no specific type is detected
    return "content"

================
File: tools/seo_audit_tool/seo_audit_tool.py
================
import json
import os
from typing import Dict, List, Any, Optional, Type, Set
from datetime import datetime
import logging
import asyncio
import aiohttp
import ssl
from collections import defaultdict
from bs4 import BeautifulSoup
from urllib.parse import urlparse, urljoin
from pydantic import BaseModel, Field
from crewai.tools import BaseTool
import dotenv
from django.core.cache import cache
import re

from apps.agents.tools.browser_tool.browser_tool import BrowserTool
from apps.agents.tools.crawl_website_tool.crawl_website_tool import CrawlWebsiteTool
from apps.agents.tools.seo_crawler_tool.seo_crawler_tool import SEOCrawlerTool
from apps.common.utils import normalize_url
from apps.agents.utils import URLDeduplicator
from .seo_checkers import SEOChecker
from apps.agents.tools.pagespeed_tool.pagespeed_tool import PageSpeedTool

dotenv.load_dotenv()
logger = logging.getLogger(__name__)

class SEOAuditToolSchema(BaseModel):
    """Input for SEOAuditTool."""
    website: str = Field(..., title="Website", description="Full URL of the website to perform SEO audit on (e.g., https://example.com)")
    max_pages: int = Field(
        default=100,
        title="Max Pages",
        description="Maximum number of pages to audit"
    )
    check_external_links: bool = Field(
        default=False,
        title="Check External Links",
        description="Whether to check external links for broken links"
    )
    crawl_delay: float = Field(
        default=1.0,
        title="Crawl Delay",
        description="Delay between crawling pages in seconds"
    )

class SEOAuditTool(BaseTool):
    name: str = "SEO Audit Tool"
    description: str = "A tool that performs comprehensive SEO audit on a website, checking for issues like broken links, duplicate content, meta tag issues, images, and more."
    args_schema: Type[BaseModel] = SEOAuditToolSchema
    tags: Set[str] = {"seo", "audit", "website", "content"}
    api_key: str = Field(default=os.environ.get('BROWSERLESS_API_KEY'))
    browser_tool: BrowserTool = Field(default_factory=BrowserTool)
    crawl_tool: CrawlWebsiteTool = Field(default_factory=CrawlWebsiteTool)
    seo_crawler: SEOCrawlerTool = Field(default_factory=SEOCrawlerTool)
    url_deduplicator: URLDeduplicator = Field(default_factory=URLDeduplicator)
    checker: SEOChecker = Field(default_factory=SEOChecker)
    pagespeed_tool: PageSpeedTool = Field(default_factory=PageSpeedTool)

    model_config = {"arbitrary_types_allowed": True}
    
    def __init__(self, **data):
        super().__init__(**data)
        if not self.api_key:
            logger.error("BROWSERLESS_API_KEY is not set in the environment variables.")
        self._session = None
        self._link_cache = {}
        self._semaphore = None
        self._checked_urls = set()

    def _run(
        self,
        website: str,
        max_pages: int = 100,
        check_external_links: bool = False,
        crawl_delay: float = 1.0,
        progress_callback = None,
        **kwargs: Any,
    ) -> Dict[str, Any]:
        """Run SEO audit."""
        logger.info(f"Starting SEO audit for: {website}")
        start_time = datetime.now()
        
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        try:
            result = loop.run_until_complete(self._async_audit(
                website=website,
                max_pages=max_pages,
                check_external_links=check_external_links,
                crawl_delay=crawl_delay,
                progress_callback=progress_callback
            ))
            end_time = datetime.now()
            if 'summary' not in result:
                result['summary'] = {}
            result['summary'].update({
                'audit_start_time': start_time.isoformat(),
                'audit_end_time': end_time.isoformat(),
                'start_time': start_time.isoformat(),  # For compatibility
                'end_time': end_time.isoformat(),      # For compatibility
                'total_audit_time_seconds': (end_time - start_time).total_seconds()
            })
            logger.info(f"SEO audit completed for: {website}")
            return json.loads(json.dumps(result, default=str))
        except Exception as e:
            logger.error(f"Error running SEO audit: {str(e)}")
            raise
        finally:
            loop.close()

    async def _async_audit(
        self,
        website: str,
        max_pages: int = 100,
        check_external_links: bool = False,
        crawl_delay: float = 1.0,
        progress_callback = None
    ) -> Dict[str, Any]:
        """Run SEO audit asynchronously."""
        logger.info("Starting crawler...")
        
        if progress_callback:
            progress_callback({
                'percent_complete': 0,
                'pages_analyzed': 0,
                'issues_found': 0,
                'status': 'Starting crawler...'
            })

        total_issues = 0  # Initialize total_issues at the module level
        audit_results = {
            "broken_links": [],
            "duplicate_content": [],
            "meta_tag_issues": [],
            "image_issues": [],
            "content_issues": [],
            "ssl_issues": {},
            "sitemap_present": False,
            "robots_txt_present": False,
            "page_analysis": []
        }

        last_progress_data = {}
        all_links = set()
        base_domain = urlparse(website).netloc

        def page_callback(page_data):
            nonlocal total_issues, last_progress_data
            
            # Check meta tags
            meta_issues = self.checker.check_meta_tags(page_data)
            if meta_issues:
                audit_results["meta_tag_issues"].extend(meta_issues)
                total_issues += len(meta_issues)
            
            # Check headings
            heading_issues = self.checker.check_headings(page_data)
            if heading_issues:
                audit_results["heading_issues"] = audit_results.get("heading_issues", [])
                audit_results["heading_issues"].extend(heading_issues)
                total_issues += len(heading_issues)
            
            # Check images
            image_issues = self.checker.check_images(page_data)
            if image_issues:
                audit_results["image_issues"] = audit_results.get("image_issues", [])
                audit_results["image_issues"].extend(image_issues)
                total_issues += len(image_issues)
            
            # Check content
            content_issues = self.checker.check_content(page_data)
            if content_issues:
                audit_results["content_issues"] = audit_results.get("content_issues", [])
                audit_results["content_issues"].extend(content_issues)
                total_issues += len(content_issues)

            # Check social media tags
            social_media_issues = self.checker.check_social_media_tags(page_data)
            if social_media_issues:
                audit_results["social_media_issues"] = audit_results.get("social_media_issues", [])
                audit_results["social_media_issues"].extend(social_media_issues)
                total_issues += len(social_media_issues)

            # Check canonical tags
            canonical_issues = self.checker.check_canonical_tags(page_data)
            if canonical_issues:
                audit_results["canonical_issues"] = audit_results.get("canonical_issues", [])
                audit_results["canonical_issues"].extend(canonical_issues)
                total_issues += len(canonical_issues)

            # Add semantic structure checks
            semantic_issues = self.checker.check_semantic_structure(page_data)
            if semantic_issues:
                audit_results["semantic_issues"] = audit_results.get("semantic_issues", [])
                audit_results["semantic_issues"].extend(semantic_issues)
                total_issues += len(semantic_issues)

            # Add robots indexing checks
            robots_issues = self.checker.check_robots_indexing(page_data)
            if robots_issues:
                audit_results["robots_issues"] = audit_results.get("robots_issues", [])
                audit_results["robots_issues"].extend(robots_issues)
                total_issues += len(robots_issues)

            # Add E-E-A-T signal checks
            eeat_issues = self.checker.check_eeat_signals(page_data)
            if eeat_issues:
                audit_results["eeat_issues"] = audit_results.get("eeat_issues", [])
                audit_results["eeat_issues"].extend(eeat_issues)
                total_issues += len(eeat_issues)

            # Add redirect chain checks
            redirect_issues = self.checker.check_redirect_chains(page_data)
            if redirect_issues:
                audit_results["redirect_issues"] = audit_results.get("redirect_issues", [])
                audit_results["redirect_issues"].extend(redirect_issues)
                total_issues += len(redirect_issues)
            
            # Collect internal links
            internal_links = self.checker.check_links(page_data, base_domain)
            for link in internal_links:
                all_links.add((page_data["url"], link))
            
            # Update progress data with all issues
            all_issues = []
            for issue_type, issues in audit_results.items():
                if issue_type.endswith('_issues'):
                    for issue in issues:
                        all_issues.append({
                            'severity': issue.get('severity', 'medium'),
                            'issue_type': issue.get('type'),
                            'url': issue.get('url'),
                            'details': issue.get('issue'),
                            'value': issue.get('value'),
                            'additional_details': issue.get('details', {})
                        })
            
            if all_issues:
                last_progress_data['recent_issues'] = all_issues
                last_progress_data['status'] = f"Found {len(all_issues)} issues on {page_data['url']}"
            
            # Add page metrics
            audit_results["page_analysis"].append(
                self.checker.get_page_metrics(page_data)
            )

        # Modify crawler call to use page callback
        def wrapped_progress_callback(data):
            if progress_callback:
                update_data = {
                    'percent_complete': int(data.get('percent_complete', 0) * 0.7),  # First 70% for crawling
                    'pages_analyzed': data.get('pages_analyzed', 0),
                    'issues_found': total_issues,  # Now using the correct total_issues
                    'status': last_progress_data.get('status', f"Analyzing: {data.get('status', '')}")
                }
                if 'recent_issues' in last_progress_data:
                    update_data['recent_issues'] = last_progress_data['recent_issues']
                    last_progress_data.clear()  # Clear after sending
                progress_callback(update_data)

        # Create a wrapper for the page callback that ensures it's called for each page
        def wrapped_page_callback(page):
            page_data = {
                "url": page.url,
                "title": page.title,
                "meta_description": page.meta_description,
                "h1_tags": page.h1_tags,
                "links": page.links,
                "text_content": page.text_content,
                "crawl_timestamp": page.crawl_timestamp,
                "status_code": page.status_code,
                "canonical_url": getattr(page, 'canonical_url', None),
                "canonical_count": len(page.canonical_tags) if hasattr(page, 'canonical_tags') else 0,
                "is_pagination": bool(page.pagination_info) if hasattr(page, 'pagination_info') else False,
                "canonical_chain": page.canonical_chain if hasattr(page, 'canonical_chain') else [],
                # Add semantic structure data
                "has_semantic_markup": getattr(page, 'has_semantic_markup', False),
                "has_header": getattr(page, 'has_header', False),
                "has_nav": getattr(page, 'has_nav', False),
                "has_main": getattr(page, 'has_main', False),
                "has_footer": getattr(page, 'has_footer', False),
                "semantic_nesting_issues": getattr(page, 'semantic_nesting_issues', []),
                "empty_semantic_elements": getattr(page, 'empty_semantic_elements', []),
                "page_type": getattr(page, 'page_type', 'content'),
                # Add robots indexing data
                "noindex": getattr(page, 'noindex', False),
                "noindex_source": getattr(page, 'noindex_source', None),
                "noindex_intentional": getattr(page, 'noindex_intentional', False),
                "x_robots_tag": getattr(page, 'x_robots_tag', None),
                "robots_blocked": getattr(page, 'robots_blocked', False),
                "robots_directive": getattr(page, 'robots_directive', None),
                "robots_user_agent": getattr(page, 'robots_user_agent', '*'),
                # Add E-E-A-T data
                "has_author": getattr(page, 'has_author', False),
                "author_info": getattr(page, 'author_info', None),
                "has_expertise": getattr(page, 'has_expertise', False),
                "expertise_indicators": getattr(page, 'expertise_indicators', []),
                "has_factual_accuracy": getattr(page, 'has_factual_accuracy', False),
                "factual_accuracy_indicators": getattr(page, 'factual_accuracy_indicators', []),
                "content_type": getattr(page, 'content_type', None),
                # Add redirect chain data
                "redirect_chain": getattr(page, 'redirect_chain', []),
                "meta_refresh": getattr(page, 'meta_refresh', False),
                "meta_refresh_url": getattr(page, 'meta_refresh_url', None),
                "meta_refresh_delay": getattr(page, 'meta_refresh_delay', None)
            }
            page_callback(page_data)
            return page

        crawler_results = await asyncio.to_thread(
            self.seo_crawler._run,
            website_url=website,
            max_pages=max_pages,
            respect_robots_txt=True,
            crawl_delay=crawl_delay,
            page_callback=wrapped_page_callback,
            progress_callback=wrapped_progress_callback
        )
        pages = crawler_results.get('pages', [])
        total_pages = len(pages)
        logger.info(f"Crawler completed. Found {total_pages} pages")

        # Check broken links (70-85%)
        if progress_callback:
            progress_callback({
                'percent_complete': 70,
                'pages_analyzed': total_pages,
                'issues_found': total_issues,
                'status': 'Checking broken links...'
            })

        logger.info("Checking for broken links...")
        await self._check_broken_links(all_links, audit_results)
        total_issues += len(audit_results["broken_links"])
        logger.info(f"Found {len(audit_results['broken_links'])} broken links")

        # Check duplicate content (85-95%)
        if progress_callback:
            progress_callback({
                'percent_complete': 75,
                'pages_analyzed': total_pages,
                'issues_found': total_issues,
                'status': 'Checking for duplicate content...'
            })

        logger.info("Checking for duplicate content...")
        # Filter out 404 pages before duplicate content check
        valid_pages = [page for page in pages if not self.checker.is_404_page(page)]
        logger.info(f"Found {len(pages) - len(valid_pages)} potential 404 pages out of {len(pages)} total pages")

        # Add 404 pages as issues
        for page in pages:
            if self.checker.is_404_page(page):
                audit_results["meta_tag_issues"].append({
                    "url": page["url"],
                    "issues": [{
                        "type": "404",
                        "issue": "Page returns 404 status or appears to be a 404 page",
                        "value": None,
                        "severity": "high"
                    }]
                })
                total_issues += 1

        # Check duplicate content
        content_map = defaultdict(list)
        for page in valid_pages:
            content = page.get('text_content', '').strip()
            if content:
                content_hash = hash(content)
                content_map[content_hash].append(page['url'])
        
        for urls in content_map.values():
            if len(urls) > 1:
                audit_results["duplicate_content"].append({
                    "urls": urls,
                    "similarity": 100,
                    "timestamp": datetime.now().isoformat()
                })
                total_issues += 1

        logger.info(f"Found {len(audit_results['duplicate_content'])} duplicate content issues")

        if progress_callback:
            progress_callback({
                'percent_complete': 80,
                'pages_analyzed': total_pages,
                'issues_found': total_issues,
                'status': 'Checking SSL, robots.txt and sitemap...'
            })

        logger.info("Checking SSL...")
        await self._check_ssl(website, audit_results)
        
        logger.info("Checking robots.txt and sitemap...")
        sitemap_issues = await self._check_robots_sitemap(website, audit_results)
        total_issues += sitemap_issues

        if progress_callback:
            progress_callback({
                'percent_complete': 85,
                'pages_analyzed': total_pages,
                'issues_found': total_issues,
                'status': 'Checking PageSpeed metrics...'
            })

        logger.info("Checking PageSpeed metrics for main URL...")
        pagespeed_issues = await self.checker.check_pagespeed_metrics(
            {"url": website}, 
            self.pagespeed_tool
        )

        if pagespeed_issues:
            if "performance_issues" not in audit_results:
                audit_results["performance_issues"] = []
            audit_results["performance_issues"].extend(pagespeed_issues)
            total_issues += len(pagespeed_issues)

        logger.info(f"Found {len(pagespeed_issues)} PageSpeed issues")

        if progress_callback:
            progress_callback({
                'percent_complete': 100,
                'pages_analyzed': total_pages,
                'issues_found': total_issues,
                'status': 'Completed',
                'recent_issues': [{
                    'severity': issue.get('severity', 'high'),
                    'issue_type': issue.get('type', 'sitemap_issue'),
                    'url': issue.get('url', ''),
                    'details': issue.get('issue', ''),
                    'value': issue.get('value', '')
                } for issue in audit_results.get("sitemap", {}).get("issues", [])]
            })

        # Add PageSpeed analysis for the main URL

        # Add summary stats
        audit_results["summary"] = {
            "total_pages": total_pages,
            "total_links": len(all_links),
            "total_issues": total_issues,
            "start_time": crawler_results["start_time"],
            "end_time": crawler_results["end_time"],
            "crawl_time_seconds": crawler_results["crawl_time_seconds"],
            "duration": (datetime.fromisoformat(crawler_results["end_time"]) - 
                        datetime.fromisoformat(crawler_results["start_time"])).total_seconds()
        }

        # Flatten all issues into a single list
        all_issues = []

        # Add all issues from each category
        for issue in audit_results.get('meta_tag_issues', []):
            all_issues.append(issue)
        for issue in audit_results.get('content_issues', []):
            all_issues.append(issue)
        for issue in audit_results.get('image_issues', []):
            all_issues.append(issue)
        for issue in audit_results.get('broken_links', []):
            all_issues.append(issue)
        for issue in audit_results.get('duplicate_content', []):
            all_issues.append(issue)
        for issue in audit_results.get('canonical_issues', []):
            all_issues.append(issue)
        for issue in audit_results.get('social_media_issues', []):
            all_issues.append(issue)
        for issue in audit_results.get('sitemap', {}).get('issues', []):
            all_issues.append(issue)
        for issue in audit_results.get('performance_issues', []):
            all_issues.append(issue)
        for issue in audit_results.get('semantic_issues', []):
            all_issues.append(issue)
        for issue in audit_results.get('robots_issues', []):
            all_issues.append(issue)
        for issue in audit_results.get('eeat_issues', []):
            all_issues.append(issue)
        for issue in audit_results.get('redirect_issues', []):
            all_issues.append(issue)

        # Add SSL issues
        ssl_results = audit_results.get('ssl_issues', {})
        if ssl_results and ssl_results.get('errors'):
            all_issues.extend(ssl_results['errors'])

        # Replace individual issue lists with a single flattened list
        audit_results['issues'] = all_issues

        logger.info("SEO audit completed successfully")

        return audit_results

    async def _check_ssl(self, website: str, audit_results: Dict[str, Any]):
        """Check SSL certificate validity and configuration."""
        # Ensure we have a proper URL
        if not website.startswith(('http://', 'https://')):
            website = f'https://{website}'
        
        parsed_url = urlparse(website)
        hostname = parsed_url.netloc
        
        ssl_results = {
            "valid_certificate": False,
            "supports_https": False,
            "errors": [],
            "certificate_info": {}
        }
        
        try:
            # Create SSL context with strict verification
            context = ssl.create_default_context()
            context.check_hostname = True
            context.verify_mode = ssl.CERT_REQUIRED
            
            async with aiohttp.TCPConnector(ssl=context) as connector:
                async with aiohttp.ClientSession(connector=connector) as session:
                    try:
                        async with session.get(f"https://{hostname}", timeout=10) as response:
                            ssl_results["supports_https"] = True
                            ssl_results["valid_certificate"] = True
                            
                            # Get certificate info if available
                            if response.connection and response.connection.transport:
                                ssl_object = response.connection.transport.get_extra_info('ssl_object')
                                if ssl_object:
                                    cert = ssl_object.getpeercert()
                                    if cert:
                                        ssl_results["certificate_info"] = {
                                            "subject": dict(x[0] for x in cert.get('subject', [])),
                                            "issuer": dict(x[0] for x in cert.get('issuer', [])),
                                            "version": cert.get('version'),
                                            "expires": cert.get('notAfter'),
                                            "valid_from": cert.get('notBefore')
                                        }
                    
                    except aiohttp.ClientConnectorCertificateError as e:
                        ssl_results["errors"].append(self.checker.create_issue(
                            issue_type="ssl_error",
                            issue="SSL Certificate Error",
                            url=website,
                            value=str(e),
                            severity="critical",
                            details={"error_type": "certificate_error"}
                        ))
                        ssl_results["valid_certificate"] = False
                    
                    except aiohttp.ClientConnectorSSLError as e:
                        ssl_results["errors"].append(self.checker.create_issue(
                            issue_type="ssl_error",
                            issue="SSL Connection Error",
                            url=website,
                            value=str(e),
                            severity="critical",
                            details={"error_type": "ssl_connection_error"}
                        ))
                        ssl_results["valid_certificate"] = False
                    
                    except aiohttp.ClientError as e:
                        ssl_results["errors"].append(self.checker.create_issue(
                            issue_type="ssl_error",
                            issue="Connection Error",
                            url=website,
                            value=str(e),
                            severity="high",
                            details={"error_type": "connection_error"}
                        ))
                        ssl_results["valid_certificate"] = False
            
            # Try HTTP fallback to check if HTTPS is supported
            if not ssl_results["supports_https"]:
                try:
                    async with aiohttp.TCPConnector(ssl=False) as connector:
                        async with aiohttp.ClientSession(connector=connector) as session:
                            async with session.get(f"http://{hostname}", timeout=10) as response:
                                if response.status == 200:
                                    ssl_results["errors"].append(self.checker.create_issue(
                                        issue_type="ssl_error",
                                        issue="Site accessible over HTTP but not HTTPS",
                                        url=website,
                                        value=None,
                                        severity="critical",
                                        details={"supports_http": True, "supports_https": False}
                                    ))
                except Exception:
                    ssl_results["errors"].append(self.checker.create_issue(
                        issue_type="ssl_error",
                        issue="Site not accessible over HTTP or HTTPS",
                        url=website,
                        value=None,
                        severity="critical",
                        details={"supports_http": False, "supports_https": False}
                    ))
        
        except Exception as e:
            ssl_results["errors"].append(self.checker.create_issue(
                issue_type="ssl_error",
                issue="Unexpected error during SSL check",
                url=website,
                value=str(e),
                severity="high",
                details={"error_type": type(e).__name__}
            ))
            ssl_results["valid_certificate"] = False
        
        audit_results["ssl_issues"] = ssl_results

    async def _check_robots_sitemap(self, website: str, audit_results: Dict[str, Any]):
        """Check for robots.txt and sitemap.xml with detailed validation."""
        base_url = f"https://{urlparse(website).netloc}"
        
        # Check robots.txt
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(f"{base_url}/robots.txt") as response:
                    audit_results["robots_txt"] = {
                        "present": response.status == 200,
                        "status_code": response.status
                    }
                    if response.status == 200:
                        content = await response.text()
                        audit_results["robots_txt"]["content"] = content
                        # Check for sitemap directive
                        sitemap_matches = re.findall(r'Sitemap:\s*(.+)', content, re.IGNORECASE)
                        audit_results["robots_txt"]["sitemap_directives"] = sitemap_matches
        except Exception as e:
            audit_results["robots_txt"] = {
                "present": False,
                "error": str(e)
            }
        
        # Perform detailed sitemap validation
        logger.info("Performing detailed sitemap validation...")
        sitemap_validation = await self.checker.validate_sitemap(base_url)
        
        # Add sitemap validation results to audit results
        audit_results["sitemap"] = {
            "present": sitemap_validation["sitemap_found"],
            "type": sitemap_validation["sitemap_type"],
            "total_urls": sitemap_validation["total_urls"],
            "valid_urls": sitemap_validation["valid_urls"],
            "urls_with_lastmod": sitemap_validation["last_modified_dates"],
            "urls_with_changefreq": sitemap_validation["change_frequencies"],
            "urls_with_priority": sitemap_validation["priorities"],
            "sitemap_locations": sitemap_validation["sitemap_locations"],
            "issues": sitemap_validation["issues"]
        }
        
        # Add sitemap issues to total issues count
        return len(sitemap_validation["issues"])

    async def _check_broken_links(self, links: Set[tuple], audit_results: Dict[str, Any]):
        """Check for broken internal links using HEAD requests with caching."""
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.5',
            'Connection': 'keep-alive',
        }
        
        async with aiohttp.ClientSession(headers=headers) as session:
            semaphore = asyncio.Semaphore(5)  # Allow more concurrent requests since HEAD is lightweight
            
            async def check_link(source_url: str, target_url: str):
                """Check if a link is broken using HEAD request with caching."""
                async with semaphore:
                    # Generate cache key
                    cache_key = f"link_status:{target_url}"
                    cached_result = cache.get(cache_key)
                    
                    if cached_result is not None:
                        # If link was broken in cache, add to audit results
                        if cached_result.get('is_broken', False):
                            audit_results["broken_links"].append({
                                "source_url": source_url,
                                "target_url": target_url,
                                "status_code": cached_result.get('status_code'),
                                "error": cached_result.get('error'),
                                "timestamp": datetime.now().isoformat()
                            })
                        return
                    
                    max_retries = 3
                    retry_count = 0
                    
                    while retry_count < max_retries:
                        try:
                            # Try HEAD first
                            try:
                                async with session.head(target_url, allow_redirects=True, timeout=5) as response:
                                    # If HEAD request is successful (status < 400), cache and return
                                    if response.status < 400:
                                        cache.set(cache_key, {
                                            'is_broken': False,
                                            'status_code': response.status,
                                            'checked_at': datetime.now().isoformat()
                                        }, timeout=86400)
                                        return
                                        
                                    # If HEAD fails, try GET
                                    async with session.get(target_url, allow_redirects=True, timeout=5) as get_response:
                                        result = {
                                            'is_broken': get_response.status >= 400,
                                            'status_code': get_response.status,
                                            'error': f"HTTP {get_response.status}" if get_response.status >= 400 else None,
                                            'checked_at': datetime.now().isoformat()
                                        }
                                        cache.set(cache_key, result, timeout=86400)
                                        
                                        if result['is_broken']:
                                            audit_results["broken_links"].append({
                                                "source_url": source_url,
                                                "target_url": target_url,
                                                "status_code": get_response.status,
                                                "error": f"HTTP {get_response.status}",
                                                "timestamp": datetime.now().isoformat()
                                            })
                                        return
                                        
                            except aiohttp.ClientError:
                                # If HEAD fails with client error, try GET
                                async with session.get(target_url, allow_redirects=True, timeout=5) as response:
                                    result = {
                                        'is_broken': response.status >= 400,
                                        'status_code': response.status,
                                        'error': f"HTTP {response.status}" if response.status >= 400 else None,
                                        'checked_at': datetime.now().isoformat()
                                    }
                                    cache.set(cache_key, result, timeout=86400)
                                    
                                    if result['is_broken']:
                                        audit_results["broken_links"].append({
                                            "source_url": source_url,
                                            "target_url": target_url,
                                            "status_code": response.status,
                                            "error": f"HTTP {response.status}",
                                            "timestamp": datetime.now().isoformat()
                                        })
                                    return
                            
                        except asyncio.TimeoutError:
                            retry_count += 1
                            if retry_count == max_retries:
                                result = {
                                    'is_broken': True,
                                    'status_code': None,
                                    'error': f"Timeout after {max_retries} retries",
                                    'checked_at': datetime.now().isoformat()
                                }
                                cache.set(cache_key, result, timeout=86400)
                                
                                audit_results["broken_links"].append({
                                    "source_url": source_url,
                                    "target_url": target_url,
                                    "status_code": None,
                                    "error": f"Timeout after {max_retries} retries",
                                    "timestamp": datetime.now().isoformat()
                                })
                            else:
                                await asyncio.sleep(1)  # Wait before retrying
                                continue
                                
                        except Exception as e:
                            result = {
                                'is_broken': True,
                                'status_code': None,
                                'error': str(e),
                                'checked_at': datetime.now().isoformat()
                            }
                            cache.set(cache_key, result, timeout=86400)
                            
                            audit_results["broken_links"].append({
                                "source_url": source_url,
                                "target_url": target_url,
                                "status_code": None,
                                "error": str(e),
                                "timestamp": datetime.now().isoformat()
                            })
                            return
            
            # Process links in smaller batches
            batch_size = 50
            all_links = list(links)
            for i in range(0, len(all_links), batch_size):
                batch = all_links[i:i + batch_size]
                tasks = []
                for source_url, target_url in batch:
                    tasks.append(asyncio.create_task(check_link(source_url, target_url)))
                
                if tasks:
                    await asyncio.gather(*tasks)
                    # Add a small delay between batches to prevent overwhelming
                    await asyncio.sleep(1)

    def _generate_report(self, audit_results: Dict[str, Any]) -> Dict[str, Any]:
        """Format the audit results into a detailed report."""
        # Calculate total issues
        total_issues = (
            len(audit_results.get("broken_links", [])) +
            len(audit_results.get("duplicate_content", [])) +
            len(audit_results.get("meta_tag_issues", [])) +
            len(audit_results.get("image_issues", [])) +
            len(audit_results.get("content_issues", [])) +
            len(audit_results.get("performance_issues", [])) +
            len(audit_results.get("mobile_issues", [])) +
            len(audit_results.get("social_media_issues", [])) +
            len(audit_results.get("canonical_issues", [])) +
            len(audit_results.get("sitemap", {}).get("issues", [])) +  # Include sitemap issues
            len([issue for issue in audit_results.get("ssl_issues", {}).get("errors", [])])  # Include SSL issues
        )
        
        report = {
            "summary": {
                "total_pages": audit_results["summary"]["total_pages"],
                "total_issues": total_issues,
                "timestamp": datetime.now().isoformat(),
                "canonical_stats": audit_results["summary"].get("canonical_stats", {}),
                "social_media_stats": {
                    "pages_with_og_tags": sum(1 for page in audit_results.get("social_media_issues", []) 
                        if not any(issue["type"].startswith("og_") for issue in page.get("issues", []))),
                    "pages_with_twitter_cards": sum(1 for page in audit_results.get("social_media_issues", [])
                        if not any(issue["type"].startswith("twitter_") for issue in page.get("issues", [])))
                }
            },
            "issues": {
                # Core issues
                "broken_links": audit_results.get("broken_links", []),
                "duplicate_content": audit_results.get("duplicate_content", []),
                "meta_tag_issues": audit_results.get("meta_tag_issues", []),
                
                # Content and structure issues
                "content_issues": audit_results.get("content_issues", []),
                "heading_issues": audit_results.get("heading_issues", []),
                "canonical_issues": audit_results.get("canonical_issues", []),
                
                # Media issues
                "image_issues": audit_results.get("image_issues", []),
                
                # Performance issues
                "performance_issues": audit_results.get("performance_issues", []),
                "page_speed_issues": audit_results.get("page_speed_issues", []),
                
                # Mobile issues
                "mobile_issues": audit_results.get("mobile_issues", []),
                "viewport_issues": audit_results.get("viewport_issues", []),
                
                # Social media issues
                "social_media_issues": audit_results.get("social_media_issues", []),
                "opengraph_issues": [
                    issue for page in audit_results.get("social_media_issues", [])
                    for issue in page.get("issues", []) if issue["type"].startswith("og_")
                ],
                "twitter_card_issues": [
                    issue for page in audit_results.get("social_media_issues", [])
                    for issue in page.get("issues", []) if issue["type"].startswith("twitter_")
                ],
                
                # Technical issues
                "sitemap_issues": audit_results.get("sitemap", {}).get("issues", []),
                "ssl_issues": [{"type": "ssl_error", "issue": error} for error in audit_results.get("ssl_issues", {}).get("errors", [])]
            },
            "technical": {
                # SSL and security
                "ssl": audit_results.get("ssl_issues", {}),
                "security_headers": audit_results.get("security_headers", {}),
                
                # Core technical aspects
                "sitemap": audit_results.get("sitemap", {}),  # Include full sitemap data
                "robots_txt": audit_results.get("robots_txt", {}),  # Include full robots.txt data
                "structured_data": audit_results.get("structured_data_validation", {}),
                "hreflang": audit_results.get("hreflang_validation", {}),
                
                # Mobile technical aspects
                "mobile_friendly": audit_results.get("mobile_friendly", False),
                "mobile_usability": audit_results.get("mobile_usability", {})
            },
            "crawl_stats": {
                "total_pages": audit_results["summary"]["total_pages"],
                "total_links": audit_results["summary"]["total_links"],
                "crawl_time": audit_results["summary"].get("crawl_time_seconds", 0),
                "average_page_load": audit_results["summary"].get("average_page_load", 0)
            },
            "page_analysis": audit_results.get("page_analysis", {})
        }
        
        return report

    async def _check_link(self, source_url: str, target_url: str) -> Dict[str, Any]:
        """Check if a link is broken using HEAD/GET requests with retries."""
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.5',
            'Connection': 'keep-alive',
        }
        
        # Generate cache key
        cache_key = f"link_status:{target_url}"
        cached_result = cache.get(cache_key)
        
        if cached_result is not None:
            return cached_result
        
        max_retries = 3
        retry_count = 0
        
        while retry_count < max_retries:
            try:
                async with aiohttp.ClientSession(headers=headers) as session:
                    # Try HEAD first
                    try:
                        async with session.head(target_url, allow_redirects=True, timeout=5) as response:
                            # If HEAD request is successful (status < 400), cache and return
                            if response.status < 400:
                                result = {
                                    'is_broken': False,
                                    'status_code': response.status,
                                    'error': None,
                                    'checked_at': datetime.now().isoformat()
                                }
                                cache.set(cache_key, result, timeout=86400)  # Cache for 24 hours
                                return result
                                
                            # If HEAD fails, try GET
                            async with session.get(target_url, allow_redirects=True, timeout=5) as get_response:
                                result = {
                                    'is_broken': get_response.status >= 400,
                                    'status_code': get_response.status,
                                    'error': f"HTTP {get_response.status}" if get_response.status >= 400 else None,
                                    'checked_at': datetime.now().isoformat()
                                }
                                cache.set(cache_key, result, timeout=86400)
                                return result
                                
                    except aiohttp.ClientError:
                        # If HEAD fails with client error, try GET
                        async with session.get(target_url, allow_redirects=True, timeout=5) as response:
                            result = {
                                'is_broken': response.status >= 400,
                                'status_code': response.status,
                                'error': f"HTTP {response.status}" if response.status >= 400 else None,
                                'checked_at': datetime.now().isoformat()
                            }
                            cache.set(cache_key, result, timeout=86400)
                            return result
                    
            except asyncio.TimeoutError:
                retry_count += 1
                if retry_count == max_retries:
                    result = {
                        'is_broken': True,
                        'status_code': None,
                        'error': f"Timeout after {max_retries} retries",
                        'checked_at': datetime.now().isoformat()
                    }
                    cache.set(cache_key, result, timeout=86400)
                    return result
                else:
                    await asyncio.sleep(1)  # Wait before retrying
                    continue
                    
            except Exception as e:
                result = {
                    'is_broken': True,
                    'status_code': None,
                    'error': str(e),
                    'checked_at': datetime.now().isoformat()
                }
                cache.set(cache_key, result, timeout=86400)
                return result

        # Should never reach here, but just in case
        return {
            'is_broken': True,
            'status_code': None,
            'error': 'Unknown error',
            'checked_at': datetime.now().isoformat()
        }

    async def _check_content_similarity(self, page1: Dict[str, Any], page2: Dict[str, Any]) -> float:
        """Check content similarity between two pages."""
        from difflib import SequenceMatcher
        
        # Get text content
        text1 = page1.get('text_content', '')
        text2 = page2.get('text_content', '')
        
        # Use SequenceMatcher for similarity ratio
        return SequenceMatcher(None, text1, text2).ratio()

================
File: tools/seo_audit_tool/seo_checkers.py
================
"""SEO check implementations for the SEO Audit Tool."""
from typing import Dict, List, Any, Optional
from urllib.parse import urlparse, urljoin
import logging
import aiohttp
from bs4 import BeautifulSoup
from datetime import datetime
import re
from .content_type_detector import determine_content_type
from apps.agents.tools.content_expertise_tool.content_expertise_tool import ContentExpertiseTool
from apps.agents.tools.business_credibility_tool.business_credibility_tool import BusinessCredibilityTool
import json

logger = logging.getLogger(__name__)

class SEOChecker:
    """Base class for SEO checks."""
    
    @staticmethod
    def create_issue(
        issue_type: str,
        issue: str,
        url: str,
        value: Any = None,
        severity: str = "medium",
        details: Dict[str, Any] = None
    ) -> Dict[str, Any]:
        """Create a standardized issue object.
        
        Args:
            issue_type: The type of issue (must match one of the ISSUE_TYPES in SEOAuditIssue model)
            issue: A human-readable description of the issue
            url: The URL where the issue was found
            value: The specific value that caused the issue (optional)
            severity: The severity level (critical, high, medium, low, info)
            details: Additional structured details about the issue
        
        Returns:
            A standardized issue dictionary
        """
        if not details:
            details = {}
        
        # Ensure severity is one of the allowed values
        allowed_severities = {'critical', 'high', 'medium', 'low', 'info'}
        if severity not in allowed_severities:
            severity = 'medium'
        
        # Create the standardized issue object
        issue_obj = {
            "type": issue_type,
            "issue": issue,
            "url": url,
            "severity": severity,
            "value": value,
            "details": details,
            "timestamp": datetime.now().isoformat()
        }
        
        return issue_obj

    @staticmethod
    def is_404_page(page_data: Dict[str, Any]) -> bool:
        """Helper function to detect 404 pages including custom error pages."""
        # Check status code first
        if page_data.get('status_code') == 404:
            return True
                
        # Check common 404 indicators in title and content
        title = page_data.get('title', '').lower()
        content = page_data.get('text_content', '').lower()
        url = page_data.get('url', '').lower()
        
        error_indicators = [
            '404', 'not found', 'page not found', 'error 404',
            'page does not exist', 'page no longer exists',
            'page couldn\'t be found', 'page could not be found',
            'nothing found', 'entry not found', 'article not found',
            'product not found', 'no results found',
            'error page', 'page missing', 'content not found'
        ]
        
        # Check title for error indicators
        if any(indicator in title for indicator in error_indicators):
            return True
                
        # Check first 1000 chars of content for error indicators
        content_start = content[:1000]
        if any(indicator in content_start for indicator in error_indicators):
            return True
                
        # Check URL patterns that often indicate 404 pages
        url_indicators = ['/404', 'error', 'not-found', 'notfound', 'page-not-found']
        if any(indicator in url for indicator in url_indicators):
            return True
                
        return False
    
    @staticmethod
    def check_meta_tags(page_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Check meta tags including title and description."""
        issues = []
        url = page_data.get("url", "")
        
        # Title tag checks
        title = page_data.get("title", "").strip()
        if not title:
            issues.append(SEOChecker.create_issue(
                issue_type="title",
                issue="Missing title tag",
                url=url,
                value=None,
                severity="critical"
            ))
        elif len(title) < 10:
            issues.append(SEOChecker.create_issue(
                issue_type="title",
                issue=f"Title tag too short ({len(title)} chars)",
                url=url,
                value=title,
                severity="high",
                details={"length": len(title)}
            ))
        elif len(title) > 60:
            issues.append(SEOChecker.create_issue(
                issue_type="title",
                issue=f"Title tag too long ({len(title)} chars)",
                url=url,
                value=title,
                severity="medium",
                details={"length": len(title)}
            ))
        
        # Meta description checks
        meta_desc = page_data.get("meta_description", "").strip()
        if not meta_desc:
            issues.append(SEOChecker.create_issue(
                issue_type="meta_description",
                issue="Missing meta description",
                url=url,
                value=None,
                severity="high"
            ))
        elif len(meta_desc) < 50:
            issues.append(SEOChecker.create_issue(
                issue_type="meta_description",
                issue=f"Meta description too short ({len(meta_desc)} chars)",
                url=url,
                value=meta_desc,
                severity="medium",
                details={"length": len(meta_desc)}
            ))
        elif len(meta_desc) > 160:
            issues.append(SEOChecker.create_issue(
                issue_type="meta_description",
                issue=f"Meta description too long ({len(meta_desc)} chars)",
                url=url,
                value=meta_desc,
                severity="low",
                details={"length": len(meta_desc)}
            ))
        
        # Viewport checks
        if not page_data.get("viewport"):
            issues.append(SEOChecker.create_issue(
                issue_type="viewport_missing",
                issue="Missing viewport meta tag",
                url=url,
                value=None,
                severity="high"
            ))
        
        return issues

    @staticmethod
    def check_headings(page_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Check heading structure."""
        issues = []
        url = page_data.get("url", "")
        
        # H1 tag checks
        h1_tags = page_data.get("h1_tags", [])
        if not h1_tags:
            issues.append(SEOChecker.create_issue(
                issue_type="h1",
                issue="Missing H1 tag",
                url=url,
                value=None,
                severity="high"
            ))
        elif len(h1_tags) > 1:
            issues.append(SEOChecker.create_issue(
                issue_type="h1",
                issue=f"Multiple H1 tags ({len(h1_tags)})",
                url=url,
                value=h1_tags,
                severity="medium",
                details={"count": len(h1_tags), "h1_contents": h1_tags}
            ))
        
        return issues

    @staticmethod
    def check_images(page_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Check image optimization."""
        issues = []
        page_url = page_data.get("url", "")
        images = page_data.get("images", [])
        
        for img in images:
            img_url = img.get("src", "")
            
            # Alt text checks
            if not img.get("alt"):
                issues.append(SEOChecker.create_issue(
                    issue_type="missing_alt",
                    issue="Missing alt text",
                    url=page_url,
                    value=img_url,
                    severity="medium",
                    details={"image_url": img_url}
                ))
            elif len(img.get("alt", "")) < 3:
                issues.append(SEOChecker.create_issue(
                    issue_type="short_alt",
                    issue="Alt text too short",
                    url=page_url,
                    value=img.get("alt"),
                    severity="medium",
                    details={"image_url": img_url, "alt_length": len(img.get("alt", ""))}
                ))
            
            # Dimension checks
            width = img.get("width")
            height = img.get("height")
            if not (width and height):
                issues.append(SEOChecker.create_issue(
                    issue_type="missing_dimensions",
                    issue="Missing width/height attributes",
                    url=page_url,
                    value=img_url,
                    severity="medium",
                    details={"image_url": img_url, "width": width, "height": height}
                ))
            
            # Filename checks
            filename = img_url.split("/")[-1]
            if filename.lower().startswith(("img", "image", "pic", "dsc")):
                issues.append(SEOChecker.create_issue(
                    issue_type="generic_filename",
                    issue="Generic image filename",
                    url=page_url,
                    value=filename,
                    severity="low",
                    details={"image_url": img_url}
                ))
            
            # Size checks
            size = img.get("size", 0)
            if size > 500000:  # 500KB
                issues.append(SEOChecker.create_issue(
                    issue_type="large_size",
                    issue=f"Image size too large ({size/1000:.0f}KB)",
                    url=page_url,
                    value=img_url,
                    severity="high",
                    details={"image_url": img_url, "size_kb": size/1000}
                ))
            
            # Lazy loading check
            if not img.get("loading") == "lazy":
                issues.append(SEOChecker.create_issue(
                    issue_type="no_lazy_loading",
                    issue="Image missing lazy loading",
                    url=page_url,
                    value=img_url,
                    severity="high",
                    details={"image_url": img_url}
                ))
            
            # Responsive image checks
            if not img.get("srcset"):
                issues.append(SEOChecker.create_issue(
                    issue_type="no_srcset",
                    issue="Image missing responsive srcset",
                    url=page_url,
                    value=img_url,
                    severity="medium",
                    details={"image_url": img_url}
                ))
        
        return issues

    @staticmethod
    def check_links(page_data: Dict[str, Any], base_domain: str) -> List[str]:
        """Extract and check internal links."""
        internal_links = []
        page_links = page_data.get("links", [])
        
        for link in page_links:
            if urlparse(link).netloc == base_domain:
                internal_links.append(link)
        
        return internal_links

    @staticmethod
    def check_content(page_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Check content quality and structure."""
        issues = []
        url = page_data.get("url", "")
        text_content = page_data.get("text_content", "")
        word_count = len(text_content.split())
        
        # Content length check
        if word_count < 300:
            issues.append(SEOChecker.create_issue(
                issue_type="thin_content",
                issue=f"Thin content ({word_count} words)",
                url=url,
                value=word_count,
                severity="medium",
                details={"word_count": word_count}
            ))
        
        # Check for keyword density and readability if content exists
        if text_content:
            # Add readability score check
            sentences = len(re.split(r'[.!?]+', text_content))
            if sentences > 0:
                avg_words_per_sentence = word_count / sentences
                if avg_words_per_sentence > 25:
                    issues.append(SEOChecker.create_issue(
                        issue_type="readability",
                        issue=f"Sentences too long (avg {avg_words_per_sentence:.1f} words)",
                        url=url,
                        value=avg_words_per_sentence,
                        severity="medium",
                        details={
                            "avg_words_per_sentence": avg_words_per_sentence,
                            "total_sentences": sentences,
                            "total_words": word_count
                        }
                    ))
            
            # Check for long paragraphs
            paragraphs = [p.strip() for p in text_content.split('\n\n') if p.strip()]
            for i, para in enumerate(paragraphs):
                para_words = len(para.split())
                if para_words > 150:  # Generally, 150 words is considered a long paragraph
                    issues.append(SEOChecker.create_issue(
                        issue_type="long_paragraph",
                        issue=f"Long paragraph detected ({para_words} words)",
                        url=url,
                        value=para_words,
                        severity="low",
                        details={
                            "paragraph_index": i,
                            "word_count": para_words,
                            "paragraph_preview": para[:100] + "..." if len(para) > 100 else para
                        }
                    ))
        
        return issues

    @staticmethod
    def check_canonical_tags(page_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Check canonical tag implementation and validation."""
        issues = []
        url = page_data.get("url", "")
        canonical_url = page_data.get("canonical_url", "")
        page_content = page_data.get("text_content", "")
        
        # Check if canonical tag exists
        if not canonical_url:
            issues.append(SEOChecker.create_issue(
                issue_type="canonical_missing",
                issue="Missing canonical tag",
                url=url,
                value=None,
                severity="high",
                details={"page_type": "content" if page_content else "unknown"}
            ))
            return issues

        # Validate canonical URL format
        if not canonical_url.startswith(('http://', 'https://')):
            issues.append(SEOChecker.create_issue(
                issue_type="canonical_invalid_format",
                issue="Invalid canonical URL format",
                url=url,
                value=canonical_url,
                severity="high",
                details={"canonical_url": canonical_url}
            ))

        # Check for self-referential canonical
        if canonical_url != url:
            # If the page is pointing to a different URL, check if it might be a duplicate
            if page_content:
                issues.append(SEOChecker.create_issue(
                    issue_type="canonical_different",
                    issue="Canonical URL points to a different page",
                    url=url,
                    value=canonical_url,
                    severity="medium",
                    details={
                        "canonical_url": canonical_url,
                        "content_length": len(page_content)
                    }
                ))

        # Check for relative canonical URLs
        if canonical_url.startswith('/'):
            issues.append(SEOChecker.create_issue(
                issue_type="canonical_relative",
                issue="Canonical URL is relative",
                url=url,
                value=canonical_url,
                severity="medium",
                details={"canonical_url": canonical_url}
            ))

        # Check for multiple canonical tags
        canonical_count = page_data.get("canonical_count", 0)
        if canonical_count > 1:
            issues.append(SEOChecker.create_issue(
                issue_type="canonical_multiple",
                issue=f"Multiple canonical tags found ({canonical_count})",
                url=url,
                value=str(canonical_count),
                severity="critical",
                details={
                    "canonical_count": canonical_count,
                    "canonical_url": canonical_url
                }
            ))

        # Check for canonical on non-canonical pages
        if page_data.get("is_pagination", False) and canonical_url == url:
            issues.append(SEOChecker.create_issue(
                issue_type="canonical_on_pagination",
                issue="Self-referential canonical on paginated page",
                url=url,
                value=canonical_url,
                severity="medium",
                details={"is_pagination": True}
            ))

        # Check for canonical chain (if available)
        canonical_chain = page_data.get("canonical_chain", [])
        if len(canonical_chain) > 1:
            issues.append(SEOChecker.create_issue(
                issue_type="canonical_chain",
                issue=f"Canonical chain detected (length: {len(canonical_chain)})",
                url=url,
                value=" -> ".join(canonical_chain),
                severity="high",
                details={
                    "chain_length": len(canonical_chain),
                    "canonical_chain": canonical_chain
                }
            ))
        
        return issues

    @staticmethod
    def get_page_metrics(page_data: Dict[str, Any]) -> Dict[str, Any]:
        """Calculate page metrics for analysis."""
        images = page_data.get("images", [])
        return {
            "url": page_data["url"],
            "title_length": len(page_data.get("title", "")),
            "meta_description_length": len(page_data.get("meta_description", "")),
            "h1_count": len(page_data.get("h1_tags", [])),
            "outbound_links": len(page_data.get("links", [])),
            "content_length": len(page_data.get("text_content", "")),
            "image_count": len(images),
            "images_without_alt": sum(1 for img in images if not img.get("alt")),
            "total_image_size": sum(img.get("size", 0) for img in images),
            "timestamp": page_data.get("crawl_timestamp"),
            "has_canonical": bool(page_data.get("canonical_url")),
            "canonical_url": page_data.get("canonical_url", ""),
            "canonical_count": page_data.get("canonical_count", 0)
        } 

    @staticmethod
    async def validate_sitemap(base_url: str) -> Dict[str, Any]:
        """Validate XML sitemap structure and content."""
        sitemap_issues = []
        sitemap_data = {
            "sitemap_found": False,
            "sitemap_type": None,  # "index" or "urlset"
            "total_urls": 0,
            "valid_urls": 0,
            "issues": [],
            "last_modified_dates": 0,
            "change_frequencies": 0,
            "priorities": 0,
            "sitemap_locations": []
        }

        async def check_sitemap_url(sitemap_url: str) -> Optional[Dict[str, Any]]:
            try:
                async with aiohttp.ClientSession() as session:
                    async with session.get(sitemap_url, allow_redirects=True) as response:
                        if response.status != 200:
                            sitemap_issues.append(SEOChecker.create_issue(
                                issue_type="sitemap_http_error",
                                issue=f"Sitemap HTTP error {response.status}",
                                url=sitemap_url,
                                value=str(response.status),
                                severity="medium"
                            ))
                            return None

                        content = await response.text()
                        soup = BeautifulSoup(content, 'xml')
                        
                        # Check if it's a sitemap index
                        sitemapindex = soup.find('sitemapindex')
                        if sitemapindex:
                            sitemap_data["sitemap_type"] = "index"
                            sitemaps = sitemapindex.find_all('sitemap')
                            for sitemap in sitemaps:
                                loc = sitemap.find('loc')
                                if loc:
                                    sitemap_data["sitemap_locations"].append(loc.text)
                                    sub_result = await check_sitemap_url(loc.text)
                                    if sub_result:
                                        for key in ["total_urls", "valid_urls", "last_modified_dates", "change_frequencies", "priorities"]:
                                            sitemap_data[key] += sub_result[key]
                            return sitemap_data

                        # Check if it's a regular sitemap
                        urlset = soup.find('urlset')
                        if urlset:
                            sitemap_data["sitemap_type"] = "urlset"
                            urls = urlset.find_all('url')
                            result = {
                                "total_urls": len(urls),
                                "valid_urls": 0,
                                "last_modified_dates": 0,
                                "change_frequencies": 0,
                                "priorities": 0
                            }

                            for url in urls:
                                loc = url.find('loc')
                                if not loc or not loc.text:
                                    sitemap_issues.append(SEOChecker.create_issue(
                                        issue_type="missing_url",
                                        issue="URL entry missing location",
                                        url=sitemap_url,
                                        value="",
                                        severity="high",
                                        details={"sitemap_type": sitemap_data["sitemap_type"]}
                                    ))
                                    continue

                                url_str = loc.text.strip()
                                if not url_str.startswith(('http://', 'https://')):
                                    sitemap_issues.append(SEOChecker.create_issue(
                                        issue_type="invalid_url",
                                        issue="Invalid URL format",
                                        url=url_str,
                                        value=url_str,
                                        severity="high",
                                        details={"sitemap_url": sitemap_url}
                                    ))
                                    continue

                                result["valid_urls"] += 1

                                # Check optional elements
                                if url.find('lastmod'):
                                    result["last_modified_dates"] += 1
                                    # Validate lastmod format
                                    lastmod = url.find('lastmod').text
                                    if not re.match(r'^\d{4}-\d{2}-\d{2}(T\d{2}:\d{2}:\d{2}(\+\d{2}:\d{2}|Z)?)?$', lastmod):
                                        sitemap_issues.append(SEOChecker.create_issue(
                                            issue_type="invalid_lastmod",
                                            issue="Invalid lastmod date format",
                                            url=url_str,
                                            value=lastmod,
                                            severity="medium",
                                            details={"sitemap_url": sitemap_url}
                                        ))

                                if url.find('changefreq'):
                                    result["change_frequencies"] += 1
                                    # Validate changefreq value
                                    changefreq = url.find('changefreq').text
                                    if changefreq not in ['always', 'hourly', 'daily', 'weekly', 'monthly', 'yearly', 'never']:
                                        sitemap_issues.append(SEOChecker.create_issue(
                                            issue_type="invalid_changefreq",
                                            issue="Invalid changefreq value",
                                            url=url_str,
                                            value=changefreq,
                                            severity="low",
                                            details={"sitemap_url": sitemap_url, "allowed_values": ['always', 'hourly', 'daily', 'weekly', 'monthly', 'yearly', 'never']}
                                        ))

                                if url.find('priority'):
                                    result["priorities"] += 1
                                    # Validate priority value
                                    priority = url.find('priority').text
                                    try:
                                        priority_float = float(priority)
                                        if not 0.0 <= priority_float <= 1.0:
                                            sitemap_issues.append(SEOChecker.create_issue(
                                                issue_type="invalid_priority",
                                                issue="Priority value out of range (0.0-1.0)",
                                                url=url_str,
                                                value=priority,
                                                severity="low",
                                                details={"sitemap_url": sitemap_url, "allowed_range": "0.0-1.0"}
                                            ))
                                    except ValueError:
                                        sitemap_issues.append(SEOChecker.create_issue(
                                            issue_type="invalid_priority",
                                            issue="Invalid priority value format",
                                            url=url_str,
                                            value=priority,
                                            severity="low",
                                            details={"sitemap_url": sitemap_url}
                                        ))

                            sitemap_issues.append(SEOChecker.create_issue(
                                issue_type="invalid_sitemap",
                                issue="Invalid sitemap format (missing sitemapindex or urlset)",
                                url=sitemap_url,
                                value="",
                                severity="high",
                                details={"content_preview": str(content)[:200] if content else None}
                            ))
                            return None

            except Exception as e:
                sitemap_issues.append(SEOChecker.create_issue(
                    issue_type="sitemap_error",
                    issue=f"Error processing sitemap: {str(e)}",
                    url=sitemap_url,
                    value=str(e),
                    severity="high",
                    details={"error_type": type(e).__name__}
                ))
                return None

        # Check common sitemap locations
        sitemap_urls = [
            f"{base_url}/sitemap_index.xml",
            f"{base_url}/sitemap.xml",
            f"{base_url}/sitemap",
            f"{base_url}/sitemap_news.xml",
            f"{base_url}/sitemap_products.xml",
            f"{base_url}/post-sitemap.xml"
        ]

        for sitemap_url in sitemap_urls:
            result = await check_sitemap_url(sitemap_url)
            if result:
                sitemap_data["sitemap_found"] = True
                break

        # Check robots.txt for Sitemap directive
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(f"{base_url}/robots.txt") as response:
                    if response.status == 200:
                        robots_content = await response.text()
                        sitemap_matches = re.findall(r'Sitemap:\s*(.+)', robots_content, re.IGNORECASE)
                        for sitemap_url in sitemap_matches:
                            sitemap_url = sitemap_url.strip()
                            if sitemap_url not in sitemap_urls:
                                result = await check_sitemap_url(sitemap_url)
                                if result:
                                    sitemap_data["sitemap_found"] = True
                                    break
        except Exception as e:
            logger.error(f"Error checking robots.txt for sitemap: {e}")

        sitemap_data["issues"] = sitemap_issues
        return sitemap_data 

    @staticmethod
    def check_social_media_tags(page_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Check social media meta tags including OpenGraph and Twitter Cards."""
        issues = []
        url = page_data.get("url", "")
        
        # OpenGraph checks
        og_title = page_data.get("og_title", "")
        og_description = page_data.get("og_description", "")
        og_image = page_data.get("og_image", "")
        
        if not og_title:
            issues.append({
                "type": "og_title_missing",
                "issue": "Missing OpenGraph title tag",
                "url": url,
                "value": None,
                "severity": "medium"
            })
        
        if not og_description:
            issues.append({
                "type": "og_description_missing",
                "issue": "Missing OpenGraph description tag",
                "url": url,
                "value": None,
                "severity": "medium"
            })
        
        if not og_image:
            issues.append({
                "type": "og_image_missing",
                "issue": "Missing OpenGraph image tag",
                "url": url,
                "value": None,
                "severity": "medium"
            })
        elif not og_image.startswith(('http://', 'https://')):
            issues.append({
                "type": "og_image_invalid",
                "issue": "Invalid OpenGraph image URL format",
                "url": url,
                "value": og_image,
                "severity": "medium"
            })
        
        return issues 

    @staticmethod
    def check_semantic_structure(page_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Check HTML5 semantic structure."""
        issues = []
        url = page_data.get("url", "")
        page_type = page_data.get("page_type", "content")
        
        # Define semantic elements and their requirements based on page type
        semantic_elements = {
            'header': {
                'purpose': 'Main header/banner area',
                'required_for': ['content', 'landing', 'blog', 'article', 'product'],
                'optional_for': ['search', 'category', 'error']
            },
            'main': {
                'purpose': 'Primary content area',
                'required_for': ['*'],  # Required for all pages
                'optional_for': []
            },
            'nav': {
                'purpose': 'Navigation menu',
                'required_for': ['content', 'landing', 'blog', 'article', 'product'],
                'optional_for': ['search', 'category', 'error']
            },
            'footer': {
                'purpose': 'Footer area',
                'required_for': ['content', 'landing', 'blog', 'article', 'product'],
                'optional_for': ['search', 'category', 'error']
            },
            'article': {
                'purpose': 'Self-contained content',
                'required_for': ['blog', 'article', 'news'],
                'optional_for': ['content', 'product']
            },
            'section': {
                'purpose': 'Thematic grouping of content',
                'required_for': [],
                'optional_for': ['*']  # Optional for all pages
            },
            'aside': {
                'purpose': 'Sidebar/complementary content',
                'required_for': [],
                'optional_for': ['*']  # Optional for all pages
            }
        }
        
        # Check for required semantic elements based on page type
        for element, config in semantic_elements.items():
            is_required = (
                '*' in config['required_for'] or 
                page_type in config['required_for']
            )
            is_optional = (
                '*' in config['optional_for'] or 
                page_type in config['optional_for']
            )
            
            if not page_data.get(f"has_{element}"):
                if is_required:
                    issues.append(SEOChecker.create_issue(
                        issue_type="semantic_structure",
                        issue=f"Missing required {element} semantic element",
                        url=url,
                        value=element,
                        severity="high" if element == 'main' else "medium",
                        details={
                            "element_type": element,
                            "element_purpose": config['purpose'],
                            "page_type": page_type,
                            "is_required": True,
                            "requirement_reason": "Required for this page type"
                        }
                    ))
                elif is_optional:
                    issues.append(SEOChecker.create_issue(
                        issue_type="semantic_structure",
                        issue=f"Missing recommended {element} semantic element",
                        url=url,
                        value=element,
                        severity="low",
                        details={
                            "element_type": element,
                            "element_purpose": config['purpose'],
                            "page_type": page_type,
                            "is_required": False,
                            "requirement_reason": "Recommended for better structure"
                        }
                    ))
        
        # Check for proper nesting of semantic elements
        if page_data.get("semantic_nesting_issues"):
            for issue in page_data["semantic_nesting_issues"]:
                issues.append(SEOChecker.create_issue(
                    issue_type="semantic_nesting",
                    issue=f"Improper nesting of semantic elements: {issue['elements']}",
                    url=url,
                    value=issue['elements'],
                    severity="medium",
                    details={
                        "parent_element": issue.get("parent"),
                        "child_element": issue.get("child"),
                        "recommended_structure": issue.get("recommendation"),
                        "page_type": page_type
                    }
                ))
        
        # Check for empty semantic elements
        if page_data.get("empty_semantic_elements"):
            for element in page_data["empty_semantic_elements"]:
                # Only report empty elements if they're required or used
                if element in semantic_elements:
                    issues.append(SEOChecker.create_issue(
                        issue_type="empty_semantic_element",
                        issue=f"Empty {element} semantic element",
                        url=url,
                        value=element,
                        severity="low",
                        details={
                            "element_type": element,
                            "element_purpose": semantic_elements[element]['purpose'],
                            "page_type": page_type,
                            "is_required": (
                                '*' in semantic_elements[element]['required_for'] or 
                                page_type in semantic_elements[element]['required_for']
                            )
                        }
                    ))
        
        return issues

    @staticmethod
    def check_redirect_chains(page_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Check for redirect chains and loops."""
        issues = []
        url = page_data.get("url", "")
        redirects = page_data.get("redirect_chain", [])
        
        # Check for long redirect chains
        if len(redirects) > 2:  # More than 2 redirects in chain
            issues.append(SEOChecker.create_issue(
                issue_type="redirect_chain",
                issue=f"Long redirect chain detected ({len(redirects)} redirects)",
                url=url,
                value=redirects,
                severity="high",
                details={
                    "chain_length": len(redirects),
                    "redirect_chain": redirects,
                    "final_url": redirects[-1] if redirects else url,
                    "hops": len(redirects) - 1
                }
            ))
        
        # Check for redirect loops
        if len(redirects) != len(set(redirects)):
            issues.append(SEOChecker.create_issue(
                issue_type="redirect_loop",
                issue="Redirect loop detected",
                url=url,
                value=redirects,
                severity="critical",
                details={
                    "chain_length": len(redirects),
                    "redirect_chain": redirects,
                    "unique_urls": len(set(redirects))
                }
            ))
        
        # Check for meta refresh redirects
        if page_data.get("meta_refresh"):
            issues.append(SEOChecker.create_issue(
                issue_type="meta_refresh",
                issue="Meta refresh redirect detected",
                url=url,
                value=page_data.get("meta_refresh_url"),
                severity="medium",
                details={
                    "refresh_delay": page_data.get("meta_refresh_delay", 0),
                    "target_url": page_data.get("meta_refresh_url"),
                    "is_immediate": page_data.get("meta_refresh_delay", 0) == 0
                }
            ))
        
        return issues

    @staticmethod
    def check_robots_indexing(page_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Check robots.txt and indexing directives."""
        issues = []
        url = page_data.get("url", "")
        
        # Check noindex directives
        if page_data.get("noindex"):
            issues.append(SEOChecker.create_issue(
                issue_type="noindex_detected",
                issue="Page has noindex directive",
                url=url,
                value=page_data.get("noindex_source", "meta"),
                severity="critical",
                details={
                    "source": page_data.get("noindex_source", "meta"),
                    "directive_type": "noindex",
                    "is_intentional": page_data.get("noindex_intentional", False)
                }
            ))
        
        # Check X-Robots-Tag header
        if page_data.get("x_robots_tag"):
            x_robots = page_data["x_robots_tag"]
            if "noindex" in x_robots or "none" in x_robots:
                issues.append(SEOChecker.create_issue(
                    issue_type="indexing_blocked",
                    issue="Indexing blocked by X-Robots-Tag header",
                    url=url,
                    value=x_robots,
                    severity="critical",
                    details={
                        "header_value": x_robots,
                        "directives": [d.strip() for d in x_robots.split(",")]
                    }
                ))
        
        # Check robots.txt blocking
        if page_data.get("robots_blocked"):
            issues.append(SEOChecker.create_issue(
                issue_type="robots_misconfiguration",
                issue="Page blocked by robots.txt",
                url=url,
                value=page_data.get("robots_directive", ""),
                severity="high",
                details={
                    "directive": page_data.get("robots_directive", ""),
                    "user_agent": page_data.get("robots_user_agent", "*")
                }
            ))
        
        return issues 

    @staticmethod
    def check_eeat_signals(page_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Check for E-E-A-T signals."""
        issues = []
        url = page_data.get("url", "")
        content_type = determine_content_type(page_data)
        logger.debug(f"Content type: {content_type}")
        # For local business homepage and general pages
        if content_type in ["business_homepage", "content", "about", "contact"]:
            try:
                # Use business credibility tool directly
                credibility_tool = BusinessCredibilityTool()
                result = credibility_tool._run(
                    text_content=page_data.get("text_content", ""),
                    html_content=page_data.get("html", "")
                )
                
                analysis = json.loads(result)
                logger.debug(f"Business credibility analysis: {analysis}")
                if "error" in analysis:
                    logger.error(f"Error in business credibility analysis: {analysis['message']}")
                    return []
                    
                # Convert tool results into issues
                credibility_signals = analysis.get("credibility_signals", {})
                signal_details = analysis.get("signal_details", {})
                
                # Map missing signals to issues
                signal_to_issue = {
                    "business_info": ("business_info_missing", "Missing basic business information", "high"),
                    "years_in_business": ("years_missing", "Years in business not specified", "medium"),
                    "customer_reviews": ("reviews_missing", "No customer reviews/testimonials found", "medium"),
                    "services_list": ("services_missing", "Services/products not clearly listed", "medium"),
                    "certifications": ("certifications_missing", "No professional certifications found", "medium")
                }
                
                for signal, (issue_type, message, severity) in signal_to_issue.items():
                    if not credibility_signals.get(signal, False):
                        issues.append(SEOChecker.create_issue(
                            issue_type=issue_type,
                            issue=message,
                            url=url,
                            severity=severity,
                            details=signal_details.get(signal, {})
                        ))
                        
            except Exception as e:
                logger.error(f"Error checking business credibility: {str(e)}")
                return []

        # For informational content, use content expertise tool
        elif content_type in ["blog", "article", "news"]:
            try:
                expertise_tool = ContentExpertiseTool()
                result = expertise_tool._run(
                    text_content=page_data.get("text_content", ""),
                    html_content=page_data.get("html", ""),
                    content_type=content_type,
                    url=url
                )
                
                analysis = json.loads(result)
                
                if "error" in analysis:
                    logger.error(f"Error in content expertise analysis: {analysis['message']}")
                    return []
                    
                # Convert tool results into issues
                expertise_signals = analysis.get("expertise_signals", {})
                signal_details = analysis.get("signal_details", {})
                
                # Map missing signals to issues
                signal_to_issue = {
                    "has_author": ("author_missing", "Missing author information", "high"),
                    "has_author_bio": ("author_bio_missing", "Author bio missing", "medium"),
                    "has_credentials": ("author_credentials_missing", "Author credentials not specified", "medium"),
                    "has_citations": ("citations_missing", "No citations or references found", "medium"),
                    "has_freshness": ("freshness_missing", "No last updated date found", "low"),
                    "has_fact_checking": ("fact_checking_missing", "No fact-checking elements found", "medium"),
                    "has_structure": ("poor_structure", "Content structure needs improvement", "medium"),
                    "has_depth": ("shallow_coverage", "Topic coverage may be insufficient", "medium"),
                    "has_schema": ("schema_missing", "Missing appropriate Article schema markup", "medium")
                }
                
                for signal, (issue_type, message, severity) in signal_to_issue.items():
                    if not expertise_signals.get(signal, False):
                        issues.append(SEOChecker.create_issue(
                            issue_type=issue_type,
                            issue=message,
                            url=url,
                            severity=severity,
                            details=signal_details.get(signal, {})
                        ))
                        
            except Exception as e:
                logger.error(f"Error checking content expertise: {str(e)}")
                return []

        return issues 

    @staticmethod
    async def check_pagespeed_metrics(page_data: Dict[str, Any], pagespeed_tool) -> List[Dict[str, Any]]:
        """Check PageSpeed metrics for a page."""
        issues = []
        url = page_data.get("url", "")
        
        try:
            # Get PageSpeed data
            result = pagespeed_tool._run(
                url=url,
                strategy="mobile",
                categories=["performance", "accessibility", "best-practices", "seo"]
            )

            # Wait for the task to complete if it's pending
            if isinstance(result, dict) and result.get('status') == 'pending':
                task_id = result.get('task_id')
                if task_id:
                    from celery.result import AsyncResult
                    task_result = AsyncResult(task_id)
                    # Wait for the task to complete (this will block until the task is done)
                    result = task_result.get()

            # Process performance score
            performance_score = result.get('performance_score')
            if performance_score is not None and performance_score < 0.5:
                issues.append(SEOChecker.create_issue(
                    issue_type="performance_poor",
                    issue="Low performance score",
                    url=url,
                    value=str(performance_score * 100),
                    severity="high" if performance_score < 0.3 else "medium",
                    details={"score": performance_score}
                ))
            
            # Process Core Web Vitals
            lab_data = result.get('core_web_vitals', {}).get('lab_data', {})
            
            # Check LCP
            lcp = lab_data.get('lcp', {})
            if lcp and lcp.get('value') and lcp.get('value') > 2500:
                issues.append(SEOChecker.create_issue(
                    issue_type="lcp_poor",
                    issue="High Largest Contentful Paint (LCP)",
                    url=url,
                    value=f"{lcp.get('display_value')}",
                    severity="high" if lcp.get('value') > 4000 else "medium",
                    details={"metric": "LCP", "value": lcp.get('value')}
                ))

            # Check CLS
            cls = lab_data.get('cls', {})
            if cls and cls.get('value') and cls.get('value') > 0.1:
                issues.append(SEOChecker.create_issue(
                    issue_type="cls_poor",
                    issue="High Cumulative Layout Shift (CLS)",
                    url=url,
                    value=f"{cls.get('display_value')}",
                    severity="high" if cls.get('value') > 0.25 else "medium",
                    details={"metric": "CLS", "value": cls.get('value')}
                ))

            # Check TBT (Total Blocking Time)
            tbt = lab_data.get('tbt', {})
            if tbt and tbt.get('value') and tbt.get('value') > 300:
                issues.append(SEOChecker.create_issue(
                    issue_type="performance_poor",
                    issue="High Total Blocking Time (TBT)",
                    url=url,
                    value=f"{tbt.get('display_value')}",
                    severity="high" if tbt.get('value') > 600 else "medium",
                    details={"metric": "TBT", "value": tbt.get('value')}
                ))

            # Process opportunities
            opportunities = result.get('opportunities', {})
            for opp_id, opp_data in opportunities.items():
                if opp_data.get('score', 1) < 0.9:  # Only report significant opportunities
                    # Map opportunity types to valid issue types
                    issue_type = "performance_poor"
                    if "render-blocking" in opp_id:
                        issue_type = "performance_render-blocking-resources"
                    elif "unoptimized-images" in opp_id:
                        issue_type = "performance_unoptimized-images"
                    elif "unused-css" in opp_id:
                        issue_type = "performance_unused-css"
                    elif "unused-javascript" in opp_id:
                        issue_type = "performance_unused-javascript"
                    elif "server-response-time" in opp_id:
                        issue_type = "performance_server-response-time"
                    
                    issues.append(SEOChecker.create_issue(
                        issue_type=issue_type,
                        issue=opp_data.get('title', 'Performance opportunity'),
                        url=url,
                        value=opp_data.get('display_value'),
                        severity="medium",
                        details={
                            "description": opp_data.get('description'),
                            "score": opp_data.get('score'),
                            "opportunity_id": opp_id
                        }
                    ))

            # Store the complete result in page_data
            page_data['pagespeed_data'] = result

        except Exception as e:
            logger.error(f"Error checking PageSpeed metrics for {url}: {str(e)}")
            issues.append(SEOChecker.create_issue(
                issue_type="pagespeed_error",
                issue="Error checking PageSpeed metrics",
                url=url,
                value=str(e),
                severity="high"
            ))
            # Store error in page_data
            page_data['pagespeed_data'] = {
                'status': 'error',
                'error': str(e)
            }

        return issues

================
File: tools/seo_crawler_tool/seo_crawler_tool.py
================
import asyncio
import logging
import json
from typing import Dict, List, Any, Optional, Type, Set
from datetime import datetime
from urllib.parse import urljoin, urlparse, urlunparse
from bs4 import BeautifulSoup
from pydantic import BaseModel, Field
from crewai.tools import BaseTool
from celery import shared_task
from celery.contrib.abortable import AbortableTask
import aiohttp
import os

from apps.agents.tools.browser_tool.browser_tool import BrowserTool
from apps.crawl_website.models import CrawlResult
from apps.common.utils import normalize_url
from apps.agents.utils import URLDeduplicator

logger = logging.getLogger(__name__)

class SEOCrawlerToolSchema(BaseModel):
    """Input schema for SEOCrawlerTool."""
    website_url: str = Field(
        ..., 
        title="Website URL",
        description="Website URL to crawl (e.g., https://example.com)"
    )
    max_pages: int = Field(
        default=100,
        title="Max Pages",
        description="Maximum number of pages to crawl"
    )
    respect_robots_txt: bool = Field(
        default=True,
        title="Respect Robots.txt",
        description="Whether to respect robots.txt rules"
    )
    crawl_delay: float = Field(
        default=1.0,
        title="Crawl Delay",
        description="Delay between requests in seconds"
    )

class SEOPage(BaseModel):
    """Represents a crawled page with SEO-relevant data."""
    url: str = Field(..., description="URL of the page")
    html: str = Field(..., description="Raw HTML content")
    text_content: str = Field(..., description="Extracted text content")
    title: str = Field(default="", description="Page title")
    meta_description: str = Field(default="", description="Meta description")
    meta_keywords: List[str] = Field(default_factory=list, description="Meta keywords")
    h1_tags: List[str] = Field(default_factory=list, description="H1 headings")
    links: List[str] = Field(default_factory=list, description="Found links")
    status_code: int = Field(..., description="HTTP status code")
    content_type: str = Field(default="general", description="Content type")
    crawl_timestamp: str = Field(default_factory=lambda: datetime.now().isoformat(), description="When the page was crawled")

    model_config = {"arbitrary_types_allowed": True}

    def model_dump(self, **kwargs):
        """Override model_dump to ensure datetime is serialized."""
        data = super().model_dump(**kwargs)
        # Ensure crawl_timestamp is a string
        if isinstance(data['crawl_timestamp'], datetime):
            data['crawl_timestamp'] = data['crawl_timestamp'].isoformat()
        return data

class SEOCrawlerToolConfig(BaseModel):
    """Configuration model for SEOCrawlerTool."""
    max_pages: int = Field(default=100, description="Maximum number of pages to crawl")
    max_concurrent: int = Field(default=5, description="Maximum number of concurrent requests")
    visited_urls: Set[str] = Field(default_factory=set, description="Set of visited URLs")
    found_links: Set[str] = Field(default_factory=set, description="Set of links found during crawling")
    pages: List[SEOPage] = Field(default_factory=list, description="List of crawled pages")
    url_deduplicator: URLDeduplicator = Field(default_factory=URLDeduplicator, description="URL deduplication utility")
    browser_tool: BrowserTool = Field(default_factory=BrowserTool, description="Browser tool for making requests")
    page_callback: Optional[Any] = Field(default=None, description="Callback function for processing pages")

    model_config = {"arbitrary_types_allowed": True}

class SEOCrawlerTool(BaseTool):
    """Tool for crawling websites and extracting SEO-relevant information."""
    name: str = "seo_crawler"
    description: str = "Tool for crawling websites and extracting SEO-relevant information"
    args_schema: Type[SEOCrawlerToolSchema] = SEOCrawlerToolSchema
    config: SEOCrawlerToolConfig = Field(default_factory=SEOCrawlerToolConfig)
    
    def __init__(self, **data):
        super().__init__(**data)
        self._semaphore = None
        # Ensure tools are initialized
        if not self.config.url_deduplicator:
            self.config.url_deduplicator = URLDeduplicator()
        if not self.config.browser_tool:
            self.config.browser_tool = BrowserTool()

    @property
    def semaphore(self) -> Optional[asyncio.Semaphore]:
        return self._semaphore
        
    @semaphore.setter
    def semaphore(self, value: Optional[asyncio.Semaphore]):
        self._semaphore = value

    async def _async_run(
        self,
        website_url: str,
        max_pages: Optional[int] = None,
        max_concurrent: Optional[int] = None,
        respect_robots_txt: bool = True,
        crawl_delay: float = 1.0,
        progress_callback = None,
        page_callback = None,
        **kwargs
    ) -> Dict[str, Any]:
        """Run the crawler asynchronously."""
        if max_pages is not None:
            self.config.max_pages = max_pages
        if max_concurrent is not None:
            self.config.max_concurrent = max_concurrent
        
        self.semaphore = asyncio.Semaphore(self.config.max_concurrent)
        self.config.page_callback = page_callback
        
        return await self._async_crawl(
            website_url=website_url,
            max_pages=self.config.max_pages,
            respect_robots_txt=respect_robots_txt,
            crawl_delay=crawl_delay,
            progress_callback=progress_callback
        )

    def _run(
        self,
        website_url: str,
        max_pages: Optional[int] = None,
        max_concurrent: Optional[int] = None,
        respect_robots_txt: bool = True,
        crawl_delay: float = 1.0,
        progress_callback = None,
        page_callback = None,
        **kwargs
    ) -> Dict[str, Any]:
        """Run the crawler synchronously."""
        # Create a new event loop if one doesn't exist
        try:
            loop = asyncio.get_running_loop()
        except RuntimeError:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
        
        try:
            return loop.run_until_complete(
                self._async_run(
                    website_url=website_url,
                    max_pages=max_pages,
                    max_concurrent=max_concurrent,
                    respect_robots_txt=respect_robots_txt,
                    crawl_delay=crawl_delay,
                    progress_callback=progress_callback,
                    page_callback=page_callback,
                    **kwargs
                )
            )
        finally:
            # Clean up the event loop if we created it
            if not loop.is_running():
                loop.close()

    async def _async_crawl(
        self,
        website_url: str,
        max_pages: int,
        respect_robots_txt: bool,
        crawl_delay: float,
        progress_callback = None
    ) -> Dict[str, Any]:
        """Crawl the website asynchronously."""
        start_time = datetime.now()
        
        # Ensure website_url has protocol
        if not website_url.startswith(('http://', 'https://')):
            website_url = 'https://' + website_url
            
        # Initialize with the start URL
        self.config.found_links.add(website_url)
        
        while len(self.config.visited_urls) < max_pages and self.config.found_links:
            # Get next batch of URLs to process
            batch_size = min(5, max_pages - len(self.config.visited_urls))
            batch_urls = set(list(self.config.found_links)[:batch_size])
            self.config.found_links -= batch_urls
            
            # Process batch concurrently
            tasks = []
            for url in batch_urls:
                if url not in self.config.visited_urls:
                    tasks.append(self._process_url(url))
            
            if tasks:
                await asyncio.gather(*tasks)
                await asyncio.sleep(crawl_delay)  # Respect crawl delay between batches

                # Send progress update
                if progress_callback:
                    pages_analyzed = len(self.config.visited_urls)
                    percent_complete = min(100, int((pages_analyzed / max_pages) * 100))
                    total_links = len(self.config.visited_urls) + len(self.config.found_links)
                    progress_callback({
                        'percent_complete': percent_complete,
                        'pages_analyzed': pages_analyzed,
                        'total_links': total_links,
                        'status': f'Page {pages_analyzed} of {max_pages}...',
                        'current_url': list(batch_urls)[-1] if batch_urls else None,
                        'new_links_found': sum(len(self._extract_links(url, '')) for url in batch_urls),
                        'remaining_urls': len(self.config.found_links)
                    })

        # Prepare results
        end_time = datetime.now()
        return {
            "pages": [page.model_dump() for page in self.config.pages],
            "total_pages": len(self.config.pages),
            "total_links": len(self.config.visited_urls),
            "crawl_time_seconds": (end_time - start_time).total_seconds(),
            "start_time": start_time.isoformat(),
            "end_time": end_time.isoformat(),
            "visited_urls": list(self.config.visited_urls),
            "remaining_urls": list(self.config.found_links),
            "timestamp": datetime.now().isoformat()  # Add timestamp for consistency
        }

    async def _process_url(self, url: str, parent_url: Optional[str] = None) -> Optional[SEOPage]:
        """Process a single URL and return a SEOPage object."""
        if not url or not self.config.url_deduplicator.should_process_url(url):
            return None
            
        # Check if URL points to an image or media file
        if self._is_media_url(url):
            # For media URLs, just verify they're accessible but don't create a page
            try:
                async with aiohttp.ClientSession() as session:
                    async with session.head(url, allow_redirects=True) as response:
                        if response.status < 400:
                            return None
                        # If HEAD fails, try GET as some servers don't support HEAD for media
                        async with session.get(url, allow_redirects=True) as get_response:
                            if get_response.status < 400:
                                return None
            except Exception as e:
                logger.warning(f"Failed to verify media URL {url}: {str(e)}")
            return None

        normalized_url = self.config.url_deduplicator._normalize_url(url)
        if normalized_url in self.config.visited_urls:
            return None

        self.config.visited_urls.add(normalized_url)

        # Get page content using BrowserTool
        #logger.info(f"Fetching content for {normalized_url}")
        raw_html = await asyncio.to_thread(
            self.config.browser_tool._run,
            normalized_url,
            output_type="raw"
        )
        
        if not raw_html:
            logger.warning(f"No content received for {normalized_url}")
            return None
        
        # Parse the page
        soup = BeautifulSoup(raw_html, 'lxml')
        
        # Extract text content
        text_content = await asyncio.to_thread(
            self.config.browser_tool._run,
            normalized_url,
            output_type="text"
        )
        
        # Extract links before creating the page object
        base_domain = urlparse(normalized_url).netloc
        extracted_links = self._extract_links(normalized_url, raw_html)
        
        # Filter links to only include same-domain URLs that haven't been visited
        new_links = {
            link for link in extracted_links
            if urlparse(link).netloc == base_domain
            and link not in self.config.visited_urls
            and self.config.url_deduplicator.should_process_url(link)
        }
        
        # Add new links to found_links
        self.config.found_links.update(new_links)
        # logger.info(f"Found {len(new_links)} new links on {normalized_url}")
        
        # Extract SEO relevant data
        page = SEOPage(
            url=normalized_url,
            html=raw_html,
            text_content=text_content,
            title=soup.title.string if soup.title else "",
            meta_description=self._get_meta_content(soup, "description"),
            meta_keywords=self._get_meta_content(soup, "keywords").split(",") if self._get_meta_content(soup, "keywords") else [],
            h1_tags=[h1.get_text(strip=True) for h1 in soup.find_all("h1")],
            links=extracted_links,
            status_code=200,  # BrowserTool would have raised an error if not 200
            content_type=self.config.browser_tool.detect_content_type(normalized_url, raw_html),
            crawl_timestamp=datetime.now().isoformat()
        )

        # Store the page
        self.config.pages.append(page)
        #logger.info(f"Successfully processed {normalized_url}")
        
        # Call the page callback if provided
        if hasattr(self.config, 'page_callback') and self.config.page_callback:
            try:
                processed_page = self.config.page_callback(page)
                if processed_page:
                    page = processed_page
            except Exception as e:
                logger.error(f"Error in page callback for {normalized_url}: {str(e)}")
        
        return page

    def _is_media_url(self, url: str) -> bool:
        """Check if a URL points to an image or media file."""
        parsed_url = urlparse(url)
        path = parsed_url.path.lower()
        return any(path.endswith(ext) for ext in [
            '.jpg', '.jpeg', '.png', '.gif', '.svg', 
            '.webp', '.ico', '.pdf', '.mp4', '.webm'
        ])

    def _get_meta_content(self, soup: BeautifulSoup, name: str) -> str:
        """Extract content from a meta tag."""
        meta = soup.find("meta", attrs={"name": name})
        return meta.get("content", "") if meta else ""

    def _extract_links(self, base_url: str, html_content: str) -> List[str]:
        """Extract and normalize all links from the page."""
        links = set()  # Use a set to avoid duplicates
        base_domain = urlparse(base_url).netloc
        normalized_base = normalize_url(base_url)
        
        soup = BeautifulSoup(html_content, 'lxml')
        
        for a in soup.find_all("a", href=True):
            href = a["href"].strip()
            try:
                # Skip empty, javascript, mailto, tel links
                if not href or href.startswith(('javascript:', 'mailto:', 'tel:', '#', 'data:', 'file:', 'about:')):
                    continue
                    
                # Convert to absolute URL
                absolute_url = urljoin(normalized_base, href)
                normalized_url = normalize_url(absolute_url)
                parsed_url = urlparse(normalized_url)
                
                # Only include http(s) URLs from the same domain
                if (parsed_url.scheme in ('http', 'https') and 
                    parsed_url.netloc == base_domain):
                    # Normalize URL
                    links.add(normalized_url)
                    
            except Exception as e:
                logger.warning(f"Error processing link {href}: {str(e)}")
                
        return list(links)

    async def _process_page(self, url: str, html_content: str, status_code: int) -> Dict[str, Any]:
        """Process a single page and extract relevant information."""
        soup = BeautifulSoup(html_content, 'html.parser')
        
        # Extract images with their attributes
        images = []
        for img in soup.find_all('img'):
            image_data = {
                "src": img.get('src', ''),
                "alt": img.get('alt', ''),
                "width": img.get('width', ''),
                "height": img.get('height', ''),
                "title": img.get('title', ''),
                "loading": img.get('loading', ''),
                "srcset": img.get('srcset', ''),
                "size": 0  # Will be populated for local images
            }
            
            # Normalize image URL
            if image_data["src"]:
                image_data["src"] = urljoin(url, image_data["src"])
                
                # Get image size if it's from the same domain
                if urlparse(image_data["src"]).netloc == urlparse(url).netloc:
                    try:
                        async with aiohttp.ClientSession() as session:
                            async with session.head(image_data["src"]) as response:
                                if response.status == 200:
                                    image_data["size"] = int(response.headers.get('content-length', 0))
                    except Exception as e:
                        logger.warning(f"Failed to get image size for {image_data['src']}: {str(e)}")
            
            images.append(image_data)

        # Extract existing data
        title = soup.title.string.strip() if soup.title else ""
        meta_desc = ""
        meta_desc_tag = soup.find('meta', attrs={'name': 'description'})
        if meta_desc_tag:
            meta_desc = meta_desc_tag.get('content', '').strip()

        h1_tags = [h1.get_text().strip() for h1 in soup.find_all('h1')]
        
        # Extract links
        links = []
        for link in soup.find_all('a'):
            href = link.get('href')
            if href:
                absolute_url = urljoin(url, href)
                if self._should_include_url(absolute_url):
                    links.append(absolute_url)

        # Get text content
        text_content = ' '.join([
            p.get_text().strip()
            for p in soup.find_all(['p', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6'])
        ])

        return {
            "url": url,
            "title": title,
            "meta_description": meta_desc,
            "h1_tags": h1_tags,
            "links": links,
            "images": images,  # Add images to the return data
            "text_content": text_content,
            "status_code": status_code,
            "crawl_timestamp": datetime.now().isoformat()
        }

@shared_task(bind=True, base=AbortableTask)
def crawl_website_task(self, website_url: str, user_id: int, max_pages: int = 100) -> Optional[int]:
    """Celery task to run the crawler asynchronously."""
    logger.info(f"Starting crawl task for {website_url}")
    
    crawler = SEOCrawlerTool()
    try:
        result = crawler._run(website_url, max_pages=max_pages)
        
        # Create CrawlResult
        crawl_result = CrawlResult.objects.create(
            user_id=user_id,
            website_url=website_url,
            content=result["pages"],
            links_visited=list(crawler.config.visited_urls),
            total_links=result["total_links"],
            links_to_visit=list(crawler.config.found_links)
        )
        
        logger.info(f"Crawl completed for {website_url}")
        return crawl_result.id
        
    except Exception as e:
        logger.error(f"Error during crawl: {str(e)}")
        return None

================
File: tools/website_distiller_tool/website_distiller_tool.py
================
import logging
from typing import Type
from pydantic import BaseModel, Field
from crewai.tools import BaseTool
from apps.agents.tools.crawl_website_tool.crawl_website_tool import CrawlWebsiteTool
from apps.agents.tools.compression_tool.compression_tool import CompressionTool
import json
from urllib.parse import urlparse, urlunparse

logger = logging.getLogger(__name__)

class WebsiteDistillerToolSchema(BaseModel):
    """Input schema for WebsiteDistillerTool."""
    website_url: str = Field(..., description="The website URL to crawl and process")
    max_tokens: int = Field(default=16384, description="Maximum number of tokens in the processed output")
    detail_level: str = Field(
        default="comprehensive",
        description="Detail level: 'comprehensive' (preserve all details), 'detailed' (preserve most details), or 'focused' (key details only)"
    )

    model_config = {
        "extra": "forbid"
    }

class WebsiteDistillerTool(BaseTool):
    name: str = "Website Content Distillation Tool"
    description: str = """
    Crawls a website to extract its content, then processes and organizes the content while preserving important information.
    Combines website crawling with advanced NLP processing for comprehensive content analysis.
    """
    args_schema: Type[BaseModel] = WebsiteDistillerToolSchema

    def _run(
        self,
        website_url: str,
        max_tokens: int = 16384,
        detail_level: str = "comprehensive"
    ) -> str:
        try:
            # Step 1: Normalize the URL
            parsed = urlparse(website_url)
            normalized_url = urlunparse((
                parsed.scheme,
                parsed.netloc.lower(),
                parsed.path.rstrip('/'),  # Remove trailing slashes
                '',
                parsed.query,
                ''
            ))
            
            # Step 2: Crawl the website using CrawlWebsiteTool
            logger.info(f"Starting website crawl for: {normalized_url}")
            crawl_tool = CrawlWebsiteTool()
            
            try:
                # Call _run directly since it handles the async execution internally
                crawl_result = crawl_tool._run(website_url=normalized_url)
            except Exception as e:
                logger.error(f"Error during crawl: {str(e)}")
                return json.dumps({
                    "error": "Crawling failed",
                    "message": str(e)
                })
            
            if not crawl_result or not isinstance(crawl_result, dict):
                return json.dumps({
                    "error": "Crawling failed",
                    "message": "No content was retrieved from the website"
                })

            # Extract content from crawl result
            content = crawl_result.get('content', '')
            if not content:
                return json.dumps({
                    "error": "Content extraction failed",
                    "message": "No content was found in the crawl result"
                })

            # Step 3: Process the crawled content
            logger.info("Processing crawled content")
            compression_tool = CompressionTool()
            processed_result = compression_tool._run(
                content=content,
                max_tokens=max_tokens,
                detail_level=detail_level
            )

            # Parse the compression tool result and add crawling metadata
            compression_data = json.loads(processed_result)
            
            # Format the final result
            result = {
                'processed_content': compression_data.get('processed_content', ''),
                'total_links': crawl_result.get('total_links', 0),
                'links_visited': len(crawl_result.get('links_visited', [])),
                'source_url': website_url,
            }
            
            return json.dumps(result)

        except Exception as e:
            logger.error(f"Error in WebsiteDistillerTool: {str(e)}")
            return json.dumps({
                "error": "Processing failed",
                "message": str(e)
            })

================
File: tools/wordpress/base.py
================
from pydantic import BaseModel, Field
from typing import Optional, Dict, Any
import aiohttp
import asyncio

class WordPressBaseSchema(BaseModel):
    website_url: str = Field(..., description="WordPress site URL")
    user_id: int = Field(..., description="ID of user initiating the change")
    auth_token: str = Field(..., description="WordPress REST API authentication token")
    verify_ssl: bool = Field(default=True, description="Verify SSL certificates for requests")

class WordPressBaseTool:
    """Shared WordPress tool functionality"""
    _session = None
    
    def _run_sync(self, coro):
        """Run async code in sync context for Celery"""
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        return loop.run_until_complete(coro)
    
    async def _get_session(self, auth_token: str):
        """Reusable aiohttp session with auth"""
        if not self._session:
            self._session = aiohttp.ClientSession(
                headers={"Authorization": f"Bearer {auth_token}"}
            )
        return self._session

================
File: tools/wordpress/content_tool.py
================
from crewai.tools import BaseTool
from pydantic import BaseModel, Field
from .base import WordPressBaseSchema, WordPressBaseTool
from typing import Type
import aiohttp
import json
import asyncio
from bs4 import BeautifulSoup

class WordPressContentSchema(WordPressBaseSchema):
    post_id: int = Field(..., description="ID of post/page to update")
    content: str = Field(..., description="HTML content to set")
    allowed_tags: list = Field(
        default=["h1", "h2", "h3", "p", "ul", "ol", "li", "strong", "em", "a"],
        description="Allowed HTML tags for content sanitization"
    )

class WordPressContentTool(BaseTool, WordPressBaseTool):
    name: str = "WordPress Content Updater"
    description: str = """Updates main content of WordPress posts/pages with proper sanitization
    and SEO-friendly formatting. Maintains semantic HTML structure."""
    args_schema: Type[BaseModel] = WordPressContentSchema

    def _run(self, **kwargs) -> str:
        """Sync entry point for Celery"""
        return self._run_sync(self._async_update_content(**kwargs))

    async def _async_update_content(self, website_url: str, post_id: int,
                                  content: str, allowed_tags: list, **kwargs) -> str:
        session = await self._get_session(kwargs['auth_token'])
        
        try:
            # Sanitize HTML content
            sanitized = self._sanitize_html(content, allowed_tags)
            
            async with session.post(
                f"{website_url}/wp-json/wp/v2/posts/{post_id}",
                json={"content": sanitized}
            ) as response:
                if response.status == 200:
                    return json.dumps({
                        "success": True,
                        "post_id": post_id,
                        "content_length": len(sanitized),
                        "allowed_tags": allowed_tags
                    })
                return json.dumps({
                    "error": f"Content update failed: {response.status}",
                    "details": await response.text()
                })
        except Exception as e:
            return json.dumps({
                "error": "Content update failed",
                "message": str(e)
            })

    def _sanitize_html(self, html: str, allowed_tags: list) -> str:
        """Sanitize HTML while preserving SEO elements"""
        soup = BeautifulSoup(html, 'html.parser')
        
        # Remove disallowed tags but keep their content
        for tag in soup.find_all(True):
            if tag.name not in allowed_tags:
                tag.unwrap()
                
        # Clean up empty tags
        for tag in soup.find_all(True):
            if len(tag.get_text(strip=True)) == 0:
                tag.decompose()
                
        return str(soup)

================
File: tools/wordpress/meta_tool.py
================
from crewai.tools import BaseTool
from pydantic import BaseModel, Field
from .base import WordPressBaseSchema, WordPressBaseTool

class WordPressMetaSchema(WordPressBaseSchema):
    post_id: int = Field(..., description="ID of post/page to update")
    meta_fields: Dict[str, str] = Field(
        ...,
        description="Meta fields to update. Valid keys: title, meta_description, og_title, og_description",
        example={"title": "New SEO Title", "meta_description": "Optimized description"}
    )

class WordPressMetaTool(BaseTool, WordPressBaseTool):
    name: str = "WordPress Meta Updater"
    description: str = """Updates SEO meta information on WordPress posts/pages including:
    - Title
    - Meta description
    - OpenGraph titles
    - OpenGraph descriptions
    
    Example usage:
    {
        "website_url": "https://blog.example.com",
        "user_id": 42,
        "auth_token": "wp_rest_token",
        "post_id": 123,
        "meta_fields": {
            "title": "New SEO Optimized Title",
            "meta_description": "Improved meta description for search engines"
        }
    }"""
    args_schema: Type[BaseModel] = WordPressMetaSchema

    def _run(self, **kwargs) -> str:
        """Sync entry point for Celery"""
        return self._run_sync(self._async_update_meta(**kwargs))

    async def _async_update_meta(self, website_url: str, post_id: int, 
                               meta_fields: Dict[str, str], **kwargs) -> str:
        session = await self._get_session(kwargs['auth_token'])
        
        valid_fields = {
            "title": "title",
            "meta_description": "meta:description",
            "og_title": "og:title",
            "og_description": "og:description"
        }
        
        updates = {
            "meta": {
                valid_fields[key]: value
                for key, value in meta_fields.items()
                if key in valid_fields
            }
        }
        
        try:
            async with session.post(
                f"{website_url}/wp-json/wp/v2/posts/{post_id}",
                json=updates
            ) as response:
                if response.status == 200:
                    return json.dumps({
                        "success": True,
                        "post_id": post_id,
                        "updated_fields": list(meta_fields.keys())
                    })
                return json.dumps({
                    "error": f"API request failed with status {response.status}",
                    "details": await response.text()
                })
        except Exception as e:
            return json.dumps({
                "error": "Meta update failed",
                "message": str(e)
            })

================
File: tools/wordpress/post_tool.py
================
from crewai.tools import BaseTool
from pydantic import BaseModel, Field
from .base import WordPressBaseSchema, WordPressBaseTool
from typing import Type
import aiohttp
import json
import asyncio

class WordPressPostSchema(WordPressBaseSchema):
    title: str = Field(..., description="Post title")
    content: str = Field(..., description="HTML content for the new post")
    status: str = Field(default="draft", description="Post status: draft, publish, future")
    categories: list = Field(default=[], description="Category IDs for the post")
    tags: list = Field(default=[], description="Tag IDs for the post")
    meta_fields: dict = Field(default={}, description="Initial meta fields")

class WordPressPostTool(BaseTool, WordPressBaseTool):
    name: str = "WordPress Post Creator"
    description: str = """Creates new WordPress posts with SEO-optimized structure.
    
    Example usage:
    {
        "website_url": "https://blog.example.com",
        "user_id": 42,
        "auth_token": "wp_rest_token",
        "title": "New SEO Optimized Post",
        "content": "<h1>Main Heading</h1><p>Quality content...</p>",
        "status": "draft",
        "categories": [5],
        "tags": [12, 15],
        "meta_fields": {
            "meta_description": "Post description for search engines"
        }
    }"""
    args_schema: Type[BaseModel] = WordPressPostSchema

    def _run(self, **kwargs) -> str:
        """Sync entry point for Celery"""
        return self._run_sync(self._async_create_post(**kwargs))

    async def _async_create_post(self, website_url: str, title: str, 
                               content: str, **kwargs) -> str:
        session = await self._get_session(kwargs['auth_token'])
        
        post_data = {
            "title": title,
            "content": content,
            "status": kwargs.get('status', 'draft'),
            "categories": kwargs.get('categories', []),
            "tags": kwargs.get('tags', []),
            "meta": kwargs.get('meta_fields', {})
        }
        
        try:
            async with session.post(
                f"{website_url}/wp-json/wp/v2/posts",
                json=post_data
            ) as response:
                if response.status == 201:
                    data = await response.json()
                    return json.dumps({
                        "success": True,
                        "post_id": data.get('id'),
                        "edit_link": data.get('link')
                    })
                return json.dumps({
                    "error": f"Post creation failed: {response.status}",
                    "details": await response.text()
                })
        except Exception as e:
            return json.dumps({
                "error": "Post creation failed",
                "message": str(e)
            })

================
File: tools/wordpress/reader_tool.py
================
from typing import Optional, List, Dict, Any
from pydantic import BaseModel, Field, ConfigDict
from crewai.tools import BaseTool
import json
import logging
from .base import WordPressBaseTool
import asyncio
import aiohttp

logger = logging.getLogger(__name__)

class WordPressReaderSchema(BaseModel):
    """Schema for WordPress content reading operations"""
    website_url: str = Field(..., description="WordPress site URL")
    auth_token: str = Field(..., description="WordPress REST API authentication token")
    
    # Search parameters
    search_query: Optional[str] = Field(
        default="",
        description="Search term to find specific content"
    )
    search_field: Optional[str] = Field(
        default="title",
        description="Field to search in (title, content, slug)"
    )
    
    # Listing parameters
    list_all: Optional[bool] = Field(
        default=True,
        description="List all posts/pages instead of searching"
    )
    post_type: Optional[str] = Field(
        default="post",
        description="Content type to retrieve (post, page)"
    )
    per_page: Optional[int] = Field(
        default=20,
        description="Number of items per page (max 100)"
    )
    page: Optional[int] = Field(
        default=1,
        description="Page number for pagination"
    )
    
    # Additional filters
    status: Optional[str] = Field(
        default="publish",
        description="Content status (publish, draft, private)"
    )
    order_by: Optional[str] = Field(
        default="date",
        description="Sort field (date, title, modified)"
    )
    order: Optional[str] = Field(
        default="desc",
        description="Sort order (asc, desc)"
    )

    model_config = ConfigDict(
        extra='forbid',
        arbitrary_types_allowed=True
    )

class WordPressReaderTool(BaseTool, WordPressBaseTool):
    name: str = "WordPress Content Reader"
    description: str = """Retrieves WordPress post/page information for editing purposes.
    
    Features:
    - Search by URL, title, or slug
    - List all posts/pages with filters
    - Get post IDs and metadata
    
    Example usage:
    {
        "website_url": "https://blog.example.com",
        "auth_token": "wp_rest_token",
        "search_query": "optimizing-seo",
        "search_field": "slug"
    }"""
    
    args_schema: type[BaseModel] = WordPressReaderSchema

    def _run(
        self,
        website_url: str,
        auth_token: str,
        search_query: str = "",
        search_field: str = "title",
        list_all: bool = True,
        post_type: str = "post",
        per_page: int = 20,
        page: int = 1,
        status: str = "publish",
        order_by: str = "date",
        order: str = "desc",
        **kwargs
    ) -> str:
        """Handle WordPress content reading operations with explicit parameters"""
        logger.debug(f"Running WordPress reader with parameters: website_url={website_url}, "
                    f"search_query={search_query}, list_all={list_all}, post_type={post_type}")
        
        # Create validated schema instance
        params = WordPressReaderSchema(
            website_url=website_url,
            auth_token=auth_token,
            search_query=search_query,
            search_field=search_field,
            list_all=list_all,
            post_type=post_type,
            per_page=per_page,
            page=page,
            status=status,
            order_by=order_by,
            order=order
        )
        
        # Pass validated parameters to async method
        return self._run_sync(self._async_get_post(
            website_url=params.website_url,
            auth_token=params.auth_token,
            search_query=params.search_query,
            search_field=params.search_field,
            list_all=params.list_all,
            post_type=params.post_type,
            per_page=params.per_page,
            page=params.page,
            status=params.status,
            order_by=params.order_by,
            order=params.order
        ))

    async def _async_get_post(
        self,
        website_url: str,
        auth_token: str,
        search_query: str = "",
        search_field: str = "title",
        list_all: bool = True,
        post_type: str = "post",
        per_page: int = 20,
        page: int = 1,
        status: str = "publish",
        order_by: str = "date",
        order: str = "desc"
    ) -> str:
        """Async method to fetch WordPress content"""
        # Create timeout object with longer durations
        timeout = aiohttp.ClientTimeout(
            total=30,  # Total timeout for the whole request
            connect=10,  # Timeout for connecting to the server
            sock_read=30  # Timeout for reading the response
        )
        
        # Get base session without timeout
        session = await self._get_session(auth_token)
        # Update session timeout
        session._timeout = timeout
        
        # Rest of the headers and params setup...
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'application/json,*/*;q=0.9',
            'Accept-Language': 'en-US,en;q=0.9',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive'
        }
        
        if auth_token:
            headers['Authorization'] = f'Bearer {auth_token.replace(" ", "")}'
        
        params = {
            'per_page': per_page,
            'page': page,
            'status': status,
            'orderby': order_by,
            'order': order
        }
        
        # Add search parameters if searching
        if search_query and not list_all:
            params['search'] = search_query
            if search_field in ['title', 'content', 'slug']:
                params['search_columns'] = [search_field]
        
        try:
            logger.debug(f"Attempting to fetch WordPress content from {website_url} with timeout {timeout}")
            async with session.get(
                f"{website_url}/wp-json/wp/v2/{post_type}s",
                params=params,
                headers=headers,
                timeout=timeout
            ) as response:
                if response.status == 200:
                    data = await response.json()
                    total_posts = response.headers.get('X-WP-Total', '0')
                    total_pages = response.headers.get('X-WP-TotalPages', '0')
                    
                    return json.dumps({
                        'success': True,
                        'total_posts': total_posts,
                        'total_pages': total_pages,
                        'current_page': page,
                        'posts': [
                            {
                                'id': post.get('id'),
                                'title': post.get('title', {}).get('rendered', ''),
                                'slug': post.get('slug', ''),
                                'status': post.get('status', ''),
                                'link': post.get('link', ''),
                                'modified': post.get('modified', '')
                            }
                            for post in data
                        ]
                    })
                return json.dumps({
                    'error': f"API request failed with status {response.status}",
                    'details': await response.text()
                })
        except asyncio.TimeoutError as e:
            logger.error(f"Timeout error fetching WordPress content: {str(e)}")
            return json.dumps({
                'error': "Request timed out",
                'message': "The request took too long to complete. Please try again."
            })
        except Exception as e:
            logger.error(f"Error fetching WordPress content: {str(e)}")
            return json.dumps({
                'error': "Failed to fetch WordPress content",
                'message': str(e)
            })

================
File: tools/youtube_video_search_tool/youtube_video_search_tool.py
================
from typing import Any, Optional, Type, Dict
from pydantic import BaseModel, Field
from crewai.tools import BaseTool
from embedchain.models.data_type import DataType
import logging
import json
from django.conf import settings

logger = logging.getLogger(__name__)

class YoutubeVideoSearchToolSchema(BaseModel):
    """Input schema for YoutubeVideoSearchTool."""
    search_query: str = Field(
        ...,
        description="The search query to use when searching the Youtube Video content"
    )
    youtube_video_url: Optional[str] = Field(
        None,
        description="Optional youtube video URL to search. If not provided, will use pre-configured URL"
    )

class YoutubeVideoSearchTool(BaseTool):
    name: str = "Youtube Video Search Tool"
    description: str = "A tool that can be used to semantic search a query from Youtube Video content."
    args_schema: Type[BaseModel] = YoutubeVideoSearchToolSchema
    rag_instance: Optional[Any] = Field(default=None, exclude=True)
    youtube_video_url: Optional[str] = Field(default=None)
    
    def __init__(self, youtube_video_url: Optional[str] = None, **kwargs):
        super().__init__(**kwargs)
        if youtube_video_url:
            self.youtube_video_url = youtube_video_url
            self.description = f"A tool that can be used to semantic search queries from the Youtube Video at: {youtube_video_url}"
            self._initialize_rag(youtube_video_url)

    def _initialize_rag(self, video_url: str) -> None:
        """Initialize RAG system with the video content"""
        try:
            # Initialize your RAG system here
            self.rag_instance = self._create_rag_instance()
            self.rag_instance.add(video_url, data_type=DataType.YOUTUBE_VIDEO)
            logger.debug(f"Initialized RAG system with video: {video_url}")
        except Exception as e:
            logger.error(f"Error initializing RAG system: {str(e)}")
            raise

    def _create_rag_instance(self) -> Any:
        """Create and return RAG instance with appropriate configuration"""
        # Implement your RAG instance creation logic here
        # This would contain the logic from your parent RagTool class
        pass

    def _run(
        self,
        search_query: str,
        youtube_video_url: Optional[str] = None,
        **kwargs: Any,
    ) -> str:
        try:
            # Initialize RAG with new URL if provided
            if youtube_video_url and youtube_video_url != self.youtube_video_url:
                self._initialize_rag(youtube_video_url)
                self.youtube_video_url = youtube_video_url
            
            # Ensure RAG is initialized
            if not self.rag_instance:
                if not self.youtube_video_url:
                    raise ValueError("No Youtube video URL provided or configured")
                self._initialize_rag(self.youtube_video_url)
            
            # Perform the search
            result = self.rag_instance.search(search_query)
            
            logger.debug(f"Youtube video search completed for query: {search_query[:50]}...")
            return str(result)

        except Exception as e:
            logger.error(f"Error in YoutubeVideoSearchTool: {str(e)}")
            return json.dumps({
                "error": "Youtube video search failed",
                "message": str(e)
            })

================
File: tools/analytics_tool.py
================


================
File: tools/base_tool.py
================
from abc import ABC, abstractmethod
from typing import Any, Callable, Optional, Type
from crewai.tools import BaseTool as CrewAIBaseTool
from langchain_core.tools import StructuredTool
from pydantic import BaseModel, ConfigDict, Field, validator
from pydantic import BaseModel as PydanticBaseModel
import logging

logger = logging.getLogger(__name__)


class BaseTool(BaseModel, ABC):
    class _ArgsSchemaPlaceholder(PydanticBaseModel):
        pass

    model_config = ConfigDict()

    name: str
    """The unique name of the tool that clearly communicates its purpose."""
    description: str
    """Used to tell the model how/when/why to use the tool."""
    args_schema: Type[PydanticBaseModel] = Field(default_factory=_ArgsSchemaPlaceholder)
    """The schema for the arguments that the tool accepts."""
    description_updated: bool = False
    """Flag to check if the description has been updated."""
    cache_function: Optional[Callable] = lambda _args, _result: True
    """Function that will be used to determine if the tool should be cached, should return a boolean. If None, the tool will be cached."""
    result_as_answer: bool = False
    """Flag to check if the tool should be the final agent answer."""

    @validator("args_schema", always=True, pre=True)
    def _default_args_schema(
        cls, v: Type[PydanticBaseModel]
    ) -> Type[PydanticBaseModel]:
        if not isinstance(v, cls._ArgsSchemaPlaceholder):
            return v

        return type(
            f"{cls.__name__}Schema",
            (PydanticBaseModel,),
            {
                "__annotations__": {
                    k: v for k, v in cls._run.__annotations__.items() if k != "return"
                },
            },
        )

    def model_post_init(self, __context: Any) -> None:
        self._generate_description()

        super().model_post_init(__context)

    def run(
        self,
        *args: Any,
        **kwargs: Any,
    ) -> Any:
        #print(f"Using Tool: {self.name}")
        return self._run(*args, **kwargs)

    @abstractmethod
    def _run(
        self,
        *args: Any,
        **kwargs: Any,
    ) -> Any:
        """Here goes the actual implementation of the tool."""

    def to_langchain(self) -> StructuredTool:
        self._set_args_schema()
        return StructuredTool(
            name=self.name,
            description=self.description,
            args_schema=self.args_schema,
            func=self._run,
        )

    def _set_args_schema(self):
        if self.args_schema is None:
            class_name = f"{self.__class__.__name__}Schema"
            self.args_schema = type(
                class_name,
                (PydanticBaseModel,),
                {
                    "__annotations__": {
                        k: v
                        for k, v in self._run.__annotations__.items()
                        if k != "return"
                    },
                },
            )

    def _generate_description(self):
        args = []
        args_description = []
        for arg, attribute in self.args_schema.schema()["properties"].items():
            if "type" in attribute:
                args.append(f"{arg}: '{attribute['type']}'")
            if "description" in attribute:
                args_description.append(f"{arg}: '{attribute['description']}'")

        description = self.description.replace("\n", " ")
        self.description = f"{self.name}({', '.join(args)}) - {description} {', '.join(args_description)}"

    def _run(self, *args, **kwargs):
        try:
            logger.info(f"Starting tool execution: {self.__class__.__name__}")
            result = self.run(*args, **kwargs)
            logger.info(f"Tool execution completed: {self.__class__.__name__}")
            # Log the result type and structure without sensitive data
            # Truncate result preview to 250 chars
            result_preview = str(result)[:250] + "..." if len(str(result)) > 250 else str(result)
            logger.debug(f"Tool result type: {type(result)}, preview: {result_preview}")
            return result
        except Exception as e:
            logger.error(f"Tool execution failed: {self.__class__.__name__}, Error: {str(e)}", exc_info=True)
            raise


class Tool(CrewAIBaseTool):
    """A tool that wraps a callable function."""
    
    func: Callable
    """The function that will be executed when the tool is called."""

    def _run(self, *args: Any, **kwargs: Any) -> Any:
        """Execute the wrapped function with the provided arguments."""
        return self.func(*args, **kwargs)


def to_langchain(
    tools: list[BaseTool | StructuredTool],
) -> list[StructuredTool]:
    return [t.to_langchain() if isinstance(t, BaseTool) else t for t in tools]


def tool(*args):
    """
    Decorator to create a tool from a function.
    """

    def _make_with_name(tool_name: str) -> Callable:
        def _make_tool(f: Callable) -> BaseTool:
            if f.__doc__ is None:
                raise ValueError("Function must have a docstring")
            if f.__annotations__ is None:
                raise ValueError("Function must have type annotations")

            class_name = "".join(tool_name.split()).title()
            args_schema = type(
                class_name,
                (PydanticBaseModel,),
                {
                    "__annotations__": {
                        k: v for k, v in f.__annotations__.items() if k != "return"
                    },
                },
            )

            return Tool(
                name=tool_name,
                description=f.__doc__,
                func=f,
                args_schema=args_schema,
            )

        return _make_tool

    if len(args) == 1 and callable(args[0]):
        return _make_with_name(args[0].__name__)(args[0])
    if len(args) == 1 and isinstance(args[0], str):
        return _make_with_name(args[0])
    raise ValueError("Invalid arguments")

================
File: tools/manager.py
================
import logging
from langchain_core.tools import Tool
from ..utils import get_tool_classes

logger = logging.getLogger(__name__)

class AgentToolManager:
    def __init__(self):
        pass

    async def load_tools(self, agent):
        """Load and initialize agent tools"""
        tools = []
        for tool_model in agent.tools.all():
            try:
                tool_classes = get_tool_classes(tool_model.tool_class)
                tool_class = next((cls for cls in tool_classes 
                                if cls.__name__ == tool_model.tool_subclass), None)
                
                if tool_class:
                    logger.info(f"Initializing tool: {tool_class.__name__}")
                    tool_instance = tool_class()
                    tools.append(tool_instance)
                else:
                    logger.error(f"Tool class not found: {tool_model.tool_subclass}")
            except Exception as e:
                logger.error(f"Error loading tool {tool_model.name}: {str(e)}")
        return tools

    def convert_to_langchain_tools(self, tools):
        """Convert custom tools to Langchain format"""
        return [self._create_langchain_tool(tool) for tool in tools]

    def _create_langchain_tool(self, tool):
        """Create individual Langchain tool"""
        formatted_name = ''.join(c for c in tool.name if c.isalnum() or c in '_-')[:64]
        
        async def tool_func(query: str, tool=tool):
            try:
                result = await self.execute_tool(tool, {"query": query})
                return result
            except Exception as e:
                logger.error(f"Tool execution error: {str(e)}")
                return f"Error: {str(e)}"

        return Tool(
            name=formatted_name,
            description=self._create_tool_description(tool),
            func=tool_func,
            coroutine=tool_func
        )

================
File: tools/pandasai.md
================
from typing import Optional, List, Dict, Any
from pydantic import BaseModel, Field
from pandasai import Agent as PandasAgent
from pandasai.llm import BambooLLM
import pandas as pd
import os

class PandasAIToolInput(BaseModel):
    """Schema for PandasAI tool inputs"""
    query: str = Field(..., description="The natural language query to analyze the data")
    data_source: str = Field(..., description="Path to data file or DataFrame variable name")
    data_format: str = Field(default="csv", description="Format of data source (csv, excel, parquet)")
    
class PandasAITool:
    """Tool for analyzing data using PandasAI"""
    name = "pandas_ai_analyzer"
    description = "Analyze data using natural language queries through PandasAI"
    args_schema = PandasAIToolInput

    def __init__(self):
        # Initialize with BambooLLM by default
        self.llm = BambooLLM(api_key=os.getenv("PANDASAI_API_KEY"))
        
    def _load_data(self, data_source: str, data_format: str) -> pd.DataFrame:
        """Load data from various sources"""
        if data_format == "csv":
            return pd.read_csv(data_source)
        elif data_format == "excel":
            return pd.read_excel(data_source)
        elif data_format == "parquet":
            return pd.read_parquet(data_source)
        else:
            raise ValueError(f"Unsupported data format: {data_format}")

    async def _run(
        self,
        query: str,
        data_source: str,
        data_format: str = "csv"
    ) -> str:
        """Execute PandasAI analysis"""
        try:
            # Load the data
            df = self._load_data(data_source, data_format)
            
            # Initialize PandasAI agent
            agent = PandasAgent(df, config={"llm": self.llm})
            
            # Run the query
            response = agent.chat(query)
            
            return str(response)
            
        except Exception as e:
            return f"Error analyzing data: {str(e)}"

================
File: tools/tool_design.md
================
# Tool Design Guidelines

This document outlines the standard patterns and best practices for creating tools in our agent system.

## Basic Tool Structure

### 1. Tool Components
Every tool should have these key components:
- Schema class (inherits from `pydantic.BaseModel`)
- Tool class (inherits from `crewai.tools.BaseTool`) 
- Proper logging configuration
- Error handling

### 2. Standard Imports
```{{python}}
from typing import Dict, Any, Type, List, Optional
from pydantic import BaseModel, Field
from crewai.tools import BaseTool
import json
import logging
from django.conf import settings
logger = logging.getLogger(__name__)
```

## Schema Definition

### 1. Input Schema
- Create a Pydantic model class named `{{ToolName}}Schema`
- Use descriptive Field annotations with proper typing
- Include clear field descriptions

Example:

```{{python}}
class ExampleToolSchema(BaseModel):
    """Input schema for ExampleTool."""
    input_field: str = Field(
        ...,  # ... means required
        description="Clear description of what this field does"
    )
    optional_field: Optional[str] = Field(
        None,
        description="Description of optional field"
    )
```

## Tool Implementation

### 1. Tool Class Structure
```{{python}}
class ExampleTool(BaseTool):
    name: str = "Example Tool"
    description: str = """
    Detailed description of what the tool does,
    its capabilities, and expected usage.
    """
    args_schema: Type[BaseModel] = ExampleToolSchema

    def _run(self, input_field: str, optional_field: Optional[str] = None) -> str:
        try:
            # Tool implementation
            pass
        except Exception as e:
            logger.error(f"Error in ExampleTool: {{str(e)}}")
            return json.dumps({{
                "error": "Operation failed",
                "message": str(e)
            }})
```

### 2. Key Implementation Points
- Always define explicit parameters in `_run()` method (avoid `**kwargs`)
- Parameters must match schema field names exactly
- Return JSON-serializable responses
- Implement proper error handling and logging
- Use type hints consistently

## Best Practices

### 1. Input Validation
- Use Pydantic schemas for automatic input validation
- Define clear field constraints and types
- Handle input preprocessing when needed

### 2. Error Handling
```{{python}}
try:
    # Tool logic
    result = perform_operation()
    return json.dumps(result)
except Exception as e:
    logger.error(f"Error in {{self.name}}: {{str(e)}}")
    return json.dumps({{
        "error": "Operation failed",
        "message": str(e)
    }})
```

### 3. Logging
- Configure proper logging for debugging and monitoring
- Log important operations and errors
- Include relevant context in log messages

### 4. Output Formatting
- Return structured JSON responses
- Clean and validate output before returning
- Handle special characters and formatting

## Example Tool Template

```{{python}}
from typing import Type
from pydantic import BaseModel, Field
from crewai.tools import BaseTool
import json
import logging

logger = logging.getLogger(__name__)

class NewToolSchema(BaseModel):
    """Input schema for NewTool."""
    input_param: str = Field(
        ...,
        description="Description of the input parameter"
    )

class NewTool(BaseTool):
    name: str = "New Tool"
    description: str = """
    Detailed description of the tool's purpose and functionality.
    """
    args_schema: Type[BaseModel] = NewToolSchema

    def _run(self, input_param: str) -> str:
        try:
            # Tool implementation
            result = self._process_input(input_param)
            
            logger.debug(f"Tool execution result: {{result[:200]}}...")
            return json.dumps(result)

        except Exception as e:
            logger.error(f"Error in {{self.name}}: {{str(e)}}")
            return json.dumps({{
                "error": "Operation failed",
                "message": str(e)
            }})

    def _process_input(self, input_param: str) -> dict:
        # Helper method for processing
        pass
```

## Common Pitfalls to Avoid

1. **Kwargs Usage**
   -  Don't use `**kwargs` in `_run()`
   -  Use explicit parameters matching schema fields

2. **Schema Mismatch**
   -  Don't have mismatched parameter names between schema and `_run()`
   -  Ensure schema field names exactly match `_run()` parameters

3. **Error Handling**
   -  Don't let exceptions propagate unhandled
   -  Catch exceptions and return structured error responses

4. **Type Safety**
   -  Don't use dynamic typing or ignore type hints
   -  Use proper type hints and Pydantic validation

## Testing Tools

1. Create unit tests for your tool
2. Test with various input combinations
3. Verify error handling
4. Check output format consistency
5. Validate schema enforcement

## Integration with Task System

Tools are executed through the task system, which:
1. Validates inputs against the schema
2. Processes input types appropriately
3. Handles async/sync execution
4. Manages tool state and logging

Remember to test your tool through the task system to ensure proper integration.

================
File: tools/utils.py
================
import os
from typing import Optional
from django.conf import settings
from django.core.files.storage import default_storage
from django.contrib.auth import get_user_model
import logging

logger = logging.getLogger(__name__)

def get_safe_path(user_id: int, path: str, directory: Optional[str] = None) -> str:
    """
    Ensures the path is valid for cloud storage and sanitizes it.
    
    Args:
        user_id: The ID of the user
        path: The requested path (/ represents user's media root)
        directory: Optional directory path
    
    Returns:
        str: Sanitized relative path for cloud storage
        
    Raises:
        ValueError: If path attempts directory traversal
    """
    try:
        # Construct user's base path
        user_base_path = str(user_id)
        
        # Handle root directory request
        if path == "/" or path == "":
            return user_base_path
        
        # Remove leading slash if present to make path relative
        path = path.lstrip('/')
        
        # Combine directory and path if directory is provided
        if directory:
            path = os.path.join(directory.lstrip('/'), path)
        
        # Create the full relative path
        relative_path = os.path.join(user_base_path, path)
        
        # Normalize path to resolve any . or .. components
        normalized_path = os.path.normpath(relative_path)
        
        # Security check: Verify the normalized path starts with user_id
        if not normalized_path.startswith(user_base_path):
            error_msg = f"Access denied: Path {path} attempts to access parent directory"
            logger.error(error_msg)
            raise ValueError(error_msg)
        
        # Ensure the path exists in storage (create if needed)
        if not path.endswith('/'):  # Only create directories for directory paths
            directory_path = os.path.dirname(normalized_path)
            if directory_path and not default_storage.exists(directory_path):
                # Create an empty placeholder file to ensure directory exists
                default_storage.save(os.path.join(directory_path, '.keep'), ContentFile(''))
                logger.debug(f"Created directory structure: {directory_path}")
        
        return normalized_path
        
    except Exception as e:
        if not isinstance(e, ValueError):  # Don't log ValueError as it's already logged
            logger.error(f"Error in get_safe_path: {str(e)}")
        raise

================
File: utils/error_handling.py
================
from functools import wraps
import logging
import json
from typing import Optional, Any, Callable
from django.core.exceptions import ValidationError

logger = logging.getLogger(__name__)

class ChatError(Exception):
    """Base class for chat-related errors"""
    def __init__(self, message: str, code: Optional[str] = None):
        super().__init__(message)
        self.code = code

def handle_chat_errors(func: Callable) -> Callable:
    """Decorator to handle chat-related errors"""
    @wraps(func)
    async def wrapper(*args, **kwargs):
        try:
            return await func(*args, **kwargs)
        except ChatError as e:
            logger.warning(f"Chat error: {str(e)}", exc_info=True)
            return {
                'error': True,
                'message': str(e),
                'code': e.code
            }
        except ValidationError as e:
            logger.warning(f"Validation error: {str(e)}", exc_info=True)
            return {
                'error': True,
                'message': str(e),
                'code': 'validation_error'
            }
        except Exception as e:
            logger.error(f"Unexpected error: {str(e)}", exc_info=True)
            return {
                'error': True,
                'message': 'An unexpected error occurred',
                'code': 'internal_error'
            }
    return wrapper

================
File: utils/formatters.py
================
import json
from typing import Any
from logger import logger

class TableFormatter:
    @staticmethod
    def detect_tabular_data(data: Any) -> bool:
        """Detect if data appears to be tabular"""
        try:
            # Handle string input
            if isinstance(data, str):
                try:
                    data = json.loads(data)
                except json.JSONDecodeError:
                    return False

            # Handle dictionary with nested data
            if isinstance(data, dict):
                # Look for common response patterns and nested data
                for key in ['data', 'results', 'search_console_data', 'analytics_data', 
                           'records', 'rows', 'items', 'response']:
                    if key in data and isinstance(data[key], list):
                        data = data[key]
                        break
                # If no list found in known keys, check all values
                if isinstance(data, dict):
                    for value in data.values():
                        if isinstance(value, list) and len(value) > 0:
                            data = value
                            break

            # Check if it's a list of dictionaries with consistent structure
            if isinstance(data, list) and len(data) > 0:
                if all(isinstance(item, dict) for item in data):
                    # Get keys from first item
                    keys = set(data[0].keys())
                    # Check if all items have same keys and at least one key
                    return len(keys) > 0 and all(set(item.keys()) == keys for item in data)

            return False
            
        except Exception as e:
            logger.error(f"Error detecting tabular data: {str(e)}")
            return False

================
File: websockets/handlers/agent_handler.py
================
import logging
from apps.common.utils import create_box
from apps.agents.models import Agent
from channels.db import database_sync_to_async
from apps.agents.websockets.handlers.callback_handler import WebSocketCallbackHandler
from apps.agents.websockets.services.chat_service import ChatService

logger = logging.getLogger(__name__)

class AgentHandler:
    def __init__(self, consumer):
        self.consumer = consumer
        self.chat_service = None

    async def process_response(self, message, agent_id, model_name, client_id):
        """Manages agent and chat service lifecycle"""
        try:
            # Get agent data
            agent = await self.get_agent(agent_id)
            if not agent:
                raise ValueError("Agent not found")

            # Get client data
            client_data = await self.consumer.client_manager.get_client_data(client_id)

            # Check if we need to reinitialize the chat service (agent or model changed)
            should_reinitialize = (
                not self.chat_service or
                str(self.chat_service.agent.id) != str(agent_id) or
                self.chat_service.model_name != model_name
            )

            if should_reinitialize:
                # Create new chat service with new agent/model but preserve message history
                logger.info(create_box("AGENT HANDLER", f"Reinitializing chat service for agent {agent_id} with model {model_name}"))
                callback_handler = WebSocketCallbackHandler(self.consumer)
                
                # Preserve the existing conversation ID and message history if it exists
                conversation_id = self.chat_service.conversation_id if self.chat_service else None
                message_manager = self.chat_service.message_manager if self.chat_service else None
                
                self.chat_service = ChatService(
                    agent=agent,
                    model_name=model_name,
                    client_data=client_data,
                    callback_handler=callback_handler,
                    session_id=self.consumer.session_id
                )
                
                # Set the preserved conversation ID and message manager if they exist
                if conversation_id:
                    self.chat_service.conversation_id = conversation_id
                if message_manager:
                    self.chat_service.message_manager = message_manager
                    
                await self.chat_service.initialize()
            else:
                # Just update client data if it changed
                self.chat_service.client_data = client_data
            
            # Process message - no return value needed as everything goes through callbacks
            await self.chat_service.process_message(message)

        except Exception as e:
            logger.error(f"Error in agent handler: {str(e)}")
            raise

    @database_sync_to_async
    def get_agent(self, agent_id):
        """Get agent from database"""
        try:
            return Agent.objects.get(id=agent_id)
        except Exception as e:
            logger.error(f"Error getting agent: {str(e)}")
            raise

================
File: websockets/handlers/callback_handler.py
================
from langchain_core.callbacks import BaseCallbackHandler
import logging
import json
from typing import Any, Dict, List
from datetime import datetime
from langchain_core.agents import  AgentFinish
import asyncio
import textwrap
import uuid
from channels.db import database_sync_to_async
from apps.common.utils import create_box
from langchain.schema import SystemMessage, AIMessage
from django.utils import timezone

logger = logging.getLogger(__name__)

class UUIDEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, uuid.UUID):
            return str(obj)
        return super().default(obj)


class WebSocketCallbackHandler(BaseCallbackHandler):
    """Callback handler that sends only essential messages to the WebSocket."""
    
    def __init__(self, consumer, message_manager=None, token_manager=None):
        """Initialize the handler with a WebSocket consumer and managers"""
        super().__init__()
        self.consumer = consumer
        self.logger = logging.getLogger(__name__)
        self._message_lock = asyncio.Lock()
        self.message_history = []
        self._last_agent_finish = None  # Track last agent finish message
        self.message_manager = message_manager
        self.token_manager = token_manager

    def _log_message(self, title: str, content: Any):
        """Log a message with proper JSON serialization."""
        # get first 250 characters of content 
        content_str = str(content)[:250] + "..." if len(str(content)) > 250 else str(content)
        try:
            if isinstance(content, dict):
                content_str = json.dumps(content, indent=2, cls=UUIDEncoder)
            else:
                content_str = str(content)
            self.logger.debug(create_box(title, content_str))
        except Exception as e:
            self.logger.error(f"Error logging message: {str(e)}")

    async def _send_message(self, message_data):
        """Send message to WebSocket and store in history."""
        try:
            # Store message in history
            self.message_history.append({
                'timestamp': datetime.now().isoformat(),
                'type': message_data.get('type'),
                'content': message_data
            })
            
            # Format message if it's a tool message
            if message_data.get('type', '').startswith('tool_') and self.message_manager:
                message_data['message'] = self.message_manager.format_message(
                    message_data['message'],
                    message_data['type']
                )
            
            # Add message ID if this is a message that was stored in DB
            if hasattr(self, '_last_message_id') and self._last_message_id:
                message_data['id'] = self._last_message_id
                self._last_message_id = None  # Clear it after use
            
            async with self._message_lock:
                await self.consumer.send_json(message_data)
                
        except Exception as e:
            self.logger.error(create_box("ERROR IN SEND MESSAGE", str(e)), exc_info=True)

    async def on_agent_finish(self, finish: AgentFinish, **kwargs: Any):
        """Handle agent completion - send final answer and save to database."""
        try:
            # Get token usage and track it
            token_usage = kwargs.get('token_usage', {})
            if self.token_manager:
                self.token_manager.track_token_usage(
                    token_usage.get('prompt_tokens', 0),
                    token_usage.get('completion_tokens', 0)
                )
                await self.token_manager.track_conversation_tokens()
            
            if hasattr(finish, 'return_values'):
                output = finish.return_values.get('output', '')
                
                # Check if this is a duplicate message
                if self._last_agent_finish == output:
                    self.logger.debug("Skipping duplicate agent finish message")
                    return
                
                self._last_agent_finish = output
                
                # Get token usage from token manager
                token_usage = self.token_manager.get_current_usage() if self.token_manager else {}
                
                debug_info = {
                    'output': output,
                    'token_usage': token_usage
                }
                self._log_message("AGENT FINISH EVENT RECEIVED", debug_info)
                # Convert dictionary output to string if necessary
                message_content = (
                    json.dumps(output, indent=2)
                    if isinstance(output, dict)
                    else str(output)
                )
                # Store message using message manager and get the message ID
                stored_message = None
                if self.message_manager:
                    stored_message = await self.message_manager.add_message(
                        AIMessage(content=message_content),
                        token_usage=token_usage
                    )
                
                message = {
                    'type': 'agent_finish',
                    'message': message_content,
                    'timestamp': datetime.now().isoformat(),
                    'token_usage': token_usage,
                    'id': str(stored_message.id) if stored_message else None
                }
                
                # Send message to websocket
                await self._send_message(message)
                
        except Exception as e:
            self.logger.error(create_box("ERROR IN AGENT FINISH", str(e)), exc_info=True)

    def on_tool_start_sync(self, serialized: Dict[str, Any], input_str: str, **kwargs: Any) -> None:
        """Synchronous handler for tool start - required by LangChain."""
        self._log_message("TOOL START (SYNC)", {
            'tool': serialized.get('name', 'Unknown Tool'),
            'input': input_str,
            'kwargs': kwargs
        })

    async def on_tool_start(self, serialized: Dict[str, Any], input_str: str, **kwargs: Any):
        """Handle tool start - send tool name and input."""
        try:
            # Skip internal exceptions
            if serialized.get('name') == '_Exception':
                return
                
            # Get token usage and track it
            token_usage = kwargs.get('token_usage', {})
            if self.token_manager:
                self.token_manager.track_token_usage(
                    token_usage.get('prompt_tokens', 0),
                    token_usage.get('completion_tokens', 0)
                )
            
            tool_name = serialized.get('name', 'Unknown Tool')
            
            # Store in message history if manager available
            stored_message = None
            if self.message_manager:
                stored_message = await self.message_manager.add_message(
                    SystemMessage(content=f"Tool Start: {tool_name} - {input_str}"),
                    token_usage=token_usage
                )
            
            # Send message to websocket
            message = {
                'type': 'tool_start',
                'content': {
                    'tool': tool_name,
                    'input': input_str
                },
                'timestamp': datetime.now().isoformat(),
                'token_usage': token_usage,
                'id': str(stored_message.id) if stored_message else None
            }
            await self.consumer.send_json(message)
                
        except Exception as e:
            logger.error(create_box("ERROR IN TOOL START", str(e)), exc_info=True)
            await self.on_tool_error(str(e), **kwargs)

    async def on_tool_end(self, output: str, **kwargs: Any) -> None:
        """Handle tool completion."""
        try:
            # Get token usage
            token_usage = kwargs.get('token_usage', {})
            if self.token_manager:
                self.token_manager.track_token_usage(
                    token_usage.get('prompt_tokens', 0),
                    token_usage.get('completion_tokens', 0)
                )

            # Log the output
            self._log_message("TOOL END EVENT RECEIVED", {
                "output": output,
                "token_usage": token_usage
            })

            # Parse output
            if isinstance(output, str):
                try:
                    data = json.loads(output)
                except json.JSONDecodeError:
                    data = {"text": output}
            else:
                data = output

            # Store in message history if manager available
            stored_message = None
            if self.message_manager:
                content = json.dumps(data, indent=2) if isinstance(data, dict) else str(data)
                stored_message = await self.message_manager.add_message(
                    SystemMessage(content=f"Tool Result: {content}"),
                    token_usage=token_usage
                )

            # Send message to websocket
            message = {
                'type': 'tool_result',
                'content': data,
                'timestamp': datetime.now().isoformat(),
                'token_usage': token_usage,
                'id': str(stored_message.id) if stored_message else None
            }
            await self.consumer.send_json(message)

        except Exception as e:
            logger.error(f"Error in on_tool_end: {str(e)}", exc_info=True)

    async def on_tool_error(self, error: str, **kwargs: Any):
        """Handle tool errors"""
        try:
            # Get token usage from kwargs if available
            token_usage = kwargs.get('token_usage', {})
            if self.token_manager:
                self.token_manager.track_token_usage(
                    token_usage.get('prompt_tokens', 0),
                    token_usage.get('completion_tokens', 0)
                )
            
            error_info = {
                'error': error,
                'token_usage': token_usage
            }
            self._log_message("TOOL ERROR EVENT RECEIVED", error_info)
            
            # Store error in message history if manager available
            stored_message = None
            if self.message_manager:
                stored_message = await self.message_manager.add_message(
                    SystemMessage(content=f"Tool Error: {error}"),
                    token_usage=token_usage
                )
            
            # Send error message to websocket
            message = {
                'type': 'tool_result',
                'content': {'error': error},
                'timestamp': datetime.now().isoformat(),
                'token_usage': token_usage,
                'id': str(stored_message.id) if stored_message else None
            }
            await self.consumer.send_json(message)
                
        except Exception as e:
            self.logger.error(create_box("ERROR IN TOOL ERROR HANDLER", str(e)), exc_info=True)

    def _handle_tool_end(self, data):
        try:
            logger.debug("Processing tool end event")
            output = data.get('output')
            
            if not output:
                logger.error("Tool end event received with no output")
                return {"output": "No output received", "token_usage": {}}
            
            # Validate output structure
            if isinstance(output, dict):
                # Log successful processing with truncated preview
                output_preview = str(output)[:250] + "..." if len(str(output)) > 250 else str(output)
                logger.debug(f"Successfully processed tool output: {type(output)}, preview: {output_preview}")
                return data
            elif isinstance(output, str):
                # Handle string output with truncation
                output_preview = output[:250] + "..." if len(output) > 250 else output
                logger.debug(f"Received string output from tool: {output_preview}")
                return data
            else:
                logger.error(f"Unexpected output type: {type(output)}")
                return {"output": f"Unexpected output type: {type(output)}", "token_usage": {}}
            
        except Exception as e:
            logger.error(f"Error processing tool end event: {str(e)}", exc_info=True)
            return {"output": "Error processing tool output", "token_usage": {}}

================
File: websockets/services/chat_service.py
================
from langchain.agents import AgentExecutor, create_structured_chat_agent
from langchain.memory import ConversationBufferMemory
from langchain_core.messages import (
    BaseMessage,
    SystemMessage,
    AIMessage,
    HumanMessage
)
from channels.db import database_sync_to_async
from apps.common.utils import create_box
import logging
from django.utils import timezone
from apps.common.utils import get_llm
from django.core.cache import cache
from typing import Optional, List, Any, Dict
import asyncio
from apps.seo_manager.models import Client
from django.db import models
from pydantic import ValidationError
from langchain_core.agents import AgentFinish
import re
from apps.common.utils import create_box

# Import our new managers
from apps.agents.chat.managers.token_manager import TokenManager
from apps.agents.chat.managers.tool_manager import ToolManager
from apps.agents.chat.managers.prompt_manager import PromptManager
from apps.agents.chat.managers.message_manager import MessageManager
from apps.agents.websockets.handlers.callback_handler import WebSocketCallbackHandler

logger = logging.getLogger(__name__)

class ChatServiceError(Exception):
    """Base exception for chat service errors"""
    pass

class ToolExecutionError(ChatServiceError):
    """Raised when a tool execution fails"""
    pass

class TokenLimitError(ChatServiceError):
    """Raised when token limit is exceeded"""
    pass

class ChatService:
    def __init__(self, agent, model_name, client_data, callback_handler, session_id=None):
        self.agent = agent
        self.model_name = model_name
        self.client_data = client_data
        self.callback_handler = callback_handler
        self.llm = None
        self.agent_executor = None
        self.processing = False
        self.tool_cache = {}  # Cache for tool results
        self.session_id = session_id or f"{agent.id}_{client_data['client_id'] if client_data else 'no_client'}"
        self.processing_lock = asyncio.Lock()
        
        # Create conversation ID from session ID if not provided
        self.conversation_id = f"conv_{self.session_id}"
        
        # Initialize managers with conversation ID
        self.token_manager = TokenManager(
            conversation_id=self.conversation_id,
            session_id=self.session_id,
            max_token_limit=64000,
            model_name=model_name
        )
        
        self.message_manager = MessageManager(
            conversation_id=self.conversation_id,
            session_id=self.session_id
        )
        
        self.tool_manager = ToolManager()
        self.prompt_manager = PromptManager()
        
        # Set up message history with token management
        self.message_history = self.message_manager
        
        # Update callback handler with managers
        if isinstance(self.callback_handler, WebSocketCallbackHandler):
            self.callback_handler.message_manager = self.message_manager
            self.callback_handler.token_manager = self.token_manager

    async def initialize(self) -> Optional[AgentExecutor]:
        """Initialize the chat service with LLM and agent"""
        try:
            # Validate and get client if present
            client_data = None
            if self.client_data and self.client_data.get('client_id'):
                try:
                    client = await database_sync_to_async(Client.objects.get)(id=self.client_data['client_id'])
                    client_data = {'client': client}
                except Client.DoesNotExist:
                    logger.error(f"Client not found with ID: {self.client_data['client_id']}")
                    raise ValueError(f"Client not found with ID: {self.client_data['client_id']}")

            # Create or get conversation
            conversation = await self._create_or_get_conversation(client_data['client'] if client_data else None)
            
            # Update managers with conversation ID
            self.conversation_id = str(conversation.id)
            self.token_manager.conversation_id = self.conversation_id
            self.message_manager.conversation_id = self.conversation_id

            # Get LLM with token tracking
            self.llm, token_callback = get_llm(
                model_name=self.model_name,
                temperature=0.7,
            )
            
            # Set up token tracking
            self.llm.callbacks = [token_callback]
            logger.debug(f"Setting up token tracking with callback: {token_callback}")
            self.token_manager.set_token_callback(token_callback)

            # Initialize memory with proper message handling
            memory = ConversationBufferMemory(
                memory_key="chat_history",
                return_messages=True,
                chat_memory=self.message_manager,
                output_key="output",
                input_key="input"
            )

            # Load initial messages into memory and get chat history
            chat_history = await self.message_manager.get_messages()
            if chat_history:
                memory.chat_memory.messages.extend(chat_history)

            # Load tools using tool manager
            tools = await self.tool_manager.load_tools(self.agent)
            
            # Create the agent-specific system prompt with client context using prompt manager
            system_prompt = self.prompt_manager.create_agent_prompt(self.agent, client_data)
            
            # Create prompt using prompt manager - pass raw data
            prompt = self.prompt_manager.create_chat_prompt(
                system_prompt=system_prompt,
                tools=tools,
                chat_history=chat_history,
                client_data=client_data
            )

            # Create the agent
            agent = create_structured_chat_agent(
                llm=self.llm,
                tools=tools,
                prompt=prompt
            )

            # Create agent executor with memory
            self.agent_executor = AgentExecutor.from_agent_and_tools(
                agent=agent,
                tools=tools,
                memory=memory,
                verbose=True,
                max_iterations=25,
                handle_parsing_errors=True,
                return_intermediate_steps=True,
                callbacks=[self.callback_handler, token_callback]
            )
            logger.debug(f"Created agent executor with callbacks: {[self.callback_handler, token_callback]}")

            # Reset session token totals
            await self.token_manager._reset_session_token_totals()

            return self.agent_executor

        except Exception as e:
            logger.error(f"Error initializing chat service: {str(e)}", exc_info=True)
            raise

    @database_sync_to_async
    def _create_or_get_conversation(self, client=None) -> Any:
        """Create or get a conversation record."""
        try:
            from apps.agents.models import Conversation
            
            # Try to get existing conversation
            conversation = Conversation.objects.filter(
                session_id=self.session_id
            ).first()
            
            if not conversation:
                # Create new conversation
                conversation = Conversation.objects.create(
                    session_id=self.session_id,
                    agent_id=self.agent.id,
                    client=client,
                    user_id=self.client_data.get('user_id') if self.client_data else None
                )
            
            return conversation
            
        except Exception as e:
            logger.error(f"Error creating/getting conversation: {str(e)}", exc_info=True)
            raise

    def _create_token_aware_memory(self) -> ConversationBufferMemory:
        """Create memory with token limit enforcement"""
        memory = ConversationBufferMemory(
            memory_key="chat_history",
            return_messages=True,
            chat_memory=self.message_manager,
            output_key="output",
            input_key="input"
        )

        # Wrap the add_message methods to check token counts
        original_add_message = self.message_manager.add_message

        async def wrapped_add_message(message: BaseMessage, **kwargs) -> None:
            """Async wrapper for add_message that handles token usage"""
            try:
                # Check token limit before adding message
                if not await self.token_manager.check_token_limit([message]):
                    raise TokenLimitError("Message would exceed token limit")
                    
                # Pass through any additional kwargs (including token_usage)
                await original_add_message(message, **kwargs)
            except Exception as e:
                logger.error(f"Error in wrapped_add_message: {str(e)}")
                raise

        # Replace the add_message method with our wrapped version
        self.message_manager.add_message = wrapped_add_message

        return memory
    
    async def process_message(self, message: str, is_edit: bool = False) -> None:
        async with self.processing_lock:
            try:
                # Reset token tracking
                self.token_manager.reset_tracking()
                logger.debug(create_box("Reset token tracking", ""))

                # Get chat history
                chat_history = await self.message_manager.get_messages()

                # Ensure chat history is a list of BaseMessage objects
                if not all(isinstance(msg, BaseMessage) for msg in chat_history):
                    logger.warning("Chat history contains non-BaseMessage objects")
                    chat_history = []

                logger.debug(create_box("Invoking agent with callbacks", f"{[self.callback_handler, self.llm.callbacks[0]]}"))
                # Get agent response
                response = await self.agent_executor.ainvoke(
                    {
                        "input": message,
                        "chat_history": chat_history
                    },
                    {"callbacks": [self.callback_handler, self.llm.callbacks[0]]}
                )
                
                # Log response safely by extracting output string
                response_str = response.get('output', str(response))
                if isinstance(response_str, str):
                    logger.debug(create_box("Agent response received", f"{response_str[-250:] if len(response_str) > 250 else response_str}"))
                else:
                    logger.debug(create_box("Agent response received", str(response)))
                    
                # Save the agent's response
                if isinstance(response, dict) and 'output' in response:
                    await self._handle_response(response['output'])

            except Exception as e:
                logger.error(f"Error in process_message: {str(e)}", exc_info=True)
                await self._handle_error(str(e), e, unexpected=True)

    async def _handle_response(self, response: str) -> None:
        """Handle successful response"""
        try:
            # Get current token usage
            token_usage = self.token_manager.get_current_usage()
            logger.debug(create_box("Current token usage from token_manager", f"{token_usage}"))
            
            # Send through callback handler for WebSocket communication
            await self.callback_handler.on_agent_finish(
                AgentFinish(
                    return_values={'output': response},
                    log='',
                ),
                token_usage=token_usage
            )
        except Exception as e:
            logger.error(f"Error handling response: {str(e)}", exc_info=True)
            await self._handle_error("Failed to handle response", e)

    async def _handle_error(self, error_msg: str, exception: Exception, unexpected: bool = False) -> None:
        """Handle errors consistently"""
        try:
            # Log the error
            logger.error(f"Error in chat service: {error_msg}", exc_info=True)
            
            # Store error message in message history
            if self.message_manager:
                await self.message_manager.add_message(
                    SystemMessage(content=f"Error: {error_msg}"),
                    token_usage=self.token_manager.get_current_usage()
                )
            
            # Send error through callback handler
            if self.callback_handler and hasattr(self.callback_handler, 'on_llm_error'):
                if asyncio.iscoroutinefunction(self.callback_handler.on_llm_error):
                    await self.callback_handler.on_llm_error(error_msg, run_id=None)
                else:
                    self.callback_handler.on_llm_error(error_msg, run_id=None)
                
            if unexpected:
                raise ChatServiceError(str(exception))
            else:
                raise exception
                
        except Exception as e:
            logger.error(f"Error in error handler: {str(e)}", exc_info=True)
            raise ChatServiceError(str(e))

    async def handle_edit(self, message_id: str) -> None:
        """Handle message editing"""
        try:
            await self.message_manager.handle_edit(message_id)
        except Exception as e:
            logger.error(f"Error handling edit: {str(e)}")
            raise ChatServiceError("Failed to handle message edit")

    async def get_conversation_token_usage(self) -> Dict:
        """Get total token usage for the conversation"""
        return await self.token_manager.get_conversation_token_usage()

    async def track_tool_token_usage(self, token_usage: Dict, tool_name: str) -> None:
        """Track token usage for tool execution"""
        await self.token_manager.store_token_usage(
            message_id=f"tool_{tool_name}_{timezone.now().timestamp()}",
            token_usage={
                **token_usage,
                'metadata': {'tool_name': tool_name, 'type': 'tool_execution'}
            }
        )

================
File: websockets/services/crew_chat_service.py
================
import uuid
from typing import Optional, Dict, Any
from django.contrib.auth import get_user_model
from apps.agents.models import (
    Conversation,
    CrewChatSession,
    ChatMessage,
    CrewExecution,
    ExecutionStage
)
from apps.agents.chat.managers.message_manager import MessageManager
from apps.agents.chat.managers.crew_manager import CrewManager
from apps.agents.chat.history import DjangoCacheMessageHistory
from langchain_core.messages import HumanMessage, AIMessage
from ..handlers.callback_handler import WebSocketCallbackHandler
from apps.agents.tasks.core.crew import initialize_crew, run_crew, get_client_data
import logging
import json
from channels.db import database_sync_to_async
from django.utils import timezone
import re
from django.core.cache import cache

User = get_user_model()
logger = logging.getLogger(__name__)

class CrewChatService:
    """Service for handling crew chat operations and context"""
    def __init__(self, user, conversation=None):
        self.user = user
        self.conversation = conversation
        self.websocket_handler = None
        self.message_manager = MessageManager(
            conversation_id=conversation.id if conversation else None,
            session_id=conversation.session_id if conversation else None
        )
        self.crew_execution = None
        self.message_history = None  # Will be initialized in initialize_chat
        self.callback_handler = None  # Will be set during initialization
        self.context_key = None  # Will be set during initialization

    @database_sync_to_async
    def _get_conversation_history(self) -> list:
        """Get formatted conversation history for crew execution"""
        if not self.message_history:
            return []
        
        messages = self.message_history.messages
        return [
            {
                'role': 'assistant' if isinstance(msg, AIMessage) else 'user',
                'content': msg.content
            }
            for msg in messages
        ]

    async def start_crew_execution(self, crew_id: int, client_id: Optional[int] = None):
        """Start a new crew execution"""
        try:
            # Create crew execution
            execution = await CrewExecution.objects.acreate(
                crew_id=crew_id,
                status='PENDING',
                user=self.user,
                conversation=self.conversation,
                client_id=client_id
            )
            
            # Update conversation
            self.conversation.participant_type = 'crew'
            self.conversation.crew_execution = execution
            if client_id:
                self.conversation.client_id = client_id
            await self.conversation.asave()

            # Initialize chat session
            await self.initialize_chat(execution)

            # Start crew execution in background task
            from apps.agents.tasks import execute_crew
            task = execute_crew.delay(execution.id)
            
            # Update execution with task ID
            execution.task_id = task.id
            await execution.asave()

            return execution
        except Exception as e:
            logger.error(f"Error starting crew execution: {str(e)}")
            raise
    
    async def initialize_chat(self, crew_execution):
        """Initialize chat session for crew execution"""
        try:
            self.crew_execution = crew_execution
            self.context_key = f"crew_chat_context_{crew_execution.id}"
            
            logger.debug(f"Initializing crew chat for execution {crew_execution.id}")
            
            # Get or create chat session
            session = await CrewChatSession.objects.filter(
                conversation=self.conversation,
                crew_execution=crew_execution
            ).afirst()
            
            if not session:
                session = await CrewChatSession.objects.acreate(
                    conversation=self.conversation,
                    crew_execution=crew_execution,
                    status='active'
                )
            
            # Initialize message manager with conversation
            self.message_manager.conversation_id = self.conversation.id
            self.message_manager.session_id = self.conversation.session_id
            
            # Initialize message history if not already set
            if not self.message_history:
                self.message_history = DjangoCacheMessageHistory(
                    session_id=self.conversation.session_id,
                    conversation_id=self.conversation.id
                )
            
            # Set up callback handler for websocket communication
            self.callback_handler = WebSocketCallbackHandler(
                consumer=self.websocket_handler,
                message_manager=self.message_manager
            )

            # Initialize context in cache
            if not cache.get(self.context_key):
                context = {
                    'messages': [],
                    'task_outputs': {},
                    'current_task': None,
                    'execution_id': crew_execution.id,
                    'current_date': timezone.now().strftime("%Y-%m-%d")
                }
                cache.set(self.context_key, context, timeout=3600)
            
            logger.info(f"Chat session initialized for execution {crew_execution.id}")
            return self.conversation
            
        except Exception as e:
            logger.error(f"Error initializing crew chat: {str(e)}")
            raise
    
    async def handle_human_input(self, message: str, task_index: Optional[int] = None):
        """Handle human input for crew execution"""
        try:
            if not self.crew_execution:
                raise ValueError("Crew execution not initialized")
            
            if task_index is None:
                raise ValueError("Task index is required for human input")

            # Get current context
            context = await self.get_context()
            current_task = context.get('current_task')
            
            # Validate task index matches current task
            if current_task is not None and current_task != task_index:
                logger.warning(f"Task index mismatch. Expected {current_task}, got {task_index}")
            
            # Add message to context with task metadata
            await self.add_message_to_context(message, is_human_input=True, task_index=task_index)
            
            # Update execution status
            self.crew_execution.status = 'PROCESSING'
            await self.crew_execution.asave()
            
            # Store human input in cache with proper key format matching crew.py
            input_key = f"execution_{self.crew_execution.id}_task_{task_index}_input"
            cache.set(input_key, message, timeout=3600)
            
            # Update context to track human input state
            context['human_input_state'] = {
                'task_index': task_index,
                'timestamp': str(timezone.now()),
                'status': 'provided'
            }
            cache.set(self.context_key, context, timeout=3600)
            
            logger.debug(f"Stored human input for task {task_index} with key: {input_key}")
            
            # Send acknowledgment through websocket
            if self.websocket_handler:
                await self.websocket_handler.send_json({
                    'type': 'human_input_received',
                    'task_index': task_index,
                    'timestamp': timezone.now().isoformat()
                })
            
        except Exception as e:
            logger.error(f"Error handling human input: {str(e)}")
            raise

    async def add_message_to_context(self, message: str, is_human_input: bool = False, task_index: Optional[int] = None):
        """Add a message to the crew chat context"""
        if not self.context_key:
            raise ValueError("Context not initialized")
            
        try:
            context = cache.get(self.context_key, {})
            messages = context.get('messages', [])
            
            # Add message to context with metadata
            message_data = {
                'content': message,
                'timestamp': str(timezone.now()),
                'is_human': True
            }
            
            # Add task metadata if this is human input
            if is_human_input and task_index is not None:
                message_data.update({
                    'is_human_input': True,
                    'task_index': task_index
                })
            
            messages.append(message_data)
            
            # Keep only last 50 messages
            if len(messages) > 50:
                messages = messages[-50:]
            
            context['messages'] = messages
            cache.set(self.context_key, context, timeout=3600)
            
        except Exception as e:
            logger.error(f"Error adding message to context: {str(e)}")
            raise

    async def add_task_output(self, task_id: int, output: Dict[str, Any]):
        """Add task output to context"""
        if not self.context_key:
            raise ValueError("Context not initialized")
            
        try:
            context = cache.get(self.context_key, {})
            task_outputs = context.get('task_outputs', {})
            task_outputs[str(task_id)] = output
            context['task_outputs'] = task_outputs
            cache.set(self.context_key, context, timeout=3600)
            
        except Exception as e:
            logger.error(f"Error adding task output: {str(e)}")
            raise

    async def get_context(self) -> Dict[str, Any]:
        """Get current crew chat context"""
        if not self.context_key:
            raise ValueError("Context not initialized")
        return cache.get(self.context_key, {})

    async def handle_message(self, message: str):
        """Handle incoming message for crew chat"""
        try:
            # Add message to context
            await self.add_message_to_context(message)
            
            # Store message in history
            stored_message = await self.message_history.add_message(HumanMessage(content=message))
            
            # Send user message confirmation
            if self.websocket_handler:
                await self.websocket_handler.send_json({
                    'type': 'user_message',
                    'content': {
                        'type': 'text',
                        'message': message
                    },
                    'id': str(stored_message.id) if stored_message else None,
                    'timestamp': timezone.now().isoformat()
                })
            
            # If this is during a human input task, check if we need to handle it
            context = await self.get_context()
            current_task = context.get('current_task')
            human_input_state = context.get('human_input_state', {})
            
            if human_input_state.get('status') == 'waiting' and current_task is not None:
                # This might be a response to a human input request
                await self.handle_human_input(message, task_index=current_task)
            
        except Exception as e:
            logger.error(f"Error handling crew message: {str(e)}")
            # Send error message through websocket
            if self.websocket_handler:
                await self.websocket_handler.send_json({
                    'type': 'error',
                    'content': {
                        'error': str(e)
                    },
                    'timestamp': timezone.now().isoformat()
                })
            raise
    
    async def send_crew_message(self, content: str, task_id: Optional[int] = None):
        """Send message from crew to chat"""
        try:
            if not content:
                logger.warning("Empty content in crew message, skipping")
                return

            logger.debug(f"Sending crew message: {content[:100]}...")
                
            # Save message in history
            stored_message = await self.message_history.add_message(
                AIMessage(content=content)
            )
            
            # Save in database
            message = await ChatMessage.objects.acreate(
                conversation=self.conversation,
                content=content,
                user=self.user,
                is_agent=True,
                task_id=task_id
            )
            
            if self.websocket_handler:
                # Base message data
                message_data = {
                    'id': str(stored_message.id) if stored_message else str(message.id),
                    'timestamp': message.timestamp.isoformat(),
                    'task_id': task_id
                }

                # Parse and format different message types
                if content.startswith(('Using tool:', 'Tool Start:')):
                    # Extract tool name and input
                    tool_match = re.match(r'^(?:Using tool:|Tool Start:)\s*(.*?)(?:\s*-\s*|\n)(.*)$', content)
                    if tool_match:
                        tool_name = tool_match.group(1).strip()
                        tool_input = tool_match.group(2).strip()
                        message_data.update({
                            'type': 'tool_start',
                            'content': {
                                'tool': tool_name,
                                'input': tool_input
                            },
                            'timestamp': message.timestamp.isoformat()
                        })
                    else:
                        # Fallback for unparseable tool messages
                        message_data.update({
                            'type': 'crew_message',
                            'content': content,
                            'timestamp': message.timestamp.isoformat()
                        })

                elif content.startswith(('Tool Result:', 'Tool result:')):
                    try:
                        # Extract result content
                        result_content = re.sub(r'^(?:Tool Result:|Tool result:)', '', content, 1).strip()
                        
                        # Parse output
                        if isinstance(result_content, str):
                            try:
                                data = json.loads(result_content)
                            except json.JSONDecodeError:
                                data = {"text": result_content}
                        else:
                            data = result_content

                        # Send message to websocket matching callback handler format
                        message_data.update({
                            'type': 'tool_result',
                            'content': data,  # Direct data object like callback handler
                            'timestamp': message.timestamp.isoformat()
                        })

                    except Exception as e:
                        logger.error(f"Error processing tool result: {str(e)}")
                        message_data.update({
                            'type': 'tool_result',
                            'content': {'error': str(e)},
                            'timestamp': message.timestamp.isoformat()
                        })

                elif content.startswith('Tool Error:'):
                    error_message = content.replace('Tool Error:', '', 1).strip()
                    message_data.update({
                        'type': 'error',
                        'message': error_message
                    })

                else:
                    # Regular crew message
                    message_data.update({
                        'type': 'crew_message',
                        'content': content,
                        'timestamp': message.timestamp.isoformat()
                    })

                # Send formatted message
                await self.websocket_handler.send_json(message_data)
            
            logger.debug(f"Crew message saved successfully with ID: {message.id}")
            return message
            
        except Exception as e:
            logger.error(f"Error sending crew message: {str(e)}")
            raise

    async def send_system_message(self, content: str, status: Optional[str] = None):
        """Send system message through websocket"""
        if self.websocket_handler:
            message_data = {
                'type': 'system_message',
                'message': content
            }
            if status:
                message_data['status'] = status
            message_data['timestamp'] = timezone.now().isoformat()
            await self.websocket_handler.send_json(message_data)

    async def send_execution_update(self, status: str, task_index: Optional[int] = None, message: Optional[str] = None):
        """Send execution status update"""
        if self.websocket_handler:
            update_data = {
                'type': 'execution_update',
                'status': status,
                'task_index': task_index
            }
            if message:
                update_data['message'] = message
            update_data['timestamp'] = timezone.now().isoformat()
            await self.websocket_handler.send_json(update_data)

================
File: websockets/base.py
================
from channels.generic.websocket import AsyncWebsocketConsumer
import json
import logging
from datetime import datetime

logger = logging.getLogger(__name__)

class BaseWebSocketConsumer(AsyncWebsocketConsumer):
    async def send_json(self, data):
        """Send JSON data as text"""
        try:
            await self.send(text_data=json.dumps(data))
        except Exception as e:
            logger.error(f"Error sending JSON: {str(e)}")
            await self.send(text_data=json.dumps({
                'error': True,
                'message': 'Error sending message'
            }))

    async def handle_binary_message(self, message):
        """Handle binary message data"""
        try:
            if isinstance(message, bytes):
                message = message.decode('utf-8')
            return json.loads(message)
        except Exception as e:
            logger.error(f"Error handling binary message: {str(e)}")
            return None

================
File: websockets/chat_consumer.py
================
from .base import BaseWebSocketConsumer
from .handlers.agent_handler import AgentHandler
from .services.crew_chat_service import CrewChatService
from ..tools.manager import AgentToolManager
from ..clients.manager import ClientDataManager
from ..chat.history import DjangoCacheMessageHistory
from ..models import Conversation, CrewExecution, ChatMessage
from django.core.cache import cache
import logging
import uuid
import json
from datetime import datetime
from urllib.parse import parse_qs
from langchain_core.chat_history import BaseChatMessageHistory
from langchain_core.messages import (
    BaseMessage, 
    HumanMessage, 
    AIMessage,
    messages_from_dict, 
    messages_to_dict
)
from channels.db import database_sync_to_async

logger = logging.getLogger(__name__)

class ChatConsumer(BaseWebSocketConsumer):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.tool_manager = AgentToolManager()
        self.client_manager = ClientDataManager()
        self.session_id = None
        self.group_name = None
        self.agent_handler = AgentHandler(self)
        self.is_connected = False
        self.message_history = None
        self.crew_chat_service = None  # Will be initialized if this is a crew chat

    @database_sync_to_async
    def get_crew_execution(self, conversation):
        """Safely get crew execution in async context"""
        try:
            return conversation.crew_execution
        except Exception as e:
            logger.error(f"Error getting crew execution: {str(e)}")
            return None

    @database_sync_to_async
    def get_crew(self, crew_execution):
        """Safely get crew in sync context"""
        try:
            return crew_execution.crew
        except Exception as e:
            logger.error(f"Error getting crew: {str(e)}")
            return None

    async def send_json(self, content):
        """Override to add logging"""
        #logger.debug(f"Sending message: {content}")
        await super().send_json(content)

    async def connect(self):
        if self.is_connected:
            return

        try:
            # Get session ID from query parameters
            query_string = self.scope.get('query_string', b'').decode()
            params = dict(param.split('=') for param in query_string.split('&') if param)
            self.session_id = params.get('session')
            
            if not self.session_id:
                logger.error("No session ID provided")
                await self.close()
                return
                
            self.user = self.scope.get("user")
            if not self.user or not self.user.is_authenticated:
                logger.error("User not authenticated")
                await self.close()
                return
        
            logger.debug(f"Connecting websocket for user {self.user.id} with session {self.session_id}")
                
            # Get or create conversation first
            conversation = await self.get_or_create_conversation()
            if not conversation:
                logger.error("Failed to get/create conversation")
                await self.close()
                return
            
            logger.debug(f"Found conversation {conversation.id} with title: {conversation.title}")
            logger.debug(f"Conversation participant type: {conversation.participant_type}")
                
            self.group_name = f"chat_{self.session_id}"

            # Initialize appropriate service based on participant type
            if conversation.participant_type == 'crew':
                self.crew_chat_service = CrewChatService(self.user, conversation)
                self.crew_chat_service.websocket_handler = self
                crew_execution = await self.get_crew_execution(conversation)
                if crew_execution:
                    await self.crew_chat_service.initialize_chat(crew_execution)
            
            # Initialize message history (used by both agent and crew chats)
            self.message_history = DjangoCacheMessageHistory(
                session_id=self.session_id,
                agent_id=conversation.agent_id if conversation.participant_type == 'agent' else None,
                conversation_id=conversation.id
            )
            
            await self.channel_layer.group_add(self.group_name, self.channel_name)
            await self.accept()
            self.is_connected = True
            
            # Send historical messages
            messages = await self.message_history.aget_messages()
            logger.debug(f"Retrieved {len(messages)} historical messages")
            
            for msg in messages:
                message_type = 'agent_message' if isinstance(msg, AIMessage) else 'user_message'
                if conversation.participant_type == 'crew':
                    message_type = 'crew_message' if isinstance(msg, AIMessage) else 'user_message'
                
                await self.send_json({
                    'type': message_type,
                    'message': msg.content,
                    'timestamp': conversation.updated_at.isoformat(),
                    'id': msg.additional_kwargs.get('id')
                })
            
            await self.send_json({
                'type': 'system_message',
                'message': 'Connected to chat server',
                'connection_status': 'connected',
                'session_id': self.session_id,
                'participant_type': conversation.participant_type
            })
            
        except Exception as e:
            logger.error(f"Error in connect: {str(e)}", exc_info=True)
            await self.close()
            return

    async def get_or_create_conversation(self):
        try:
            # Get existing conversation
            conversation = await Conversation.objects.filter(
                session_id=self.session_id,
                user=self.user
            ).afirst()
            
            if not conversation:
                # Create new conversation with placeholder title
                conversation = await Conversation.objects.acreate(
                    session_id=self.session_id,
                    user=self.user,
                    title="...",  # Will be updated with first message
                    participant_type='agent'  # Default to agent chat
                )
            
            return conversation
            
        except Exception as e:
            logger.error(f"Error getting/creating conversation: {str(e)}")
            return None

    @database_sync_to_async
    def set_cache_value(self, key, value):
        """Safely set cache value in async context"""
        cache.set(key, value)

    @database_sync_to_async
    def get_conversation_details(self, conversation):
        """Get conversation details in sync context"""
        details = {
            'participant_type': conversation.participant_type,
            'has_crew_execution': hasattr(conversation, 'crew_execution'),
            'title': conversation.title
        }
        
        # Get crew name if this is a crew chat
        if conversation.participant_type == 'crew' and conversation.crew_execution:
            details['crew_name'] = conversation.crew_execution.crew.name
        
        return details

    async def update_conversation(self, message, agent_id=None, client_id=None):
        """Update conversation details"""
        try:
            conversation = await Conversation.objects.filter(
                session_id=self.session_id
            ).afirst()
            
            if conversation:
                # Get conversation details in sync context
                details = await self.get_conversation_details(conversation)
                
                # Update title if it's still the default and we have a message
                if details['title'] == "..." and message:
                    # Format the message part of the title
                    title_message = message.strip().replace('\n', ' ')[:50]
                    if len(message) > 50:
                        title_message += "..."
                    
                    # Set title to just the message - participant name is shown separately in UI
                    conversation.title = title_message
                
                # Update agent/crew info based on participant type
                if details['participant_type'] == 'agent' and agent_id:
                    conversation.agent_id = agent_id
                
                # Update client if provided
                if client_id:
                    conversation.client_id = client_id
                    
                await conversation.asave()
                
        except Exception as e:
            logger.error(f"Error updating conversation: {str(e)}")
            raise

    async def execution_update(self, event):
        """Handle execution status updates from crew tasks"""
        try:
            status = event.get('status')
            message = event.get('message')
            task_index = event.get('task_index')
            
            # Only send status update - no message content
            await self.send_json({
                'type': 'execution_update',
                'status': status,
                'task_index': task_index,
                'timestamp': datetime.now().isoformat()
            })

            # If there's a message, send it as a crew message
            if message and self.crew_chat_service:
                await self.crew_chat_service.send_crew_message(
                    content=message,
                    task_id=task_index
                )

        except Exception as e:
            logger.error(f"Error sending execution update: {str(e)}")

    async def crew_message(self, event):
        """Handle crew messages from tasks"""
        try:
            if self.crew_chat_service:
                await self.crew_chat_service.send_crew_message(
                    content=event.get('message'),
                    task_id=event.get('task_id')
                )
        except Exception as e:
            logger.error(f"Error handling crew message: {str(e)}")

    async def receive(self, text_data=None, bytes_data=None):
        try:
            # Handle binary data if present
            if bytes_data:
                data = await self.handle_binary_message(bytes_data)
            else:
                # Handle text data
                if isinstance(text_data, dict):
                    # Already parsed JSON (from websocket_receive)
                    data = text_data
                else:
                    try:
                        data = json.loads(text_data)
                    except (json.JSONDecodeError, TypeError):
                        # If not JSON or None, treat as plain text message
                        data = {
                            'type': 'user_message',
                            'message': text_data or ''
                        }

            logger.debug(f"Received data: {data}")

            # Process keep-alive messages
            if data.get('type') == 'keep_alive':
                return

            # Process message
            await self.process_message(data)

        except Exception as e:
            logger.error(f" Error: {str(e)}", exc_info=True)
            await self.send_json({
                'type': 'error',
                'message': f'Error processing message: {str(e)}',
                'timestamp': datetime.now().isoformat()
            })

    async def process_message(self, data):
        """Primary entry point for all messages"""
        try:
            # Handle human input response
            if data.get('context', {}).get('is_human_input'):
                context = data.get('context', {})
                message = data.get('message')
                
                if not self.crew_chat_service:
                    raise ValueError("Crew chat service not initialized")
                
                # Handle human input through service
                await self.crew_chat_service.handle_human_input(
                    message=message,
                    task_index=context.get('task_index')
                )
                
                # Send user message back to show in chat
                await self.send_json({
                    'type': 'user_message',
                    'message': message,
                    'timestamp': datetime.now().isoformat()
                })
                return

            # Handle crew start request
            if data.get('type') == 'start_crew':
                crew_id = data.get('crew_id')
                client_id = data.get('client_id')
                if not crew_id:
                    raise ValueError('Missing crew ID')

                # Get conversation
                conversation = await Conversation.objects.filter(session_id=self.session_id).afirst()
                if not conversation:
                    raise ValueError('No active conversation found')

                # Initialize crew chat service if not exists
                if not self.crew_chat_service:
                    self.crew_chat_service = CrewChatService(self.scope['user'], conversation)
                    self.crew_chat_service.websocket_handler = self

                # Start crew execution through service
                try:
                    await self.crew_chat_service.start_crew_execution(crew_id, client_id)
                    
                    # Send confirmation
                    await self.send_json({
                        'type': 'system_message',
                        'message': 'Starting crew execution...',
                        'timestamp': datetime.now().isoformat()
                    })
                except Exception as e:
                    logger.error(f"Error starting crew: {str(e)}")
                    await self.send_json({
                        'type': 'error',
                        'message': f'Failed to start crew: {str(e)}',
                        'timestamp': datetime.now().isoformat()
                    })
                return

            # Extract message data
            message = data.get('message', '').strip()
            agent_id = data.get('agent_id')
            model_name = data.get('model')
            client_id = data.get('client_id')
            is_edit = data.get('type') == 'edit'  # Check for edit type
            message_id = data.get('message_id')  # Get message ID for edits

            #logger.debug(f"Processing message: type={data.get('type')}, message_id={message_id}, is_edit={is_edit}")

            if not message and not is_edit:  # Allow empty message for edit
                raise ValueError('Missing required fields')

            # Handle message editing if needed
            if is_edit:
                if not message_id:
                    raise ValueError('Missing message ID for edit')
                logger.debug(f"Handling edit for message {message_id}")
                await self.message_history.handle_edit(message_id)
                return  # Return early for edit messages

            # Get current conversation to check participant type
            conversation = await Conversation.objects.filter(session_id=self.session_id).afirst()
            if not conversation:
                raise ValueError('No active conversation found')

            # Get conversation details in sync context
            details = await self.get_conversation_details(conversation)

            # Initialize crew chat service if needed
            if details['participant_type'] == 'crew' and not self.crew_chat_service:
                self.crew_chat_service = CrewChatService(self.scope['user'], conversation)
                self.crew_chat_service.websocket_handler = self
                self.crew_chat_service.message_history = self.message_history  # Share the same message history

            # Update conversation with agent and client info
            await self.update_conversation(message, agent_id, client_id)

            # Store user message in history and database
            stored_message = await self.message_history.add_message(
                HumanMessage(content=message)
            )

            # Send user message with ID
            await self.send_json({
                'type': 'user_message',
                'message': message,
                'timestamp': datetime.now().isoformat(),
                'id': str(stored_message.id) if stored_message else None
            })
            
            # Handle crew chat messages if this is a crew chat
            if details['participant_type'] == 'crew':
                if not self.crew_chat_service:
                    raise ValueError('Crew chat service not initialized')
                await self.crew_chat_service.handle_message(message)
                return

            # Process with agent - responses come via callback_handler
            await self.agent_handler.process_response(
                message, agent_id, model_name, client_id
            )

        except Exception as e:
            logger.error(f"Error processing message: {str(e)}", exc_info=True)
            await self.send_json({
                'type': 'error',
                'message': f'Error processing message: {str(e)}',
                'timestamp': datetime.now().isoformat()
            })

    async def receive_json(self, content):
        """Disabled in favor of receive() to prevent duplicate message processing"""
        pass

    async def human_input_request(self, event):
        """Handle human input request from crew tasks"""
        try:
            # Extract prompt from event - it could be in different fields
            prompt = event.get('human_input_request') or event.get('prompt') or event.get('message', 'Input required')
            
            # Send as a crew message
            await self.send_json({
                'type': 'crew_message',
                'message': str(prompt),  # Ensure it's a string
                'context': {  # Include context for handling the response
                    'is_human_input': True,
                    'execution_id': event.get('context', {}).get('execution_id'),
                    'task_index': event.get('task_index')
                },
                'timestamp': datetime.now().isoformat()
            })
        except Exception as e:
            logger.error(f"Error sending human input request: {str(e)}")

================
File: admin.py
================
from django.contrib import admin
from .models import Crew, CrewExecution, CrewMessage, Agent, Task, Tool, CrewTask, SlackChannelClientMapping
from .forms import AgentForm, TaskForm, CrewForm

class CrewTaskInline(admin.TabularInline):
    model = CrewTask
    extra = 1

@admin.register(Crew)
class CrewAdmin(admin.ModelAdmin):
    list_display = ('name', 'process', 'verbose')
    filter_horizontal = ('agents',)
    inlines = [CrewTaskInline]
    fieldsets = (
        (None, {
            'fields': ('name', 'agents', 'process', 'verbose', 'manager_llm', 'function_calling_llm', 'config', 'max_rpm', 'language', 'language_file', 'memory', 'cache', 'embedder', 'full_output', 'share_crew', 'output_log_file', 'manager_agent', 'manager_callbacks', 'prompt_file', 'planning', 'planning_llm')
        }),
    )

    def get_form(self, request, obj=None, **kwargs):
        form = super().get_form(request, obj, **kwargs)
        form.base_fields['agents'].widget.can_add_related = True
        form.base_fields['agents'].widget.can_change_related = True
        return form

@admin.register(CrewExecution)
class CrewExecutionAdmin(admin.ModelAdmin):
    list_display = ('crew', 'user', 'client', 'status', 'created_at', 'updated_at')
    list_filter = ('status', 'created_at', 'updated_at')
    search_fields = ('crew__name', 'user__username', 'client__name')
    readonly_fields = ('created_at', 'updated_at', 'human_input_request', 'human_input_response', 'error_message')
    fieldsets = (
        (None, {
            'fields': ('crew', 'user', 'client', 'status', 'inputs', 'crew_output')
        }),
        ('Human Input', {
            'fields': ('human_input_request', 'human_input_response')
        }),
        ('Error Information', {
            'fields': ('error_message',)
        }),
        ('Timestamps', {
            'fields': ('created_at', 'updated_at')
        }),
    )

@admin.register(CrewMessage)
class CrewMessageAdmin(admin.ModelAdmin):
    list_display = ('execution', 'timestamp')
    list_filter = ('timestamp',)
    search_fields = ('execution__crew__name', 'content')

@admin.register(Agent)
class AgentAdmin(admin.ModelAdmin):
    form = AgentForm
    list_display = ('name', 'role', 'llm', 'function_calling_llm', 'verbose', 'allow_delegation', 'allow_code_execution')
    list_filter = ('verbose', 'allow_delegation', 'allow_code_execution', 'use_system_prompt', 'respect_context_window')
    search_fields = ('name', 'role', 'goal', 'backstory')
    filter_horizontal = ('tools',)
    fieldsets = (
        (None, {
            'fields': ('name', 'role', 'goal', 'backstory', 'llm', 'tools')
        }),
        ('Advanced options', {
            'classes': ('collapse',),
            'fields': ('function_calling_llm', 'max_iter', 'max_rpm', 'max_execution_time', 'verbose', 'allow_delegation', 'step_callback', 'cache', 'system_template', 'prompt_template', 'response_template', 'allow_code_execution', 'max_retry_limit', 'use_system_prompt', 'respect_context_window'),
        }),
    )

@admin.register(Task)
class TaskAdmin(admin.ModelAdmin):
    form = TaskForm
    list_display = ('description', 'agent', 'async_execution', 'human_input', 'output_type')
    list_filter = ('async_execution', 'human_input')
    filter_horizontal = ('tools', 'context')
    search_fields = ('description', 'agent__name', 'expected_output')
    readonly_fields = ('output',)

    def output_type(self, obj):
        if obj.output_json:
            return 'JSON'
        elif obj.output_pydantic:
            return 'Pydantic'
        elif obj.output_file:
            return 'File'
        else:
            return 'Default'
    output_type.short_description = 'Output Type'

    fieldsets = (
        (None, {
            'fields': ('description', 'agent', 'expected_output', 'tools', 'async_execution', 'context')
        }),
        ('Advanced options', {
            'classes': ('collapse',),
            'fields': ('config', 'output_json', 'output_pydantic', 'output_file', 'human_input', 'converter_cls'),
        }),
        ('Output', {
            'fields': ('output',),
        }),
    )

@admin.register(Tool)
class ToolAdmin(admin.ModelAdmin):
    list_display = ('name', 'description')
    search_fields = ('name', 'description', 'function')

@admin.register(SlackChannelClientMapping)
class SlackChannelClientMappingAdmin(admin.ModelAdmin):
    list_display = ('channel_id', 'team_id', 'client', 'created_at')
    search_fields = ('channel_id', 'team_id')
    list_filter = ('team_id', 'created_at')

================
File: apps.py
================
from django.apps import AppConfig
import os
import logging
import sys
from django.conf import settings

logger = logging.getLogger(__name__)

class AgentsConfig(AppConfig):
    default_auto_field = 'django.db.models.BigAutoField'
    name = 'apps.agents'
    verbose_name = 'CrewAI Agents'
    
    def ready(self):
        """Initialize the Slack bot only once under Daphne"""
        # Get the current process name
        process_name = sys.argv[0] if sys.argv else ''
        #logger.info(f"AgentsConfig.ready() called with process_name: {process_name}")
        #logger.info(f"RUN_MAIN: {os.environ.get('RUN_MAIN')}")
        #logger.info(f"Already initialized: {getattr(self, '_slack_initialized', False)}")
        
        # Only initialize if:
        # 1. We're running under Daphne
        # 2. We haven't already initialized in this process
        # 3. We're not in an auto-reload cycle
        if ('daphne' not in process_name or 
            getattr(self, '_slack_initialized', False) or
            os.environ.get('RUN_MAIN') == 'true'):
            logger.info("Skipping Slack bot initialization due to conditions not met")
            return
            
        #logger.info("All conditions met, proceeding with Slack bot initialization...")
        
        try:
            from .integrations.slack_bot import start_slack_bot
            start_slack_bot()
            self._slack_initialized = True
            logger.info("Slack bot initialization completed and flag set")
        except Exception as e:
            logger.error(f"Failed to initialize Slack bot: {e}", exc_info=True)

================
File: celery.py
================
from celery import Celery
import os
from django.conf import settings

# Set the default Django settings module for the 'celery' program.
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'core.settings')

app = Celery('core')

# Using a string here means the worker doesn't have to serialize
# the configuration object to child processes.
# - namespace='CELERY' means all celery-related configuration keys
#   should have a `CELERY_` prefix.
app.config_from_object('django.conf:settings', namespace='CELERY')

# Load task modules from all registered Django app configs.
app.autodiscover_tasks(lambda: settings.INSTALLED_APPS)

================
File: consumers.py
================
import json
from channels.generic.websocket import AsyncWebsocketConsumer
from channels.db import database_sync_to_async
from django.contrib.auth import get_user_model
from .models import CrewExecution, CrewMessage, ChatMessage, Agent
from django.core.cache import cache
from apps.common.utils import format_message, get_llm
from .utils import get_tool_classes
import logging
import uuid
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, FunctionMessage, BaseMessage, messages_from_dict, messages_to_dict
import asyncio
import tiktoken
from langchain_community.chat_models import ChatLiteLLM
from langchain_core.tools import Tool
from django.utils import timezone
from apps.seo_manager.models import Client
from langchain.prompts import ChatPromptTemplate
from langchain.agents import initialize_agent, AgentType, AgentExecutor, create_structured_chat_agent
from langchain.agents.format_scratchpad import format_to_openai_function_messages
from langchain.agents.output_parsers import JSONAgentOutputParser
from langchain_core.callbacks import BaseCallbackHandler
import datetime
from langchain.tools import StructuredTool
from typing import Dict, Any, List
from pydantic import create_model
from langchain.memory import ConversationBufferMemory
from langchain_core.chat_history import BaseChatMessageHistory
import re
import time

logger = logging.getLogger(__name__)

def count_tokens(text):
    """Count tokens in text using tiktoken"""
    encoding = tiktoken.encoding_for_model("gpt-3.5-turbo")
    return len(encoding.encode(text))

class ConnectionTestConsumer(AsyncWebsocketConsumer):
    async def connect(self):
        await self.accept()
        await self.send(text_data=json.dumps({
            'message': 'Connected to server'
        }))

    async def disconnect(self, close_code):
        pass

    async def receive(self, text_data):
        try:
            text_data_json = json.loads(text_data)
            message = text_data_json['message']

            # Echo the received message back to the client
            await self.send(text_data=json.dumps({
                'message': f'Server received: {message}'
            }))
        except json.JSONDecodeError:
            await self.send(text_data=json.dumps({
                'error': 'Invalid JSON format'
            }))
        except KeyError:
            await self.send(text_data=json.dumps({
                'error': 'Missing "message" key in JSON'
            }))

class CrewExecutionConsumer(AsyncWebsocketConsumer):
    async def connect(self):
        self.execution_id = self.scope['url_route']['kwargs']['execution_id']
        self.execution_group_name = f'crew_execution_{self.execution_id}'

        # Join room group
        await self.channel_layer.group_add(
            self.execution_group_name,
            self.channel_name
        )

        await self.accept()

        # Send initial status
        await self.send_execution_status()

    async def disconnect(self, close_code):
        # Leave room group
        await self.channel_layer.group_discard(
            self.execution_group_name,
            self.channel_name
        )

    async def receive(self, text_data):
        text_data_json = json.loads(text_data)
        message_type = text_data_json.get('type')

        if message_type == 'human_input':
            input_key = text_data_json.get('input_key')
            user_input = text_data_json.get('input')
            await self.handle_human_input(input_key, user_input)

    async def crew_execution_update(self, event):
        status = event.get('status', '')  # No formatting applied
        formatted_messages = [
            {
                'agent': msg.get('agent', 'System'),
                'content': format_message(msg.get('content', ''))
            } for msg in event.get('messages', []) if msg.get('content')
        ]
        # logger.info(f"Sending status: {status}")
        # logger.info(f"Sending formatted messages: {formatted_messages}")
        await self.send(text_data=json.dumps({
            'status': status,
            'messages': formatted_messages,
            'human_input_request': event.get('human_input_request')
        }))

    @database_sync_to_async
    def handle_human_input(self, input_key, user_input):
        cache.set(f"{input_key}_response", user_input, timeout=3600)
        execution = CrewExecution.objects.get(id=self.execution_id)
        CrewMessage.objects.create(
            execution=execution,
            agent='Human',
            content=f"Human input received: {user_input}"
        )

    @database_sync_to_async
    def get_execution_status(self):
        execution = CrewExecution.objects.get(id=self.execution_id)
        messages = CrewMessage.objects.filter(execution=execution).order_by('-timestamp')[:10]
        return {
            'status': execution.status,
            'messages': [{'agent': msg.agent, 'content': msg.content} for msg in messages],
        }

    async def send_execution_status(self):
        status_data = await self.get_execution_status()
        status = status_data['status']  # No formatting applied
        formatted_messages = [
            {
                'agent': msg['agent'],
                'content': format_message(msg['content'])
            } for msg in status_data['messages'] if msg.get('content')
        ]
        
        # logger.info(f"Sending status: {status}")
        # logger.info(f"Sending formatted messages: {formatted_messages}")
        
        await self.send(text_data=json.dumps({
            'status': status,
            'messages': formatted_messages,
        }))

================
File: forms.py
================
import random
from django.conf import settings
from django import forms
from .models import CrewExecution, Agent, Task, Tool, Crew, get_available_tools, AVATAR_CHOICES
from apps.seo_manager.models import Client
from apps.common.utils import get_models
import json
import logging
from .utils import get_available_tools, get_tool_classes

logger = logging.getLogger(__name__)

class CrewExecutionForm(forms.ModelForm):
    inputs = forms.JSONField(widget=forms.Textarea(attrs={'rows': 4}), required=False)

    class Meta:
        model = CrewExecution
        fields = ['inputs']

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.fields['inputs'].widget.attrs['class'] = 'form-control'
        self.fields['inputs'].help_text = 'Enter JSON formatted inputs for the crew execution.'

    def clean_inputs(self):
        inputs = self.cleaned_data.get('inputs')
        if inputs:
            try:
                return json.loads(inputs)
            except json.JSONDecodeError:
                raise forms.ValidationError("Invalid JSON format in inputs field")
        return {}

class HumanInputForm(forms.Form):
    response = forms.CharField(widget=forms.Textarea(attrs={'rows': 4}), required=True)

class AgentForm(forms.ModelForm):
    avatar = forms.ChoiceField(
        choices=[(choice, choice) for choice in AVATAR_CHOICES],
        widget=forms.RadioSelect(),
        required=False
    )
    llm = forms.ChoiceField(
        choices=[(model, model) for model in get_models()],
        widget=forms.Select(attrs={'class': 'form-select'}),
        required=True
    )
    function_calling_llm = forms.ChoiceField(
        choices=[(model, model) for model in get_models()],
        widget=forms.Select(attrs={'class': 'form-select'}),
        required=False
    )
    
    tools = forms.ModelMultipleChoiceField(
        queryset=Tool.objects.all(),
        widget=forms.CheckboxSelectMultiple,
        required=False
    )

    class Meta:
        model = Agent
        fields = '__all__'  # Include all fields from the model
        widgets = {
            'goal': forms.Textarea(attrs={'rows': 3}),
            'backstory': forms.Textarea(attrs={'rows': 3}),
            'system_template': forms.Textarea(attrs={'rows': 4}),
            'prompt_template': forms.Textarea(attrs={'rows': 4}),
            'response_template': forms.Textarea(attrs={'rows': 4}),
            'tools': forms.SelectMultiple(attrs={'class': 'form-select'}),
            'llm': forms.Select(attrs={'class': 'form-select'}),
        }

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        for field in self.fields:
            if isinstance(self.fields[field].widget, forms.CheckboxInput):
                self.fields[field].widget.attrs['class'] = 'form-check-input'
            elif not isinstance(self.fields[field].widget, (forms.SelectMultiple, forms.RadioSelect)):
                self.fields[field].widget.attrs['class'] = 'form-control'

        # Ensure avatar choices are set
        self.fields['avatar'].choices = [(choice, choice) for choice in AVATAR_CHOICES]

        # Ensure the initial values are set correctly
        self.initial['llm'] = self.initial.get('llm', settings.GENERAL_MODEL)
        self.initial['function_calling_llm'] = self.initial.get('function_calling_llm', settings.GENERAL_MODEL)

    def clean(self):
        cleaned_data = super().clean()
        logger.debug(f"Cleaned form data: {cleaned_data}")
        return cleaned_data

    def save(self, commit=True):
        logger.debug(f"Saving form with data: {self.cleaned_data}")
        instance = super().save(commit=False)
        # Ensure LLM values are set on the instance
        instance.llm = self.cleaned_data.get('llm')
        instance.function_calling_llm = self.cleaned_data.get('function_calling_llm')
        if commit:
            instance.save()
            self.save_m2m()
        logger.debug(f"Saved instance: {instance.__dict__}")
        return instance

class TaskForm(forms.ModelForm):
    config = forms.CharField(widget=forms.Textarea(attrs={'rows': 4}), required=False)

    class Meta:
        model = Task
        fields = ['description', 'agent', 'expected_output', 'tools', 'async_execution', 'context', 'config', 'output_json', 'output_pydantic', 'output_file', 'human_input', 'converter_cls']
        widgets = {
            'description': forms.Textarea(attrs={'rows': 4}),
            'expected_output': forms.Textarea(attrs={'rows': 4}),
            'tools': forms.CheckboxSelectMultiple(),
            'context': forms.CheckboxSelectMultiple(),
            'output_json': forms.TextInput(),
            'output_pydantic': forms.TextInput(),
            'output_file': forms.TextInput(attrs={'placeholder': 'e.g., outputs/task_result.txt'}),
            'converter_cls': forms.TextInput(),
        }

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        if self.instance.config:
            self.initial['config'] = json.dumps(self.instance.config, indent=2)

    def clean_config(self):
        config = self.cleaned_data.get('config')
        if config:
            try:
                return json.loads(config)
            except json.JSONDecodeError:
                raise forms.ValidationError("Invalid JSON format in config field")
        return None

    def clean_output_file(self):
        output_file = self.cleaned_data.get('output_file')
        if output_file:
            # You can add additional validation here if needed
            # For example, check if the path is within allowed directories
            pass
        return output_file

class ToolForm(forms.ModelForm):
    tool_class = forms.ChoiceField(
        choices=[],
        widget=forms.Select(attrs={'class': 'form-control'}),
        required=True
    )
    tool_subclass = forms.ChoiceField(
        choices=[],
        widget=forms.Select(attrs={'class': 'form-control'}),
        required=True
    )
    description = forms.CharField(widget=forms.Textarea(attrs={'readonly': 'readonly'}), required=False)

    class Meta:
        model = Tool
        fields = ['tool_class', 'tool_subclass', 'name', 'description']

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        available_tools = get_available_tools()
        self.fields['tool_class'].choices = [(tool, tool) for tool in available_tools]
        self.fields['name'].widget = forms.HiddenInput()
        self.fields['name'].required = False
        
        if self.data.get('tool_class'):
            self.fields['tool_subclass'].choices = self.get_subclass_choices(self.data['tool_class'])
        elif self.instance.pk:
            self.fields['tool_subclass'].choices = self.get_subclass_choices(self.instance.tool_class)

    def get_subclass_choices(self, tool_class):
        subclasses = get_tool_classes(tool_class)
        return [(cls.__name__, cls.__name__) for cls in subclasses]

    def clean(self):
        cleaned_data = super().clean()
        tool_class = cleaned_data.get('tool_class')
        tool_subclass = cleaned_data.get('tool_subclass')

        if tool_class:
            self.fields['tool_subclass'].choices = self.get_subclass_choices(tool_class)

        if tool_class and tool_subclass:
            subclasses = dict(self.fields['tool_subclass'].choices)
            if tool_subclass not in subclasses:
                raise forms.ValidationError(f"Invalid tool subclass '{tool_subclass}' for tool class '{tool_class}'")

        # Set the name field to the value of tool_subclass
        cleaned_data['name'] = tool_subclass

        return cleaned_data

    def save(self, commit=True):
        instance = super().save(commit=False)
        instance.name = self.cleaned_data['tool_subclass']
        if commit:
            instance.save()
        return instance

class CrewForm(forms.ModelForm):
    config = forms.CharField(widget=forms.Textarea(attrs={'rows': 4}), required=False)
    manager_callbacks = forms.CharField(widget=forms.Textarea(attrs={'rows': 4}), required=False)
    agents = forms.ModelMultipleChoiceField(
        queryset=Agent.objects.all(),
        required=False,
        widget=forms.SelectMultiple(attrs={'class': 'form-control form-select'})
    )

    class Meta:
        model = Crew
        fields = [
            'name', 'agents', 'tasks', 'process', 'verbose', 'manager_llm',
            'function_calling_llm', 'config', 'max_rpm', 'language',
            'language_file', 'memory', 'cache', 'embedder', 'full_output',
            'share_crew', 'output_log_file', 'manager_agent', 'manager_callbacks',
            'prompt_file', 'planning', 'planning_llm'
        ]
        # Note: input_variables is not included here as it's handled separately in the view

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        available_models = get_models()
        self.fields['manager_llm'] = forms.ChoiceField(
            choices=[(model, model) for model in available_models],
            widget=forms.Select(attrs={'class': 'form-control'}),
            required=False
        )
        self.fields['function_calling_llm'] = forms.ChoiceField(
            choices=[(model, model) for model in available_models],
            widget=forms.Select(attrs={'class': 'form-control'}),
            required=False
        )
        self.fields['planning_llm'] = forms.ChoiceField(
            choices=[(model, model) for model in available_models],
            widget=forms.Select(attrs={'class': 'form-control'}),
            required=False
        )
        self.fields['max_rpm'].widget.attrs['min'] = 0
        self.fields['max_rpm'].widget.attrs['step'] = 1

        if self.instance.config:
            self.initial['config'] = json.dumps(self.instance.config, indent=2)
        if self.instance.manager_callbacks:
            self.initial['manager_callbacks'] = json.dumps(self.instance.manager_callbacks, indent=2)
        if self.instance.embedder:
            self.initial['embedder'] = json.dumps(self.instance.embedder, indent=2)

        # Remove the 'required' attribute from the agents field
        if 'agents' in self.fields:
            self.fields['agents'].required = False

        print(f"Initial manager_llm: {self.initial.get('manager_llm')}")  # Debugging line
        print(f"Initial function_calling_llm: {self.initial.get('function_calling_llm')}")  # Debugging line

    def clean_config(self):
        return self._clean_json_field('config')

    def clean_manager_callbacks(self):
        return self._clean_json_field('manager_callbacks')

    def clean_embedder(self):
        return self._clean_json_field('embedder')

    def _clean_json_field(self, field_name):
        data = self.cleaned_data.get(field_name)
        if data:
            try:
                return json.loads(data)
            except json.JSONDecodeError:
                raise forms.ValidationError(f"Invalid JSON format in {field_name} field")
        return None

================
File: kanban_consumers.py
================
from channels.generic.websocket import AsyncWebsocketConsumer
import json
from channels.db import database_sync_to_async
from django.contrib.auth import get_user_model
import logging

logger = logging.getLogger(__name__)
User = get_user_model()

class CrewKanbanConsumer(AsyncWebsocketConsumer):
    async def connect(self):
        """
        Handle WebSocket connection setup
        """
        self.crew_id = self.scope['url_route']['kwargs']['crew_id']
        self.room_group_name = f'crew_{self.crew_id}_kanban'
        self.is_connected = False
        
        try:
            # Initialize channel layer from parent
            await super().connect()
            
            # Ensure channel layer is available
            if not hasattr(self, 'channel_layer') or not self.channel_layer:
                logger.error("Channel layer not initialized")
                await self.close()
                return
                
            # Add to crew group
            await self.channel_layer.group_add(
                self.room_group_name,
                self.channel_name
            )
            
            self.is_connected = True
            logger.info(f"WebSocket connection established for crew {self.crew_id}")
        except Exception as e:
            logger.error(f"Error establishing WebSocket connection: {str(e)}")
            if not self.is_connected:
                await self.close()
    
    async def disconnect(self, close_code):
        """
        Handle WebSocket disconnection cleanup
        """
        try:
            self.is_connected = False
            if hasattr(self, 'channel_layer') and self.channel_layer:
                await self.channel_layer.group_discard(
                    self.room_group_name,
                    self.channel_name
                )
                logger.info(f"WebSocket connection closed for crew {self.crew_id} with code {close_code}")
            else:
                logger.warning("Channel layer not available during disconnect")
        except Exception as e:
            logger.error(f"Error during WebSocket disconnect: {str(e)}")
    
    async def receive(self, text_data):
        """
        Handle incoming WebSocket messages
        """
        if not self.is_connected:
            logger.warning("Received message but WebSocket is not connected")
            return
            
        try:
            data = json.loads(text_data)
            message_type = data.get('type')
            logger.debug(f"Received WebSocket message: {message_type}")
            
            # Handle ping messages immediately
            if message_type == 'ping':
                await self.send(text_data=json.dumps({
                    'type': 'pong'
                }))
                return
            
            handlers = {
                'execution_update': self.handle_execution_update,
                'agent_step': self.handle_agent_step,
                'human_input_request': self.handle_human_input_request,
                'task_complete': self.handle_task_complete
            }
            
            handler = handlers.get(message_type)
            if handler:
                await handler(data)
            else:
                logger.warning(f"Unknown message type received: {message_type}")
        
        except json.JSONDecodeError:
            logger.error(f"Failed to decode WebSocket message: {text_data}")
        except Exception as e:
            logger.error(f"Error processing WebSocket message: {str(e)}")
            if self.is_connected:
                await self.send(text_data=json.dumps({
                    'type': 'error',
                    'message': 'Internal server error occurred'
                }))
    
    async def handle_execution_update(self, data):
        """Handle execution status updates"""
        if not self.is_connected:
            logger.warning("Cannot send execution update - WebSocket not connected")
            return
            
        try:
            # Get crewai_task_id from execution
            execution_id = data.get('execution_id')
            if execution_id:
                crewai_task_id = await self.get_task_id_for_execution(execution_id)
                data['crewai_task_id'] = crewai_task_id
            
            await self.channel_layer.group_send(
                self.room_group_name,
                {
                    'type': 'execution_update',
                    **data
                }
            )
            logger.debug(f"Sent execution update for execution {execution_id}")
        except Exception as e:
            logger.error(f"Error sending execution update: {str(e)}")
            # Don't try to send error message if we already know connection is broken
            if self.is_connected:
                try:
                    await self.send(text_data=json.dumps({
                        'type': 'error',
                        'message': 'Failed to send execution update'
                    }))
                except:
                    pass

    async def handle_agent_step(self, data):
        """Handle individual agent step updates"""
        if not self.is_connected:
            logger.warning("Cannot send agent step - WebSocket not connected")
            return
            
        try:
            await self.channel_layer.group_send(
                self.room_group_name,
                {
                    'type': 'agent_step',
                    'execution_id': data.get('execution_id'),
                    'agent': data.get('agent', ''),
                    'content': data.get('content', ''),
                    'step_type': data.get('step_type', ''),
                    'is_final_step': data.get('is_final_step', False)
                }
            )
        except Exception as e:
            logger.error(f"Error sending agent step: {str(e)}")
            if self.is_connected:
                try:
                    await self.send(text_data=json.dumps({
                        'type': 'error',
                        'message': 'Failed to send agent step'
                    }))
                except:
                    pass

    async def handle_human_input_request(self, data):
        """Handle requests for human input"""
        if not self.is_connected:
            logger.warning("Cannot send human input request - WebSocket not connected")
            return
            
        try:
            await self.channel_layer.group_send(
                self.room_group_name,
                {
                    'type': 'human_input_request',
                    'execution_id': data.get('execution_id'),
                    'prompt': data.get('prompt', ''),
                    'context': data.get('context', {})
                }
            )
        except Exception as e:
            logger.error(f"Error sending human input request: {str(e)}")
            if self.is_connected:
                try:
                    await self.send(text_data=json.dumps({
                        'type': 'error',
                        'message': 'Failed to send human input request'
                    }))
                except:
                    pass

    async def handle_task_complete(self, data):
        """Handle task completion notifications"""
        if not self.is_connected:
            logger.warning("Cannot send task complete - WebSocket not connected")
            return
            
        try:
            await self.channel_layer.group_send(
                self.room_group_name,
                {
                    'type': 'task_complete',
                    'execution_id': data.get('execution_id'),
                    'message': data.get('message', ''),
                    'results': data.get('results', {})
                }
            )
        except Exception as e:
            logger.error(f"Error sending task complete: {str(e)}")
            if self.is_connected:
                try:
                    await self.send(text_data=json.dumps({
                        'type': 'error',
                        'message': 'Failed to send task complete'
                    }))
                except:
                    pass
    
    # WebSocket send handlers
    async def execution_update(self, event):
        """Send execution updates to WebSocket"""
        if not self.is_connected:
            logger.warning("Cannot send execution update - WebSocket not connected")
            return
            
        try:
            # Ensure stage data has all required fields
            stage = event.get('stage', {})
            if stage:
                stage.setdefault('stage_type', 'processing')
                stage.setdefault('title', 'Processing...')
                stage.setdefault('content', '')
                stage.setdefault('status', 'in_progress')
                stage.setdefault('agent', 'System')
                stage.setdefault('completed', False)
                
                if stage.get('status') == 'completed':
                    stage['completed'] = True
                
                if 'chat_message_prompts' not in stage:
                    stage['chat_message_prompts'] = [{
                        'role': 'system',
                        'content': stage.get('content', 'Processing task...')
                    }]
            
            message = {
                'type': 'execution_update',
                'execution_id': event['execution_id'],
                'status': event['status'],
                'crewai_task_id': event.get('crewai_task_id'),
                'task_index': event.get('task_index'),
                'message': event.get('message'),
                'stage': stage,
                'human_input_request': event.get('human_input_request')
            }
            #logger.debug(f"Consumer sending message: {message}")
            await self.send(text_data=json.dumps(message))
        except Exception as e:
            logger.error(f"Error sending execution update: {str(e)}")
            if self.is_connected:
                try:
                    await self.send(text_data=json.dumps({
                        'type': 'error',
                        'message': 'Failed to send execution update'
                    }))
                except:
                    pass

    async def agent_step(self, event):
        """Send agent step updates to WebSocket"""
        if not self.is_connected:
            logger.warning("Cannot send agent step - WebSocket not connected")
            return
            
        try:
            # Get crewai_task_id for this execution
            execution_id = event['execution_id']
            crewai_task_id = await self.get_task_id_for_execution(execution_id)
            
            # Format agent step as a stage update with chat_message_prompts
            stage_data = {
                'stage_type': event.get('step_type', 'agent_step'),
                'title': f"Agent: {event.get('agent', 'System')}",
                'content': event.get('content', ''),
                'status': 'in_progress',
                'agent': event.get('agent', 'System'),
                'completed': False,
                'chat_message_prompts': [{
                    'role': 'assistant',
                    'content': event.get('content', '')
                }]
            }
            
            await self.send(text_data=json.dumps({
                'type': 'execution_update',
                'execution_id': execution_id,
                'crewai_task_id': crewai_task_id,
                'stage': stage_data
            }))
            
            # Send a completion update for this stage if it's the final step
            if event.get('is_final_step', False):
                stage_data.update({
                    'status': 'completed',
                    'completed': True
                })
                await self.send(text_data=json.dumps({
                    'type': 'execution_update',
                    'execution_id': execution_id,
                    'crewai_task_id': crewai_task_id,
                    'stage': stage_data
                }))
        except Exception as e:
            logger.error(f"Error sending agent step: {str(e)}")
            if self.is_connected:
                try:
                    await self.send(text_data=json.dumps({
                        'type': 'error',
                        'message': 'Failed to send agent step'
                    }))
                except:
                    pass

    async def human_input_request(self, event):
        """Send human input requests to WebSocket"""
        logger.debug(f"Consumer received human_input_request event: {event}")
        try:
            message = {
                'type': 'human_input_request',
                'execution_id': event['execution_id'],
                'prompt': event['prompt'],
                'context': event.get('context', {})
            }
            #logger.debug(f"Consumer attempting to send message: {message}")
            await self.send(text_data=json.dumps(message))
            logger.debug("Consumer successfully sent message")
        except Exception as e:
            logger.error(f"Consumer failed to send message: {e}")

    async def task_complete(self, event):
        """Send task completion notifications to WebSocket"""
        execution_id = event['execution_id']
        crewai_task_id = await self.get_task_id_for_execution(execution_id)
        
        await self.send(text_data=json.dumps({
            'type': 'task_complete',
            'execution_id': execution_id,
            'crewai_task_id': crewai_task_id,
            'message': event['message'],
            'results': event['results']
        }))

    @database_sync_to_async
    def get_task_id_for_execution(self, execution_id):
        """Get CrewAI task ID for a given execution"""
        from .models import CrewExecution
        try:
            execution = CrewExecution.objects.get(id=execution_id)
            # Get the latest execution stage for this execution
            latest_stage = execution.executionstage_set.order_by('-created_at').first()
            return latest_stage.crewai_task_id if latest_stage else None
        except CrewExecution.DoesNotExist:
            return None

================
File: models.py
================
from django.db import models
from django.contrib.auth import get_user_model
from django.core.exceptions import ValidationError
from apps.common.utils import get_models
from pydantic import BaseModel
import os
import importlib
import logging
import uuid
import random
import json
from django.contrib.postgres.fields import ArrayField
from django.conf import settings
from apps.agents.utils import load_tool, get_tool_description
from django.core.files.storage import default_storage
from django.core.files.base import ContentFile

logger = logging.getLogger(__name__)

User = get_user_model()

import glob

def get_agent_avatars():
    # Get the default avatar list
    default_avatars = [
        'team-5.jpg', 'team-4.jpg', 'team-3.jpg', 'team-2.jpg', 'kal-visuals-square.jpg',
        'team-1.jpg', 'marie.jpg', 'ivana-squares.jpg', 'ivana-square.jpg'
    ]
    
    # Get additional avatars from static directory
    static_path = os.path.join('static', 'assets', 'img', 'agent-avatar*')
    additional_avatars = [os.path.basename(f) for f in glob.glob(static_path)]
    
    return default_avatars + additional_avatars

AVATAR_CHOICES = get_agent_avatars()

def random_avatar():
    return random.choice(AVATAR_CHOICES)

def get_available_tools():
    tools_dir = os.path.join('apps', 'agents', 'tools')
    available_tools = []

    for root, dirs, files in os.walk(tools_dir):
        for dir_name in dirs:
            if not dir_name.startswith('__'):  # Exclude directories like __pycache__
                tool_path = os.path.relpath(os.path.join(root, dir_name), tools_dir)
                available_tools.append(tool_path.replace(os.path.sep, '.'))

    return available_tools

def default_embedder():
    return {'provider': 'openai'}

def user_directory_path(instance, filename):
    return f'user_{instance.crew_execution.user.id}/{filename}'

class Tool(models.Model):
    tool_class = models.CharField(max_length=255)
    tool_subclass = models.CharField(max_length=255)
    name = models.CharField(max_length=255)
    description = models.TextField(blank=True)
    module_path = models.CharField(max_length=255)

    def __str__(self):
        return self.name

    def save(self, *args, **kwargs):
        if not self.module_path:
            self.module_path = f"apps.agents.tools.{self.tool_class}"
        
        try:
            tool = load_tool(self)
            if tool:
                self.name = getattr(tool, 'name', self.tool_subclass)
                self.description = get_tool_description(tool.__class__)
            else:
                raise ValueError(f"Failed to load tool: {self.module_path}.{self.tool_subclass}. Check the logs for more details.")
        except Exception as e:
            logger.error(f"Error in Tool.save: {str(e)}")
            raise ValidationError(f"Error loading tool: {str(e)}")

        super().save(*args, **kwargs)

class ToolRun(models.Model):
    """Model to track tool executions"""
    TOOL_RUN_STATUS = (
        ('pending', 'Pending'),
        ('running', 'Running'),
        ('completed', 'Completed'),
        ('failed', 'Failed'),
    )
    
    tool = models.ForeignKey(Tool, on_delete=models.CASCADE)
    conversation = models.ForeignKey('Conversation', on_delete=models.CASCADE, related_name='tool_runs', null=True, blank=True)
    message = models.ForeignKey('ChatMessage', on_delete=models.CASCADE, related_name='tool_runs', null=True, blank=True)
    status = models.CharField(max_length=20, choices=TOOL_RUN_STATUS, default='pending')
    inputs = models.JSONField()
    result = models.JSONField(null=True, blank=True)
    error = models.TextField(null=True, blank=True)
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)
    is_deleted = models.BooleanField(default=False)
    
    class Meta:
        ordering = ['-created_at']

    def __str__(self):
        return f"{self.tool.name} - {self.status} ({self.created_at})"

class Agent(models.Model):
    name = models.CharField(max_length=255)
    role = models.CharField(max_length=100)
    goal = models.TextField()
    backstory = models.TextField()
    llm = models.CharField(max_length=100, default=settings.GENERAL_MODEL)
    tools = models.ManyToManyField(Tool, blank=True)
    function_calling_llm = models.CharField(max_length=100, null=True, blank=True, default=settings.GENERAL_MODEL)
    max_iter = models.IntegerField(default=25)
    max_rpm = models.IntegerField(null=True, blank=True)
    max_execution_time = models.IntegerField(null=True, blank=True)
    verbose = models.BooleanField(default=False)
    allow_delegation = models.BooleanField(default=False)
    step_callback = models.CharField(max_length=255, null=True, blank=True)
    cache = models.BooleanField(default=True)
    system_template = models.TextField(null=True, blank=True)
    prompt_template = models.TextField(null=True, blank=True)
    response_template = models.TextField(null=True, blank=True)
    allow_code_execution = models.BooleanField(default=False)
    max_retry_limit = models.IntegerField(default=2)
    use_system_prompt = models.BooleanField(default=True)
    respect_context_window = models.BooleanField(default=True)
    avatar = models.CharField(max_length=100, default=random_avatar)

    def __str__(self):
        return self.name

    def clean(self):
        super().clean()
        available_models = get_models()
        if self.llm not in available_models:
            raise ValidationError({'llm': f"Selected LLM '{self.llm}' is not available. Please choose from: {', '.join(available_models)}"})

    def get_tool_settings(self, tool):
        """Get settings for a specific tool."""
        return self.tool_settings.filter(tool=tool).first()

    def get_forced_output_tools(self):
        """Get all tools that have force_output_as_result=True."""
        return self.tools.filter(
            id__in=self.tool_settings.filter(
                force_output_as_result=True
            ).values_list('tool_id', flat=True)
        )

    def has_force_output_enabled(self, tool):
        """Check if force output is enabled for a specific tool."""
        tool_setting = self.tool_settings.filter(tool=tool).first()
        return tool_setting.force_output_as_result if tool_setting else False

class Task(models.Model):
    description = models.TextField()
    agent = models.ForeignKey(Agent, on_delete=models.SET_NULL, null=True, blank=True)
    expected_output = models.TextField()
    tools = models.ManyToManyField(Tool, blank=True)
    async_execution = models.BooleanField(default=False)
    context = models.ManyToManyField('self', symmetrical=False, blank=True)
    config = models.JSONField(null=True, blank=True)
    output_json = models.CharField(max_length=255, null=True, blank=True)
    output_pydantic = models.CharField(max_length=255, null=True, blank=True)
    output_file = models.CharField(max_length=255, null=True, blank=True)
    output = models.TextField(null=True, blank=True)
    callback = models.CharField(max_length=255, null=True, blank=True)
    human_input = models.BooleanField(default=False)
    converter_cls = models.CharField(max_length=255, null=True, blank=True)

    def __str__(self):
        return self.description[:50]

    def save_output_file(self, content):
        if self.output_file:
            file_name = os.path.basename(self.output_file)
        else:
            file_name = f"task_{self.id}_output.txt"
        
        # Generate the relative path using your existing user_directory_path function
        file_path = user_directory_path(self, file_name)
        
        try:
            # Save the content using default_storage
            default_storage.save(file_path, ContentFile(content))
            
            # Update the model's output_file field
            self.output_file = file_path
            self.save()
        except Exception as e:
            logger.error(f"Error saving output file for task {self.id}: {e}")
            raise

class Crew(models.Model):
    name = models.CharField(max_length=100)
    agents = models.ManyToManyField(Agent)
    tasks = models.ManyToManyField(Task, through='CrewTask')
    process = models.CharField(max_length=20, choices=[('sequential', 'Sequential'), ('hierarchical', 'Hierarchical')], default='sequential')
    verbose = models.BooleanField(default=False)
    manager_llm = models.CharField(max_length=100, null=True, blank=True, default=settings.GENERAL_MODEL)
    function_calling_llm = models.CharField(max_length=100, null=True, blank=True, default=settings.GENERAL_MODEL)
    config = models.JSONField(null=True, blank=True)
    max_rpm = models.IntegerField(null=True, blank=True)
    language = models.CharField(max_length=50, default='English')
    language_file = models.CharField(max_length=255, null=True, blank=True)
    memory = models.BooleanField(default=False)
    cache = models.BooleanField(default=True)
    embedder = models.JSONField(default=default_embedder)
    full_output = models.BooleanField(default=False)
    share_crew = models.BooleanField(default=False)
    output_log_file = models.CharField(max_length=255, null=True, blank=True)
    manager_agent = models.ForeignKey(Agent, on_delete=models.SET_NULL, null=True, blank=True, related_name='managed_crews')
    manager_callbacks = models.JSONField(null=True, blank=True)
    prompt_file = models.CharField(max_length=255, null=True, blank=True)
    planning = models.BooleanField(default=False)
    planning_llm = models.CharField(max_length=100, null=True, blank=True, default=settings.GENERAL_MODEL)
    input_variables = models.JSONField(null=True, blank=True, default=list)

    def __str__(self):
        return self.name

class CrewExecution(models.Model):
    """Represents a single execution of a crew"""
    crew = models.ForeignKey(Crew, on_delete=models.CASCADE)
    user = models.ForeignKey(User, on_delete=models.CASCADE)
    client = models.ForeignKey('seo_manager.Client', on_delete=models.CASCADE, null=True)
    status = models.CharField(max_length=50, default='PENDING')
    task_id = models.CharField(max_length=50, null=True)
    inputs = models.JSONField(null=True, blank=True)
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)
    conversation = models.ForeignKey('Conversation', on_delete=models.SET_NULL, null=True, related_name='crew_executions')
    crew_output = models.OneToOneField('CrewOutput', on_delete=models.SET_NULL, null=True, blank=True, related_name='crew_execution')
    human_input_request = models.JSONField(null=True, blank=True)
    human_input_response = models.JSONField(null=True, blank=True)
    error_message = models.TextField(blank=True, null=True)
    chat_enabled = models.BooleanField(default=False)

    def get_conversation_history(self):
        """Get formatted conversation history including messages and tool results"""
        if not self.conversation:
            return []
            
        messages = ChatMessage.objects.filter(
            conversation=self.conversation,
            is_deleted=False
        ).order_by('timestamp')
        
        # Use the formatted_message property for each message
        return [msg.formatted_message for msg in messages]

    def __str__(self):
        return f"{self.crew.name} - {self.status} ({self.created_at})"

    def save_task_output_file(self, task, content):
        task.save_output_file(content)

class CrewMessage(models.Model):
    execution = models.ForeignKey(CrewExecution, on_delete=models.CASCADE, related_name='messages')
    content = models.TextField()
    timestamp = models.DateTimeField(auto_now_add=True)
    agent = models.CharField(max_length=255, null=True, blank=True)
    crewai_task_id = models.IntegerField(null=True, blank=True)  # For kanban board placement

    def __str__(self):
        return f"{self.timestamp}: {self.content[:50]}"

class CrewOutput(models.Model):
    raw = models.TextField()
    pydantic = models.JSONField(null=True, blank=True)
    json_dict = models.JSONField(null=True, blank=True)
    token_usage = models.JSONField(null=True, blank=True)

    @property
    def json(self):
        return json.dumps(self.json_dict) if self.json_dict else None

    def to_dict(self):
        return self.json_dict or (self.pydantic.dict() if self.pydantic else None) or {}

    def __str__(self):
        if self.pydantic:
            return str(self.pydantic)
        elif self.json_dict:
            return json.dumps(self.json_dict)
        else:
            return self.raw

    def save(self, *args, **kwargs):
        # Convert UsageMetrics to a dictionary if it's not already
        if self.token_usage and hasattr(self.token_usage, 'dict'):
            self.token_usage = self.token_usage.dict()
        super().save(*args, **kwargs)

class CrewTask(models.Model):
    crew = models.ForeignKey(Crew, on_delete=models.CASCADE, related_name='crew_tasks')
    task = models.ForeignKey(Task, on_delete=models.CASCADE)
    order = models.PositiveIntegerField(default=0)

    class Meta:
        ordering = ['order']
        unique_together = ('crew', 'task')

    def __str__(self):
        return f"{self.crew.name} - {self.task.description} (Order: {self.order})"

class AgentToolSettings(models.Model):
    agent = models.ForeignKey('Agent', on_delete=models.CASCADE, related_name='tool_settings')
    tool = models.ForeignKey('Tool', on_delete=models.CASCADE)
    force_output_as_result = models.BooleanField(default=False)

    class Meta:
        unique_together = ('agent', 'tool')

class SlackChannelClientMapping(models.Model):
    """Map Slack channels to clients for automatic client identification"""
    channel_id = models.CharField(max_length=32)
    team_id = models.CharField(max_length=32)
    client = models.ForeignKey('seo_manager.Client', on_delete=models.CASCADE)
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)

    class Meta:
        unique_together = ('channel_id', 'team_id')
        db_table = 'slack_channel_client_mappings'

    def __str__(self):
        return f"Slack Channel {self.channel_id} -> Client {self.client_id}"

class ExecutionStage(models.Model):
    STAGE_TYPES = [
        ('task_start', 'Task Start'),
        ('thinking', 'Thinking'),
        ('tool_usage', 'Tool Usage'),
        ('tool_results', 'Tool Results'),
        ('human_input', 'Human Input'),
        ('completion', 'Completion')
    ]
    
    STATUS_CHOICES = [
        ('pending', 'Pending'),
        ('in_progress', 'In Progress'),
        ('completed', 'Completed'),
        ('failed', 'Failed')
    ]
    
    execution = models.ForeignKey(CrewExecution, on_delete=models.CASCADE, related_name='stages')
    stage_type = models.CharField(max_length=20, choices=STAGE_TYPES)
    title = models.CharField(max_length=200)
    content = models.TextField()
    status = models.CharField(max_length=20, choices=STATUS_CHOICES, default='pending')
    agent = models.ForeignKey(Agent, on_delete=models.SET_NULL, null=True, blank=True)
    metadata = models.JSONField(default=dict)
    crewai_task_id = models.IntegerField(null=True, blank=True)  # For kanban board placement
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)
    
    class Meta:
        ordering = ['created_at']
        verbose_name = 'Execution Stage'
        verbose_name_plural = 'Execution Stages'
    
    def __str__(self):
        return f"{self.get_stage_type_display()} - {self.title}"

class Conversation(models.Model):
    session_id = models.UUIDField(unique=True)
    user = models.ForeignKey(get_user_model(), on_delete=models.CASCADE)
    agent = models.ForeignKey('Agent', on_delete=models.SET_NULL, null=True)
    client = models.ForeignKey('seo_manager.Client', on_delete=models.SET_NULL, null=True)
    participant_type = models.CharField(
        max_length=50, 
        choices=[
            ('agent', 'Agent Chat'),
            ('crew', 'Crew Chat')
        ],
        default='agent'
    )
    crew_execution = models.OneToOneField(
        'CrewExecution',
        on_delete=models.SET_NULL,
        null=True,
        blank=True,
        related_name='chat_conversation'
    )
    title = models.CharField(max_length=255)
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)
    is_active = models.BooleanField(default=True)

    class Meta:
        ordering = ['-updated_at']

    def __str__(self):
        return f"{self.title} ({self.session_id})"

    async def get_recent_messages(self, limit=10):
        """Get recent messages for this conversation"""
        return await self.chatmessage_set.filter(
            is_deleted=False
        ).order_by('-timestamp')[:limit]

    async def get_task_outputs(self, limit=5):
        """Get recent task outputs from crew execution"""
        if self.crew_execution and self.crew_execution.crew_output:
            return self.crew_execution.crew_output.to_dict()
        return None

class CrewChatSession(models.Model):
    conversation = models.OneToOneField(
        'Conversation',
        on_delete=models.CASCADE,
        related_name='crew_chat_session'
    )
    crew_execution = models.OneToOneField(
        'CrewExecution',
        on_delete=models.CASCADE,
        related_name='chat_session'
    )
    last_activity = models.DateTimeField(auto_now=True)
    status = models.CharField(
        max_length=50,
        choices=[
            ('active', 'Active'),
            ('paused', 'Paused'),
            ('completed', 'Completed'),
            ('cleaned', 'Cleaned')
        ],
        default='active'
    )
    context_data = models.JSONField(default=dict)

    class Meta:
        indexes = [
            models.Index(fields=['last_activity', 'status'])
        ]

    def __str__(self):
        return f"Crew Chat Session - {self.conversation.title}"

    async def get_full_context(self):
        """Get full context including messages, task outputs, and context data"""
        messages = await self.conversation.get_recent_messages()
        task_outputs = await self.conversation.get_task_outputs()
        
        return {
            'messages': messages,
            'task_outputs': task_outputs,
            'context_data': self.context_data
        }

    def update_context(self, key, value):
        """Update a specific context value"""
        if self.context_data is None:
            self.context_data = {}
        self.context_data[key] = value
        self.save(update_fields=['context_data', 'last_activity'])

class ChatMessage(models.Model):
    """Model for storing chat messages."""
    conversation = models.ForeignKey(Conversation, on_delete=models.CASCADE)
    session_id = models.CharField(max_length=255)
    agent = models.ForeignKey(Agent, on_delete=models.SET_NULL, null=True)
    user = models.ForeignKey(User, on_delete=models.CASCADE)
    content = models.TextField()
    is_agent = models.BooleanField(default=False)
    is_deleted = models.BooleanField(default=False)
    timestamp = models.DateTimeField(auto_now_add=True)
    model = models.CharField(max_length=255, default='unknown')
    task_id = models.IntegerField(null=True, blank=True)
    
    @property
    def formatted_message(self):
        """Get message with associated tool results"""
        base = {
            'type': 'agent_message' if self.is_agent else 'user_message',
            'content': self.content,
            'timestamp': self.timestamp.isoformat(),
            'model': self.model,
            'task_id': self.task_id
        }
        
        # Add tool results if any exist
        tool_runs = self.tool_runs.all()
        if tool_runs:
            base['tool_results'] = [
                {
                    'tool': run.tool.name,
                    'inputs': run.inputs,
                    'result': run.result,
                    'status': run.status
                }
                for run in tool_runs
            ]
            
        return base

    class Meta:
        ordering = ['timestamp']
        indexes = [
            models.Index(fields=['conversation', 'timestamp']),
            models.Index(fields=['session_id']),
            models.Index(fields=['is_deleted']),  # Add index for is_deleted field
        ]

    def __str__(self):
        return f"{self.timestamp}: {'Agent' if self.is_agent else 'User'} - {self.content[:50]}..."

class TokenUsage(models.Model):
    conversation = models.ForeignKey(Conversation, on_delete=models.CASCADE, related_name='token_usage')
    message = models.ForeignKey('ChatMessage', on_delete=models.SET_NULL, null=True, blank=True)
    tool_run = models.ForeignKey('ToolRun', on_delete=models.SET_NULL, null=True, blank=True)
    prompt_tokens = models.IntegerField(default=0)
    completion_tokens = models.IntegerField(default=0)
    total_tokens = models.IntegerField(default=0)
    model = models.CharField(max_length=100)
    timestamp = models.DateTimeField(auto_now_add=True)
    metadata = models.JSONField(default=dict, blank=True)  # Changed from JSONField to models.JSONField

    class Meta:
        indexes = [
            models.Index(fields=['conversation', 'timestamp']),
        ]

    def __str__(self):
        return f"{self.conversation_id} - {self.total_tokens} tokens"

class UserSlackIntegration(models.Model):
    """Store Slack integration details for users"""
    user = models.OneToOneField(get_user_model(), on_delete=models.CASCADE)
    access_token = models.CharField(max_length=255)
    team_id = models.CharField(max_length=32)
    team_name = models.CharField(max_length=255)
    is_active = models.BooleanField(default=True)
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)

    class Meta:
        db_table = 'user_slack_integrations'

    def __str__(self):
        return f"{self.user.username} - {self.team_name}"

class Flow(models.Model):
    name = models.CharField(max_length=100)
    description = models.TextField(blank=True)
    crews = models.ManyToManyField('Crew', through='FlowCrew')
    state_schema = models.JSONField(help_text="JSON schema for flow state validation")
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)

    def __str__(self):
        return self.name

class FlowCrew(models.Model):
    flow = models.ForeignKey(Flow, on_delete=models.CASCADE)
    crew = models.ForeignKey('Crew', on_delete=models.CASCADE)
    order = models.PositiveIntegerField(default=0)
    trigger_condition = models.TextField(blank=True, 
        help_text="Python condition for triggering this crew")

    class Meta:
        ordering = ['order']

class FlowExecution(models.Model):
    flow = models.ForeignKey(Flow, on_delete=models.CASCADE)
    state = models.JSONField(default=dict)
    status = models.CharField(max_length=20, default='pending', 
        choices=(
            ('pending', 'Pending'),
            ('running', 'Running'),
            ('completed', 'Completed'),
            ('failed', 'Failed')
        ))
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)

================
File: README.md
================
# Crew Execution and Human Input

This document provides an overview of the crew execution process and the human input feature in the CrewAI platform.

## Crew Execution

Crews are executed using the following process:

1. A user initiates a crew execution from the crew detail page.
2. The `execute_crew` Celery task is triggered, which creates a `CrewExecution` instance.
3. The crew is executed using the CrewAI library.
4. If the execution completes successfully, the results are stored in the `CrewExecution` instance.
5. If an error occurs, the execution is marked as failed, and an error message is logged.

## Human Input Feature

The human input feature allows crews to request input from users during execution. Here's how it works:

1. If a task in the crew requires human input, it raises a `HumanInputRequired` exception.
2. The `execute_crew` task catches this exception and updates the `CrewExecution` status to "WAITING_FOR_HUMAN_INPUT".
3. The execution detail page displays the human input request to the user.
4. The user submits their input through a form on the execution detail page.
5. The `resume_crew_execution` task is triggered, which continues the execution with the provided human input.

### Implementation Details

- The `CrewExecution` model includes fields for `human_input_request` and `human_input_response`.
- The `execution_detail.html` template includes a form for submitting human input when required.
- The `tasks.py` file contains the logic for handling human input requests and resuming execution.

## Testing

Unit tests for crew execution and human input handling can be found in `tests.py`. These tests cover:

- Basic crew execution
- Handling of human input requests
- Resuming execution after human input
- Creation of crew messages

To run the tests, use the following command:

```
python manage.py test apps.agents
```

## Future Improvements

- Implement a notification system to alert users when their input is required.
- Add more comprehensive error handling and recovery mechanisms.
- Enhance the user interface for a more intuitive human input experience.

For any questions or issues, please contact the development team.

================
File: tasks.py
================
from celery import shared_task
import asyncio
import logging
from .utils import load_tool
from django.shortcuts import get_object_or_404
from .models import Tool, ToolRun
import inspect
import json
import traceback
from apps.agents.tools.wordpress.meta_tool import WordPressMetaTool

logger = logging.getLogger(__name__)

@shared_task(bind=True)
def run_tool(self, tool_id: int, inputs: dict):
    """Generic Celery task to run any tool"""
    try:
        # Load the tool
        tool = get_object_or_404(Tool, id=tool_id)
        tool_instance = load_tool(tool)
        
        if tool_instance is None:
            raise ValueError('Failed to load tool')

        # Create a tool run record
        tool_run = ToolRun.objects.create(
            tool=tool,
            status='running',
            inputs=inputs
        )
        
        try:
            # Process inputs if tool has args_schema
            if hasattr(tool_instance, 'args_schema'):
                processed_inputs = {}
                for key, value in inputs.items():
                    if value != '':
                        try:
                            processed_inputs[key] = json.loads(value)
                        except json.JSONDecodeError:
                            processed_inputs[key] = value
                            
                validated_inputs = tool_instance.args_schema(**processed_inputs)
                inputs = validated_inputs.dict()
            
            # Run the tool
            if inspect.iscoroutinefunction(tool_instance._run):
                # Create event loop for async tools
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                try:
                    result = loop.run_until_complete(tool_instance._run(**inputs))
                finally:
                    loop.close()
            else:
                # Run sync tools directly
                result = tool_instance._run(**inputs)
            
            # Update tool run record with success
            tool_run.status = 'completed'
            tool_run.result = result
            tool_run.save()
            
            return {
                'status': 'completed',
                'result': result,
                'tool_run_id': tool_run.id
            }
            
        except Exception as e:
            # Update tool run record with error
            tool_run.status = 'failed'
            tool_run.error = str(e)
            tool_run.save()
            raise
            
    except Exception as e:
        logger.error(f"Error running tool: {str(e)}\n{traceback.format_exc()}")
        return {
            'status': 'failed',
            'error': str(e)
        }

@shared_task
def update_wordpress_meta(**kwargs):
    tool = WordPressMetaTool()
    return tool._run(**kwargs)

================
File: tools.py
================


================
File: urls.py
================
from django.urls import path, re_path
from . import views
from . import views_agents
from . import views_tasks
from . import views_tools
from . import views_crews
from . import views_kanban
from . import views_chat
from .views_chat import ChatView


app_name = 'agents'

urlpatterns = [
    path('', views.crewai_home, name='crewai_home'),
    path('crews/', views.crew_list, name='crew_list'),
    path('crew/<int:crew_id>/', views.crew_detail, name='crew_detail'),
    path('crew/<int:crew_id>/kanban/', views_kanban.crew_kanban, name='crew_kanban'),
    path('crew/<int:crew_id>/start-execution/', views_kanban.start_execution, name='start_execution'),
    path('crew/<int:crew_id>/active-executions/', views_kanban.get_active_executions, name='get_active_executions'),
    path('crew/execution/<int:execution_id>/input/', views_kanban.submit_human_input, name='submit_human_input'),
    path('executions/', views.execution_list, name='execution_list'),
    path('execution/<int:execution_id>/', views_kanban.execution_detail, name='execution_detail'),
    path('execution/<int:execution_id>/status/', views_kanban.get_active_executions, name='execution_status'),
    path('execution/<int:execution_id>/submit_human_input/', views.submit_human_input, name='submit_human_input'),
    path('execution/<int:execution_id>/cancel/', views_kanban.cancel_execution, name='cancel_execution'),
    path('execution/<int:execution_id>/cancel/', views_kanban.cancel_execution, name='cancel_execution'),
    
    # Admin views
    path('manage/agents/', views_agents.manage_agents, name='manage_agents'),
    path('manage/agents/add/', views_agents.add_agent, name='add_agent'),
    path('manage/agents/edit/<int:agent_id>/', views_agents.edit_agent, name='edit_agent'),
    path('manage/agents/delete/<int:agent_id>/', views_agents.delete_agent, name='delete_agent'),
    path('manage/agents/duplicate/<int:agent_id>/', views_agents.duplicate_agent, name='duplicate_agent'),
    
    path('manage/tasks/', views_tasks.manage_tasks, name='manage_tasks'),
    path('manage/tasks/add/', views_tasks.add_task, name='add_task'),
    path('manage/tasks/edit/<int:task_id>/', views_tasks.edit_task, name='edit_task'),
    path('manage/tasks/delete/<int:task_id>/', views_tasks.delete_task, name='delete_task'),
    path('manage/tasks/duplicate/<int:task_id>/', views_tasks.duplicate_task, name='duplicate_task'),
    
    path('manage/tools/', views_tools.manage_tools, name='manage_tools'),
    path('manage/tools/add/', views_tools.add_tool, name='add_tool'),
    path('manage/tools/edit/<int:tool_id>/', views_tools.edit_tool, name='edit_tool'),
    path('manage/tools/delete/<int:tool_id>/', views_tools.delete_tool, name='delete_tool'),
    path('tool-schema/<int:tool_id>/', views_tools.get_tool_schema, name='get_tool_schema'),
    path('test-tool/<int:tool_id>/', views_tools.test_tool, name='test_tool'),
    path('tool-status/<str:task_id>/', views_tools.get_tool_status, name='get_tool_status'),
    path('get_tool_info/', views_tools.get_tool_info, name='get_tool_info'),
    path('get_tool_schema/<int:tool_id>/', views_tools.get_tool_schema, name='get_tool_schema'),
    path('test_tool/<int:tool_id>/', views_tools.test_tool, name='test_tool'),  # Django 3.1+ automatically handles async views
    path('manage/crews/', views_crews.manage_crews, name='manage_crews'),
    path('manage/crews/add/', views_crews.crew_create_or_update, name='add_crew'),
    path('manage/crews/edit/<int:crew_id>/', views_crews.crew_create_or_update, name='edit_crew'),
    path('manage/crews/delete/<int:crew_id>/', views_crews.delete_crew, name='delete_crew'),
    path('manage/crews/duplicate/<int:crew_id>/', views_crews.duplicate_crew, name='duplicate_crew'),
    path('manage/crews/update_agents/<int:crew_id>/', views_crews.update_crew_agents, name='update_crew_agents'),
    
    path('manage/agents/card-view/', views_agents.manage_agents_card_view, name='manage_agents_card_view'),
    path('manage/crews/card-view/', views_crews.manage_crews_card_view, name='manage_crews_card_view'),
    
    path('connection-test/', views.connection_test, name='connection_test'),
    path('chat/', ChatView.as_view(), name='chat'),
    path('chat/<uuid:session_id>/', ChatView.as_view(), name='chat'),
    path('chat/<uuid:session_id>/delete/', views_chat.delete_conversation, name='delete_conversation'),
    
    # Slack OAuth
    path('slack/oauth/start/', views.slack_oauth_start, name='slack_oauth_start'),
    path('slack/oauth/callback/', views.slack_oauth_callback, name='slack_oauth_callback'),
]

================
File: utils.py
================
import os
import importlib
from crewai.tools import BaseTool as CrewAIBaseTool
from langchain.tools import BaseTool as LangChainBaseTool
import logging
import crewai_tools
from typing import Optional, Type
from django.core.cache import cache
from urllib.parse import urlparse, parse_qs, urlencode, urlunparse
import re
from pydantic import BaseModel
from crewai.tools import BaseTool

logger = logging.getLogger(__name__)

def get_available_tools():
    tools_dir = os.path.join('apps', 'agents', 'tools')
    available_tools = []

    for root, dirs, files in os.walk(tools_dir):
        for item in dirs + files:
            if item.endswith('.py') and not item.startswith('__'):
                rel_path = os.path.relpath(os.path.join(root, item), tools_dir)
                module_path = os.path.splitext(rel_path)[0].replace(os.path.sep, '.')
                available_tools.append(module_path)

    return available_tools

def get_tool_classes(tool_path):
    module_path = f"apps.agents.tools.{tool_path}"
    if module_path.endswith('.py'):
        module_path = module_path[:-3]
    try:
        module = importlib.import_module(module_path)
    except ImportError as e:
        logger.error(f"Failed to import module {module_path}: {e}")
        return []
    
    tool_classes = []
    for name, obj in module.__dict__.items():
        if isinstance(obj, type) and name.endswith('Tool'):
            try:
                if issubclass(obj, (CrewAIBaseTool, LangChainBaseTool)) or (hasattr(obj, '_run') and callable(getattr(obj, '_run'))):
                    if not any(issubclass(other, obj) and other != obj for other in module.__dict__.values() if isinstance(other, type)):
                        tool_classes.append(obj)
            except TypeError:
                # This can happen if obj is not a class or doesn't inherit from the expected base classes
                logger.warning(f"Skipping {name} as it's not a valid tool class")
    
    logger.debug(f"Found tool classes for {tool_path}: {[cls.__name__ for cls in tool_classes]}")
    return tool_classes

def get_tool_description(tool_class_obj):
    logger.debug(f"Attempting to get description for {tool_class_obj}")

    if hasattr(tool_class_obj, 'description'):
        description = getattr(tool_class_obj, 'description')
        if isinstance(description, str):
            logger.debug(f"Found description class attribute: {description}")
            return description

    if hasattr(tool_class_obj, 'name'):
        name = getattr(tool_class_obj, 'name')
        if isinstance(name, str):
            logger.debug(f"Found name class attribute: {name}")
            return name

    if hasattr(tool_class_obj, '__annotations__') and 'description' in tool_class_obj.__annotations__:
        description = tool_class_obj.__annotations__['description']
        if isinstance(description, str):
            logger.debug(f"Found description in class annotations: {description}")
            return description

    if hasattr(tool_class_obj, 'model_fields') and 'description' in tool_class_obj.model_fields:
        description = tool_class_obj.model_fields['description'].default
        if isinstance(description, str):
            #logger.debug(f"Found description in model_fields: {description}")
            return description

    if tool_class_obj.__doc__:
        docstring = tool_class_obj.__doc__.strip()
        logger.debug(f"Found docstring: {docstring}")
        return docstring

    #  Corrected schema handling: Access the description directly if it exists.
    if hasattr(tool_class_obj, 'schema') and callable(tool_class_obj.schema):
        try:
            schema = tool_class_obj.schema()
            if isinstance(schema, dict) and 'description' in schema and isinstance(schema['description'], str):
                 logger.debug(f"Found description in schema: {schema['description']}")
                 return schema['description']
        except Exception as e:
            logger.warning(f"Error getting schema for {tool_class_obj.__name__}: {str(e)}")


    default_description = f"A tool of type {tool_class_obj.__name__}"
    logger.debug(f"Using default description: {default_description}")
    return default_description

def get_tool_class_obj(tool_class: str, tool_subclass: str = None) -> Type[BaseTool]:
    """
    Get the tool class object from the tool class path.
    
    Args:
        tool_class: Dot-separated path to the tool class
        tool_subclass: Optional subclass name if the module has multiple tools
        
    Returns:
        Type[BaseTool]: The tool class (not instance)
    """
    logger.debug(f"Getting tool class for {tool_class}.{tool_subclass}")
    
    # Get all tool classes from the module
    tool_classes = get_tool_classes(tool_class)
    
    if not tool_classes:
        raise ValueError(f"No tool classes found in {tool_class}")
    
    # If subclass specified, find it in the list
    if tool_subclass:
        for cls in tool_classes:
            if cls.__name__ == tool_subclass:
                logger.debug(f"Found tool class: {cls}")
                return cls
        raise ValueError(f"Tool subclass {tool_subclass} not found in {tool_class}")
    
    # If no subclass specified, return the first tool class
    logger.debug(f"Found tool class: {tool_classes[0]}")
    return tool_classes[0]

def load_tool(tool_model) -> Optional[CrewAIBaseTool]:
    
    try:
        # Check if it's a pre-built CrewAI tool
        if hasattr(crewai_tools, tool_model.tool_class):
            logger.info(f"Loading pre-built CrewAI tool: {tool_model.tool_class}")
            tool_class = getattr(crewai_tools, tool_model.tool_class)
            return tool_class()

        # If not, try to import a custom tool
        full_module_path = f"apps.agents.tools.{tool_model.tool_class}"
        logger.info(f"Attempting to import custom tool module: {full_module_path}")
        module = importlib.import_module(full_module_path)
        tool_class = getattr(module, tool_model.tool_subclass)
        
        if issubclass(tool_class, CrewAIBaseTool):
            logger.info(f"Loaded custom tool: {tool_model.tool_subclass}")
            return tool_class()
        elif issubclass(tool_class, LangChainBaseTool):
            logger.info(f"Loaded and wrapped LangChain tool: {tool_model.tool_subclass}")
            # Wrap LangChain tool in CrewAI compatible class
            class WrappedLangChainTool(CrewAIBaseTool):
                name = tool_class.name
                description = get_tool_description(tool_class)

                def _run(self, *args, **kwargs):
                    return tool_class()(*args, **kwargs)

            return WrappedLangChainTool()
        else:
            raise ValueError(f"Unsupported tool class: {tool_class}")

    except ImportError as e:
        logger.error(f"Error importing tool module {full_module_path}: {str(e)}")
    except AttributeError as e:
        logger.error(f"Error finding tool class {tool_model.tool_subclass} in module {full_module_path}: {str(e)}")
    except Exception as e:
        logger.error(f"Unexpected error loading tool {full_module_path}.{tool_model.tool_subclass}: {str(e)}")
    
    return None

def get_tool_info(tool_model):
    
    full_module_path = f"apps.agents.tools.{tool_model.tool_class}"
    
    return {
        'module_path': full_module_path,
        'class_name': tool_model.tool_subclass
    }

class URLDeduplicator:
    def __init__(self):
        # Common CMS page identifiers
        self.cms_patterns = {
            'wordpress': [
                r'(?:page_id|p|post)=\d+',
                r'\d{4}/\d{2}/\d{2}',  # Date-based permalinks
                r'(?:category|tag)/[\w-]+',
            ],
            'woocommerce': [
                r'product=\d+',
                r'product-category/[\w-]+',
            ],
        }
        
        # Patterns that indicate filter/sort URLs
        self.filter_patterns = [
            # E-commerce filters
            r'product_type=\d+',
            r'prefilter=',
            r'filter\[.*?\]=',
            r'sort(?:by)?=',
            r'order=',
            r'view=',
            r'display=',
            # Pagination
            r'page=\d+',
            r'per_page=\d+',
            # Common parameters
            r'utm_.*?=',
        ]
        
        # Initialize sets for tracking seen URLs and content hashes
        self._seen_urls = set()
        self._seen_hashes = set()
        self._content_hashes = {}
        
    def should_process_url(self, url: str) -> bool:
        parsed = urlparse(url)
        query_params = parse_qs(parsed.query)
        
        # First check if it's a CMS page
        if self._is_cms_page(parsed.query):
            return True
            
        # For filter URLs, check both the filtered URL and the base URL
        if self._is_filter_url(parsed.query):
            # Create base URL without query parameters
            base_url = urlunparse((
                parsed.scheme,
                parsed.netloc,
                parsed.path,
                '',
                '',
                ''
            ))
            # Add base URL to seen URLs to avoid duplicate processing
            normalized_base = self._normalize_url(base_url)
            if normalized_base not in self._seen_urls:
                self._seen_urls.add(normalized_base)
                return True
            return False
            
        # If unclear, normalize and check if we've seen it
        normalized = self._normalize_url(url)
        return normalized not in self._seen_urls
        
    def _is_cms_page(self, query: str) -> bool:
        return any(
            re.search(pattern, query)
            for patterns in self.cms_patterns.values()
            for pattern in patterns
        )
        
    def _is_filter_url(self, query: str) -> bool:
        return any(
            re.search(pattern, query)
            for pattern in self.filter_patterns
        )
        
    def _normalize_url(self, url: str) -> str:
        parsed = urlparse(url)
        # Keep only essential query parameters
        query_params = parse_qs(parsed.query)
        essential_params = {
            k: v for k, v in query_params.items()
            if not any(re.search(pattern, f"{k}={v[0]}") 
                      for pattern in self.filter_patterns)
        }
        query = urlencode(essential_params, doseq=True) if essential_params else ''
        
        return urlunparse((
            parsed.scheme,
            parsed.netloc.lower(),
            parsed.path.rstrip('/'),
            '',
            query,
            ''
        ))
        
    def _hash_main_content(self, content: str) -> int:
        """Hash the main content, ignoring common dynamic elements"""
        # TODO: Implement content cleaning/normalization if needed
        return hash(content)
        
    def fallback_content_check(self, url: str, content: str) -> bool:
        """Use content hash as fallback for ambiguous cases"""
        if url not in self._content_hashes:
            content_hash = self._hash_main_content(content)
            if content_hash in self._seen_hashes:
                return False
            self._content_hashes[url] = content_hash
            self._seen_hashes.add(content_hash)
        return True
        return True

================
File: views_agents.py
================
import logging
from django.shortcuts import render, redirect, get_object_or_404
from django.contrib.auth.decorators import login_required, user_passes_test
from django.contrib import messages
from .models import Agent, AgentToolSettings
from .forms import AgentForm
import traceback
from django.conf import settings

logger = logging.getLogger(__name__)

def is_admin(user):
    return user.is_staff or user.is_superuser

@login_required
@user_passes_test(is_admin)
def manage_agents(request):
    agents = Agent.objects.all().order_by('name')
    return render(request, 'agents/manage_agents.html', {'agents': agents})

@login_required
def manage_agents_card_view(request):
    agents = Agent.objects.prefetch_related('crew_set', 'task_set', 'tools').all().order_by('name')
    form = AgentForm()  # Now AgentForm is defined
    context = {
        'page_title': 'Manage Agents',
        'agents': agents,
        'form': form,
    }
    return render(request, 'agents/manage_agents_card_view.html', context)

@login_required
@user_passes_test(is_admin)
def add_agent(request):
    if request.method == 'POST':
        form = AgentForm(request.POST)
        if form.is_valid():
            try:
                agent = form.save(commit=False)
                agent.avatar = form.cleaned_data['avatar']
                agent.save()
                
                # Save many-to-many fields
                form.save_m2m()
                
                # Handle tool settings
                for tool in agent.tools.all():
                    force_output = request.POST.get(f'force_tool_output_{tool.id}') == 'on'
                    AgentToolSettings.objects.create(
                        agent=agent,
                        tool=tool,
                        force_output_as_result=force_output
                    )
                
                messages.success(request, 'Agent added successfully.')
                return redirect('agents:manage_agents')
            except Exception as e:
                messages.error(request, f"Error adding agent: {str(e)}")
    else:
        form = AgentForm()

    # Add page_title to the context
    context = {
        'form': form,
        'page_title': 'Add Agent',
    }
    return render(request, 'agents/agent_form.html', context)

@login_required
@user_passes_test(is_admin)
def edit_agent(request, agent_id):
    agent = get_object_or_404(Agent, id=agent_id)
    if request.method == 'POST':
        form = AgentForm(request.POST, instance=agent)
        if form.is_valid():
            try:
                agent = form.save(commit=False)
                agent.avatar = form.cleaned_data['avatar']
                agent.save()
                form.save_m2m()
                
                # Update tool settings
                agent.tool_settings.all().delete()  # Remove existing settings
                for tool in agent.tools.all():
                    force_output = request.POST.get(f'force_tool_output_{tool.id}') == 'on'
                    AgentToolSettings.objects.create(
                        agent=agent,
                        tool=tool,
                        force_output_as_result=force_output
                    )
                
                messages.success(request, 'Agent updated successfully.')
                return redirect('agents:manage_agents_card_view')
            except Exception as e:
                messages.error(request, f"Error updating agent: {str(e)}")
    else:
        form = AgentForm(instance=agent)
    
    # Add page_title to the context
    context = {
        'form': form,
        'agent': agent,
        'page_title': 'Edit Agent',
    }
    
    return render(request, 'agents/agent_form.html', context)

@login_required
@user_passes_test(is_admin)
def delete_agent(request, agent_id):
    agent = get_object_or_404(Agent, id=agent_id)
    if request.method == 'POST':
        agent.delete()
        messages.success(request, 'Agent deleted successfully.')
        return redirect('agents:manage_agents')
    context = {
        'object': agent,
        'type': 'agent',
        'page_title': 'Delete Agent',
    }
    return render(request, 'agents/confirm_delete.html', context)

@login_required
@user_passes_test(is_admin)
def duplicate_agent(request, agent_id):
    original_agent = get_object_or_404(Agent, id=agent_id)
    if request.method == 'POST':
        try:
            # Get all field values except id and auto-generated fields
            field_values = {
                field.name: getattr(original_agent, field.name)
                for field in original_agent._meta.fields
                if not field.primary_key and not field.auto_created
            }
            
            # Modify the name for the copy
            field_values['name'] = f"{field_values['name']} (Copy)"
            
            # Create new agent with copied values
            new_agent = Agent.objects.create(**field_values)
            
            # Copy many-to-many relationships
            for field in original_agent._meta.many_to_many:
                getattr(new_agent, field.name).set(getattr(original_agent, field.name).all())
            
            # Copy tool settings
            for tool_setting in original_agent.tool_settings.all():
                AgentToolSettings.objects.create(
                    agent=new_agent,
                    tool=tool_setting.tool,
                    force_output_as_result=tool_setting.force_output_as_result
                )
            
            messages.success(request, 'Agent duplicated successfully.')
            
            # Check for next URL in POST data first, then GET, then fall back to referer
            next_url = request.POST.get('next') or request.GET.get('next')
            if next_url:
                return redirect(next_url)
            
            # If no next parameter, check the referer
            referer = request.META.get('HTTP_REFERER', '')
            if 'card-view' in referer:
                return redirect('agents:manage_agents_card_view')
            return redirect('agents:manage_agents')
            
        except Exception as e:
            logger.error(f"Error duplicating agent: {str(e)}\n{traceback.format_exc()}")
            messages.error(request, f"Error duplicating agent: {str(e)}")
            # Check for next URL in POST data first, then GET, then fall back to referer
            next_url = request.POST.get('next') or request.GET.get('next')
            if next_url:
                return redirect(next_url)
            
            # If no next parameter, check the referer
            referer = request.META.get('HTTP_REFERER', '')
            if 'card-view' in referer:
                return redirect('agents:manage_agents_card_view')
            return redirect('agents:manage_agents')
            
    return redirect('agents:manage_agents')

================
File: views_chat.py
================
from django.views.generic import TemplateView
from django.shortcuts import render, get_object_or_404
from django.contrib.auth.mixins import LoginRequiredMixin
from django.urls import reverse
from django.http import JsonResponse
from django.views.decorators.http import require_POST
from django.contrib.auth.decorators import login_required
from apps.agents.models import Agent, Conversation, Crew
from apps.common.utils import get_models
from django.conf import settings
from apps.seo_manager.models import Client
import logging
import uuid

logger = logging.getLogger(__name__)

@login_required
@require_POST
def delete_conversation(request, session_id):
    try:
        conversation = get_object_or_404(Conversation, session_id=session_id, user=request.user)
        conversation.delete()
        logger.info(f"Deleted conversation: {conversation.id}")
        return JsonResponse({'status': 'success'})
    except Exception as e:
        logger.error(f"Error deleting conversation: {str(e)}")
        return JsonResponse({'status': 'error', 'message': str(e)}, status=500)

class ChatView(LoginRequiredMixin, TemplateView):
    template_name = 'agents/chat.html'

    def get_context_data(self, **kwargs):
        context = super().get_context_data(**kwargs)
        try:
            # Get session_id from URL parameters or generate new one
            session_id = self.kwargs.get('session_id', str(uuid.uuid4()))
            
            # Get base queryset for conversations
            conversations_qs = Conversation.objects.filter(
                user=self.request.user,
                is_active=True
            ).select_related('agent', 'client').order_by('-updated_at')
            
            # Get current conversation if exists
            current_conversation = None
            if 'session_id' in self.kwargs:
                try:
                    current_conversation = conversations_qs.get(session_id=session_id)
                    logger.info(f"Found existing conversation: {current_conversation}")
                except Conversation.DoesNotExist:
                    logger.warning(f"No conversation found for session_id: {session_id}")
            
            # Get recent conversations (limited to 50)
            conversations = conversations_qs[:50]
            logger.info(f"Found {conversations.count()} conversations")
            
            # Get all agents
            agents = Agent.objects.all().order_by('name')
            
            # Get all crews
            crews = Crew.objects.all().order_by('name')
            
            # Get all clients
            clients = Client.objects.all().order_by('name')
            
            # Get models list
            models = get_models()
            
            # Get default model
            default_model = settings.GENERAL_MODEL
            
            context.update({
                'page_title': 'Chat',
                'agents': agents,
                'crews': crews,
                'clients': clients,
                'models': models,
                'conversations': conversations,
                'current_conversation': current_conversation,
                'add_agent_url': reverse('agents:add_agent'),
                'segment': 'chat',
                'default_model': default_model,
                'session_id': session_id,
            })
            
        except Exception as e:
            logger.error(f"Error preparing chat view context: {str(e)}", exc_info=True)
            raise
            
        return context

================
File: views_crews.py
================
# This file was previously named views_admin.py
# The content remains the same, but you might want to remove any unused imports

import logging
from django.shortcuts import render, redirect, get_object_or_404
from django.contrib.auth.decorators import login_required, user_passes_test
from django.contrib import messages
from .models import Crew, CrewTask
from .forms import CrewForm
import json
from apps.seo_manager.models import Client
from django.conf import settings
































































































import traceback

logger = logging.getLogger(__name__)

def is_admin(user):
    return user.is_staff or user.is_superuser

@login_required
@user_passes_test(is_admin)
def manage_crews(request):
    crews = Crew.objects.all().order_by('name')
    
    # Get the selected client_id from the session
    selected_client_id = request.session.get('selected_client_id')
    selected_client = None
    
    if selected_client_id:
        selected_client = get_object_or_404(Client, id=selected_client_id)
        # Optionally, you can filter crews by the selected client if there's a relationship
        # crews = crews.filter(client=selected_client)
    
    context = {
        'page_title': 'Manage Crews',
        'crews': crews,
        'selected_client': selected_client,
    }
    return render(request, 'agents/manage_crews.html', context)

@login_required
@user_passes_test(is_admin)
def add_crew(request):
    if request.method == 'POST':
        form = CrewForm(request.POST)
        if form.is_valid():
            form.save()
            messages.success(request, 'Crew added successfully.')
            return redirect('agents:manage_crews')
    else:
        initial_data = {
            'manager_llm': settings.GENERAL_MODEL,
            'function_calling_llm': settings.GENERAL_MODEL
        }
        logger.debug(f"Initial data for form: {initial_data}")
        form = CrewForm(initial=initial_data)
    # Add page_title to the context
    context = {
        'form': form,
        'page_title': 'Add Crew',
    }
    return render(request, 'agents/crew_form.html', context)

@login_required
@user_passes_test(is_admin)
def edit_crew(request, crew_id):
    crew = get_object_or_404(Crew, id=crew_id)
    if request.method == 'POST':
        form = CrewForm(request.POST, instance=crew)
        if form.is_valid():
            form.save()
            messages.success(request, 'Crew updated successfully.')
            return redirect('agents:manage_crews')
    else:
        form = CrewForm(instance=crew, initial={
            'manager_llm': settings.GENERAL_MODEL,
            'function_calling_llm': settings.GENERAL_MODEL
        })
    # Add page_title to the context
    context = {
        'form': form,
        'crew': crew,
        'page_title': 'Edit Crew',
    }
    return render(request, 'agents/crew_form.html', context)

@login_required
@user_passes_test(is_admin)
def delete_crew(request, crew_id):
    crew = get_object_or_404(Crew, id=crew_id)
    if request.method == 'POST':
        crew.delete()
        messages.success(request, 'Crew deleted successfully.')
        return redirect('agents:manage_crews')
    context = {
        'object': crew,
        'type': 'crew',
        'page_title': 'Delete Crew',
    }
    return render(request, 'agents/confirm_delete.html', context)

@login_required
@user_passes_test(is_admin)
def duplicate_crew(request, crew_id):
    original_crew = get_object_or_404(Crew, id=crew_id)
    if request.method == 'POST':
        try:
            # Get all field values except id and auto-generated fields
            field_values = {
                field.name: getattr(original_crew, field.name)
                for field in original_crew._meta.fields
                if not field.primary_key and not field.auto_created
            }
            
            # Modify the name for the copy
            field_values['name'] = f"{field_values['name']} (Copy)"
            
            # Create new crew with copied values
            new_crew = Crew.objects.create(**field_values)
            
            # Copy many-to-many relationships except tasks (which we'll handle separately)
            for field in original_crew._meta.many_to_many:
                if field.name != 'tasks':  # Skip tasks as we handle them through CrewTask
                    getattr(new_crew, field.name).set(getattr(original_crew, field.name).all())
            
            # Copy crew tasks with their order
            crew_tasks = CrewTask.objects.filter(crew=original_crew).order_by('order')
            for crew_task in crew_tasks:
                CrewTask.objects.create(
                    crew=new_crew,
                    task=crew_task.task,
                    order=crew_task.order
                )
            
            messages.success(request, 'Crew duplicated successfully.')
            
            # Check for next URL in POST data first, then GET, then fall back to referer
            next_url = request.POST.get('next') or request.GET.get('next')
            if next_url:
                return redirect(next_url)
            
            # If no next parameter, check the referer
            referer = request.META.get('HTTP_REFERER', '')
            if 'card-view' in referer:
                return redirect('agents:manage_crews_card_view')
            return redirect('agents:manage_crews')
            
        except Exception as e:
            logger.error(f"Error duplicating crew: {str(e)}\n{traceback.format_exc()}")
            messages.error(request, f"Error duplicating crew: {str(e)}")
            # Check for next URL in POST data first, then GET, then fall back to referer
            next_url = request.POST.get('next') or request.GET.get('next')
            if next_url:
                return redirect(next_url)
            
            # If no next parameter, check the referer
            referer = request.META.get('HTTP_REFERER', '')
            if 'card-view' in referer:
                return redirect('agents:manage_crews_card_view')
            return redirect('agents:manage_crews')
            
    return redirect('agents:manage_crews')

@login_required
@user_passes_test(is_admin)
def update_crew_agents(request, crew_id):
    crew = get_object_or_404(Crew, id=crew_id)
    if request.method == 'POST':
        agent_ids = request.POST.getlist('agents')
        crew.agents.set(agent_ids)
        
        # Update manager_agent if it's in the POST data
        manager_agent_id = request.POST.get('manager_agent')
        if manager_agent_id:
            crew.manager_agent_id = manager_agent_id
        else:
            crew.manager_agent = None
        
        crew.save()
        messages.success(request, 'Crew agents updated successfully.')
    return redirect('agents:manage_crews')

@login_required
@user_passes_test(is_admin)
def manage_crews_card_view(request):
    crews = Crew.objects.all().order_by('name')
    
    # Get the selected client_id from the session
    selected_client_id = request.session.get('selected_client_id')
    selected_client = None
    
    if selected_client_id:
        selected_client = get_object_or_404(Client, id=selected_client_id)
        # Optionally, you can filter crews by the selected client if there's a relationship
        # crews = crews.filter(client=selected_client)
    
    context = {
        'page_title': 'Manage Crews',
        'crews': crews,
        'selected_client': selected_client,
    }
    return render(request, 'agents/manage_crews_card_view.html', context)

@login_required
def crew_create_or_update(request, crew_id=None):
    if crew_id:
        crew = get_object_or_404(Crew, id=crew_id)
    else:
        crew = None

    next_url = request.GET.get('next') or request.POST.get('next')

    if request.method == 'POST':
        form = CrewForm(request.POST, instance=crew)
        if form.is_valid():
            crew = form.save(commit=False)
            
            # Handle input variables - ensure it's a proper JSON array
            input_variables = request.POST.getlist('input_variables[]')
            # Filter out empty strings and convert to list
            input_variables = [var.strip() for var in input_variables if var.strip()]
            # Store as JSON array
            crew.input_variables = input_variables if input_variables else []
            
            crew.save()
            form.save_m2m()  # This is important for saving many-to-many relationships
            
            # Handle task order
            task_order = request.POST.getlist('task_order[]')
            CrewTask.objects.filter(crew=crew).delete()
            for index, task_id in enumerate(task_order):
                CrewTask.objects.create(crew=crew, task_id=task_id, order=index)
            
            messages.success(request, f'Crew {"updated" if crew_id else "created"} successfully.')
            
            if next_url:
                return redirect(next_url)
            else:
                return redirect('agents:manage_crews')
        else:
            messages.error(request, f'Error {"updating" if crew_id else "creating"} crew. Please check the form.')
    else:
        form = CrewForm(instance=crew)
        input_variables = crew.input_variables if crew and crew.input_variables else []

    context = {
        'page_title': 'Create or Update Crew',
        'form': form,
        'crew': crew,
        'input_variables_json': json.dumps(input_variables if input_variables else []),
        'next': next_url,
    }

    return render(request, 'agents/crew_form.html', context)

================
File: views_kanban.py
================
from django.shortcuts import render, get_object_or_404
from django.contrib.auth.decorators import login_required
from django.http import JsonResponse
from django.views.decorators.http import require_http_methods
from django.views.decorators.csrf import csrf_protect
from django.utils import timezone
import json
from django.core.cache import cache
from celery import current_app

from .models import Crew, CrewExecution, ExecutionStage, Task, Agent, CrewTask
from apps.seo_manager.models import Client
from apps.agents.tasks.messaging.execution_bus import ExecutionMessageBus

import logging
logger = logging.getLogger(__name__)

@login_required
def crew_kanban(request, crew_id):
    crew = get_object_or_404(Crew, id=crew_id)
    client_id = request.GET.get('client_id')
    client = get_object_or_404(Client, id=client_id) if client_id else None
    
    # Get all tasks for this crew through CrewTask
    crew_tasks = CrewTask.objects.filter(crew=crew).select_related('task')
    kanban_tasks = []
    
    for crew_task in crew_tasks:
        task = crew_task.task
        # Get executions for this crew
        executions = CrewExecution.objects.filter(
            crew=crew,
            client=client
        ).prefetch_related('stages')
        
        execution_data = []
        for execution in executions:
            stages = execution.stages.all()
            stage_data = {}
            
            for stage in stages:
                stage_data[stage.stage_type] = {
                    'title': stage.title,
                    'content': stage.content,
                    'status': stage.status,
                    'agent': stage.agent.name if stage.agent else None
                }
                
                # Add stage-specific metadata
                if stage.metadata:
                    stage_data[stage.stage_type].update(stage.metadata)
            
            execution_data.append({
                'id': execution.id,
                'name': f'Execution #{execution.id}',
                'status': execution.status,
                'stages': stage_data
            })
        
        kanban_tasks.append({
            'id': task.id,
            'name': task.description,
            'executions': execution_data
        })
    
    # Add page_title to the context
    context = {
        'crew': crew,
        'client': client,
        'tasks': kanban_tasks,
        'page_title': 'Crew Run',
    }
    return render(request, 'agents/crew_kanban.html', context)

@login_required
@require_http_methods(['POST'])
@csrf_protect
def start_execution(request, crew_id):
    crew = get_object_or_404(Crew, id=crew_id)
    
    try:
        data = json.loads(request.body)
        client_id = data.get('client_id')
            
        if not client_id:
            return JsonResponse({
                'status': 'error',
                'message': 'Client ID is required'
            }, status=400)
            
        client = get_object_or_404(Client, id=client_id)
        
        # Get the first task for this crew
        crew_task = CrewTask.objects.filter(crew=crew).order_by('order').first()
        if not crew_task:
            return JsonResponse({
                'status': 'error',
                'message': 'No tasks found for this crew'
            }, status=400)
        
        # Create new execution
        execution = CrewExecution.objects.create(
            crew=crew,
            status='PENDING',
            inputs={
                'client_id': client_id
            },
            user=request.user,
            client=client
        )
        
        # Create initial stage
        stage = ExecutionStage.objects.create(
            execution=execution,
            stage_type='task_start',
            title='Starting New Execution',
            content='Initializing crew execution workflow',
            status='pending'
        )
        
        # Start the Celery task
        from .tasks import execute_crew
        task = execute_crew.delay(execution.id)
        
        # Update execution with task_id immediately
        execution.task_id = task.id
        execution.save()
        
        # Use ExecutionMessageBus for notifications
        message_bus = ExecutionMessageBus(execution.id)
        message_bus.publish('execution_update', {
            'status': 'PENDING',
            'message': 'New execution started',
            'crewai_task_id': crew_task.task.id,  # For proper board placement
            'stage': {
                'stage_type': 'task_start',
                'title': 'Starting New Execution',
                'content': 'Initializing crew execution workflow',
                'status': 'pending'
            }
        })
        
        return JsonResponse({
            'status': 'success',
            'execution_id': execution.id,
            'task_id': crew_task.task.id
        })
        
    except json.JSONDecodeError:
        return JsonResponse({
            'status': 'error',
            'message': 'Invalid JSON data'
        }, status=400)
    except Exception as e:
        logger.error(f'Error starting execution: {str(e)}', exc_info=True)
        return JsonResponse({
            'status': 'error',
            'message': str(e)
        }, status=500)

@login_required
@require_http_methods(['GET'])
def get_active_executions(request, crew_id):
    """Get all active executions for a crew"""
    crew = get_object_or_404(Crew, id=crew_id)
    
    # Get all in-progress executions for this crew
    executions = CrewExecution.objects.filter(
        crew=crew,
        status__in=['pending', 'in_progress']
    ).prefetch_related('stages')
    
    execution_data = []
    for execution in executions:
        stages = execution.stages.all()
        stage_data = {}
        
        for stage in stages:
            stage_data[stage.stage_type] = {
                'title': stage.title,
                'content': stage.content,
                'status': stage.status,
                'agent': stage.agent.name if stage.agent else None
            }
            
            if stage.metadata:
                stage_data[stage.stage_type].update(stage.metadata)
        
        execution_data.append({
            'execution_id': execution.id,
            'task_id': execution.task_id if hasattr(execution, 'task_id') else None,
            'name': f'Execution #{execution.id}',
            'status': execution.status,
            'stages': stage_data
        })
    
    return JsonResponse({'executions': execution_data})

@login_required
@require_http_methods(['POST'])
@csrf_protect
def submit_human_input(request, execution_id):
    execution = get_object_or_404(CrewExecution, id=execution_id)
    
    try:
        data = json.loads(request.body)
        input_text = data.get('input')
        
        if not input_text:
            return JsonResponse({
                'status': 'error',
                'message': 'Input text is required'
            }, status=400)
        
        # Update execution with human input
        execution.human_input_response = {'input': input_text}
        execution.status = 'RUNNING'
        execution.save()
        
        # Set response in cache with correct key format
        input_key = f"execution_{execution_id}_task_0_input"  # We use task 0 as that's the current task
        cache.set(input_key, input_text, timeout=3600)
        
        # Create human input stage
        stage = ExecutionStage.objects.create(
            execution=execution,
            stage_type='human_input',
            title='Human Input Received',
            content=input_text,
            status='completed',
            metadata={
                'input_timestamp': timezone.now().isoformat()
            }
        )
        
        # Use ExecutionMessageBus for notifications
        message_bus = ExecutionMessageBus(execution_id)
        message_bus.publish('execution_update', {
            'status': 'RUNNING',
            'message': 'Human input received',
            'stage': {
                'stage_type': 'human_input',
                'title': stage.title,
                'content': stage.content,
                'status': stage.status,
                'completed': True,
                'agent': 'Human'
            }
        })
        
        return JsonResponse({'status': 'success'})
        
    except json.JSONDecodeError:
        return JsonResponse({
            'status': 'error',
            'message': 'Invalid JSON data'
        }, status=400)
    except Exception as e:
        return JsonResponse({
            'status': 'error',
            'message': str(e)
        }, status=500)

@login_required
@require_http_methods(["POST"])
def cancel_execution(request, execution_id):
    execution = get_object_or_404(CrewExecution, id=execution_id)
    
    if execution.task_id:
        # Revoke the Celery task
        current_app.control.revoke(task_id=execution.task_id, terminate=True)
        
        # Update execution status
        execution.status = 'CANCELLED'
        execution.save()
        
        # Notify about cancellation
        message_bus = ExecutionMessageBus(execution_id)
        message_bus.publish('execution_update', {
            'status': 'CANCELLED',
            'message': 'Execution cancelled by user',
            'stage': {
                'stage_type': 'cancellation',
                'title': 'Execution Cancelled',
                'content': 'The execution was cancelled by the user',
                'status': 'cancelled',
                'agent': 'System'
            }
        })
        
        return JsonResponse({'status': 'success'})
    
    return JsonResponse({'status': 'error', 'message': 'No task ID found'}, status=404)

@login_required
def execution_detail(request, execution_id):
    execution = get_object_or_404(CrewExecution.objects.select_related('crew', 'crew_output'), id=execution_id)
    crew = execution.crew
    
    # Define the columns we want to show
    columns = [
        {'id': 'task_start', 'name': 'Task Start'},
        {'id': 'thinking', 'name': 'Thinking'},
        {'id': 'tool_usage', 'name': 'Tool Usage'},
        {'id': 'tool_results', 'name': 'Tool Results'},
        {'id': 'human_input', 'name': 'Human Input'},
        {'id': 'completion', 'name': 'Completion'}
    ]
    
    # Get all stages for this execution
    stages = execution.stages.all().select_related('agent').order_by('created_at')
    
    # Get all messages for this execution
    messages = execution.messages.all().order_by('timestamp')
    
    # Organize stages by stage_type
    kanban_columns = []
    for column in columns:
        column_stages = []
        
        # Add stages for this column
        for stage in stages:
            if stage.stage_type == column['id']:
                stage_data = {
                    'id': stage.id,
                    'title': stage.title,
                    'content': stage.content,
                    'status': stage.status,
                    'agent': stage.agent.name if stage.agent else None,
                    'created_at': stage.created_at,
                    'metadata': stage.metadata or {},
                    'type': 'stage'
                }
                column_stages.append(stage_data)
        
        # Add messages that might be related to this stage type
        if column['id'] == 'thinking':
            for message in messages:
                column_stages.append({
                    'id': f'msg_{message.id}',
                    'title': f'Message from {message.agent}',
                    'content': message.content,
                    'status': 'completed',
                    'agent': message.agent,
                    'created_at': message.timestamp,
                    'type': 'message'
                })
        
        # Add crew output to completion column
        if column['id'] == 'completion' and execution.crew_output:
            output_data = {
                'id': 'output',
                'title': 'Final Output',
                'content': execution.crew_output.raw,
                'status': 'completed',
                'created_at': execution.updated_at,
                'type': 'output',
                'metadata': {
                    'json_output': execution.crew_output.json_dict,
                    'token_usage': execution.crew_output.token_usage
                }
            }
            column_stages.append(output_data)
        
        kanban_columns.append({
            'id': column['id'],
            'name': column['name'],
            'stages': sorted(column_stages, key=lambda x: x['created_at'])
        })
    
    context = {
        'page_title': 'Execution Detail',
        'execution': execution,
        'crew': crew,
        'columns': kanban_columns
    }
    
    return render(request, 'agents/execution_detail.html', context)

================
File: views_tasks.py
================
import logging
from django.shortcuts import render, redirect, get_object_or_404
from django.contrib.auth.decorators import login_required, user_passes_test
from django.contrib import messages
from .models import Task
from .forms import TaskForm
import traceback

logger = logging.getLogger(__name__)

def is_admin(user):
    return user.is_staff or user.is_superuser

@login_required
@user_passes_test(is_admin)
def manage_tasks(request):
    tasks = Task.objects.all().order_by('description')
    # Add page_title to the context
    context = {
        'tasks': tasks,
        'page_title': 'Manage Tasks',
    }
    return render(request, 'agents/manage_tasks.html', context)

@login_required
@user_passes_test(is_admin)
def add_task(request):
    if request.method == 'POST':
        form = TaskForm(request.POST)
        if form.is_valid():
            form.save()
            messages.success(request, 'Task added successfully.')
            return redirect('agents:manage_tasks')
    else:
        form = TaskForm()
    # Add page_title to the context
    context = {
        'form': form,
        'page_title': 'Add Task',
    }
    return render(request, 'agents/task_form.html', context)

@login_required
@user_passes_test(is_admin)
def edit_task(request, task_id):
    task = get_object_or_404(Task, id=task_id)
    if request.method == 'POST':
        form = TaskForm(request.POST, instance=task)
        if form.is_valid():
            form.save()
            messages.success(request, 'Task updated successfully.')
            return redirect('agents:manage_tasks')
    else:
        form = TaskForm(instance=task)
    # Add page_title to the context
    context = {
        'form': form,
        'task': task,
        'page_title': 'Edit Task',
    }
    return render(request, 'agents/task_form.html', context)

@login_required
@user_passes_test(is_admin)
def delete_task(request, task_id):
    task = get_object_or_404(Task, id=task_id)
    if request.method == 'POST':
        task.delete()
        messages.success(request, 'Task deleted successfully.')
        return redirect('agents:manage_tasks')
    context = {
        'object': task,
        'type': 'task',
        'page_title': 'Delete Task',
    }
    return render(request, 'agents/confirm_delete.html', context)

@login_required
@user_passes_test(is_admin)
def duplicate_task(request, task_id):
    original_task = get_object_or_404(Task, id=task_id)
    if request.method == 'POST':
        try:
            # Get all field values except id and auto-generated fields
            field_values = {
                field.name: getattr(original_task, field.name)
                for field in original_task._meta.fields
                if not field.primary_key and not field.auto_created
            }
            
            # Modify the description for the copy
            field_values['description'] = f"{field_values['description']} (Copy)"
            
            # Create new task with copied values
            new_task = Task.objects.create(**field_values)
            
            # Copy many-to-many relationships if any
            for field in original_task._meta.many_to_many:
                getattr(new_task, field.name).set(getattr(original_task, field.name).all())
            
            messages.success(request, 'Task duplicated successfully.')
            
            # Check for next URL in POST data first, then GET
            next_url = request.POST.get('next') or request.GET.get('next')
            if next_url:
                return redirect(next_url)
            return redirect('agents:manage_tasks')
            
        except Exception as e:
            logger.error(f"Error duplicating task: {str(e)}\n{traceback.format_exc()}")
            messages.error(request, f"Error duplicating task: {str(e)}")
            next_url = request.POST.get('next') or request.GET.get('next')
            if next_url:
                return redirect(next_url)
            return redirect('agents:manage_tasks')
            
    return redirect('agents:manage_tasks')

================
File: views_tools.py
================
import logging
from django.shortcuts import render, redirect, get_object_or_404
from django.contrib.auth.decorators import login_required, user_passes_test
from django.contrib import messages
from django.views.decorators.http import require_http_methods
from django.http import JsonResponse
import traceback
from .models import Tool
from .forms import ToolForm
from .utils import get_available_tools, get_tool_classes, get_tool_description, get_tool_class_obj, load_tool
from pydantic import BaseModel
import inspect
import json
import tiktoken
import csv
from io import StringIO
import asyncio
from asgiref.sync import sync_to_async

logger = logging.getLogger(__name__)

def is_admin(user):
    return user.is_staff or user.is_superuser

def count_tokens(text):
    encoding = tiktoken.encoding_for_model("gpt-3.5-turbo")
    return len(encoding.encode(text))

@login_required
@user_passes_test(is_admin)
def manage_tools(request):
    tools = Tool.objects.all().order_by('name')
    return render(request, 'agents/manage_tools.html', {'tools': tools, 'page_title': 'Manage Tools'})

@login_required
@user_passes_test(is_admin)
def add_tool(request):
    if request.method == 'POST':
        form = ToolForm(request.POST)
        #logger.debug(f"POST data: {request.POST}")
        if form.is_valid():
            tool = form.save(commit=False)
            tool_class = form.cleaned_data['tool_class']
            tool_subclass = form.cleaned_data['tool_subclass']
            
            #logger.debug(f"Adding tool: class={tool_class}, subclass={tool_subclass}")
            
            # Get the tool class object and its description
            tool_classes = get_tool_classes(tool_class)
            #logger.debug(f"Available tool classes: {[cls.__name__ for cls in tool_classes]}")
            if tool_classes:
                tool_class_obj = next((cls for cls in tool_classes if cls.__name__ == tool_subclass), None)
                if tool_class_obj:
                    #logger.debug(f"Tool class object: {tool_class_obj}")
                    
                    tool.description = get_tool_description(tool_class_obj)
                    #logger.debug(f"Tool description: {tool.description}")
                    
                    # Save the tool
                    tool.save()
                    
                    messages.success(request, 'Tool added successfully.')
                    return redirect('agents:manage_tools')
                else:
                    messages.error(request, f'Tool subclass {tool_subclass} not found.')
            else:
                messages.error(request, 'Tool class not found.')
        else:
            for field, errors in form.errors.items():
                for error in errors:
                    messages.error(request, f"{field}: {error}")
            logger.error(f"Form errors: {form.errors}")
    else:
        form = ToolForm()
    # Add page_title to the context
    context = {
        'form': form,
        'page_title': 'Add Tool',
    }
    return render(request, 'agents/tool_form.html', context)

@login_required
@user_passes_test(is_admin)
def edit_tool(request, tool_id):
    tool = get_object_or_404(Tool, id=tool_id)
    if request.method == 'POST':
        form = ToolForm(request.POST, instance=tool)
        if form.is_valid():
            tool = form.save(commit=False)
            tool.name = form.cleaned_data['tool_subclass']
            tool_class = form.cleaned_data['tool_class']
            tool_subclass = form.cleaned_data['tool_subclass']
            
            tool_class_obj = get_tool_class_obj(tool_class, tool_subclass)
            tool.description = get_tool_description(tool_class_obj)
            tool.save()
            messages.success(request, 'Tool updated successfully.')
            return redirect('agents:manage_tools')
    else:
        form = ToolForm(instance=tool)
    # Add page_title to the context
    context = {
        'form': form,
        'tool': tool,
        'page_title': 'Edit Tool',
    }
    
    return render(request, 'agents/tool_form.html', context)

@login_required
@user_passes_test(is_admin)
def delete_tool(request, tool_id):
    tool = get_object_or_404(Tool, id=tool_id)
    if request.method == 'POST':
        tool.delete()
        messages.success(request, 'Tool deleted successfully.')
        return redirect('agents:manage_tools')
    return render(request, 'agents/confirm_delete.html', {'object': tool, 'type': 'tool', 'page_title': 'Delete Tool'})

@login_required
@user_passes_test(is_admin)
def get_tool_info(request):
    tool_class = request.GET.get('tool_class')
    logger.info(f"Received request for tool_class: {tool_class}")
    
    if tool_class:
        try:
            tool_objects = get_tool_classes(tool_class)
            #logger.debug(f"Found tool objects: {[obj.__name__ for obj in tool_objects]}")
            
            class_info = []
            for obj in tool_objects:
                description = get_tool_description(obj)
                #logger.debug(f"Tool: {obj.__name__}, Description: {description}")
                class_info.append({
                    'name': obj.__name__,
                    'description': description
                })
            
            #logger.debug(f"Returning class_info: {class_info}")
            return JsonResponse({
                'classes': class_info
            })
        except ImportError as e:
            logger.error(f"ImportError: {e}")
            logger.error(f"Traceback: {traceback.format_exc()}")
            return JsonResponse({'error': f"Failed to import tool module: {str(e)}"}, status=500)
        except Exception as e:
            logger.error(f"Unexpected error: {e}")
            logger.error(f"Traceback: {traceback.format_exc()}")
            return JsonResponse({'error': f"An unexpected error occurred: {str(e)}"}, status=500)
    
    logger.warning("Invalid request: tool_class parameter is missing")
    return JsonResponse({'error': 'Invalid request: tool_class parameter is missing'}, status=400)

@login_required
@user_passes_test(is_admin)
def get_tool_schema(request, tool_id):
    tool = get_object_or_404(Tool, id=tool_id)
    try:
        tool_class = get_tool_class_obj(tool.tool_class, tool.tool_subclass)
        
        
        manual_schema = {
            "type": "object",
            "properties": {}
        }

        # Access schema through Pydantic's model fields
        if hasattr(tool_class, 'model_fields') and 'args_schema' in tool_class.model_fields:
            
            schema_class = tool_class.model_fields['args_schema'].default
            
            if issubclass(schema_class, BaseModel):
                # Use Pydantic v2 method if available
                if hasattr(schema_class, 'model_json_schema'):
                    schema = schema_class.model_json_schema()
                else:
                    schema = schema_class.schema()
                
                for field_name, field_info in schema.get('properties', {}).items():
                    manual_schema['properties'][field_name] = {
                        "type": field_info.get('type', 'string'),
                        "title": field_info.get('title', field_name.capitalize()),
                        "description": field_info.get('description', '')
                    }

        if not manual_schema["properties"]:
            logger.warning("No properties found in schema")
            return JsonResponse({'error': 'No input fields found for this tool'}, status=400)

        return JsonResponse(manual_schema)
    except Exception as e:
        logger.error(f"Schema error: {str(e)}", exc_info=True)
        return JsonResponse({'error': str(e)}, status=500)

@login_required
@user_passes_test(is_admin)
@require_http_methods(["POST"])
def test_tool(request, tool_id):
    """Run a tool test using Celery for both sync and async tools"""
    logger.debug(f"Starting test_tool for tool_id: {tool_id}")
    tool = get_object_or_404(Tool, id=tool_id)
    logger.debug(f"Found tool: {tool.name}")
    
    # Get inputs from request
    inputs = {key: value for key, value in request.POST.items() if key != 'csrfmiddlewaretoken'}
    logger.debug(f"Tool inputs: {inputs}")
    
    try:
        # Import and verify Celery app configuration
        from celery import current_app
        logger.debug(f"Celery broker URL: {current_app.conf.broker_url}")
        logger.debug(f"Celery result backend: {current_app.conf.result_backend}")
        
        # Start Celery task
        from .tasks.tools import run_tool
        logger.debug("Attempting to queue tool execution task...")
        task = run_tool.delay(tool_id, inputs)
        logger.debug(f"Task queued successfully with ID: {task.id}")
        
        return JsonResponse({
            'status': 'started',
            'task_id': task.id,
            'message': f'Tool execution started. Task ID: {task.id}'
        })
        
    except Exception as e:
        logger.error(f"Error starting tool execution: {str(e)}", exc_info=True)
        return JsonResponse({
            'error': str(e)
        }, status=400)

@login_required
@user_passes_test(is_admin)
def get_tool_status(request, task_id):
    """Get the status of a tool execution"""
    from celery.result import AsyncResult
    
    task = AsyncResult(task_id)
    
    response = {
        'status': task.status,
        'token_count': 0
    }
    
    if task.ready():
        if task.successful():
            try:
                result = task.get()
                #logger.debug(f"Raw task result: {result} (Type: {type(result)})")
                
                # Preserve existing response structure
                if isinstance(result, dict):
                    response.update({
                        'result': result.get('result', ''),
                        'error': result.get('error')
                    })
                else:
                    response['result'] = str(result)
                
                # Calculate tokens from the original result
                if isinstance(result, (dict, list)):
                    output_text = json.dumps(result, indent=2)
                else:
                    output_text = str(result)
                
                #logger.debug(f"Formatted output text for token counting: {output_text[:200]}...")  # Log first 200 chars
                token_count = count_tokens(output_text)
                #logger.debug(f"Calculated token count: {token_count}")
                response['token_count'] = token_count
                
            except Exception as e:
                logger.error(f"Error processing task result: {str(e)}")
                response.update({
                    'status': 'FAILURE',
                    'error': str(e)
                })
        else:
            logger.error(f"Task failed: {task.result}")
            response.update({
                'error': str(task.result)
            })
    
    return JsonResponse(response)

================
File: views.py
================
from django.shortcuts import render, redirect, get_object_or_404
from django.contrib.auth.decorators import login_required
from django.contrib import messages
from django.core.paginator import Paginator
from django.http import JsonResponse
from django.views.decorators.http import require_POST, require_http_methods
from django.views.decorators.csrf import csrf_exempt, csrf_protect
from .models import Crew, CrewExecution, CrewMessage, Agent, CrewTask, Task, UserSlackIntegration
from .forms import CrewExecutionForm, HumanInputForm, AgentForm
from .tasks import execute_crew
from django.core.exceptions import ValidationError
import logging
import json
from django.urls import reverse
from django.core.cache import cache
from django.conf import settings
import os
from apps.seo_manager.models import Client  # Import the Client model
from markdown_it import MarkdownIt  # Import markdown-it
from apps.common.utils import get_models
from slack_sdk.oauth import AuthorizeUrlGenerator
from slack_sdk.web import WebClient
from apps.agents.tasks.messaging.execution_bus import ExecutionMessageBus

logger = logging.getLogger(__name__)

# Initialize the MarkdownIt instance
md = MarkdownIt()

@login_required
@csrf_exempt
def connection_test(request):
    return render(request, 'agents/connection_test.html')

@login_required
def crewai_home(request):
    crews = Crew.objects.all()  # Get the first 3 crews for the summary
    recent_executions = CrewExecution.objects.filter(user=request.user).order_by('-created_at')[:10]
    clients = Client.objects.all()  # Get all clients
    
    # Get the selected client_id from the request, fallback to session
    selected_client_id = request.GET.get('client_id') or request.session.get('selected_client_id')
    
    if selected_client_id:
        request.session['selected_client_id'] = selected_client_id
    else:
        # If no client is selected, remove it from the session
        request.session.pop('selected_client_id', None)
    
    context = {
        'page_title': 'Crews Home',
        'crews': crews,
        'recent_executions': recent_executions,
        'clients': clients,
        'selected_client_id': selected_client_id,
    }
    return render(request, 'agents/crewai_home.html', context)

@login_required
def crew_list(request):
    logger.debug("Entering crew_list view")
    crews = Crew.objects.all()
    # Add page_title to the context
    context = {
        'crews': crews,
        'page_title': 'Crew List',
    }
    return render(request, 'agents/crew_list.html', context)

@login_required
def crew_detail(request, crew_id):
    crew = get_object_or_404(Crew, id=crew_id)
    recent_executions = CrewExecution.objects.filter(crew=crew).order_by('-created_at')[:5]
    
    # Get the selected client_id from the session
    selected_client_id = request.session.get('selected_client_id')
    selected_client = None
    if selected_client_id:
        selected_client = get_object_or_404(Client, id=selected_client_id)
    
    if request.method == 'POST':
        form = CrewExecutionForm(request.POST)
        if form.is_valid():
            execution = form.save(commit=False)
            execution.crew = crew
            execution.user = request.user
            execution.client = selected_client  # Associate the selected client with the execution
            
            # Handle input variables
            input_variables = json.loads(request.POST.get('input_variables', '{}'))
            execution.inputs = input_variables
            
            execution.save()
            
            # Start the execution
            execute_crew.delay(execution.id)
            
            messages.success(request, 'Crew execution started.')
            return JsonResponse({'status': 'success', 'execution_id': execution.id})
    else:
        form = CrewExecutionForm()
    
    context = {
        'page_title': 'Crew Detail',
        'crew': crew,
        'form': form,
        'recent_executions': recent_executions,
        'selected_client': selected_client,
    }
    return render(request, 'agents/crew_detail.html', context)

@login_required
def execution_list(request):
    logger.debug("Entering execution_list view")
    executions = CrewExecution.objects.filter(user=request.user).order_by('-created_at')
    crews = Crew.objects.all()

    # Apply filters
    crew_id = request.GET.get('crew')
    status = request.GET.get('status')

    if crew_id:
        executions = executions.filter(crew_id=crew_id)
    if status:
        executions = executions.filter(status=status)

    # Pagination
    paginator = Paginator(executions, 10)  # Show 10 executions per page
    page_number = request.GET.get('page')
    page_obj = paginator.get_page(page_number)

    context = {
        'page_title': 'Execution List',
        'executions': page_obj,
        'crews': crews,
    }
    return render(request, 'agents/execution_list.html', context)

@login_required
def execution_detail(request, execution_id):
    execution = get_object_or_404(CrewExecution, id=execution_id)
    
    # Get all tasks for this crew through CrewTask
    crew_tasks = CrewTask.objects.filter(crew=execution.crew).select_related('task')
    kanban_tasks = []
    
    for crew_task in crew_tasks:
        task = crew_task.task
        stages = execution.stages.filter(task=task).order_by('created_at')
        
        stage_data = []
        for stage in stages:
            stage_data.append({
                'id': stage.id,
                'title': stage.title,
                'content': stage.content,
                'status': stage.status,
                'agent': stage.agent.name if stage.agent else None,
                'created_at': stage.created_at,
                'metadata': stage.metadata or {}
            })
        
        kanban_tasks.append({
            'id': task.id,
            'name': task.description,
            'stages': stage_data
        })
    
    context = {
        'page_title': 'Execution Detail',
        'execution': execution,
        'crew': execution.crew,
        'tasks': kanban_tasks
    }
    
    return render(request, 'agents/execution_detail.html', context)

@login_required
def execution_status(request, execution_id):
    try:
        execution = CrewExecution.objects.get(id=execution_id, user=request.user)
        
        # Get the last message ID from the request
        last_message_id = request.GET.get('last_message_id')
        
        # Only fetch new messages if there are any
        if last_message_id:
            messages = CrewMessage.objects.filter(
                execution=execution,
                id__gt=last_message_id
            ).order_by('timestamp')
        else:
            messages = CrewMessage.objects.filter(
                execution=execution
            ).order_by('timestamp')
        
        # Get status badge class
        status_classes = {
            'PENDING': 'info',
            'RUNNING': 'primary',
            'WAITING_FOR_HUMAN_INPUT': 'warning',
            'COMPLETED': 'success',
            'FAILED': 'danger'
        }
        status_class = status_classes.get(execution.status, 'secondary')
        
        response_data = {
            'status': execution.get_status_display(),
            'status_class': status_class,
            'updated_at': execution.updated_at.isoformat(),
            'outputs': execution.outputs,
            'human_input_request': execution.human_input_request,
            'messages': [{
                'id': msg.id,
                'agent': msg.agent,
                'content': msg.content,
                'timestamp': msg.timestamp.strftime("%d %b %H:%M")
            } for msg in messages],
        }
        return JsonResponse(response_data)
    except CrewExecution.DoesNotExist:
        return JsonResponse({'error': 'Execution not found'}, status=404)

@login_required
@csrf_protect
@require_POST
def provide_human_input(request, execution_id):
    try:
        execution = CrewExecution.objects.get(id=execution_id, user=request.user)
        if execution.status != 'WAITING_FOR_HUMAN_INPUT':
            return JsonResponse({'error': 'Execution is not waiting for human input'}, status=400)

        data = json.loads(request.body)
        user_input = data.get('input')

        if user_input is None:
            return JsonResponse({'error': 'No input provided'}, status=400)

        # Store the user input in the cache
        cache.set(f'human_input_response_{execution_id}', user_input, timeout=3600)
        logger.info(f"Stored user input for execution {execution_id}: {user_input}")

        # Update execution status
        execution.status = 'RUNNING'
        execution.save()

        # Use ExecutionMessageBus for consistent messaging
        message_bus = ExecutionMessageBus(execution_id)
        message_bus.publish('execution_update', {
            'status': 'RUNNING',
            'message': f'Input provided: {user_input}',
            'stage': {
                'stage_type': 'human_input',
                'title': 'Human Input',
                'content': f'Input provided: {user_input}',
                'status': 'completed',
                'agent': 'Human'
            }
        })

        return JsonResponse({
            'message': 'Human input received and processing resumed', 
            'input': user_input
        })

    except CrewExecution.DoesNotExist:
        return JsonResponse({'error': 'Execution not found'}, status=404)
    except json.JSONDecodeError:
        return JsonResponse({'error': 'Invalid JSON'}, status=400)
    except Exception as e:
        logger.error(f"Error in provide_human_input: {str(e)}")
        return JsonResponse({'error': 'An unexpected error occurred'}, status=500)


@login_required
@require_POST
def submit_human_input(request, execution_id):
    input_key = request.POST.get('input_key')
    response = request.POST.get('response')
    
    if not input_key or not response:
        return JsonResponse({'error': 'Missing input_key or response'}, status=400)
    
    execution = get_object_or_404(CrewExecution, id=execution_id, user=request.user)
    
    # Store the response in the cache
    cache_key = f"{input_key}_response"
    cache.set(cache_key, response, timeout=3600)
    logger.info(f"Stored human input in cache for execution {execution_id}: key={cache_key}, value={response}")
    
    # Update execution status
    execution.status = 'RUNNING'
    execution.save()
    
    # Use ExecutionMessageBus for consistent messaging
    message_bus = ExecutionMessageBus(execution_id)
    message_bus.publish('execution_update', {
        'status': 'RUNNING',
        'message': f'Human input received: {response}',
        'stage': {
            'stage_type': 'human_input',
            'title': 'Human Input',
            'content': f'Input received: {response}',
            'status': 'completed',
            'agent': 'Human'
        }
    })
    
    return JsonResponse({'message': 'Human input received and processed'})

@login_required
def chat_view(request):
    clients = Client.objects.all().order_by('name')
    print(f"Found {clients.count()} clients")  # Debug print
    
    context = {
        'agents': Agent.objects.all(),
        'models': get_models(),
        'default_model': settings.GENERAL_MODEL,
        'clients': clients,
    }
    return render(request, 'agents/chat.html', context)

@login_required
def slack_oauth_start(request):
    """Start Slack OAuth flow"""
    redirect_uri = f"https://{settings.APP_DOMAIN}/agents/slack/oauth/callback/"
    authorize_url_generator = AuthorizeUrlGenerator(
        client_id=settings.DSLACK_CLIENT_ID,
        scopes=["chat:write", "channels:read", "channels:history"],
        redirect_uri=redirect_uri
    )
    authorize_url = authorize_url_generator.generate("")
    return redirect(authorize_url)

@login_required
def slack_oauth_callback(request):
    """Handle Slack OAuth callback"""
    code = request.GET.get('code')
    if not code:
        return JsonResponse({"error": "No code provided"}, status=400)
    
    try:
        client = WebClient()
        response = client.oauth_v2_access(
            client_id=settings.DSLACK_CLIENT_ID,
            client_secret=settings.DSLACK_CLIENT_SECRET,
            code=code
        )
        
        # Save the tokens
        integration, created = UserSlackIntegration.objects.update_or_create(
            user=request.user,
            defaults={
                'access_token': response['access_token'],
                'team_id': response['team']['id'],
                'team_name': response['team']['name'],
                'is_active': True
            }
        )
        
        messages.success(request, "Successfully connected to Slack!")
        return redirect('profile')
    except Exception as e:
        return JsonResponse({"error": str(e)}, status=400)
