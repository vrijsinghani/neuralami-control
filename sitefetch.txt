This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repomix on: 2025-01-16T18:51:03.055Z

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Repository structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.

Additional Info:
----------------

For more information about Repomix, visit: https://github.com/yamadashy/repomix

================================================================
Repository Structure
================================================================
src/
  cli.ts
  index.ts
  logger.ts
  to-markdown.ts
  types.ts
  utils.ts
.gitignore
.prettierrc
LICENSE
package.json
README.md
rolldown.config.js
shims.d.ts
tsconfig.json

================================================================
Repository Files
================================================================

================
File: src/cli.ts
================
import path from "node:path"
import fs from "node:fs"
import { cac } from "cac"
import { encode } from "gpt-tokenizer/model/gpt-4o"
import { fetchSite, serializePages } from "./index.ts"
import { logger } from "./logger.ts"
import { ensureArray, formatNumber } from "./utils.ts"
import { version } from "../package.json"

const cli = cac("sitefetch")

cli
  .command("[url]", "Fetch a site")
  .option("-o, --outfile <path>", "Write the fetched site to a text file")
  .option("--concurrency <number>", "Number of concurrent requests", {
    default: 3,
  })
  .option("-m, --match <pattern>", "Only fetch matched pages")
  .option("--content-selector <selector>", "The CSS selector to find content")
  .option("--limit <limit>", "Limit the result to this amount of pages")
  .option("--silent", "Do not print any logs")
  .action(async (url, flags) => {
    if (!url) {
      cli.outputHelp()
      return
    }

    if (flags.silent) {
      logger.setLevel("silent")
    }

    const pages = await fetchSite(url, {
      concurrency: flags.concurrency,
      match: flags.match && ensureArray(flags.match),
      contentSelector: flags.contentSelector,
      limit: flags.limit,
    })

    if (pages.size === 0) {
      logger.warn("No pages found")
      return
    }

    const pagesArr = [...pages.values()]

    const totalTokenCount = pagesArr.reduce(
      (acc, page) => acc + encode(page.content).length,
      0
    )

    logger.info(
      `Total token count for ${pages.size} pages: ${formatNumber(
        totalTokenCount
      )}`
    )

    if (flags.outfile) {
      const output = serializePages(
        pages,
        flags.outfile.endsWith(".json") ? "json" : "text"
      )
      fs.mkdirSync(path.dirname(flags.outfile), { recursive: true })
      fs.writeFileSync(flags.outfile, output, "utf8")
    } else {
      console.log(serializePages(pages, "text"))
    }
  })

cli.version(version)
cli.help()
cli.parse()

================
File: src/index.ts
================
import Queue from "p-queue"
import { Window } from "happy-dom"
import { Readability } from "@mozilla/readability"
import c from "picocolors"
import { toMarkdown } from "./to-markdown.ts"
import { logger } from "./logger.ts"
import { load } from "cheerio"
import { matchPath } from "./utils.ts"
import type { Options, FetchSiteResult } from "./types.ts"

export async function fetchSite(
  url: string,
  options: Options
): Promise<FetchSiteResult> {
  const fetcher = new Fetcher(options)

  return fetcher.fetchSite(url)
}

class Fetcher {
  #pages: FetchSiteResult = new Map()
  #fetched: Set<string> = new Set()
  #queue: Queue

  constructor(public options: Options) {
    const concurrency = options.concurrency || 3
    this.#queue = new Queue({ concurrency })
  }

  #limitReached() {
    return this.options.limit && this.#pages.size >= this.options.limit
  }

  #getContentSelector(pathname: string) {
    if (typeof this.options.contentSelector === "function")
      return this.options.contentSelector({ pathname })

    return this.options.contentSelector
  }

  async fetchSite(url: string) {
    logger.info(
      `Started fetching ${c.green(url)} with a concurrency of ${
        this.#queue.concurrency
      }`
    )

    await this.#fetchPage(url, {
      skipMatch: true,
    })

    await this.#queue.onIdle()

    return this.#pages
  }

  async #fetchPage(
    url: string,
    options: {
      skipMatch?: boolean
    }
  ) {
    const { host, pathname } = new URL(url)

    if (this.#fetched.has(pathname) || this.#limitReached()) {
      return
    }

    this.#fetched.add(pathname)

    // return if not matched
    // we don't need to extract content for this page
    if (
      !options.skipMatch &&
      this.options.match &&
      !matchPath(pathname, this.options.match)
    ) {
      return
    }

    logger.info(`Fetching ${c.green(url)}`)

    const res = await (this.options.fetch || fetch)(url, {
      headers: {
        "user-agent":
          "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36",
      },
    })

    if (!res.ok) {
      logger.warn(`Failed to fetch ${url}: ${res.statusText}`)
      return
    }

    if (this.#limitReached()) {
      return
    }

    const contentType = res.headers.get("content-type")

    if (!contentType?.includes("text/html")) {
      logger.warn(`Not a HTML page: ${url}`)
      return
    }

    const resUrl = new URL(res.url)

    // redirected to other site, ignore
    if (resUrl.host !== host) {
      logger.warn(`Redirected from ${host} to ${resUrl.host}`)
      return
    }
    const extraUrls: string[] = []

    const $ = load(await res.text())
    $("script,style,link,img,video").remove()

    $("a").each((_, el) => {
      const href = $(el).attr("href")

      if (!href) {
        return
      }

      const thisUrl = new URL(href, url)
      if (thisUrl.host !== host) {
        return
      }

      extraUrls.push(thisUrl.href)
    })

    if (extraUrls.length > 0) {
      for (const url of extraUrls) {
        this.#queue.add(() =>
          this.#fetchPage(url, { ...options, skipMatch: false })
        )
      }
    }

    const window = new Window({
      url,
      settings: {
        disableJavaScriptFileLoading: true,
        disableJavaScriptEvaluation: true,
        disableCSSFileLoading: true,
      },
    })

    const pageTitle = $("title").text()
    const contentSelector = this.#getContentSelector(pathname)
    const html = contentSelector
      ? $(contentSelector).prop("outerHTML")
      : $.html()

    if (!html) {
      logger.warn(`No readable content on ${pathname}`)
      return
    }

    window.document.write(html)

    await window.happyDOM.waitUntilComplete()

    const article = new Readability(window.document as any).parse()

    await window.happyDOM.close()

    if (!article) {
      return
    }

    const content = toMarkdown(article.content)

    this.#pages.set(pathname, {
      title: article.title || pageTitle,
      url,
      content,
    })
  }
}

export function serializePages(
  pages: FetchSiteResult,
  format: "json" | "text"
): string {
  if (format === "json") {
    return JSON.stringify([...pages.values()])
  }

  return [...pages.values()]
    .map((page) =>
      `<page>
  <title>${page.title}</title>
  <url>${page.url}</url>
  <content>${page.content}</content>
</page>`.trim()
    )
    .join("\n\n")
}

================
File: src/logger.ts
================
import c from "picocolors"

type LoggerLevel = "silent" | "warn"

class Logger {
  private level?: LoggerLevel

  setLevel(level: LoggerLevel): void {
    this.level = level
  }

  info(...args: any[]): void {
    if (this.level === "silent") return
    console.log(c.cyan("INFO"), ...args)
  }

  warn(...args: any[]): void {
    if (this.level === "silent") return
    console.warn(c.yellow("WARN"), ...args)
  }
}

export const logger: Logger = new Logger()

================
File: src/to-markdown.ts
================
import Turndown from "turndown"
import { gfm } from "turndown-plugin-gfm"

const turndown = new Turndown()
turndown.use(gfm)

export function toMarkdown(html: string): string {
  return turndown.turndown(html)
}

================
File: src/types.ts
================
export type Options = {
  /** How many requests can be made at the same time */
  concurrency?: number

  /**
   * Match pathname by specific patterns, powered by micromatch
   * Only pages matched by this will be fetched
   */
  match?: string[]

  /**
   * The CSS selector to find content
   */
  contentSelector?:
    | string
    | ((ctx: { pathname: string }) => string | void | undefined)

  /**
   * Limit the result to this amount of pages
   */
  limit?: number

  /**
   * A custom function to fetch URL
   */
  fetch?: (url: string, init: RequestInit) => Promise<Response>
}

export type Page = {
  title: string
  url: string
  content: string
}

export type FetchSiteResult = Map<string, Page>

================
File: src/utils.ts
================
import micromatch from "micromatch"

// xK or xM
export function formatNumber(num: number): string {
  return num > 1000000
    ? `${(num / 1000000).toFixed(1)}M`
    : num > 1000
    ? `${(num / 1000).toFixed(1)}K`
    : num.toString()
}

export function matchPath(path: string, pattern: string | string[]): boolean {
  return micromatch.isMatch(path, pattern)
}

export function ensureArray<T>(input: T | T[]): T[] {
  return Array.isArray(input) ? input : [input]
}

================
File: .gitignore
================
node_modules
foo.txt
*.log
.DS_Store
dist/

================
File: .prettierrc
================
{
  "semi": false
}

================
File: LICENSE
================
MIT License

Copyright (c) 2025 EGOIST <hi@egoist.dev>

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.

================
File: package.json
================
{
  "name": "sitefetch",
  "version": "0.0.16",
  "description": "Fetch an entire site and save it as a text file",
  "bin": "./dist/cli.js",
  "main": "./dist/index.js",
  "types": "./dist/index.d.ts",
  "files": [
    "dist"
  ],
  "type": "module",
  "scripts": {
    "test": "echo \"Error: no test specified\" && exit 1",
    "build": "rm -rf dist && rolldown -c",
    "prepublishOnly": "bun run build"
  },
  "keywords": [],
  "author": "EGOIST <hi@egoist.dev>",
  "license": "MIT",
  "dependencies": {
    "happy-dom": "^16.5.3",
    "cheerio": "^1.0.0",
    "gpt-tokenizer": "^2.8.1",
    "turndown": "^7.2.0",
    "turndown-plugin-gfm": "^1.0.2",
    "micromatch": "^4.0.8"
  },
  "devDependencies": {
    "@mozilla/readability": "^0.5.0",
    "@types/bun": "^1.1.15",
    "@types/micromatch": "^4.0.9",
    "@types/turndown": "^5.0.5",
    "cac": "^6.7.14",
    "p-queue": "^8.0.1",
    "picocolors": "^1.1.1",
    "rolldown": "^1.0.0-beta.1",
    "typescript": "^5.7.3",
    "unplugin-isolated-decl": "^0.10.4"
  }
}

================
File: README.md
================
# sitefetch

Fetch an entire site and save it as a text file (to be used with AI models).

![image](https://github.com/user-attachments/assets/e6877428-0e1c-444a-b7af-2fb21ded8814)

## Install

One-off usage (choose one of the followings):

```bash
bunx sitefetch
npx sitefetch
pnpx sitefetch
```

Install globally (choose one of the followings):

```bash
bun i -g sitefetch
npm i -g sitefetch
pnpm i -g sitefetch
```

## Usage

```bash
sitefetch https://egoist.dev -o site.txt

# or better concurrency
sitefetch https://egoist.dev -o site.txt --concurrency 10
```

### Match specific pages

Use the `-m, --match` flag to specify the pages you want to fetch:

```bash
sitefetch https://vite.dev -m "/blog/**" -m "/guide/**"
```

The match pattern is tested against the pathname of target pages, powered by micromatch, you can check out all the supported [matching features](https://github.com/micromatch/micromatch#matching-features).

### Content selector

We use [mozilla/readability](https://github.com/mozilla/readability) to extract readable content from the web page, but on some pages it might return irrelevant contents, in this case you can specify a CSS selector so we know where to find the readable content:

```sitefetch
sitefetch https://vite.dev --content-selector ".content"
```

## Plug

If you like this, please check out my LLM chat app: https://chatwise.app

## API

```ts
import { fetchSite } from "sitefetch"

await fetchSite("https://egoist.dev", {
  //...options
})
```

Check out options in [types.ts](./src/types.ts).

## License

MIT.

================
File: rolldown.config.js
================
// @ts-check
import fs from "node:fs"
import { defineConfig } from "rolldown"
import { isBuiltin } from "node:module"
import UnpluginIsolatedDecl from "unplugin-isolated-decl/rolldown"

const pkg = JSON.parse(fs.readFileSync("./package.json", "utf8"))

export default defineConfig({
  input: ["src/cli.ts", "src/index.ts"],
  output: {
    dir: "dist",
    format: "esm",
    banner(chunk) {
      if (chunk.fileName === "cli.js") {
        return `#!/usr/bin/env node`
      }
      return ""
    },
  },
  platform: "node",
  external: Object.keys(pkg.dependencies)
    .map((name) => [name, new RegExp(`^${name}/`)])
    .flat(),
  plugins: [
    process.env.NO_DTS
      ? undefined
      : UnpluginIsolatedDecl({ transformer: "typescript" }),
    {
      // make sure every node builtin module is prefixed with node:
      name: "add-node-prefix",
      renderChunk(code) {
        return code.replace(/import (.+) from "(.+)"/g, (m, m1, m2) => {
          if (isBuiltin(m2) && !m2.startsWith("node:")) {
            return `import ${m1} from "node:${m2}"`
          }
          return m
        })
      },
      resolveId(id) {
        if (isBuiltin(id) && !id.startsWith("node:")) {
          return {
            id: `node:${id}`,
            external: true,
          }
        }
      },
    },
  ],
})

================
File: shims.d.ts
================
declare module "turndown-plugin-gfm"

================
File: tsconfig.json
================
{
    "compilerOptions": {
      // Enable latest features
      "lib": ["ESNext"],
      "target": "ESNext",
      "module": "ESNext",
      "moduleDetection": "force",
      "jsx": "react-jsx",
      "isolatedDeclarations": true,
      "declaration": true,
  
      // Bundler mode
      "moduleResolution": "bundler",
      "allowImportingTsExtensions": true,
      "verbatimModuleSyntax": true,
      "noEmit": true,
  
      // Best practices
      "strict": true,
      "skipLibCheck": true,
      "noFallthroughCasesInSwitch": true,
  
      // Some stricter flags
      "noUnusedLocals": true,
      "noUnusedParameters": true,
      "noPropertyAccessFromIndexSignature": true
    }
  }
